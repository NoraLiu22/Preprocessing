koqcbsdmooxmlshoholsigzowccggscazaqgxeom length 6 537003 page 537003 <!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@verge"/><meta property="fb:app_id" content="549923288395304"/><meta property="og:site_name" content="The Verge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="apple-mobile-web-app-title" content="Verge"/><meta name="google-site-verification" content="IucFf_TKtbFFH8_YeFyEteQIwYPdANM1R46_U9DpAr4"/><link rel="alternate" type="application/rss+xml" title="The Verge" href="/rss/index.xml"/><title>Google DeepMind CEO Demis Hassabis on ChatGPT, AI, LLMs, and more - The Verge</title><meta name="robots" content="index,follow,max-image-preview:large"/><meta name="description" content="Demis Hassabis talks about the future of AI, why the merger between DeepMind and Google Brain will advance tech research, and why AlphaFold was a scientific breakthrough."/><meta property="og:title" content="ChatGPT gets the headlines, but scientific research like AlphaFold is also the future of AI, says Google DeepMind CEO Demis Hassabis"/><meta property="og:description" content="The buzz around AI has moved from science research to chatbots, but Google DeepMind’s CEO says it’s all relevant to progress."/><meta property="og:url" content="https://www.theverge.com/23778745/demis-hassabis-google-deepmind-ai-alphafold-risks"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2023-07-10T19:42:50.519Z"/><meta property="article:modified_time" content="2023-07-10T19:42:50.519Z"/><meta property="og:image" content="https://cdn.vox-cdn.com/thumbor/YplCPWLGEe8tmfSGj2nBwBlGZBs=/0x0:3000x2000/1200x628/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg"/><meta property="og:image:alt" content="Demis Hassabis smiles at the camera"/><meta property="og:image:type" content="image/jpeg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="628"/><link rel="canonical" href="https://www.theverge.com/23778745/demis-hassabis-google-deepmind-ai-alphafold-risks"/><meta property="author" content="Nilay Patel"/><script type="application/ld+json">{"@context":"http://schema.org/","@type":"NewsArticle","headline":"Google DeepMind CEO Demis Hassabis on ChatGPT, AI, LLMs, and more","description":"Demis Hassabis talks about the future of AI, why the merger between DeepMind and Google Brain will advance tech research, and why AlphaFold was a scientific breakthrough.","datePublished":"2023-07-10T19:42:50.519Z","dateModified":"2023-07-10T19:42:50.519Z","thumbnailUrl":"https://cdn.vox-cdn.com/thumbor/iLAMKg1KOgXmjUV1SPpix14HB4o=/0x0:3000x2000/1400x788/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg","author":[{"@type":"Person","name":"Nilay Patel","url":"https://www.theverge.com/authors/nilay-patel"}],"publisher":{"@type":"Organization","name":"The Verge","logo":{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png","width":250,"height":50}},"image":[{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/iLAMKg1KOgXmjUV1SPpix14HB4o=/0x0:3000x2000/1400x788/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg","width":1400,"height":788},{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/7_Dhv03l6b1HpaHIKhJvL65hcW8=/0x0:3000x2000/1400x1050/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg","width":1400,"height":1050},{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/oaA61v3nf8X7NZfPcIsPW9DlCPo=/0x0:3000x2000/1400x1400/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg","width":1400,"height":1400}],"url":"https://www.theverge.com/23778745/demis-hassabis-google-deepmind-ai-alphafold-risks","articleBody":"Today, I’m talking to Demis Hassabis, the CEO of Google DeepMind, the newly created division of Google responsible for AI efforts across the company. Google DeepMind is the result of an internal merger: Google acquired Demis’ DeepMind startup in 2014 and ran it as a separate company inside its parent company, Alphabet, while Google itself had an AI team called Google Brain. \n\nGoogle has been showing off AI demos for years now, but with the explosion of ChatGPT and a renewed threat from Microsoft in search, Google and Alphabet CEO Sundar Pichai made the decision to bring DeepMind into Google itself earlier this year to create… Google DeepMind.\n\nWhat’s interesting is that Google Brain and DeepMind were not necessarily compatible or even focused on the same things: DeepMind was famous for applying AI to things like games and protein-folding simulations. The AI that beat world champions at Go, the ancient board game? That was DeepMind’s AlphaGo. Meanwhile, Google Brain was more focused on what’s come to be the familiar generative AI toolset: large language models for chatbots, editing features in Google Photos, and so on. This was a culture clash and a big structure decision with the goal of being more competitive and faster to market with AI products.\n\nAnd the competition isn’t just OpenAI and Microsoft — you might have seen a memo from a Google engineer floating around the web recently claiming that Google has no competitive moat in AI because open-source models running on commodity hardware are rapidly evolving and catching up to the tools run by the giants. Demis confirmed that the memo was real but said it was part of Google’s debate culture, and he disagreed with it because he has other ideas about where Google’s competitive edge might come into play.\n\nOf course, we also talked about AI risk and especially artificial general intelligence. Demis is not shy that his goal is building an AGI, and we talked through what risks and regulations should be in place and on what timeline. Demis recently signed onto a 22-word statement about AI risk with OpenAI’s Sam Altman and others that simply reads, “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.” That’s pretty chill, but is that the real risk right now? Or is it just a distraction from other more tangible problems like AI replacing a bunch of labor in various creative industries? We also talked about the new kinds of labor AI is creating — armies of low-paid taskers classifying data in countries like Kenya and India in order to train AI systems. We just published a big feature on these taskers. I wanted to know if Demis thought these jobs were here to stay or just a temporary side effect of the AI boom.\n\nThis one really hits all the Decoder high points: there’s the big idea of AI, a lot of problems that come with it, an infinite array of complicated decisions to be made, and of course, a gigantic org chart decision in the middle of it all. Demis and I got pretty in the weeds, and I still don’t think we covered it all, so we’ll have to have him back soon.\n\nAlright, Demis Hassabis, CEO of Google DeepMind. Here we go.\n\nThis transcript has been lightly edited for length and clarity\n\nDemis Hassabis, you are the CEO of Google DeepMind. Welcome to Decoder.\n\nThanks for having me.\n\nI don’t think we have ever had a more perfect Decoder guest. There’s a big idea in AI. It comes with challenges and problems, and then, with you in particular, there’s a gigantic org chart move and a set of high-stakes decisions to be made. I am thrilled that you are here.\n\nGlad to be here.\n\nLet’s start with Google DeepMind itself. Google DeepMind is a new part of Google that is constructed of two existing parts of Google. There was Google Brain, which was the AI team we were familiar with as we covered Google that was run by Jeff Dean. And there was DeepMind, which was your company that you founded. You sold it to Alphabet in 2014. You were outside of Google. It was run as a separate company inside that holding company Alphabet structure until just now. Start at the very beginning. Why were DeepMind and Google Brain separate to begin with?\n\nAs you mentioned, we started DeepMind actually back in 2010, a long time ago now, especially in the age of AI. So that’s sort of like prehistory. Myself and the co-founders, we realized coming from academia and seeing what was going on there, things like deep learning had just been invented. We were big proponents of reinforcement learning. We could see GPUs and other hardware was coming online, that a lot of great progress could be made with a focused effort on general learning systems and also taking some ideas from neuroscience and how the brain works. So we put all those ingredients together back in 2010. We had this thesis we’d make fast progress, and that’s what happened with our initial game systems. And then, we decided in 2014 to join forces with Google at the time because we could see that a lot more compute was going to be needed. Obviously, Google has the most computers and had the most computers in the world. That was the obvious home for us to be able to focus on pushing the research as fast as possible. \n\nSo you were acquired by Google, and then somewhere along the way, Google reoriented itself. They turned into Alphabet, and Google became a division of Alphabet. There are other divisions of Alphabet, and DeepMind was out of it. That’s just the part I want to focus on here at the beginning, because there was what Google was doing with Google Brain, which is a lot of LLM research. I recall, six years ago, Google was showing off LLMs at Google I/O, but DeepMind was focused on winning the game [Go] and protein folding, a very different kind of AI research wholly outside of Google. Why was that outside of Google? Why was that in Alphabet proper?\n\n---\n\n[Image: https://cdn.vox-cdn.com/thumbor/ROZOugNkLXkQJVP30tl2R8ozzbc=/0x0:3000x3000/3000x3000/filters:focal(1500x1500:1501x1501)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg]\n\nListen to Decoder, a show hosted by The Verge’s Nilay Patel about big ideas — and other problems. Subscribe here!\n---\n\nThat was part of the agreement as we were acquired was that we would pursue pushing forward research into general AI, or sometimes called AGI, a system that out of the box can operate across a wide range of cognitive tasks and basically has all the cognitive capabilities that humans have.\n\nAnd also using AI to accelerate scientific discovery, that’s one of my personal passions. And that explains projects like AlphaFold that I’m sure we’re going to get back to. But also, from the start of DeepMind and actually prior to even DeepMind starting, I believe that games was a perfect testing or proving ground for developing AI algorithms efficiently, quickly, and you can generate a lot of data and the objective functions are very clear: obviously, winning games or maximizing the score. There were a lot of reasons to use games in the early days of AI research, and that was a big part of why we were so successful and why we were able to advance so quickly with things like AlphaGo, the program that beat the world champion at the ancient game of Go.\n\nThose were all really important proof points for the whole field really that these general learning techniques would work. And of course we’ve done a lot of work on deep learning and neural networks as well. And our specialty, I suppose, was combining that with reinforcement learning to allow these systems to actively solve problems and make plans and do things like win games. And in terms of the differences, we always had that remit to push the research agenda and push things, advanced science. And that was very much the focus we were given and very much the focus that I wanted to have. And then, the internal Google AI teams like Google Brain, they had slightly different remits and were a bit closer to product and obviously to the rest of Google and infusing Google with amazing AI technology. And we also had an applied division that was introducing DeepMind technology into Google products, too. But the cultures were quite different, and the remits were quite different.\n\nFrom the outside, the timeline looks like this: everyone’s been working on this for ages, we’ve all been talking about it for ages. It is a topic of conversation for a bunch of nerdy journalists like me, a bunch of researchers, we talk about it in the corner at Google events. \n\nThen ChatGPT is released, not even as a product. I don’t even think Sam [Altman] would call it a great product when it was released, but it was just released, and people could use it. And everyone freaked out, and Microsoft releases Bing based on ChatGPT, and the world goes upside down, and Google reacts by merging DeepMind and Google Brain. That’s what it looks like from the outside. Is that what it felt like from the inside?\n\nThat timeline is correct, but it’s not these direct consequences; it’s more indirect in a sense. So, Google and Alphabet have always run like this. They let many flowers bloom, and I think that’s always been the way that even from Larry [Page] and Sergey [Brin] from the beginning set up Google. And it served them very well, and it’s allowed them to organically create incredible things and become the amazing company that it is today. On the research side, I think it’s very compatible with doing research, which is another reason we chose Google as our partners back in 2014. I felt they really understood what fundamental and blue sky research was, ambitious research was, and they were going to facilitate us being and enable us to be super ambitious with our research. And you’ve seen the results of that, right?\n\n\"“...AI has entered a new era.”\"\n\nBy any measure, AlphaGo, AlphaFold, but more than 20 nature and science papers and so on — all the normal metrics one would use for really delivering amazing cutting-edge research we were able to do. But in a way, what ChatGPT and the large models and the public reaction to that confirmed is that AI has entered a new era. And by the way, it was a little bit surprising for all of us at the coalface, including OpenAI, how viral that went because — us and some other startups like Anthropic and OpenAI — we all had these large language models. They were roughly the same capabilities. \n\nAnd so, it was surprising, not so much what the technology was because we all understood that, but the public’s appetite for that and obviously the buzz that generated. And I think that’s indicative of something we’ve all been feeling for the last, I would say, two, three years, which is these systems are reaching a level of maturity now and sophistication where it can really come out of the research phase and the lab and go into powering incredible next-generation products and experiences and also breakthroughs, things like AlphaFold directly being useful for biologists. And so, to me, this is just indicative of a new phase that AI is in of being practically useful to people in their everyday lives and actually being able to solve really hard real-world problems that really matter, not just the curiosities or fun, like games.\n\nWhen you recognize that shift, then I think that necessitates a change in your approach as to how you’re approaching the research and how much focus you’re having on products and those kinds of things. And I think that’s what we all came to the realization of, which was: now was the time to streamline our AI efforts and focus them more. And the obvious conclusion of that was to do the merger.\n\nI want to just stop there for one second and ask a philosophical question.\n\nSure.\n\nIt feels like the ChatGPT moment that led to this AI explosion this year was really rooted in the AI being able to do something that regular people could do. I want you to write me an email, I want you to write me a screenplay, and maybe the output of the LLM is a C+, but it’s still something I can do. People can see it. I want you to fill out the rest of this photo. That’s something people can imagine doing. Maybe they don’t have the skills to do it, but they can imagine doing it. All the previous AI demos that we have gotten, even yours, AlphaFold, you’re like, this is going to model all the proteins in the world.\n\nBut I can’t do that; a computer should do that. Even a microbiologist might think, “That is great. I’m very excited that a computer can do that because I’m just looking at how much time it would take us, and there’s no way we could ever do it.” “I want to beat the world champion at Go. I can’t do that. It’s like, fine. A computer can do that.” \n\nThere’s this turn where the computer is starting to do things I can do, and they’re not even necessarily the most complicated tasks. Read this webpage and deliver a summary of it to me. But that’s the thing that unlocked everyone’s brain. And I’m wondering why you think the industry didn’t see that turn coming because we’ve been very focused on these very difficult things that people couldn’t do, and it seems like what got everyone is when the computer started doing things people do all the time.\n\nI think that analysis is correct. I think that is why the large language models have really entered the public consciousness because it’s something the average person, that the “Joe Public,” can actually understand and interact with. And, of course, language is core to human intelligence and our everyday lives. I think that does explain why chatbots specifically have gone viral in the way they have. Even though I would say things like AlphaFold, I mean of course I’d be biased in saying this, but I think it’s actually had the most unequivocally biggest beneficial effects so far in AI on the world because if you talk to any biologist or there’s a million biologists now, researchers and medical researchers, have used AlphaFold. I think that’s nearly every biologist in the world. Every Big Pharma company is using it to advance their drug discovery programs. I’ve had multiple, dozens, of Nobel Prize-winner-level biologists and chemists talk to me about how they’re using AlphaFold.\n\nSo a certain set of all the world’s scientists, let’s say, they all know AlphaFold, and it’s affected and massively accelerated their important research work. But of course, the average person in the street doesn’t know what proteins are even and doesn’t know what the importance of those things are for things like drug discovery. Whereas obviously, for a chatbot, everyone can understand, this is incredible. And it’s very visceral to get it to write you a poem or something that everybody can understand and process and measure compared to what they do or are able to do. \n\nIt seems like that is the focus of productized AI: these chatbot-like interfaces or these generative products that are going to make stuff for people, and that’s where the risk has been focused. But even the conversation about risk has escalated because people can now see, “Oh, these tools can do stuff.” Did you perceive the same level of scrutiny when you were working on AlphaFold? It doesn’t seem like anyone thought, “Oh, AlphaFold’s going to destroy humanity.”\n\nNo, but there was a lot of scrutiny, but again, it was in a very specialized area, right? With renowned experts, and actually, we did talk to over 30 experts in the field, from top biologists to bioethicists to biosecurity people, and actually our partners — we partnered with the European Bioinformatics Institute to release the AlphaFold database of all the protein structures, and they guided us as well on how this could be safely put out there. So there was a lot of scrutiny, and the overwhelming conclusion from the people we consulted was that the benefits far outweighed any risks. Although we did make some small adjustments based on their feedback about which structures to release. But there was a lot of scrutiny, but again, it’s just in a very expert domain. And just going back to your first question about the generative models, I do think we are right at the beginning of an incredible new era that’s going to play out over the next five, 10 years.\n\nNot only in advancing science with AI but in terms of the types of products we can build to improve people’s everyday lives, billions of people in their everyday lives, and help them to be more efficient and to enrich their lives. And I think what we’re seeing today with these chatbots is literally just scratching the surface. There are a lot more types of AI than generative AI.  Generative AI is now the “in” thing, but I think that planning and deep reinforcement learning and problem-solving and reasoning, those kinds of capabilities are going to come back in the next wave after this, along with the current capabilities of the current systems. So I think, in a year or two’s time, if we were to talk again, we are going to be talking about entirely new types of products and experiences and services with never-seen-before capabilities. And I’m very excited about building those things, actually. And that’s one of the reasons I’m very excited about leading Google DeepMind now in this new era and focusing on building these AI-powered next-generation products.\n\nLet’s stay in the weeds of Google DeepMind itself, for one more turn. Sundar Pichai comes to you and says, “All right, I’m the CEO of Alphabet and the CEO of Google. I can just make this call. I’m going to bring DeepMind into Google, merge you with Google Brain, you’re going to be the CEO.” How did you react to that prompt?\n\nIt wasn’t like that. It was much more of a conversation between the leaders of the various different relevant groups and Sundar about pretty much the inflection point that we’re seeing, the maturity of the systems, what could be possible with those in the product space, and how to improve experiences for our users, our billions of users, and how exciting that might be, and what that all requires in totality. Both the change in focus, a change in the approach to research, the combination of resources that are required, like compute resources. So there was a big collection of factors to take into account that we all discussed as a leadership group, and then, conclusions from that then result in actions, including the merger and also what the plans are then for the next couple of years and what the focus should be of that merged unit.\n\nDo you perceive a difference being a CEO inside of Google versus being a CEO inside of Alphabet?\n\nIt’s still early days, but I think it’s been pretty similar because, although DeepMind was an Alphabet company, it was very unusual for another bet, as they call it an “alpha bet,” which is that we already were very closely integrated and collaborating with many of the Google product area teams and groups. We had an applied team at DeepMind whose job it was to translate our research work into features in products by collaborating with the Google product teams. And so, we’ve had hundreds of successful launches already actually over the last few years, just quiet ones behind the scenes. So, in fact, many of the services or devices or systems that you use every day at Google will have some DeepMind technology under the hood as a component. So we already had that integrative structure, and then, of course, what we were famous for was doing the scientific advances and gaming advances, but behind the scenes, there was a lot of bread and butter work going on that was affecting all parts of Google.\n\nWe were different from other bets where they have to make a business outside of Google and become an independent business. That was never the goal or the remit for us, even as an independent bet company. And now, within Google, we’re just more tightly integrated in terms of the product services, and I see that as an advantage because we can actually go deeper and do more exciting and ambitious things in much closer collaboration with these other product teams than we could from outside of Google. But we still retain some latitude to pick the processes and the systems that optimize our mission of producing the most capable and general AI systems in the world.\n\nThere’s been reporting that this is actually a culture clash. You’re now in charge of both. How have you structured the group? How has Google DeepMind structured under you as CEO, and how are you managing that culture integration?\n\nActually, it turns out that the culture’s a lot more similar than perhaps has been reported externally. And in the end, it’s actually been surprisingly smooth and pleasant because you’re talking about two world-class research groups, two of the best AI research organizations in the world, incredible talent on both sides, storied histories. As we were thinking about the merger and planning it, we were looking at some document where we listed the top 10 breakthroughs from each group. And when you take that in totality, it’s like 80–90 percent of over the last decade, of the breakthroughs that underpin the modern AI industry, from deep reinforcement learning to transformers, of course. It’s an incredible set of people and talent, and there’s massive respect for both groups on both sides. And there was actually a lot of collaboration on a project-based level ongoing over the last decade.\n\nOf course, we all know each other very well. I just think it’s a question of focus and a bit of coordination across both groups, actually, and more in terms of what are we going to focus on, other places that it makes sense for the two separate teams to collaborate on, and maybe de-duplicate some efforts that basically are overlapping. So fairly obvious stuff, to be honest, but it’s important moving into this new phase now of where we are into more of an engineering phase of AI, and that requires huge resources, both compute, engineering, and other things. And, even as a company the size of Google, we’ve got to pick our bets carefully and be clear about which arrows we are going to put our wood behind and then focus on those and then massively deliver on those things. So I think it’s part of the natural course of evolution as to where we are in the AI journey.\n\nThat thing you talked about, “We’re going to combine these groups, we’re going to pick what we’re doing, we’re going to de-duplicate some efforts.” Those are structure questions. Have you decided on a structure yet, and what do you think that structure will be?\n\nThe structure’s still evolving. We’re only a couple of months into it. We wanted to make sure we didn’t break anything, that it was working. Both teams are incredibly productive, doing super amazing research, but also plugging in to very important product things that are going on. All of that needs to continue.\n\nYou keep saying both teams. Do you think of it as two teams, or are you trying to make one team?\n\nNo, no, for sure it’s one unified team. I like to call it a “super unit,” and I’m very excited about that. But obviously, we’re still combining that and forming the new culture and forming the new grouping, including the organizational structures. It’s a complex thing — putting two big research groups together like this. But I think, by the end of the summer, we’ll be a single unified entity, and I think that’ll be very exciting. And we’re already feeling, even a couple of months in, the benefits and the strengths of that with projects like Gemini that you may have heard of, which is our next-generation multimodal large models — very, very exciting work going on there, combining all the best ideas from across both world-class research groups. It’s pretty impressive to see.\n\nYou have a lot of decisions to make. What you’re describing is a bunch of complicated decisions and then, out in the world, how should we regulate this? Another set of very complicated decisions. You are a chess champion, you are a person who has made games. What is your framework for making decisions? I suspect it is much more rigorous than the other ones I hear about.\n\n\"“Chess is basically decision-making under pressure with an opponent.”\"\n\nYes, I think it probably is. And I think if you play a game like chess that seriously — effectively professionally — since all my childhood, since the age of four, I think it’s very formative for your brain. So I think, in chess, the problem-solving and strategizing, I find it a very useful framework for many things and decision-making. Chess is basically decision-making under pressure with an opponent, and it’s very complex, and I think it’s a great thing. I advocate it being taught at school, part of the school curriculum, because I think it’s a really fantastic training ground for problem-solving and decision-making. But then, I think actually the overarching approach is more of the scientific method.\n\nSo I think all my training is doing my PhDs and postdocs and so on, obviously I did it in neuroscience, so I was learning about the brain, but it also taught me how to do rigorous hypothesis testing and hypothesis generation and then update based on empirical evidence. The whole scientific method as well as the chess planning, both can be translated into the business domain. You have to be smart about how to translate that, you can’t be academic about these things. And often, in the real world, in business, there’s a lot of uncertainty and hidden information that you don’t know. So, in chess, obviously all the information’s there for you on the board. You can’t just directly translate those skills, but I think, in the background, they can be very helpful if applied in the right way.\n\nHow do you combine those two in some decisions you’ve made?\n\nThere are so many decisions I make every day,it’s hard to come up with one now. But I tend to try and plan out and scenario a plan many, many years in advance. So I tell you the way I try to approach things is, I have an end goal. I’m quite good at imagining things, so that’s a different skill, visualizing or imagining what would a perfect end state look like, whether that’s organizational or it’s product-based or it’s research-based. And then, I work back from the end point and then figure out what all the steps would be required and in what order to make that outcome as likely as possible.\n\nSo that’s a little bit chess-like, right? In the sense of you have some plan that you would like to get to checkmate your opponent, but you’re many moves away from that. So what are the incremental things one must do to improve your position in order to increase the likelihood of that final outcome? And I found that extremely useful to do that search process from the end goal back to the current state that you find yourself in.\n\nLet’s put that next to some products. You said there’s a lot of DeepMind technology and a lot of Google products. The ones that we can all look at are Bard and then your Search Generative Experience. There’s AI in Google Photos and all this stuff, but focused on the LLM moment, it’s Bard and the Search Generative Experience. Those can’t be the end state. They’re not finished. Gemini is coming, and we’ll probably improve both of those, and all that will happen. When you think about the end state of those products, what do you see?\n\nThe AI systems around Google are also not just in the consumer-facing things but also under the hood that you may not realize. So even, for example, one of the things we applied our AI systems to very initially was the cooling systems in Google’s data centers, enormous data centers, and actually reducing the energy they use by nearly 30 percent that the cooling systems use, which is obviously huge if you multiply that by all of the data centers and computers they have there. So there are actually a lot of things under the hood where AI is being used to improve the efficiency of those systems all the time. But you’re right, the current products are not the end state; they’re actually just waypoints. And in the case of chatbots and those kinds of systems, ultimately, they will become these incredible universal personal assistants that you use multiple times during the day for really useful and helpful things across your daily lives.\n\n\"“...today’s chatbots will look trivial by comparison to I think what’s coming in the next few years.”\"\n\nFrom what books to read to recommendations on maybe live events and things like that to booking your travel to planning trips for you to assisting you in your everyday work. And I think we’re still far away from that with the current chatbots, and I think we know what’s missing: things like planning and reasoning and memory, and we are working really hard on those things. And I think what you’ll see in maybe a couple of years’ time is today’s chatbots will look trivial by comparison to I think what’s coming in the next few years.\n\nMy background is as a person who’s reported on computers. I think of computers as somewhat modular systems. You look at a phone — it’s got a screen, it’s got a chip, it’s got a cell antenna, whatever. Should I look at AI systems that way — there’s an LLM, which is a very convincing human language interface, and behind it might be AlphaFold that’s actually doing the protein folding? Is that how you’re thinking about stitching these things together, or is it a different evolutionary pathway?\n\nActually, there’s a whole branch of research going into what’s called tool use. This is the idea that these large language models or large multimodal models, they’re expert at language, of course, and maybe a few other capabilities, like math and possibly coding. But when you ask them to do something specialized, like fold a protein or play a game of chess or something like this, then actually what they end up doing is calling a tool, which could be another AI system, that then provides the solution or the answer to that particular problem. And then that’s transmitted back to the user via language or pictorially through the central large language model system. So it may be actually invisible to the user because, to the user, it just looks like one big AI system that has many capabilities, but under the hood, it could be that actually the AI system is broken down into smaller ones that have specializations.\n\nAnd I actually think that probably is going to be the next era. The next generation of systems will use those kinds of capabilities. And then you can think of the central system as almost a switch statement that you effectively prompt with language, and it roots your query or your question or whatever it is you’re asking it to the right tool to solve that question for you or provide the solution for you. And then transmit that back in a very understandable way. Again, using through the interface, the best interface really, of natural language.\n\nDoes that process get you closer to an AGI, or does that get you to some maximum state and you got to do something else?\n\nI think that is on the critical path to AGI, and that’s another reason, by the way, I’m very excited about this new role and actually doing more products and things because I actually think the product roadmap from here and the research roadmap from here toward something like AGI or human-level AI is very complementary. The kinds of capabilities one would need to push in order to build those kinds of products that are useful in your everyday life like a universal assistant requires pushing on some of these capabilities, like planning and memory and reasoning, that I think are vital for us to get to AGI. So I actually think there’s a really neat feedback loop now between products and research where they can effectively help each other.\n\nI feel like I had a lot of car CEOs on the show at the beginning of it. I asked all of them, “When do you think we’re going to get self-driving cars?” And they all said five years, and they’ve been saying five years for five years, right?\n\nYes.\n\nI’m going to ask you a version of that question about AGI, but I feel like the number has gotten smaller recently with people I’ve talked to. How many years until you think we have AGI?\n\nI think there’s a lot of uncertainty over how many more breakthroughs are required to get to AGI, big, big breakthroughs — innovative breakthroughs — versus just scaling up existing solutions. And I think it very much depends on that in terms of timeframe. Obviously, if there are a lot of breakthroughs still required, those are a lot harder to do and take a lot longer. But right now, I would not be surprised if we approached something like AGI or AGI-like in the next decade.\n\nIn the next decade. All right, I’m going to come back to you in 10 years. We’re going to see if that happens.\n\nSure.\n\nThat’s not a straight line, though. You called it the critical path, that’s not a straight line. There are breakthroughs along the way that might upset the train and send you along a different path, you think.\n\n\"“...research is never a straight line. If it is, then it’s not real research.”\"\n\nResearch is never a straight line. If it is, then it’s not real research. If you knew the answer before you started it, then that’s not research. So research and blue sky research at the frontier always has uncertainty around it, and that’s why you can’t really predict timelines with any certainty. But what you can look at is trends, and we can look at the quality of ideas and projects that are being worked on today, look at how they’re progressing. And I think that could go either way over the next five to 10 years where we might asymptote, we might hit a brick wall with current techniques and scaling. I wouldn’t be surprised if that happened, either: that we may find that just scaling the existing systems resulted in diminishing returns in terms of the performance of the system.\n\nAnd actually, that would then signal some new innovations were really required to make further progress. At the moment, I think nobody knows which regime we’re in. So the answer to that is you have to push on both as hard as possible. So both the scaling and the engineering of existing systems and existing ideas as well as investing heavily into exploratory research directions that you think might deliver innovations that might solve some of the weaknesses in the current systems. And that’s one advantage of being a large research organization with a lot of resources is we can bet on both of those things maximally, both of those directions. In a way, I’m agnostic to that question of “do we need more breakthroughs or will existing systems just scale all the way?” My view is it’s an empirical question, and one should push both as hard as possible. And then the results will speak for themselves.\n\nThis is a real tension. When you were at DeepMind in Alphabet and you were very research-focused, and then the research was moved back into Google and Google’s engineers would turn it into products. And you can see how that relationship worked. Now, you’re inside of Google. Google is under a lot of pressure as a company to win this battle. And those are product concerns. Those are “Make it real for people and go win in the market.” There’s a leaked memo that went around. It was purportedly from inside Google. It said the company had no moat and open-source AI models or leaked models would run on people’s laptops, and they would outpace the company because the history of open computing would outpace a closed-source competitor. Was that memo real?\n\n\"“I think that memo was real.”\"\n\nI think that memo was real. I think engineers at Google often write various documents, and sometimes they get leaked and go viral. I think that’s just a thing that happens, but I wouldn’t take it too seriously. These are just opinions. I think it’s interesting to listen to them, and then you’ve got to chart your own course. And I haven’t read that specific memo in detail, but I disagree with the conclusions from that. And I think there’s obviously open source and publishing, and we’ve done tons of that in the history of DeepMind. I mean, AlphaFold was open sourced, right? So we obviously believe in open source and supporting research and open research. That’s a key thing of the scientific discourse, which we’ve been a huge part of. And so is Google, of course, publishing transformers and other things. And TensorFlow and you look at all the things we’ve done.\n\nWe do a huge amount in that space. But I also think there are other considerations that need to be had as well. Obviously commercial ones but also safety questions about access to these very powerful systems. What if bad actors can access it? Who maybe aren’t that technical, so they couldn’t have built it themselves, but they can certainly reconfigure a system that is out there? What do you do about those things? And I think that’s been quite theoretical till now, but I think that that is really important from here all the way to AGI as these systems become more general, more sophisticated, more powerful. That question is going to be very important about how does one stop bad actors just using these systems for things they weren’t intended for but for malicious purposes.\n\nThat’s something we need to increasingly come up with, but just back to your question, look at the history of what Google and DeepMind have done in terms of coming up with new innovations and breakthroughs and multiple, multiple breakthroughs over the last decade or more. And I would bet on us, and I’m certainly very confident that that will continue and actually be even more true over the next decade in terms of us producing the next key breakthroughs just like we did in the past.\n\nDo you think that’s the moat: we invented most of this stuff, so we’re going to invent most of the next stuff?\n\nI don’t really think about it as moats, but I’m an incredibly competitive person. That’s maybe another thing I got from chess, and many researchers are. Of course, they’re doing it to discover knowledge, and ultimately, that’s what we are here for is to improve the human condition. But also, we want to be first to do these things and do them responsibly and boldly. We have some of the world’s best researchers. I think we have the biggest collection of great researchers in the world, anywhere in the world, and an incredible track record. And there’s no reason why that shouldn’t continue in the future. And in fact, I think with our new organization and environment might be conducive to even more and faster-paced breakthroughs than we’ve done in the past.\n\nYou’re leading me toward risk and regulation. I want to talk about that, but I want to start in with just a different spin on it. You’re talking about all the work that has to be done. You’re talking about deep mind reinforcement learning, how that works. We ran a gigantic cover story in collaboration with New York Magazine about the taskers who are actually doing the training, who are actually labeling the data. There’s a lot of labor conversation with AI along the way. Hollywood writers are on strike right now because they don’t want ChatGPT to write a bunch of scripts. I think that’s appropriate.\n\nBut then there’s a new class of labor that’s being developed where a bunch of people around the world are sitting in front of computers and saying, “Yep, that’s a stop sign. No, that’s not a stop sign. Yep, that’s clothes you can wear. No, that’s not clothes you can wear.” Is that a forever state? Is that just a new class of work that needs to be done for these systems to operate? Or does that come to an end?\n\nI think it’s hard to say. I think it’s definitely a moment in time and the current systems and what they’re requiring at the moment. We’ve been very careful just to say, from our part, and I think you quoted some of our researchers in that article, to be very careful to pay living wages and be very responsible about how we do that kind of work and which partners we use. And we also use internal teams as well. So actually, I’m very proud of how responsible we’ve been on that type of work. But going forward, I think there may be ways that these systems, especially once you have millions and millions of users, effectively can bootstrap themselves. Or one could imagine AI systems that are capable of actually conversing with themselves or critiquing themselves.\n\nThis would be a bit like turning language systems into a game-like setting, which of course we’re very expert in and we’ve been thinking about where these reinforcement learning systems, different versions of them, can actually rate each other in some way. And it may not be as good as a human rater, but it’s actually a useful way to do some of the bread and butter rating and then maybe just calibrate it by checking those ratings with a human rater at the end, rather than getting human raters to rate everything. So I think there are lots of innovations I can see coming down the line that will help with this and potentially mean that there’s less requirement for this all to be done by human raters.\n\nBut you think there are always human raters in the mix? Even as you get closer to AGI, it seems like you need someone to tell the computer if it’s doing a good job or not.\n\nLet’s take AlphaZero as an example, our general games playing system that ended up learning, itself, how to play any two-player game, including chess and Go. And it’s interesting. What happened there is we set up the system so that it could play against itself tens of millions of times. So, in fact, it built up its own knowledge base. It started from random, played itself, bootstrapped itself, trained better versions of itself, and played those off each other in sort of mini-tournaments. But at the end, you still want to test it against the human world champion or something like this or an external computer program that was built in a conventional way so that you can just calibrate your own metrics, which are telling you these systems are improving according to these objectives or these metrics.\n\nBut you don’t know for sure until you calibrate it with an external benchmark or measure. And depending on what that is, a human rater or human benchmark — a human expert is often the best thing to calibrate your internal testing against. And you make sure that your internal tests are actually mapping reality. And again, that’s something quite exciting about products for researchers because, when you put your research into products and millions of people are using it every day, that’s when you get real-world feedback, and there’s no way around that, right? That’s the reality, and that’s the best test of any theories or any system that you’ve built.\n\nDo you think that work is rewarding or appropriate, the labeling of data for AI systems? There’s just something about that, which is, “I’m going to tell a computer how to understand the world so that it might go off in the future and displace other people.” There’s a loop in there that seems like it’s worth more just moral or philosophical consideration. Have you spent time thinking about that?\n\nYeah, I do think about that. I think I don’t really see it like that. I think that what raters are doing is they’re part of the development cycle of making these systems safer, more useful for everybody, and more helpful and more reliable. So I think it’s a critical component. In many industries, we have safety testing of technologies and products. Today, that’s the best we can do for AI systems is to have human raters. I think, in the future, the next few years, I think we need a lot more research. And I’ve been calling for this, and we are doing this ourselves, but it needs more than just one organization to do this, is great, robust evaluation benchmarks for capabilities so that we know if a system passes these benchmarks, then it has certain properties, and it’s safe and it’s reliable in these particular ways.\n\nAnd right now, I think we are in the space of many researchers in academia and civil society and elsewhere, we have a lot of good suggestions for what those tests could be, but I don’t think they are robust or practical yet. I think they’re basically theoretical and philosophical in nature, and I think they need to be made practical so that we can measure our systems empirically against those tests and then that gives us some assurances about how the system will perform. And I think once we have those, then the need for this human rating testing feedback will be reduced. I just think that’s required in the volumes that’s required now because we don’t have these kinds of independent benchmarks yet. Partly because we haven’t rigorously defined what those properties are. I mean, it’s almost a neuroscience and psychology and philosophy area as well, right? A lot of these terms have not been defined properly, even for the human brain.\n\nYou’ve signed a letter from the Center for AI Safety — OpenAI’s Sam Altman and others have also signed this letter — that warns against the risk from AI. And yet, you’re pushing on, Google’s in the market, you’ve got to win, you’ve described yourself as competitive. There’s a tension there: needing to win in the market with products and “Oh boy, please regulate us because raw capitalism will drive us off the cliff with AI if we don’t stop it in some way.” How do you balance that risk?\n\nIt is a tension. It’s a creative tension. What we like to say at Google is we want to be bold and responsible, and that’s exactly what we’re trying to do and live out and role model. So the bold part is being brave and optimistic about the benefits, the amazing benefits, incredible benefits, AI can bring to the world and to help humanity with our biggest challenges, whether that’s disease or climate or sustainability. AI has a huge part to play in helping our scientists and medical experts solve those problems. And we’re working hard on that  and all those areas. And AlphaFold, again, I’d point to as a poster child for that, what we want to do there. So that’s the bold part. And then, the responsible bit is to make sure we do that as thoughtfully as possible with as much foresight as possible ahead of time.\n\nTry and anticipate what the issues might be if one was successful ahead of time. Not in hindsight, and perhaps this happened with social media, for example, where it is this incredible growth story. Obviously, it’s done a lot of good in the world, but then it turns out 15 years later we realize there are some unintended consequences as well to those types of systems. And I would like to chart a different path with AI. And I think it’s such a profound and important and powerful technology. I think we have to do that with something as potentially as transformative as AI. And it doesn’t mean no mistakes will be made. It’s very new, anything new, you can’t predict everything ahead of time, but I think we can try and do the best job we can.\n\n\"“It’s very new. You can’t predict everything ahead of time, but I think we can try and do the best job we can.”\"\n\nAnd that’s what signing that letter was for was just to point out that I don’t think it’s likely, I don’t know on the timescales, but it’s something that we should consider, too, in the limit is what these systems can do and might be able to do as we get closer to AGI. We are nowhere near that now. So this is not a question of today’s technologies or even the next few years’, but at some point, and given the technology’s accelerating very fast, we will need to think about those questions, and we don’t want to be thinking about them on the eve of them happening. We need to use the time now, the next five, 10, whatever it is, years, to do the research and to do the analysis and to engage with various stakeholders, civil society, academia, government, to figure out, as this stuff is developing very rapidly, what the best way is of making sure we maximize the benefits and minimize any risks.\n\nAnd that includes mostly, at this stage, doing more research into these areas, like coming up with better evaluations and benchmarks to rigorously test the capabilities of these frontier systems.\n\nYou talked about tool usage for AI models, you ask an LLM to do something, it goes off and asks AlphaFold to fold the protein for you. Combining systems like that, integrating systems like that, historically that’s where emergent behaviors appear, things you couldn’t have predicted start happening. Are you worried about that? There’s not a rigorous way to test that. \n\nRight, exactly. I think that’s exactly the sort of thing we should be researching and thinking about ahead of time is: as tool use becomes more sophisticated and you can combine different AI systems together in different ways, there is scope for emergent behavior. Of course, that emergent behavior may be very desirable and be extremely useful, but it could also potentially be harmful in the wrong hands and in the hands of bad actors, whether that’s individuals or even nation-states.\n\nLet’s say the United States and the EU and China all agree on some framework to regulate AI, and then North Korea or Iran says, “Fuck it, no rules.” And that becomes a center of bad actor AI research. How does that play out? Do you foresee a world in which that’s possible?\n\nYeah, I think that is a possible world. This is why I’ve been talking to governments — UK, US mostly, but also EU — on I think whatever regulations or guardrails or whatever that is that transpires over the next few years, and tests. They ideally would be international, and there would be international cooperation around those safeguards and international agreement around deployment of these systems and other things. Now, I don’t know how likely that is given the geopolitical tensions around the world, but that is by far the best state. And I think what we should be aiming for if we can.\n\nIf the government here passes a rule. It says, “Here’s what Google is allowed to do, here’s what Microsoft is allowed to do. You are in charge, you are accountable.” And you can go say, “All right, we’re just not running this code in our data center. We are not going to have these capabilities; it’s not legal.” If I’m just a person with a MacBook, would you accept some limitation on what a MacBook could do because the threat from AI is so scary? That’s the thing I worry about. Practically, if you have open-source models and people are going to use them for weird things, are we going to tell Intel to restrict what its chips can do? How would we implement that such that it actually affects everyone? And not just, we’re going to throw Demis in jail if Google does stuff we don’t like.\n\nI think those are the big questions that are being debated right now. And I do worry about that. On the one hand, there are a lot of benefits of open-sourcing and accelerating scientific discourse and lots of advances happen there and it gives access to many developers. On the other hand, there could be some negative consequences with that if there are bad individual actors that do bad things with that access and that proliferates. And I think that’s a question for the next few years that will need to be resolved. Because right now, I think it’s okay because the systems are not that sophisticated or that powerful and therefore not that risky.\n\nBut I think, as systems increase in their power and generality, the access question will need to be thought about from government and how they want to restrict that or control that or monitor that is going to be an important question. I don’t have any answers for you because I think this is a societal question actually that requires stakeholders from right across society to come together and weigh up the benefits with the risks there.\n\nGoogle’s own work, you said we’re not there yet, but Google’s own work in AI certainly had some controversy associated with this around responsibility, around what the models can do or can’t do. There’s a famous “Stochastic Parrots” paper from Emily Bender and Timnit Gebru and Margaret Mitchell that led to a lot of controversy inside of Google. It led to them leaving. Did you read that paper and think, “Okay, this is correct. LLMs are going to lie to people and Google will be responsible for that”? And how do you think about that now with all of the scrutiny?\n\nYeah, look, the large language models, and I think this is one reason that Google’s been very responsible with this, is that we know that they hallucinate and they can be inaccurate. And that’s one of the key areas that has to be improved over the next few years is factuality and grounding and making sure that they don’t spread disinformation, these kinds of things. And that’s very much top of mind for us. And we have many ideas of how to improve that. And our old DeepMind’s Sparrow language model, which we published a couple of years ago, was an experiment into just how good can we get factuality and rules adherence in these systems. And turns out, we can maybe make it an order of magnitude better, but it sometimes comes at the expense of lucidness or creativity on the part of the language model and therefore usefulness.\n\nSo it’s a bit of a Pareto frontier where, if you improve one dimension, you reduce the capability in another dimension. And ideally, what we want to do in the next phases and the next generations of systems is combine the best of both worlds — keep the creativity and lucidness and funness of the current systems but improve their factuality and reliability. And we’ve got a long way to go on that. But I can see things improving, and I don’t see any theoretical reason why these systems can’t get to extremely high levels of accuracy and reliability in the next few years.\n\nWhen you’re using the Google Search Generative Experience, do you believe what it says?\n\nI do. I sometimes double-check things, especially in the scientific domain where I’ve had very funny situations where, actually all of these models do this, where you ask them to summarize an area of research, which I think would be super useful if they could do that, and then say, “Well, what are the key papers I should read?” And they come up with very plausible sounding papers with very plausible author lists. But then, when you go and look into it, it turns out that they’re just like the most famous people in that field or the titles from two different papers combined together. But of course, they’re extremely plausible as a collection of words. And I think, there what needs to happen is these systems need to understand that citations and papers and author lists are a unitary block rather than a word-by-word prediction. \n\nThere are interesting cases like that where we need to improve, and there’s something which is, of course, us as wanting to advance the frontiers of science, that’s a particularly interesting use case that we would like to improve and fix — for our own needs as well. I’d love these systems to better summarize for me “here are the top five papers to read about a particular disease” or something like that to just quickly onboard you in that particular area. I think it would be incredibly useful.\n\nI’ll tell you, I googled my friend John Gruber, and SGE confidently told me that he pioneered the use of a Mac in newspapers and invented WebKit. I don’t know where that came from. Is there a quality level, a truthfulness level that you need to hit before you roll that out to the mass audience?\n\nYeah, we think about this all the time, especially at Google because of the incredibly high standards Google holds itself to on things like search and that we all rely on every day and every moment of every day, really, and we want to get toward that level of reliability. Obviously, we’re a long, long, long way away from that at the moment with not just us but anybody with their generative systems. But that’s the gold standard. And actually, things like tool use can come in very handy here where you could, in effect, build these systems so that they fact-check themselves, perhaps even using search or other reliable sources, cross-reference, just like a good researcher would, cross-reference your facts. Also having a better understanding of the world. What are research papers? What entities are they? \n\nSo these systems need to have a better understanding of the media they’re dealing with. And maybe also give these systems the ability to reason and plan because then they could potentially turn that on their own outputs and critique themselves. And again, this is something we have a lot of experience in in games programs. They don’t just output the first move that you think of in chess or Go. You actually plan and do some search around that and then back up. And sometimes they change their minds and switch to a better move. And you could imagine some process like that with words and language as well.\n\nThere’s the concept of model collapse. That we’re going to train LLMs on LLM-generated data, and that’s going to go into a circle. When you talk about cross-referencing facts, and I think about Google — Google going out in the web and trying to cross-reference a bunch of stuff but maybe all that stuff has been generated by LLMs that were hallucinating in 2023. How do you guard against that?\n\nWe are working on some pretty cool solutions to that. I think the answer is, and this is an answer to deepfakes as well, is to do some encrypted watermarking, sophisticated watermarking, that can’t be removed easily or at all, and it’s probably built into the generative models themselves, so it’s part of the generative process. We hope to release that and maybe provide it to third parties as well as a generic solution. But I think that the industry in the field needs those types of solutions where we can mark generated media, be that images, audio, perhaps even text with some Kitemark that says to the user and future AI systems that these were AI-generated. And I think that’s a very, very pressing need right now for near-term issues with AI like deepfakes and disinformation and so on. But I actually think a solution is on the horizon now.\n\nI had Microsoft CTO and EVP of AI Kevin Scott on the show a few weeks ago. He said something very similar. I promised him that we would do a one-hour episode on metadata. So you’re coming for that one. If I know this audience, a full hour on metadata ideas will be our most popular episode ever.\n\nOkay, sounds perfect.\n\nDemis, thank you so much for coming on Decoder. You have to come back soon.\n\nThanks so much.\n"}</script><meta name="parsely-type" content="post"/><meta name="parsely-title" content="Inside Google’s big AI shuffle — and how it plans to stay competitive, with Google DeepMind CEO Demis Hassabis"/><meta name="parsely-link" content="https://www.theverge.com/23778745/demis-hassabis-google-deepmind-ai-alphafold-risks"/><meta name="parsely-image-url" content="https://cdn.vox-cdn.com/thumbor/YplCPWLGEe8tmfSGj2nBwBlGZBs=/0x0:3000x2000/1200x628/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg"/><meta name="parsely-pub-date" content="2023-07-10T19:42:50.519Z"/><meta name="parsely-section" content="front-page"/><meta name="parsely-tags" content="verge,front-page,decoder-podcast-with-nilay-patel,podcast,business,featured-story,ai-artificial-intelligence,tech,google,stream-23374468"/><meta name="parsely-author" content="Nilay Patel"/><link rel="preload" as="image" imageSrcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/376x376/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/384x384/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/415x415/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/480x480/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/540x540/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/640x640/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/750x750/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/828x828/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1080x1080/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1200x1200/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1440x1440/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1920x1920/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2048x2048/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2400x2400/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 2400w" imageSizes="(max-width: 768px) 100vw, (max-width: 1180px) 700px, 550px"/><meta name="next-head-count" content="35"/><meta name="robots" content="nocache"/><link rel="me" href="https://mastodon.social/@verge"/><link rel="shortcut icon" href="/icons/favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="/icons/apple_touch_icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon_32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon_96x96.png"/><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon_16x16.png"/><link rel="mask-icon" href="/icons/safari_pinned_tab.svg" color="#5200ff"/><link rel="icon" type="image/png" href="/icons/android_chrome_192x192.png" sizes="192x192"/><link rel="icon" type="image/png" href="/icons/android_chrome_512x512.png" sizes="512x512"/><link rel="dns-prefetch" href="https://pagead2.googlesyndication.com"/><link rel="dns-prefetch" href="https://micro.rubiconproject.com/prebid/dynamic/7470.js"/><link rel="dns-prefetch" href="https://securepubads.g.doubleclick.net"/><link rel="dns-prefetch" href="https://stats.g.doubleclick.net"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://cdn.permutive.com"/><link rel="preload" href="/_next/static/media/b61d461e2e1d8573-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/af51b8e80b7e5b97-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/4c161430243654b9-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/faa4a7ab7fe4ff34-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/e0d450417c4fcdb2-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/c6806ee6b9a6284f-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/167de315d6f8820c-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/c32d4f9e62509b70-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/8314bd48671746e7-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/1acdcb23bd60cdf8-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/e334064d2786be51-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/dbe24bfb7e9bcd79-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/caa65695070c604f-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/7f8638c9585902a6-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/d2cd5f6e542bad4c-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/857aa1a339c7fe20-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/516340c748fee9da-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/afa7a955b67174eb-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/d2ddd5a6c0493c79-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/70754f98ca969379-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/60369a8d37d9d5b8-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/96fec850ad729c00-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/78c96ab956e7dd1d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/78c96ab956e7dd1d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/df212bc532bc2860.css" as="style"/><link rel="stylesheet" href="/_next/static/css/df212bc532bc2860.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="https://micro.rubiconproject.com/prebid/dynamic/7470.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://c.amazon-adsystem.com/aax2/apstag.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://www.googletagservices.com/tag/js/gpt.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://cdn.concert.io/lib/concert-ads/v2-latest/concert_ads.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://cdn.concert.io/lib/concert-concierge.2.10.1.min.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://pub.doubleverify.com/dvtag/21236410/DV464041/pub.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://polyfill.io/v3/polyfill.min.js?features=AbortController,Array.prototype.entries,Array.prototype.keys,Array.prototype.sort,Array.prototype.values,ArrayBuffer,ArrayBuffer.isView,AudioContext,Blob,console,console.error,console.log,console.warn,CustomEvent,DataView,document,Document,DocumentFragment,DocumentFragment.prototype.append,DOMRect,DOMTokenList,DOMTokenList.prototype.forEach,DOMTokenList.prototype.replace,Element,Element.prototype.after,Element.prototype.append,Element.prototype.before,Element.prototype.classList,Element.prototype.closest,Element.prototype.matches,Element.prototype.previousElementSibling,Element.prototype.remove,Element.prototype.scroll,Element.prototype.scrollIntoView,Event,EventSource,getComputedStyle,globalThis,HTMLDocument,HTMLPictureElement,HTMLTemplateElement,IntersectionObserver,IntersectionObserverEntry,Intl,Intl.DateTimeFormat,Intl.NumberFormat,Intl.RelativeTimeFormat,JSON,location.origin,Math.clz32,Math.imul,Math.sign,modernizr:es6string,MutationObserver,Node.prototype.contains,NodeList.prototype.forEach,Object.getOwnPropertySymbols,Object.isExtensible,Object.isFrozen,Object.preventExtensions,Object.setPrototypeOf,queueMicrotask,Reflect.construct,Reflect.defineProperty,Reflect.set,RegExp.prototype.flags,requestAnimationFrame,ResizeObserver,String.prototype.link,String.prototype.normalize,String.prototype.sub,Symbol.for,Symbol.iterator,Symbol.prototype.description,Symbol.toPrimitive,Symbol.toStringTag,TextDecoder,TextEncoder,Uint8Array,Window,XMLHttpRequest,Intl.RelativeTimeFormat,Intl.RelativeTimeFormat.~locale.en" defer="" data-nscript="beforeInteractive"></script><script src="/_next/static/chunks/webpack-c376b9c42b10a4ef.js" defer=""></script><script src="/_next/static/chunks/framework-1d2b8554342c6a75.js" defer=""></script><script src="/_next/static/chunks/main-a19b11f4c6f53406.js" defer=""></script><script src="/_next/static/chunks/pages/_app-da18e97646b55740.js" defer=""></script><script src="/_next/static/chunks/7404-a1bc449f4440a25c.js" defer=""></script><script src="/_next/static/chunks/5833-5ad65b6eeff676da.js" defer=""></script><script src="/_next/static/chunks/4723-ec0bd4ab4f72e2c9.js" defer=""></script><script src="/_next/static/chunks/5271-346d91caff9b1218.js" defer=""></script><script src="/_next/static/chunks/3882-4e711a09aa4476ce.js" defer=""></script><script src="/_next/static/chunks/2156-6ec5849a2514173a.js" defer=""></script><script src="/_next/static/chunks/996-f415a23a59cde4f1.js" defer=""></script><script src="/_next/static/chunks/3494-79231dcbde5aec1f.js" defer=""></script><script src="/_next/static/chunks/5207-f1962b33fbbeca79.js" defer=""></script><script src="/_next/static/chunks/6276-ea6f3169216875c5.js" defer=""></script><script src="/_next/static/chunks/9549-99a115a465a16121.js" defer=""></script><script src="/_next/static/chunks/9546-25ba14b07b9f1957.js" defer=""></script><script src="/_next/static/chunks/5055-f42044eaed03c6a4.js" defer=""></script><script src="/_next/static/chunks/4640-33e62f43d3f652bf.js" defer=""></script><script src="/_next/static/chunks/5218-ff5f614f1dfc08d1.js" defer=""></script><script src="/_next/static/chunks/pages/entry/feature/%5Buid%5D-e459bf40d237c510.js" defer=""></script><script src="/_next/static/TIjH7e7ABna7etOOsIsVO/_buildManifest.js" defer=""></script><script src="/_next/static/TIjH7e7ABna7etOOsIsVO/_ssgManifest.js" defer=""></script><style id="__jsx-2324231005">:root{--font-fkroman:'__fkRomanStandard_6bdc6d', '__fkRomanStandard_Fallback_6bdc6d', Georgia, serif;--font-manuka:'__manuka_e0d4a3', '__manuka_Fallback_e0d4a3', Impact, Helvetica, sans-serif;--font-polysans:'__polySans_c60300', '__polySans_Fallback_c60300', Helvetica, Arial, sans-serif;--font-polysans-mono:'__polySansMono_0d16dc', '__polySansMono_Fallback_0d16dc', Courier New, Courier, monospace}</style></head><body class="antialiased"><div id="__next"><style>
        *, *::before, *::after {
          transition: none!important;
        }
      </style><div class="jsx-2324231005 duet--app"><a class="text-2xl text-pink-500 border-b-pink-500 focus:outline-pink-500 sr-only z-50 block border-8 bg-white p-7 text-center opacity-0 transition-opacity focus:visible focus:static focus:h-auto focus:w-full focus:overflow-auto focus:opacity-100  focus:outline-dotted" href="#content">Skip to main content</a><div class=""><div class="duet--navigation--navigation"><div class="absolute h-[64px] w-full overflow-x-hidden md:h-[150px]"><div class="relative h-[64px] w-full max-w-container-lg md:left-1/2 md:h-[150px] md:-translate-x-1/2"><a href="/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 309 70" role="img" class="absolute left-[-16px] top-[-3px] z-0 h-[64px] w-[282px] md:h-[174px] md:w-[769px] md:left-[-200px] md:top-[-24px] fill-white md:fill-white/50" width="100%" height="100%" fill="none"><title>The Verge</title><desc>The Verge logo.</desc><path d="m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z"></path></svg></a><a class="absolute left-0 top-0 z-10 h-[60px] w-[265px] md:hidden" href="/"><span class="sr-only">The Verge homepage</span></a></div></div><div class="md:px-34 pointer-events-none relative mx-auto mb-16 flex h-[48px] w-full max-w-container-lg items-end px-20 font-polysans text-15 md:mb-80 md:h-80 md:text-19 lg:px-0"><nav class="pointer-events-auto relative ml-auto border-b pb-6 md:pb-8 text-black"><ul class="flex items-end font-light"><li class="hidden md:flex"><a href="/"><span class="sr-only">The Verge homepage</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 309 70" role="img" class="h-[28px] w-[117px] hover:opacity-60 hover:transition-all hover:ease-in-out md:translate-y-2 fill-black" width="100%" height="100%" fill="none"><title>The Verge</title><desc>The Verge logo.</desc><path d="m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z"></path></svg></a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li class="hidden md:inline"><a href="/tech" class="hover:opacity-50 hover:transition-all hover:ease-in-out">Tech</a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li class="hidden md:inline"><a href="/reviews" class="hover:opacity-50 hover:transition-all hover:ease-in-out">Reviews</a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li class="hidden md:inline"><a href="/science" class="hover:opacity-50 hover:transition-all hover:ease-in-out">Science</a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li class="hidden md:inline"><a href="/entertainment" class="hover:opacity-50 hover:transition-all hover:ease-in-out">Entertainment</a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li class="hidden md:inline"><a href="/ai-artificial-intelligence" class="hover:opacity-50 hover:transition-all hover:ease-in-out tracking-widest">AI</a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li><button class="flex cursor-pointer flex-nowrap items-center hover:opacity-50 hover:transition-all hover:ease-in-out"><span class="hidden md:inline">More</span><span class="md:hidden">Menu</span><svg width="100%" height="100%" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="ml-8 inline-block h-18 w-18 md:mt-2 md:h-[22px] md:w-[22px] fill-black"><title>Expand</title><path d="M28 11.76H16.24V0h-4.48v11.76H0v4.48h11.76V28h4.48V16.24H28v-4.48Z"></path></svg></button></li></ul></nav></div></div><div class="duet--navigation--sticky-nav fixed inset-x-0 top-0 z-40 w-full bg-white drop-shadow-sticky-nav transition-opacity duration-200 pointer-events-none opacity-0"><div class="mx-auto flex h-50 w-full max-w-container-lg items-center justify-between justify-self-start px-12 lg:px-0"><a class="flex" href="/" aria-label="The Verge logo. Click to visit the homepage" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 309 70" role="img" class="w-[141px] fill-black hover:opacity-60 hover:transition-all hover:ease-in-out" width="100%" height="100%" fill="none"><title>The Verge</title><desc>The Verge logo.</desc><path d="m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z"></path></svg></a><div class="group flex flex-nowrap"><button class="cursor-pointer items-center font-polysans text-15 flex"><span class="group-hover:opacity-60">Menu</span><svg width="100%" height="100%" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="ml-8 inline-block h-18 w-18 fill-black group-hover:opacity-60 md:mt-2 md:h-[22px] md:w-[22px]"><title>Expand</title><path d="M28 11.76H16.24V0h-4.48v11.76H0v4.48h11.76V28h4.48V16.24H28v-4.48Z"></path></svg></button></div></div></div></div><div class="duet--page-layout--feature-article"><div style="position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none"></div><div style="position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none"></div><main class="feature px-20"><article class="mx-auto w-full max-w-container-lg"><div class="duet--article--lede duet--article--lede-split relative mx-auto flex flex-col md:max-w-container-md md:pb-60 lg:max-w-none lg:flex-row-reverse"><div class="fullbleed below-0 absolute -z-20 hidden h-[2000px] lg:block bg-pernod"></div><div class="lg:w-1/2 lg:pl-40"><div class="[&amp;_a]:text-black"><div class="mb-18 md:mb-24"><ul class="lg:px-0 article-groups leading-100 mb-8"><li class="inline font-polysans-mono text-12 font-medium uppercase tracking-12 text-blurple"><a class="hover:shadow-underline-inherit" href="/decoder-podcast-with-nilay-patel">Decoder</a></li></ul><div class="mb-8"><h1 class="duet--article--feature-headline sticky-nav-trigger relative bg-[length:1px_1.04em] pb-8 font-polysans text-45 font-medium leading-[1.04] -tracking-2 before:w-full lg:text-65 bg-repeating-lines-dark">Inside Google’s big AI shuffle — and how it plans to stay competitive, with Google DeepMind CEO Demis Hassabis</h1></div><h2 class="duet--article--dangerously-set-cms-markup duet--article--feature-dek font-polysans text-22 font-light leading-110 lg:text-26">Google invented a lot of core AI technology, and now the company’s turning to Demis to get back in front of the AI race for AI breakthroughs.</h2></div><div class="mb-2"><p class="duet--article--article-byline max-w-[550px] font-polysans text-12 leading-120"><span>By</span> <span><span class="duet--article-byline-and"></span> <span class="font-medium"><a class="hover:shadow-underline-inherit" href="/authors/nilay-patel">Nilay Patel</a></span><span class="text-gray-13">, <span class="duet--article--dangerously-set-cms-markup">editor-in-chief of the Verge, host of the Decoder podcast, and co-host of The Vergecast.</span></span></span></p></div><div class="duet--article--date-and-comments mb-20 font-polysans text-12"><time dateTime="2023-07-10T19:42:50.519Z" class="duet--article--timestamp font-polysans text-12"> <!-- -->Jul 10, 2023, 7:42 PM UTC</time></div><div class="mb-18 md:mb-28 lg:mb-36"><div class="flex"><div class="flex"><div><h2 class="sr-only">Share this story</h2><ul class="duet--article--share-buttons flex leading-[0]"><li class="mr-8"><div class="relative flex items-center"><button aria-label="Copy link" class="rounded-full bg-transparent transition shadow-border-pernod hover:bg-black hover:shadow-border-black"><svg width="30" height="30" class="transition fill-black hover:fill-pernod" viewBox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"><path d="M13.7876 20.18C12.6943 21.2733 10.9133 21.2733 9.81998 20.18C8.72669 19.0867 8.72666 17.3056 9.81998 16.2123L12.0243 14.0081C13.1176 12.9147 14.8986 12.9147 15.9919 14.0081C16.0816 14.0954 16.1326 14.2149 16.1335 14.34C16.1343 14.4651 16.085 14.5854 15.9965 14.6739C15.9081 14.7624 15.7877 14.8118 15.6627 14.8109C15.5376 14.81 15.418 14.759 15.3306 14.6693C14.5922 13.9309 13.4239 13.9309 12.6855 14.6693L10.4812 16.8736C9.74277 17.6121 9.74277 18.7803 10.4812 19.5188C11.2197 20.2572 12.3879 20.2571 13.1264 19.5188L15.2204 17.4246V17.4247C15.3077 17.335 15.4273 17.284 15.5525 17.2832C15.6776 17.2823 15.7978 17.3317 15.8863 17.4202C15.9747 17.5087 16.0241 17.6289 16.0232 17.7541C16.0224 17.8792 15.9714 17.9987 15.8817 18.086L13.7876 20.18ZM17.9757 15.9919C16.8824 17.0852 15.1014 17.0852 14.0081 15.9919V15.992C13.9184 15.9047 13.8674 15.7852 13.8665 15.6601C13.8658 15.5349 13.915 15.4147 14.0035 15.3262C14.092 15.2377 14.2123 15.1883 14.3374 15.1892C14.4626 15.19 14.582 15.241 14.6694 15.3307C15.4078 16.0692 16.5761 16.0692 17.3145 15.3307L19.5188 13.1265C20.2572 12.388 20.2572 11.2197 19.5188 10.4813C18.7803 9.74283 17.6121 9.74283 16.8736 10.4813L14.7796 12.5753C14.6923 12.665 14.5727 12.7161 14.4475 12.717C14.3224 12.7179 14.2022 12.6685 14.1137 12.58C14.0252 12.4915 13.9758 12.3712 13.9767 12.246C13.9775 12.1208 14.0285 12.0012 14.1183 11.914L16.2124 9.82001C17.3057 8.72668 19.0867 8.72668 20.18 9.82001C21.2733 10.9133 21.2733 12.6944 20.18 13.7877L17.9757 15.992L17.9757 15.9919Z"></path></svg></button></div></li><li class="mr-8"><button aria-label="Share on Facebook" class="rounded-full bg-transparent transition shadow-border-pernod hover:bg-black hover:shadow-border-black"><svg width="30" height="30" class="transition fill-black hover:fill-pernod" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 30 30"><path d="M17.407 15.6999L17.7398 13.5442H15.6561V12.1455C15.6561 11.5562 15.9467 10.9806 16.8808 10.9806H17.8286V9.14574C17.8286 9.14574 16.9685 9 16.1464 9C14.4304 9 13.3083 10.0317 13.3083 11.9012V13.5442H11.4V15.6999H13.3083V20.9098C13.6908 20.9696 14.0828 21 14.4822 21C14.8816 21 15.2736 20.9685 15.6561 20.9098V15.6999H17.407Z"></path></svg></button></li><li class=""><button aria-label="Share on Twitter" class="rounded-full bg-transparent transition shadow-border-pernod hover:bg-black hover:shadow-border-black"><svg width="30" height="30" class="transition fill-black hover:fill-pernod" viewBox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"><path d="M20.0896 12.4337C20.0974 12.5459 20.0974 12.6581 20.0974 12.7713C20.0974 16.2205 17.4557 20.1985 12.6254 20.1985V20.1964C11.1985 20.1985 9.80122 19.7922 8.60001 19.0262C8.80749 19.051 9.01601 19.0634 9.22506 19.0639C10.4076 19.0649 11.5563 18.6705 12.4865 17.9443C11.3628 17.9231 10.3774 17.1948 10.0331 16.1316C10.4268 16.207 10.8324 16.1915 11.2188 16.0866C9.99363 15.8406 9.11221 14.7706 9.11221 13.528C9.11221 13.5166 9.11221 13.5058 9.11221 13.4949C9.47726 13.697 9.88599 13.8092 10.3041 13.8216C9.15017 13.055 8.79449 11.5292 9.4913 10.3362C10.8246 11.967 12.7918 12.9584 14.9035 13.0633C14.6919 12.1567 14.981 11.2066 15.6633 10.5693C16.721 9.58102 18.3845 9.63167 19.3787 10.6825C19.9669 10.5672 20.5306 10.3527 21.0464 10.0488C20.8504 10.653 20.4401 11.1663 19.892 11.4925C20.4125 11.4315 20.9211 11.293 21.4 11.0815C21.0474 11.6067 20.6034 12.0642 20.0896 12.4337Z"></path></svg></button></li></ul></div><span class="duet--article--lede-share-tools-separator mx-16 mt-4 h-[20px] border-l border-[#96AB16]"></span><div class=""><button title="Go to comments" class="duet--article--comments-link text-0 inline-block text-16 md:inline"><span class="inline-block h-18 align-text-bottom font-polysans text-12 font-medium leading-[18px] text-black"><span class="coral-count" data-coral-id="aead0074-0a38-4e37-a342-5dbfaab046b5" data-coral-url="https://www.theverge.com/23778745/demis-hassabis-google-deepmind-ai-alphafold-risks"></span></span></button></div></div><div style="margin:0" class="_1gsaw2w0 _1gsaw2w1" data-concert="article_sponsorship"></div></div></div></div></div><div class="relative lg:w-1/2 lg:[&amp;_cite]:text-gray-4a lg:[&amp;_figcaption]:text-gray-13"><div class="duet--article--lede-background fullbleed lede-background-positioning absolute -z-20 h-[10000px] lg:hidden bg-pernod"></div><figure class="duet--article--lede-image w-full"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:100%"></span><img alt="Demis Hassabis smiles at the camera" sizes="(max-width: 768px) 100vw, (max-width: 1180px) 700px, 550px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/376x376/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/384x384/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/415x415/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/480x480/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/540x540/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/640x640/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/750x750/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/828x828/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1080x1080/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1200x1200/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1440x1440/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1920x1920/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2048x2048/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2400x2400/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2400x2400/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/></span><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Photo illustration by Alex Parkin / The Verge</cite></div></figure></div></div><div class="relative mt-28 md:mx-auto md:flex md:max-w-container-md lg:mt-36 lg:max-w-none"><div class="duet--article--article-body-component-container sm:ml-auto md:ml-100 md:max-w-article-body lg:mx-100"><div id="content" class="clearfix"><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup mb-20 font-fkroman text-22 leading-150 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-franklin [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white first-letter:float-left first-letter:mr-18 first-letter:font-polysans-mono first-letter:text-[117px] first-letter:font-medium first-letter:leading-[.72] dark:first-letter:text-franklin">Today, I’m talking to Demis Hassabis, the CEO of Google DeepMind, the newly created division of Google responsible for AI efforts across the company. Google DeepMind is the result of an internal merger: Google acquired Demis’ DeepMind startup in 2014 and ran it as a separate company inside its parent company, Alphabet, while Google itself had an AI team called Google Brain. </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Google has been showing off AI demos for years now, but with the explosion of ChatGPT and a renewed threat from Microsoft in search, Google and Alphabet CEO Sundar Pichai made the decision to bring DeepMind into Google itself earlier this year to create… Google DeepMind.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">What’s interesting is that Google Brain and DeepMind were not necessarily compatible or even focused on the same things: DeepMind was famous for applying AI to things like games and protein-folding simulations. The <a href="/2019/11/27/20985260/ai-go-alphago-lee-se-dol-retired-deepmind-defeat">AI that beat world champions at Go</a>, the ancient board game? That was DeepMind’s AlphaGo. Meanwhile, Google Brain was more focused on what’s come to be the familiar generative AI toolset: large language models for chatbots, editing features in Google Photos, and so on. This was a culture clash and a big structure decision with the goal of being more competitive and faster to market with AI products.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">And the competition isn’t just OpenAI and Microsoft — you might have seen <a href="https://fortune.com/2023/05/09/a-leaked-google-memo-raises-questions-about-open-source-a-i-but-the-white-house-doesnt-seem-to-have-gotten-it/">a memo from a Google engineer</a> floating around the web recently claiming that Google has no competitive moat in AI because open-source models running on commodity hardware are rapidly evolving and catching up to the tools run by the giants. Demis confirmed that the memo was real but said it was part of Google’s debate culture, and he disagreed with it because he has other ideas about where Google’s competitive edge might come into play.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Of course, we also talked about AI risk and especially artificial general intelligence. Demis is not shy that his goal is building an AGI, and we talked through what risks and regulations should be in place and on what timeline. Demis recently signed onto a <a href="/2023/5/30/23742005/ai-risk-warning-22-word-statement-google-deepmind-openai">22-word statement about AI risk</a> with OpenAI’s Sam Altman and others that simply reads, “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.” That’s pretty chill, but is that the real risk right now? Or is it just a distraction from other more tangible problems like AI replacing a bunch of labor in various creative industries? We also talked about the new kinds of labor AI is <em>creating</em> — armies of low-paid taskers classifying data in countries like Kenya and India in order to train AI systems. We just published a big feature on these taskers. I wanted to know if Demis thought these jobs were here to stay or just a temporary side effect of the AI boom.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">This one really hits all the <em>Decoder</em> high points: there’s the big idea of AI, a lot of problems that come with it, an infinite array of complicated decisions to be made, and of course, a gigantic org chart decision in the middle of it all. Demis and I got pretty in the weeds, and I still don’t think we covered it all, so we’ll have to have him back soon.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Alright, Demis Hassabis, CEO of Google DeepMind. Here we go.</p></div><div class="duet--article--article-body-component clear-both block"><div class="duet--article--dangerously-set-cms-markup my-40"><iframe frameborder="0" height="200" scrolling="no" src="https://playlist.megaphone.fm/?e=VMP3975282129" width="100%"></iframe></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><em>This transcript has been lightly edited for length and clarity</em></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Demis Hassabis, you are the CEO of Google DeepMind. Welcome to <em>Decoder</em>.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Thanks for having me.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>I don’t think we have ever had a more perfect <em>Decoder</em> guest. There’s a big idea in AI. It comes with challenges and problems, and then, with you in particular, there’s a gigantic org chart move and a set of high-stakes decisions to be made. I am thrilled that you are here.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Glad to be here.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Let’s start with Google DeepMind itself. Google DeepMind is a new part of Google that is constructed of two existing parts of Google. There was Google Brain, which was the AI team we were familiar with as we covered Google that was run by Jeff Dean. And there was DeepMind, which was your company that you founded. You sold it to Alphabet in 2014. You were outside of Google. It was run as a separate company inside that holding company Alphabet structure until just now. Start at the very beginning. Why were DeepMind and Google Brain separate to begin with?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">As you mentioned, we started DeepMind actually back in 2010, a long time ago now, especially in the age of AI. So that’s sort of like prehistory. Myself and the co-founders, we realized coming from academia and seeing what was going on there, things like deep learning had just been invented. We were big proponents of reinforcement learning. We could see GPUs and other hardware was coming online, that a lot of great progress could be made with a focused effort on general learning systems and also taking some ideas from neuroscience and how the brain works. So we put all those ingredients together back in 2010. We had this thesis we’d make fast progress, and that’s what happened with our initial game systems. And then, we decided in 2014 to join forces with Google at the time because we could see that a lot more compute was going to be needed. Obviously, Google has the most computers and had the most computers in the world. That was the obvious home for us to be able to focus on pushing the research as fast as possible. </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>So you were acquired by Google, and then somewhere along the way, Google reoriented itself. They turned into Alphabet, and Google became a division of Alphabet. There are other divisions of Alphabet, and DeepMind was out of it. That’s just the part I want to focus on here at the beginning, because there was what Google was doing with Google Brain, which is a lot of LLM research. I recall, six years ago, Google was showing off LLMs at Google I/O, but DeepMind was focused on winning the game [Go] and protein folding, a very different kind of AI research wholly outside of Google. Why was that outside of Google? Why was that in Alphabet proper?</strong></p></div><div class="duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100"><div class="duet--article--sidebar bg-gray-200 mb-20 w-full rounded-sm bg-[#F8F5FF] p-20 [&amp;&gt;*:last-child&gt;*:last-child]:mb-0"><div class="[&amp;_p]:font-polysans [&amp;_p]:text-16 [&amp;_p]:font-light [&amp;_p]:leading-130"></div><div class="my-9"><div class="transition-all duration-300 ease-in-out"><div class="fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0" role="button" aria-label="Close" tabindex="0"></div><div role="button" aria-label="Zoom" tabindex="0" class="visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:100%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/376x376/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/384x384/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/415x415/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/480x480/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/540x540/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/640x640/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/750x750/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/828x828/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/1080x1080/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/1200x1200/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/1440x1440/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/1920x1920/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/2048x2048/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/2400x2400/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/2400x2400/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg"/></noscript></span></div></div></figure></div><div class="z-1 w-full hidden"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:100%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/376x376/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/384x384/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/415x415/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/480x480/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/540x540/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/640x640/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/750x750/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/828x828/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/1080x1080/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/1200x1200/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/1440x1440/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/1920x1920/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/2048x2048/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/2400x2400/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x3000/2400x2400/filters:focal(1500x1500:1501x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg"/></noscript></span></div></div></figure></div></div></div><div class="[&amp;_p]:font-polysans [&amp;_p]:text-16 [&amp;_p]:font-light [&amp;_p]:leading-130"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Listen to <em>Decoder</em>, a show hosted by <em>The Verge</em>’s Nilay Patel about big ideas — and other problems. Subscribe <a href="https://podcasts.apple.com/us/podcast/welcome-to-decoder/id1011668648?i=1000496212371&itsct=podcast_box&itscg=30200&ls=1&at=1001l7uV&ct=verge091322">here</a>!</p></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">That was part of the agreement as we were acquired was that we would pursue pushing forward research into general AI, or sometimes called AGI, a system that out of the box can operate across a wide range of cognitive tasks and basically has all the cognitive capabilities that humans have.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">And also using AI to accelerate scientific discovery, that’s one of my personal passions. And that explains projects like AlphaFold that I’m sure we’re going to get back to. But also, from the start of DeepMind and actually prior to even DeepMind starting, I believe that games was a perfect testing or proving ground for developing AI algorithms efficiently, quickly, and you can generate a lot of data and the objective functions are very clear: obviously, winning games or maximizing the score. There were a lot of reasons to use games in the early days of AI research, and that was a big part of why we were so successful and why we were able to advance so quickly with things like AlphaGo, the program that beat the world champion at the ancient game of Go.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Those were all really important proof points for the whole field really that these general learning techniques would work. And of course we’ve done a lot of work on deep learning and neural networks as well. And our specialty, I suppose, was combining that with reinforcement learning to allow these systems to actively solve problems and make plans and do things like win games. And in terms of the differences, we always had that remit to push the research agenda and push things, advanced science. And that was very much the focus we were given and very much the focus that I wanted to have. And then, the internal Google AI teams like Google Brain, they had slightly different remits and were a bit closer to product and obviously to the rest of Google and infusing Google with amazing AI technology. And we also had an applied division that was introducing DeepMind technology into Google products, too. But the cultures were quite different, and the remits were quite different.</p></div><div class="duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100"><div class="duet--recirculation--related-list mb-40"><h3 class="mb-16 font-polysans-mono text-14 font-medium leading-120 -tracking-1 text-blurple after:pl-8 after:content-[&#x27;/&#x27;]">Related</h3><ul class="list-disc pl-18 font-polysans text-16 font-medium leading-110 marker:text-franklin"><li class="mb-16 pl-12"><a class="hover:shadow-underline-black" href="/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai">Bing, Bard, and ChatGPT: AI chatbots are rewriting the internet </a></li><li class="mb-16 pl-12"><a class="hover:shadow-underline-black" href="/2023/7/5/23784257/google-ai-bard-privacy-policy-train-web-scraping">Google confirms it’s training Bard on scraped web data, too</a></li></ul></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>From the outside, the timeline looks like this: everyone’s been working on this for ages, we’ve all been talking about it for ages. It is a topic of conversation for a bunch of nerdy journalists like me, a bunch of researchers, we talk about it in the corner at Google events. </strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Then ChatGPT is released, not even as a product. I don’t even think Sam [Altman] would call it a great product when it was released, but it was just released, and people could use it. And everyone freaked out, and Microsoft releases Bing based on ChatGPT, and the world goes upside down, and Google reacts by merging DeepMind and Google Brain. That’s what it looks like from the outside. Is that what it felt like from the inside?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">That timeline is correct, but it’s not these direct consequences; it’s more indirect in a sense. So, Google and Alphabet have always run like this. They let many flowers bloom, and I think that’s always been the way that even from Larry [Page] and Sergey [Brin] from the beginning set up Google. And it served them very well, and it’s allowed them to organically create incredible things and become the amazing company that it is today. On the research side, I think it’s very compatible with doing research, which is another reason we chose Google as our partners back in 2014. I felt they really understood what fundamental and blue sky research was, ambitious research was, and they were going to facilitate us being and enable us to be super ambitious with our research. And you’ve seen the results of that, right?</p></div><div class="duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100"><div class="duet--article--article-pullquote mb-20"><div class="mb-10 h-[22px] w-[65px] bg-franklin"></div><p class="duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple">“...AI has entered a new era.”</p></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">By any measure, AlphaGo, AlphaFold, but more than 20 nature and science papers and so on — all the normal metrics one would use for really delivering amazing cutting-edge research we were able to do. But in a way, what ChatGPT and the large models and the public reaction to that confirmed is that AI has entered a new era. And by the way, it was a little bit surprising for all of us <a href="https://dictionary.cambridge.org/us/dictionary/english/at-the-coalface">at the coalface</a>, including OpenAI, how viral that went because — us and some other startups like Anthropic and OpenAI — we all had these large language models. They were roughly the same capabilities. </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">And so, it was surprising, not so much what the technology was because we all understood that, but the public’s appetite for that and obviously the buzz that generated. And I think that’s indicative of something we’ve all been feeling for the last, I would say, two, three years, which is these systems are reaching a level of maturity now and sophistication where it can really come out of the research phase and the lab and go into powering incredible next-generation products and experiences and also breakthroughs, things like AlphaFold directly being useful for biologists. And so, to me, this is just indicative of a new phase that AI is in of being practically useful to people in their everyday lives and actually being able to solve really hard real-world problems that really matter, not just the curiosities or fun, like games.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">When you recognize that shift, then I think that necessitates a change in your approach as to how you’re approaching the research and how much focus you’re having on products and those kinds of things. And I think that’s what we all came to the realization of, which was: now was the time to streamline our AI efforts and focus them more. And the obvious conclusion of that was to do the merger.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>I want to just stop there for one second and ask a philosophical question.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Sure.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>It feels like the ChatGPT moment that led to this AI explosion this year was really rooted in the AI being able to do something that regular people could do. I want you to write me an email, I want you to write me a screenplay, and maybe the output of the LLM is a C+, but it’s still something I can do. People can see it. I want you to fill out the rest of this photo. That’s something people can imagine doing. Maybe they don’t have the skills to do it, but they can imagine doing it. All the previous AI demos that we have gotten, even yours, AlphaFold, you’re like, this is going to model all the proteins in the world.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>But I can’t do that; a computer should do that. Even a microbiologist might think, “That is great. I’m very excited that a computer can do that because I’m just looking at how much time it would take us, and there’s no way we could ever do it.” “I want to beat the world champion at Go. I can’t do that. It’s like, fine. A computer can do that.” </strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>There’s this turn where the computer is starting to do things I can do, and they’re not even necessarily the most complicated tasks. Read this webpage and deliver a summary of it to me. But that’s the thing that unlocked everyone’s brain. And I’m wondering why you think the industry didn’t see that turn coming because we’ve been very focused on these very difficult things that people couldn’t do, and it seems like what got everyone is when the computer started doing things people do all the time.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">I think that analysis is correct. I think that is why the large language models have really entered the public consciousness because it’s something the average person, that the “Joe Public,” can actually understand and interact with. And, of course, language is core to human intelligence and our everyday lives. I think that does explain why chatbots specifically have gone viral in the way they have. Even though I would say things like AlphaFold, I mean of course I’d be biased in saying this, but I think it’s actually had the most unequivocally biggest beneficial effects so far in AI on the world because if you talk to any biologist or there’s a million biologists now, researchers and medical researchers, have used AlphaFold. I think that’s nearly every biologist in the world. Every Big Pharma company is using it to advance their drug discovery programs. I’ve had multiple, dozens, of Nobel Prize-winner-level biologists and chemists talk to me about how they’re using AlphaFold.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">So a certain set of all the world’s scientists, let’s say, they all know AlphaFold, and it’s affected and massively accelerated their important research work. But of course, the average person in the street doesn’t know what proteins are even and doesn’t know what the importance of those things are for things like drug discovery. Whereas obviously, for a chatbot, everyone can understand, this is incredible. And it’s very visceral to get it to write you a poem or something that everybody can understand and process and measure compared to what they do or are able to do. </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>It seems like that is the focus of productized AI: these chatbot-like interfaces or these generative products that are going to make stuff for people, and that’s where the risk has been focused. But even the conversation about risk has escalated because people can now see, “Oh, these tools can do stuff.” Did you perceive the same level of scrutiny when you were working on AlphaFold? It doesn’t seem like anyone thought, “Oh, AlphaFold’s going to destroy humanity.”</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">No, but there was a lot of scrutiny, but again, it was in a very specialized area, right? With renowned experts, and actually, we did talk to over 30 experts in the field, from top biologists to bioethicists to biosecurity people, and actually our partners — we partnered with the European Bioinformatics Institute to release the AlphaFold database of all the protein structures, and they guided us as well on how this could be safely put out there. So there was a lot of scrutiny, and the overwhelming conclusion from the people we consulted was that the benefits far outweighed any risks. Although we did make some small adjustments based on their feedback about which structures to release. But there was a lot of scrutiny, but again, it’s just in a very expert domain. And just going back to your first question about the generative models, I do think we are right at the beginning of an incredible new era that’s going to play out over the next five, 10 years.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Not only in advancing science with AI but in terms of the types of products we can build to improve people’s everyday lives, billions of people in their everyday lives, and help them to be more efficient and to enrich their lives. And I think what we’re seeing today with these chatbots is literally just scratching the surface. There are a lot more types of AI than generative AI.  Generative AI is now the “in” thing, but I think that planning and deep reinforcement learning and problem-solving and reasoning, those kinds of capabilities are going to come back in the next wave after this, along with the current capabilities of the current systems. So I think, in a year or two’s time, if we were to talk again, we are going to be talking about entirely new types of products and experiences and services with never-seen-before capabilities. And I’m very excited about building those things, actually. And that’s one of the reasons I’m very excited about leading Google DeepMind now in this new era and focusing on building these AI-powered next-generation products.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Let’s stay in the weeds of Google DeepMind itself, for one more turn. Sundar Pichai comes to you and says, “All right, I’m the CEO of Alphabet and the CEO of Google. I can just make this call. I’m going to bring DeepMind into Google, merge you with Google Brain, you’re going to be the CEO.” How did you react to that prompt?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">It wasn’t like that. It was much more of a conversation between the leaders of the various different relevant groups and Sundar about pretty much the inflection point that we’re seeing, the maturity of the systems, what could be possible with those in the product space, and how to improve experiences for our users, our billions of users, and how exciting that might be, and what that all requires in totality. Both the change in focus, a change in the approach to research, the combination of resources that are required, like compute resources. So there was a big collection of factors to take into account that we all discussed as a leadership group, and then, conclusions from that then result in actions, including the merger and also what the plans are then for the next couple of years and what the focus should be of that merged unit.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Do you perceive a difference being a CEO inside of Google versus being a CEO inside of Alphabet?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">It’s still early days, but I think it’s been pretty similar because, although DeepMind was an Alphabet company, it was very unusual for another bet, as they call it an “alpha bet,” which is that we already were very closely integrated and collaborating with many of the Google product area teams and groups. We had an applied team at DeepMind whose job it was to translate our research work into features in products by collaborating with the Google product teams. And so, we’ve had hundreds of successful launches already actually over the last few years, just quiet ones behind the scenes. So, in fact, many of the services or devices or systems that you use every day at Google will have some DeepMind technology under the hood as a component. So we already had that integrative structure, and then, of course, what we were famous for was doing the scientific advances and gaming advances, but behind the scenes, there was a lot of bread and butter work going on that was affecting all parts of Google.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">We were different from other bets where they have to make a business outside of Google and become an independent business. That was never the goal or the remit for us, even as an independent bet company. And now, within Google, we’re just more tightly integrated in terms of the product services, and I see that as an advantage because we can actually go deeper and do more exciting and ambitious things in much closer collaboration with these other product teams than we could from outside of Google. But we still retain some latitude to pick the processes and the systems that optimize our mission of producing the most capable and general AI systems in the world.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>There’s been </strong><a href="/2023/5/4/23750910/command-line-inside-googles-culture-clash"><strong>reporting that this is actually a culture clash</strong></a><strong>. You’re now in charge of both. How have you structured the group? How has Google DeepMind structured under you as CEO, and how are you managing that culture integration?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Actually, it turns out that the culture’s a lot more similar than perhaps has been reported externally. And in the end, it’s actually been surprisingly smooth and pleasant because you’re talking about two world-class research groups, two of the best AI research organizations in the world, incredible talent on both sides, storied histories. As we were thinking about the merger and planning it, we were looking at some document where we listed the top 10 breakthroughs from each group. And when you take that in totality, it’s like 80–90 percent of over the last decade, of the breakthroughs that underpin the modern AI industry, from deep reinforcement learning to <a href="https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/">transformers</a>, of course. It’s an incredible set of people and talent, and there’s massive respect for both groups on both sides. And there was actually a lot of collaboration on a project-based level ongoing over the last decade.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Of course, we all know each other very well. I just think it’s a question of focus and a bit of coordination across both groups, actually, and more in terms of what are we going to focus on, other places that it makes sense for the two separate teams to collaborate on, and maybe de-duplicate some efforts that basically are overlapping. So fairly obvious stuff, to be honest, but it’s important moving into this new phase now of where we are into more of an engineering phase of AI, and that requires huge resources, both compute, engineering, and other things. And, even as a company the size of Google, we’ve got to pick our bets carefully and be clear about which arrows we are going to put our wood behind and then focus on those and then massively deliver on those things. So I think it’s part of the natural course of evolution as to where we are in the AI journey.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>That thing you talked about, “We’re going to combine these groups, we’re going to pick what we’re doing, we’re going to de-duplicate some efforts.” Those are structure questions. Have you decided on a structure yet, and what do you think that structure will be?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">The structure’s still evolving. We’re only a couple of months into it. We wanted to make sure we didn’t break anything, that it was working. Both teams are incredibly productive, doing super amazing research, but also plugging in to very important product things that are going on. All of that needs to continue.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>You keep saying both teams. Do you think of it as two teams, or are you trying to make one team?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">No, no, for sure it’s one unified team. I like to call it a “super unit,” and I’m very excited about that. But obviously, we’re still combining that and forming the new culture and forming the new grouping, including the organizational structures. It’s a complex thing — putting two big research groups together like this. But I think, by the end of the summer, we’ll be a single unified entity, and I think that’ll be very exciting. And we’re already feeling, even a couple of months in, the benefits and the strengths of that with projects like <a href="https://www.tomsguide.com/news/googles-new-gemini-ai-could-beat-chatgpt-heres-why">Gemini</a> that you may have heard of, which is our next-generation multimodal large models — very, very exciting work going on there, combining all the best ideas from across both world-class research groups. It’s pretty impressive to see.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>You have a lot of decisions to make. What you’re describing is a bunch of complicated decisions and then, out in the world, how should we regulate this? Another set of very complicated decisions. You are a chess champion, you are a person who has made games. What is your framework for making decisions? I suspect it is much more rigorous than the other ones I hear about.</strong></p></div><div class="duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100"><div class="duet--article--article-pullquote mb-20"><div class="mb-10 h-[22px] w-[65px] bg-franklin"></div><p class="duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple">“Chess is basically decision-making under pressure with an opponent.”</p></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Yes, I think it probably is. And I think if you play a game like chess that seriously — effectively professionally — since all my childhood, since the age of four, I think it’s very formative for your brain. So I think, in chess, the problem-solving and strategizing, I find it a very useful framework for many things and decision-making. Chess is basically decision-making under pressure with an opponent, and it’s very complex, and I think it’s a great thing. I advocate it being taught at school, part of the school curriculum, because I think it’s a really fantastic training ground for problem-solving and decision-making. But then, I think actually the overarching approach is more of the scientific method.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">So I think all my training is doing my PhDs and postdocs and so on, obviously I did it in neuroscience, so I was learning about the brain, but it also taught me how to do rigorous hypothesis testing and hypothesis generation and then update based on empirical evidence. The whole scientific method as well as the chess planning, both can be translated into the business domain. You have to be smart about how to translate that, you can’t be academic about these things. And often, in the real world, in business, there’s a lot of uncertainty and hidden information that you don’t know. So, in chess, obviously all the information’s there for you on the board. You can’t just directly translate those skills, but I think, in the background, they can be very helpful if applied in the right way.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>How do you combine those two in some decisions you’ve made?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">There are so many decisions I make every day,it’s hard to come up with one now. But I tend to try and plan out and scenario a plan many, many years in advance. So I tell you the way I try to approach things is, I have an end goal. I’m quite good at imagining things, so that’s a different skill, visualizing or imagining what would a perfect end state look like, whether that’s organizational or it’s product-based or it’s research-based. And then, I work back from the end point and then figure out what all the steps would be required and in what order to make that outcome as likely as possible.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">So that’s a little bit chess-like, right? In the sense of you have some plan that you would like to get to checkmate your opponent, but you’re many moves away from that. So what are the incremental things one must do to improve your position in order to increase the likelihood of that final outcome? And I found that extremely useful to do that search process from the end goal back to the current state that you find yourself in.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Let’s put that next to some products. You said there’s a lot of DeepMind technology and a lot of Google products. The ones that we can all look at are </strong><a href="https://bard.google.com/"><strong>Bard</strong></a><strong> and then your Search Generative Experience. There’s AI in Google Photos and all this stuff, but focused on the LLM moment, it’s Bard and the Search Generative Experience. Those can’t be the end state. They’re not finished. Gemini is coming, and we’ll probably improve both of those, and all that will happen. When you think about the end state of those products, what do you see?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">The AI systems around Google are also not just in the consumer-facing things but also under the hood that you may not realize. So even, for example, one of the things we applied our AI systems to very initially was the cooling systems in Google’s data centers, enormous data centers, and actually reducing the energy they use by nearly 30 percent that the cooling systems use, which is obviously huge if you multiply that by all of the data centers and computers they have there. So there are actually a lot of things under the hood where AI is being used to improve the efficiency of those systems all the time. But you’re right, the current products are not the end state; they’re actually just waypoints. And in the case of chatbots and those kinds of systems, ultimately, they will become these incredible universal personal assistants that you use multiple times during the day for really useful and helpful things across your daily lives.</p></div><div class="duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100"><div class="duet--article--article-pullquote mb-20"><div class="mb-10 h-[22px] w-[65px] bg-franklin"></div><p class="duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple">“...today’s chatbots will look trivial by comparison to I think what’s coming in the next few years.”</p></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">From what books to read to recommendations on maybe live events and things like that to booking your travel to planning trips for you to assisting you in your everyday work. And I think we’re still far away from that with the current chatbots, and I think we know what’s missing: things like planning and reasoning and memory, and we are working really hard on those things. And I think what you’ll see in maybe a couple of years’ time is today’s chatbots will look trivial by comparison to I think what’s coming in the next few years.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>My background is as a person who’s reported on computers. I think of computers as somewhat modular systems. You look at a phone — it’s got a screen, it’s got a chip, it’s got a cell antenna, whatever. Should I look at AI systems that way — there’s an LLM, which is a very convincing human language interface, and behind it might be AlphaFold that’s actually doing the protein folding? Is that how you’re thinking about stitching these things together, or is it a different evolutionary pathway?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Actually, there’s a whole branch of research going into what’s called tool use. This is the idea that these large language models or large multimodal models, they’re expert at language, of course, and maybe a few other capabilities, like math and possibly coding. But when you ask them to do something specialized, like fold a protein or play a game of chess or something like this, then actually what they end up doing is calling a tool, which could be another AI system, that then provides the solution or the answer to that particular problem. And then that’s transmitted back to the user via language or pictorially through the central large language model system. So it may be actually invisible to the user because, to the user, it just looks like one big AI system that has many capabilities, but under the hood, it could be that actually the AI system is broken down into smaller ones that have specializations.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">And I actually think that probably is going to be the next era. The next generation of systems will use those kinds of capabilities. And then you can think of the central system as almost a switch statement that you effectively prompt with language, and it roots your query or your question or whatever it is you’re asking it to the right tool to solve that question for you or provide the solution for you. And then transmit that back in a very understandable way. Again, using through the interface, the best interface really, of natural language.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Does that process get you closer to an AGI, or does that get you to some maximum state and you got to do something else?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">I think that is on the critical path to AGI, and that’s another reason, by the way, I’m very excited about this new role and actually doing more products and things because I actually think the product roadmap from here and the research roadmap from here toward something like AGI or human-level AI is very complementary. The kinds of capabilities one would need to push in order to build those kinds of products that are useful in your everyday life like a universal assistant requires pushing on some of these capabilities, like planning and memory and reasoning, that I think are vital for us to get to AGI. So I actually think there’s a really neat feedback loop now between products and research where they can effectively help each other.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>I feel like I had a lot of car CEOs on the show at the beginning of it. I asked all of them, “When do you think we’re going to get self-driving cars?” And they all said five years, and they’ve been saying five years for five years, right?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Yes.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>I’m going to ask you a version of that question about AGI, but I feel like the number has gotten smaller recently with people I’ve talked to. How many years until you think we have AGI?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">I think there’s a lot of uncertainty over how many more breakthroughs are required to get to AGI, big, big breakthroughs — innovative breakthroughs — versus just scaling up existing solutions. And I think it very much depends on that in terms of timeframe. Obviously, if there are a lot of breakthroughs still required, those are a lot harder to do and take a lot longer. But right now, I would not be surprised if we approached something like AGI or AGI-like in the next decade.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>In the next decade. All right, I’m going to come back to you in 10 years. We’re going to see if that happens.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Sure.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>That’s not a straight line, though. You called it the critical path, that’s not a straight line. There are breakthroughs along the way that might upset the train and send you along a different path, you think.</strong></p></div><div class="duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100"><div class="duet--article--article-pullquote mb-20"><div class="mb-10 h-[22px] w-[65px] bg-franklin"></div><p class="duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple">“...research is never a straight line. If it is, then it’s not real research.”</p></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Research is never a straight line. If it is, then it’s not real research. If you knew the answer before you started it, then that’s not research. So research and blue sky research at the frontier always has uncertainty around it, and that’s why you can’t really predict timelines with any certainty. But what you can look at is trends, and we can look at the quality of ideas and projects that are being worked on today, look at how they’re progressing. And I think that could go either way over the next five to 10 years where we might asymptote, we might hit a brick wall with current techniques and scaling. I wouldn’t be surprised if that happened, either: that we may find that just scaling the existing systems resulted in diminishing returns in terms of the performance of the system.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">And actually, that would then signal some new innovations were really required to make further progress. At the moment, I think nobody knows which regime we’re in. So the answer to that is you have to push on both as hard as possible. So both the scaling and the engineering of existing systems and existing ideas as well as investing heavily into exploratory research directions that you think might deliver innovations that might solve some of the weaknesses in the current systems. And that’s one advantage of being a large research organization with a lot of resources is we can bet on both of those things maximally, both of those directions. In a way, I’m agnostic to that question of “do we need more breakthroughs or will existing systems just scale all the way?” My view is it’s an empirical question, and one should push both as hard as possible. And then the results will speak for themselves.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>This is a real tension. When you were at DeepMind in Alphabet and you were very research-focused, and then the research was moved back into Google and Google’s engineers would turn it into products. And you can see how that relationship worked. Now, you’re inside of Google. Google is under a lot of pressure as a company to win this battle. And those are product concerns. Those are “Make it real for people and go win in the market.” There’s </strong><a href="https://fortune.com/2023/05/09/a-leaked-google-memo-raises-questions-about-open-source-a-i-but-the-white-house-doesnt-seem-to-have-gotten-it/"><strong>a leaked memo</strong></a><strong> that went around. It was purportedly from inside Google. It said the company had no moat and open-source AI models or leaked models would run on people’s laptops, and they would outpace the company because the history of open computing would outpace a closed-source competitor. Was that memo real?</strong></p></div><div class="duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100"><div class="duet--article--article-pullquote mb-20"><div class="mb-10 h-[22px] w-[65px] bg-franklin"></div><p class="duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple">“I think that memo was real.”</p></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">I think that memo was real. I think engineers at Google often write various documents, and sometimes they get leaked and go viral. I think that’s just a thing that happens, but I wouldn’t take it too seriously. These are just opinions. I think it’s interesting to listen to them, and then you’ve got to chart your own course. And I haven’t read that specific memo in detail, but I disagree with the conclusions from that. And I think there’s obviously open source and publishing, and we’ve done tons of that in the history of DeepMind. I mean, AlphaFold was open sourced, right? So we obviously believe in open source and supporting research and open research. That’s a key thing of the scientific discourse, which we’ve been a huge part of. And so is Google, of course, publishing transformers and other things. And <a href="/2019/3/6/18253002/google-ai-data-privacy-tensorflow-differential-module-code">TensorFlow</a> and you look at all the things we’ve done.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">We do a huge amount in that space. But I also think there are other considerations that need to be had as well. Obviously commercial ones but also safety questions about access to these very powerful systems. What if bad actors can access it? Who maybe aren’t that technical, so they couldn’t have built it themselves, but they can certainly reconfigure a system that is out there? What do you do about those things? And I think that’s been quite theoretical till now, but I think that that is really important from here all the way to AGI as these systems become more general, more sophisticated, more powerful. That question is going to be very important about how does one stop bad actors just using these systems for things they weren’t intended for but for malicious purposes.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">That’s something we need to increasingly come up with, but just back to your question, look at the history of what Google and DeepMind have done in terms of coming up with new innovations and breakthroughs and multiple, multiple breakthroughs over the last decade or more. And I would bet on us, and I’m certainly very confident that that will continue and actually be even more true over the next decade in terms of us producing the next key breakthroughs just like we did in the past.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Do you think that’s the moat: we invented most of this stuff, so we’re going to invent most of the next stuff?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">I don’t really think about it as moats, but I’m an incredibly competitive person. That’s maybe another thing I got from chess, and many researchers are. Of course, they’re doing it to discover knowledge, and ultimately, that’s what we are here for is to improve the human condition. But also, we want to be first to do these things and do them responsibly and boldly. We have some of the world’s best researchers. I think we have the biggest collection of great researchers in the world, anywhere in the world, and an incredible track record. And there’s no reason why that shouldn’t continue in the future. And in fact, I think with our new organization and environment might be conducive to even more and faster-paced breakthroughs than we’ve done in the past.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>You’re leading me toward risk and regulation. I want to talk about that, but I want to start in with just a different spin on it. You’re talking about all the work that has to be done. You’re talking about deep mind reinforcement learning, how that works. We ran a gigantic cover story </strong><a href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html"><strong>in collaboration with <em>New York</em> Magazine</strong></a><strong> about the taskers who are actually doing the training, who are actually labeling the data. There’s a lot of labor conversation with AI along the way. Hollywood writers are on strike right now because they don’t want ChatGPT to write a bunch of scripts. I think that’s appropriate.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>But then there’s a new class of labor that’s being developed where a bunch of people around the world are sitting in front of computers and saying, “Yep, that’s a stop sign. No, that’s not a stop sign. Yep, that’s clothes you can wear. No, that’s not clothes you can wear.” Is that a forever state? Is that just a new class of work that needs to be done for these systems to operate? Or does that come to an end?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">I think it’s hard to say. I think it’s definitely a moment in time and the current systems and what they’re requiring at the moment. We’ve been very careful just to say, from our part, and I think you quoted some of our researchers in that article, to be very careful to pay living wages and be very responsible about how we do that kind of work and which partners we use. And we also use internal teams as well. So actually, I’m very proud of how responsible we’ve been on that type of work. But going forward, I think there may be ways that these systems, especially once you have millions and millions of users, effectively can bootstrap themselves. Or one could imagine AI systems that are capable of actually conversing with themselves or critiquing themselves.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">This would be a bit like turning language systems into a game-like setting, which of course we’re very expert in and we’ve been thinking about where these reinforcement learning systems, different versions of them, can actually rate each other in some way. And it may not be as good as a human rater, but it’s actually a useful way to do some of the bread and butter rating and then maybe just calibrate it by checking those ratings with a human rater at the end, rather than getting human raters to rate everything. So I think there are lots of innovations I can see coming down the line that will help with this and potentially mean that there’s less requirement for this all to be done by human raters.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>But you think there are always human raters in the mix? Even as you get closer to AGI, it seems like you need someone to tell the computer if it’s doing a good job or not.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Let’s take AlphaZero as an example, our general games playing system that ended up learning, itself, how to play any two-player game, including chess and Go. And it’s interesting. What happened there is we set up the system so that it could play against itself tens of millions of times. So, in fact, it built up its own knowledge base. It started from random, played itself, bootstrapped itself, trained better versions of itself, and played those off each other in sort of mini-tournaments. But at the end, you still want to test it against the human world champion or something like this or an external computer program that was built in a conventional way so that you can just calibrate your own metrics, which are telling you these systems are improving according to these objectives or these metrics.</p></div><div class="duet--article--article-body-component"></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">But you don’t know for sure until you calibrate it with an external benchmark or measure. And depending on what that is, a human rater or human benchmark — a human expert is often the best thing to calibrate your internal testing against. And you make sure that your internal tests are actually mapping reality. And again, that’s something quite exciting about products for researchers because, when you put your research into products and millions of people are using it every day, that’s when you get real-world feedback, and there’s no way around that, right? That’s the reality, and that’s the best test of any theories or any system that you’ve built.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Do you think that work is rewarding or appropriate, the labeling of data for AI systems? There’s just something about that, which is, “I’m going to tell a computer how to understand the world so that it might go off in the future and displace other people.” There’s a loop in there that seems like it’s worth more just moral or philosophical consideration. Have you spent time thinking about that?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Yeah, I do think about that. I think I don’t really see it like that. I think that what raters are doing is they’re part of the development cycle of making these systems safer, more useful for everybody, and more helpful and more reliable. So I think it’s a critical component. In many industries, we have safety testing of technologies and products. Today, that’s the best we can do for AI systems is to have human raters. I think, in the future, the next few years, I think we need a lot more research. And I’ve been calling for this, and we are doing this ourselves, but it needs more than just one organization to do this, is great, robust evaluation benchmarks for capabilities so that we know if a system passes these benchmarks, then it has certain properties, and it’s safe and it’s reliable in these particular ways.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">And right now, I think we are in the space of many researchers in academia and civil society and elsewhere, we have a lot of good suggestions for what those tests could be, but I don’t think they are robust or practical yet. I think they’re basically theoretical and philosophical in nature, and I think they need to be made practical so that we can measure our systems empirically against those tests and then that gives us some assurances about how the system will perform. And I think once we have those, then the need for this human rating testing feedback will be reduced. I just think that’s required in the volumes that’s required now because we don’t have these kinds of independent benchmarks yet. Partly because we haven’t rigorously defined what those properties are. I mean, it’s almost a neuroscience and psychology and philosophy area as well, right? A lot of these terms have not been defined properly, even for the human brain.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>You’ve </strong><a href="/2023/5/30/23742005/ai-risk-warning-22-word-statement-google-deepmind-openai"><strong>signed a letter from the Center for AI Safety</strong></a><strong> — OpenAI’s Sam Altman and others have also signed this letter — that warns against the risk from AI. And yet, you’re pushing on, Google’s in the market, you’ve got to win, you’ve described yourself as competitive. There’s a tension there: needing to win in the market with products and “Oh boy, please regulate us because raw capitalism will drive us off the cliff with AI if we don’t stop it in some way.” How do you balance that risk?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">It is a tension. It’s a creative tension. What we like to say at Google is we want to be bold and responsible, and that’s exactly what we’re trying to do and live out and role model. So the bold part is being brave and optimistic about the benefits, the amazing benefits, incredible benefits, AI can bring to the world and to help humanity with our biggest challenges, whether that’s disease or climate or sustainability. AI has a huge part to play in helping our scientists and medical experts solve those problems. And we’re working hard on that  and all those areas. And AlphaFold, again, I’d point to as a poster child for that, what we want to do there. So that’s the bold part. And then, the responsible bit is to make sure we do that as thoughtfully as possible with as much foresight as possible ahead of time.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Try and anticipate what the issues might be if one was successful ahead of time. Not in hindsight, and perhaps this happened with social media, for example, where it is this incredible growth story. Obviously, it’s done a lot of good in the world, but then it turns out 15 years later we realize there are some unintended consequences as well to those types of systems. And I would like to chart a different path with AI. And I think it’s such a profound and important and powerful technology. I think we have to do that with something as potentially as transformative as AI. And it doesn’t mean no mistakes will be made. It’s very new, anything new, you can’t predict everything ahead of time, but I think we can try and do the best job we can.</p></div><div class="duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100"><div class="duet--article--article-pullquote mb-20"><div class="mb-10 h-[22px] w-[65px] bg-franklin"></div><p class="duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple">“It’s very new. You can’t predict everything ahead of time, but I think we can try and do the best job we can.”</p></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">And that’s what signing that letter was for was just to point out that I don’t think it’s likely, I don’t know on the timescales, but it’s something that we should consider, too, in the limit is what these systems can do and might be able to do as we get closer to AGI. We are nowhere near that now. So this is not a question of today’s technologies or even the next few years’, but at some point, and given the technology’s accelerating very fast, we will need to think about those questions, and we don’t want to be thinking about them on the eve of them happening. We need to use the time now, the next five, 10, whatever it is, years, to do the research and to do the analysis and to engage with various stakeholders, civil society, academia, government, to figure out, as this stuff is developing very rapidly, what the best way is of making sure we maximize the benefits and minimize any risks.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">And that includes mostly, at this stage, doing more research into these areas, like coming up with better evaluations and benchmarks to rigorously test the capabilities of these frontier systems.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>You talked about tool usage for AI models, you ask an LLM to do something, it goes off and asks AlphaFold to fold the protein for you. Combining systems like that, integrating systems like that, historically that’s where emergent behaviors appear, things you couldn’t have predicted start happening. Are you worried about that? There’s not a rigorous way to test that. </strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Right, exactly. I think that’s exactly the sort of thing we should be researching and thinking about ahead of time is: as tool use becomes more sophisticated and you can combine different AI systems together in different ways, there is scope for emergent behavior. Of course, that emergent behavior may be very desirable and be extremely useful, but it could also potentially be harmful in the wrong hands and in the hands of bad actors, whether that’s individuals or even nation-states.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Let’s say the United States and the EU and China all agree on some framework to regulate AI, and then North Korea or Iran says, “Fuck it, no rules.” And that becomes a center of bad actor AI research. How does that play out? Do you foresee a world in which that’s possible?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Yeah, I think that is a possible world. This is why I’ve been talking to governments — UK, US mostly, but also EU — on I think whatever regulations or guardrails or whatever that is that transpires over the next few years, and tests. They ideally would be international, and there would be international cooperation around those safeguards and international agreement around deployment of these systems and other things. Now, I don’t know how likely that is given the geopolitical tensions around the world, but that is by far the best state. And I think what we should be aiming for if we can.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>If the government here passes a rule. It says, “Here’s what Google is allowed to do, here’s what Microsoft is allowed to do. You are in charge, you are accountable.” And you can go say, “All right, we’re just not running this code in our data center. We are not going to have these capabilities; it’s not legal.” If I’m just a person with a MacBook, would you accept some limitation on what a MacBook could do because the threat from AI is so scary? That’s the thing I worry about. Practically, if you have open-source models and people are going to use them for weird things, are we going to tell Intel to restrict what its chips can do? How would we implement that such that it actually affects everyone? And not just, we’re going to throw Demis in jail if Google does stuff we don’t like.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">I think those are the big questions that are being debated right now. And I do worry about that. On the one hand, there are a lot of benefits of open-sourcing and accelerating scientific discourse and lots of advances happen there and it gives access to many developers. On the other hand, there could be some negative consequences with that if there are bad individual actors that do bad things with that access and that proliferates. And I think that’s a question for the next few years that will need to be resolved. Because right now, I think it’s okay because the systems are not that sophisticated or that powerful and therefore not that risky.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">But I think, as systems increase in their power and generality, the access question will need to be thought about from government and how they want to restrict that or control that or monitor that is going to be an important question. I don’t have any answers for you because I think this is a societal question actually that requires stakeholders from right across society to come together and weigh up the benefits with the risks there.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Google’s own work, you said we’re not there yet, but Google’s own work in AI certainly had some controversy associated with this around responsibility, around what the models can do or can’t do. There’s a famous “</strong><a href="https://dl.acm.org/doi/10.1145/3442188.3445922"><strong>Stochastic Parrots</strong></a><strong>” paper from Emily Bender and Timnit Gebru and Margaret Mitchell that led to a lot of controversy inside of Google. It led to them leaving. Did you read that paper and think, “Okay, this is correct. LLMs are going to lie to people and Google will be responsible for that”? And how do you think about that now with all of the scrutiny?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Yeah, look, the large language models, and I think this is one reason that Google’s been very responsible with this, is that we know that they hallucinate and they can be inaccurate. And that’s one of the key areas that has to be improved over the next few years is factuality and grounding and making sure that they don’t spread disinformation, these kinds of things. And that’s very much top of mind for us. And we have many ideas of how to improve that. And our old DeepMind’s Sparrow language model, which we published a couple of years ago, was an experiment into just how good can we get factuality and rules adherence in these systems. And turns out, we can maybe make it an order of magnitude better, but it sometimes comes at the expense of lucidness or creativity on the part of the language model and therefore usefulness.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">So it’s a bit of a <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">Pareto</a> frontier where, if you improve one dimension, you reduce the capability in another dimension. And ideally, what we want to do in the next phases and the next generations of systems is combine the best of both worlds — keep the creativity and lucidness and funness of the current systems but improve their factuality and reliability. And we’ve got a long way to go on that. But I can see things improving, and I don’t see any theoretical reason why these systems can’t get to extremely high levels of accuracy and reliability in the next few years.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>When you’re using the Google Search Generative Experience, do you believe what it says?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">I do. I sometimes double-check things, especially in the scientific domain where I’ve had very funny situations where, actually all of these models do this, where you ask them to summarize an area of research, which I think would be super useful if they could do that, and then say, “Well, what are the key papers I should read?” And they come up with very plausible sounding papers with very plausible author lists. But then, when you go and look into it, it turns out that they’re just like the most famous people in that field or the titles from two different papers combined together. But of course, they’re extremely plausible as a collection of words. And I think, there what needs to happen is these systems need to understand that citations and papers and author lists are a unitary block rather than a word-by-word prediction. </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">There are interesting cases like that where we need to improve, and there’s something which is, of course, us as wanting to advance the frontiers of science, that’s a particularly interesting use case that we would like to improve and fix — for our own needs as well. I’d love these systems to better summarize for me “here are the top five papers to read about a particular disease” or something like that to just quickly onboard you in that particular area. I think it would be incredibly useful.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>I’ll tell you, I googled my friend John Gruber, and </strong><a href="/2023/5/12/23720396/google-search-generative-experience-blue-links"><strong>SGE</strong></a><strong> confidently told me that he pioneered the use of a Mac in newspapers and invented WebKit. I don’t know where that came from. Is there a quality level, a truthfulness level that you need to hit before you roll that out to the mass audience?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Yeah, we think about this all the time, especially at Google because of the incredibly high standards Google holds itself to on things like search and that we all rely on every day and every moment of every day, really, and we want to get toward that level of reliability. Obviously, we’re a long, long, long way away from that at the moment with not just us but anybody with their generative systems. But that’s the gold standard. And actually, things like tool use can come in very handy here where you could, in effect, build these systems so that they fact-check themselves, perhaps even using search or other reliable sources, cross-reference, just like a good researcher would, cross-reference your facts. Also having a better understanding of the world. What are research papers? What entities are they? </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">So these systems need to have a better understanding of the media they’re dealing with. And maybe also give these systems the ability to reason and plan because then they could potentially turn that on their own outputs and critique themselves. And again, this is something we have a lot of experience in in games programs. They don’t just output the first move that you think of in chess or Go. You actually plan and do some search around that and then back up. And sometimes they change their minds and switch to a better move. And you could imagine some process like that with words and language as well.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>There’s the concept of model collapse. That we’re going to train LLMs on LLM-generated data, and that’s going to go into a circle. When you talk about cross-referencing facts, and I think about Google — Google going out in the web and trying to cross-reference a bunch of stuff but maybe all that stuff has been generated by LLMs that were hallucinating in 2023. How do you guard against that?</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">We are working on some pretty cool solutions to that. I think the answer is, and this is an answer to deepfakes as well, is to do some encrypted watermarking, sophisticated watermarking, that can’t be removed easily or at all, and it’s probably built into the generative models themselves, so it’s part of the generative process. We hope to release that and maybe provide it to third parties as well as a generic solution. But I think that the industry in the field needs those types of solutions where we can mark generated media, be that images, audio, perhaps even text with some Kitemark that says to the user and future AI systems that these were AI-generated. And I think that’s a very, very pressing need right now for near-term issues with AI like deepfakes and disinformation and so on. But I actually think a solution is on the horizon now.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>I had Microsoft CTO and EVP of AI Kevin Scott on the show a few weeks ago. He said something very similar. I promised him that we would do a one-hour episode on metadata. So you’re coming for that one. If I know this audience, a full hour on metadata ideas will be our most popular episode ever.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Okay, sounds perfect.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><strong>Demis, thank you so much for coming on <em>Decoder</em>. You have to come back soon.</strong></p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Thanks so much.</p></div><div class="duet--article--article-body-component clear-both block"><div class="duet--article--action-box action-box mb-20 border-t border-blurple px-12 pt-16 font-polysans-mono text-14 leading-130 -tracking-2 text-blurple md:text-15 md:flex md:flex-row md:items-start md:justify-between"><div class="mb-14 md:mb-0"><h2 class="inline font-medium">Decoder with Nilay Patel<!-- --> <!-- --> / </h2><p class="duet--article--dangerously-set-cms-markup text-sm md:text-base inline font-light">A podcast about big ideas and other problems</p></div><a class="duet--article--dangerously-set-cms-markup inline-block whitespace-nowrap rounded-sm border border-blurple px-18 py-12 text-12 font-medium uppercase tracking-12 no-underline hover:bg-blurple hover:text-white md:ml-28" href="http://pod.link/decoder">SUBSCRIBE NOW!</a></div></div></div><div class="mb-40 mt-30"><button class="duet--article--comments-button group inline-flex h-40 w-full items-center justify-center rounded-[2px] border-[1px] border-solid border-blurple font-polysans-mono text-11 font-light uppercase tracking-12 text-blurple hover:bg-blurple hover:text-white md:w-auto md:px-30"><svg class="mr-10 inline pt-2" width="12" height="14" fill="none" viewBox="0 0 12 12" stroke-width="1px" xmlns="http://www.w3.org/2000/svg"><title>Comments</title><path d="M2.4 9.1h-.207l-.147.146L.5 10.793V1.2c0-.384.316-.7.7-.7h9.6c.384 0 .7.316.7.7v7.2c0 .384-.316.7-.7.7H2.4Z" stroke="currentColor"></path></svg><span class="coral-count" data-coral-id="aead0074-0a38-4e37-a342-5dbfaab046b5" data-coral-url="https://www.theverge.com/23778745/demis-hassabis-google-deepmind-ai-alphafold-risks"></span></button></div></div><div class="duet--layout--rail max-h-[8000px] max-w-[300px] hidden z-0 text-white lg:flex lg:flex-1 lg:flex-col"><div class="flex-auto"><div style="min-height:250px;min-width:300px;position:sticky;top:90px;margin-bottom:40px" class="_1gsaw2w0 _1gsaw2w5" data-concert="medium_rectangle_variable"></div></div><div class="flex-auto"><div class="duet--recirculation--list-breaker-standard sticky m-auto my-50 rounded-[4px] lg:mb-40 lg:mt-0 bg-white top-90 w-mobile-breaker p-20"><div class="absolute right-[-25px] top-0 h-full rotate-180 whitespace-nowrap text-center font-manuka text-[168px] font-ultra leading-100 text-franklin opacity-50" style="writing-mode:vertical-rl;text-orientation:sideways">Most Popular</div><div class="relative z-10 mb-20 flex justify-between font-polysans text-11 font-medium uppercase tracking-15 text-blurple">Most Popular</div><ol class="styled-counter styled-counter-standard md:w-full w-full"><li class="leading-120 text-blurple"><a class="text-black hover:text-blurple" href="/2024/5/6/24150274/tesla-layoffs-employee-fourth-week-elon-musk-ev-demand"><h2 class="mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1">More Tesla employees laid off as bloodbath enters its fourth week</h2></a><hr class="-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple"/></li><li class="leading-120 text-blurple"><a class="text-black hover:text-blurple" href="/2024/5/6/24150573/sonos-ace-headphones-reveal-leak-wireless"><h2 class="mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1">These are the upcoming Sonos Ace wireless headphones</h2></a><hr class="-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple"/></li><li class="leading-120 text-blurple"><a class="text-black hover:text-blurple" href="/2024/5/5/24148223/arc-browser-windows-claude-sofa-bose-beats-hacks-coffee-installer"><h2 class="mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1">The best new browser for Windows</h2></a><hr class="-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple"/></li><li class="leading-120 text-blurple"><a class="text-black hover:text-blurple" href="/2024/5/5/24147995/apple-siri-ai-research-chatbot-creativity"><h2 class="mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1">Better Siri is coming: what Apple’s research says about its AI plans</h2></a><hr class="-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple"/></li><li class="leading-120 text-blurple"><a class="text-black hover:text-blurple" href="/2024/5/6/24150198/apple-pencil-pro-japan-website-code-leak"><h2 class="mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1">‘Apple Pencil Pro’ spotted in code on Apple’s Japanese site</h2></a><hr class="-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple"/></li></ol></div> </div><div class="flex-auto"><div class="sticky top-90"><div style="min-height:250px;min-width:300px;margin-bottom:40px" class="_1gsaw2w0 _1gsaw2w5" data-concert="medium_rectangle_gamestop"></div><div style="min-height:100px;min-width:300px;padding-bottom:40px" class="_1gsaw2w0 _1gsaw2w5" data-concert="connatix_right_rail"></div></div></div><div class="flex-auto"><aside class="sticky top-90 pb-40 duet--article--rail"><div class="mb-8 hidden md:block"><div><form class=""><div class="duet--cta--newsletter flex w-full flex-col border-t px-12 pt-16 font-polysans-mono text-14 font-light leading-130 -tracking-2 md:text-15 text-blurple border-blurple"><div class="mb-10"><h2 class="inline font-medium">Verge Deals</h2><p class="inline"> / <span class="duet--article--dangerously-set-cms-markup">Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.</span></p></div><div><fieldset><div class="mb-4 flex"><label class="sr-only" for="email">Email (required)</label><input id="email" type="email" name="email" placeholder="Enter your email" class="mr-8 rounded-sm border px-10 font-polysans text-15 font-light focus:outline-none w-full placeholder:text-blurple bg-white"/><button type="submit" class="whitespace-nowrap rounded-sm border px-18 py-12 text-12 font-medium uppercase tracking-12 no-underline border-blurple hover:bg-blurple hover:text-white">Sign up</button></div></fieldset><div class="mt-2 font-polysans text-11 leading-110">By submitting your email, you agree to our<!-- --> <a href="https://www.voxmedia.com/legal/terms-of-use" class="underline">Terms</a> and <a href="https://www.voxmedia.com/legal/privacy-notice" class="underline">Privacy Notice</a>. <!-- -->This site is protected by reCAPTCHA and the Google<!-- --> <a href="https://policies.google.com/privacy" class="underline">Privacy Policy</a> <!-- -->and<!-- --> <a href="https://policies.google.com/terms" class="underline">Terms of Service</a> <!-- -->apply.</div></div></div></form></div></div></aside></div><div class="duet--ad--native-ad-rail hidden flex-auto" data-native-ad-id="container"><div class="sticky top-90 mb-40"><div class="hidden"><div class="dynamic-native-ad-native_ad_latest"></div></div><div class="flex items-center text-black"><div class="w-[210px]"><div class="mb-6"><span class="border-b border-b-blurple pb-6 font-polysans text-10 font-medium uppercase leading-140 tracking-15 text-gray-5a">From our sponsor</span></div><h3 class="font-polysans text-20 leading-110 tracking-1"><a data-native-ad-id="title" href="http://theverge.com" class="hover:shadow-underline-black"></a></h3><a href="http://theverge.com"><div class="mb-4 flex items-center text-gray-31"><span data-native-ad-id="preamble" class="font-polysans text-10 font-medium uppercase leading-140 tracking-15">Advertiser Content From</span><img data-native-ad-id="sponsored_logo" class="max-h-[24px] max-w-[120px] pl-8" alt="Sponsor logo" src="/icons/native-ad-placeholder.png"/></div></a></div><div><img data-native-ad-id="thumbnail" class="max-w-[75px] pl-8" alt="Sponsor thumbnail" src="/icons/native-ad-placeholder.png"/></div></div></div></div><div class="flex-auto"><div style="min-height:250px;min-width:300px;position:sticky;top:90px;margin-bottom:40px" class="_1gsaw2w0 _1gsaw2w5" data-concert="btf_medium_rectangle_variable_article"></div></div></div><div style="position:absolute;top:8200px;right:10px;bottom:40px" class="_1gsaw2w0 _1gsaw2w5" data-concert="btf_medium_rectangle_variable_feature_extended_sticky"></div></div></article></main><div style="min-height:250px;min-width:300px;margin-bottom:40px" class="_1gsaw2w0 _1gsaw2w4" data-concert="medium_rectangle_gamestop"></div><section class="duet--article--more-stories bg-franklin px-20 py-30 lg:py-50"><div class="md:mx-auto md:max-w-container-md lg:max-w-container-lg"><h2 class="mb-24 font-polysans-mono text-16 font-light leading-120 tracking-2 text-gray-13">More from this stream<!-- --> <a class="border-b font-medium hover:border-blurple hover:text-blurple" href="/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai">From ChatGPT to Google Bard: how AI is rewriting the internet</a></h2><ul><li class="relative pb-20 pl-24 last:pb-0 lg:pl-28 [&amp;&gt;div]:border-b [&amp;&gt;div]:border-black/30 [&amp;&gt;div]:last:border-b-0 [&amp;&gt;div]:last:border-l-0"><div class="absolute -left-10 top-0 h-20 w-20 rounded-full border border-black bg-black lg:top-8"></div><div class="absolute left-0 top-0 h-full border-l border-l-black lg:top-8"></div><h3 class="mb-10 font-polysans text-22 font-medium leading-100 -tracking-1 selection:bg-franklin-20 lg:text-34"><a class="hover:border-b" href="/2024/2/16/24074878/at-least-in-canada-companies-are-responsible-when-their-customer-service-chatbots-lie-to-their-custo">At least in Canada, companies are responsible when their customer service chatbots lie to their customer.</a></h3><div class="pb-20 font-polysans text-11 lg:text-12"><time dateTime="2024-02-16T15:29:28.524Z" class="duet--article--timestamp font-polysans text-12"> <!-- -->Feb 16, 2024, 3:29 PM UTC</time></div></li><li class="relative pb-20 pl-24 last:pb-0 lg:pl-28 [&amp;&gt;div]:border-b [&amp;&gt;div]:border-black/30 [&amp;&gt;div]:last:border-b-0 [&amp;&gt;div]:last:border-l-0"><div class="absolute -left-10 top-0 h-20 w-20 rounded-full border border-black bg-black lg:top-8"></div><div class="absolute left-0 top-0 h-full border-l border-l-black lg:top-8"></div><h3 class="mb-10 font-polysans text-22 font-medium leading-100 -tracking-1 selection:bg-franklin-20 lg:text-34"><a class="hover:border-b" href="/2024/2/16/24074816/scientists-are-extremely-concerned-about-this-rats-dck">Scientists are extremely concerned about this rat&#x27;s “dck.”</a></h3><div class="pb-20 font-polysans text-11 lg:text-12"><time dateTime="2024-02-16T15:26:31.548Z" class="duet--article--timestamp font-polysans text-12"> <!-- -->Feb 16, 2024, 3:26 PM UTC</time></div></li><li class="relative pb-20 pl-24 last:pb-0 lg:pl-28 [&amp;&gt;div]:border-b [&amp;&gt;div]:border-black/30 [&amp;&gt;div]:last:border-b-0 [&amp;&gt;div]:last:border-l-0"><div class="absolute -left-10 top-0 h-20 w-20 rounded-full border border-black bg-black lg:top-8"></div><div class="absolute left-0 top-0 h-full border-l border-l-black lg:top-8"></div><h3 class="mb-10 font-polysans text-22 font-medium leading-100 -tracking-1 selection:bg-franklin-20 lg:text-34"><a class="hover:border-b" href="/2024/2/16/24074815/soras-ai-generated-video-looks-cool-but-its-still-bad-with-hands">Sora’s AI-generated video looks cool, but it’s still bad with hands.</a></h3><div class="pb-20 font-polysans text-11 lg:text-12"><time dateTime="2024-02-16T15:07:32.888Z" class="duet--article--timestamp font-polysans text-12"> <!-- -->Feb 16, 2024, 3:07 PM UTC</time></div></li><li class="relative pb-20 pl-24 last:pb-0 lg:pl-28 [&amp;&gt;div]:border-b [&amp;&gt;div]:border-black/30 [&amp;&gt;div]:last:border-b-0 [&amp;&gt;div]:last:border-l-0"><div class="absolute -left-10 top-0 h-20 w-20 rounded-full border border-black bg-black lg:top-8"></div><div class="absolute left-0 top-0 h-full border-l border-l-black lg:top-8"></div><h3 class="mb-10 font-polysans text-22 font-medium leading-100 -tracking-1 selection:bg-franklin-20 lg:text-34"><a class="hover:border-b" href="/24067999/ai-bot-chatgpt-chatbot-dungeon">You sound like a bot</a></h3><div class="pb-20 font-polysans text-11 lg:text-12"><time dateTime="2024-02-16T14:30:00.000Z" class="duet--article--timestamp font-polysans text-12"> <!-- -->Feb 16, 2024, 2:30 PM UTC</time></div></li></ul><a class="border-b font-polysans text-11 uppercase leading-120 tracking-15 text-gray-13  hover:border-blurple hover:text-blurple lg:text-12" href="/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai">See all <!-- -->436<!-- --> stories</a> <svg class="inline-block" width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" tabindex="-1" aria-hidden="true"><path fill-rule="evenodd" clip-rule="evenodd" d="M8.85017 5.58349L5.68241 2.38336L6.25987 1.79999L10.5 6.05807L6.39998 10.2L5.82251 9.61662L8.99818 6.40849L1.5 6.40849V5.58349L8.85017 5.58349Z"></path></svg></div></section></div></div><footer class="duet--navigation--footer bg-gray-13 pb-70 pt-20 text-center font-polysans text-10 uppercase leading-[19px] tracking-[0.1em] text-white md:pt-40 lg:text-left lg:text-12 lg:leading-[21px]"><div class="mx-auto max-w-container-lg"><a href="/" class="mx-auto mb-24 inline-block w-full overflow-hidden lg:mx-0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 309 70" role="img" class="relative mx-auto w-[calc(100vw-40px)] fill-white md:static md:w-[204px] lg:ml-0 lg:w-[398px]" width="100%" height="100%" fill="none"><title>The Verge</title><desc>The Verge logo.</desc><path d="m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z"></path></svg></a><div class="flex flex-col lg:flex-row"><div class="mb-4 sm:mb-0 sm:basis-1/3 lg:basis-2/3"><div class="flex flex-col"><ul class="mb-16 flex list-inside flex-wrap justify-center pl-20 lg:justify-start"><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:hidden"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/legal/terms-of-use">Terms of Use</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/legal/privacy-notice">Privacy Notice</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/legal/cookie-policy">Cookie Policy</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/contact">Do Not Sell Or Share My Personal Info</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/pages/licensing">Licensing FAQ</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/legal/accessibility">Accessibility</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://status.voxmedia.com">Platform Status</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/pages/how-we-rate">How We Rate and Review Products</a></li></ul><ul class="mb-16 flex list-inside flex-wrap justify-center pl-20 lg:justify-start"><li class="mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:hidden"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/contact-the-verge">Contact</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/c/tech/22579076/how-to-tip-the-verge-email-signal-and-more">Tip Us</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/community-guidelines">Community Guidelines</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/about-the-verge">About</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/ethics-statement">Ethics Statement</a></li></ul></div></div><div class="lg:basis-1/3"><p class="mb-8 font-bold uppercase">The Verge is a vox media network</p><ul class="mb-8 flex list-inside flex-wrap justify-center lg:justify-start"><li class="mr-8 list-none leading-5 before:mr-8 before:inline-block before:text-hot-brick before:hidden"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/vox-advertising">Advertise with us</a></li><li class="mr-8 list-none leading-5 before:mr-8 before:inline-block before:text-hot-brick before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://jobs.voxmedia.com">Jobs @ Vox Media</a></li></ul><p class="font-fkroman tracking-12 text-white">© <!-- -->2024<!-- --> <a rel="nofollow" href="https://www.voxmedia.com">Vox Media</a>, LLC. All Rights Reserved</p></div></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"hydration":{"responses":[{"operationName":"FeatureArticleLayoutQuery","variables":{"uid":"Entry:aead0074-0a38-4e37-a342-5dbfaab046b5","communityId":372},"data":{"entryRevision":{"__typename":"Entry","uid":"Entry:aead0074-0a38-4e37-a342-5dbfaab046b5","author":{"_id":499946,"fullName":"Nilay Patel","authorProfile":{"url":"https://www.theverge.com/authors/nilay-patel","shortBio":"editor-in-chief of the Verge, host of the Decoder podcast, and co-host of The Vergecast.","uid":"AuthorProfile:23957"}},"uuid":"aead0074-0a38-4e37-a342-5dbfaab046b5","type":"STORY","community":{"_id":372,"domain":"theverge.com","network":{"domain":"theverge.com"},"placeholderImageUrl":"https://cdn.vox-cdn.com/uploads/network/placeholder_image/2/The_Verge.644.jpg","slug":"verge","name":"The Verge","googleAmpLogo":{"url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png","width":250,"height":50},"communityID":372},"title":"Inside Google’s big AI shuffle — and how it plans to stay competitive, with Google DeepMind CEO Demis Hassabis","seoHeadline":"Google DeepMind CEO Demis Hassabis on ChatGPT, AI, LLMs, and more","socialHeadline":"ChatGPT gets the headlines, but scientific research like AlphaFold is also the future of AI, says Google DeepMind CEO Demis Hassabis","promoHeadline":null,"legacyId":23542786,"hasAffiliateLinks":false,"publishDate":"2023-07-10T19:42:50.519Z","originalPublishDate":"2023-07-10T19:42:50.519Z","wordCount":10210,"streams":[{"legacyId":23374468,"__isEntryRevision":"Entry","title":"From ChatGPT to Google Bard: how AI is rewriting the internet","uid":"Entry:967a3ae7-91ee-4c55-b1a3-a123f84ee10e","url":"https://www.theverge.com/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai","relatedStream":{"recentEntries":{"totalCount":436,"results":[{"title":"At least in Canada, companies are responsible when their customer service chatbots lie to their customer.","uid":"Entry:c0791c8a-8898-4515-a3c7-59d01b1e09e5","author":{"fullName":"Elizabeth Lopatto"},"promoHeadline":null,"url":"https://www.theverge.com/2024/2/16/24074878/at-least-in-canada-companies-are-responsible-when-their-customer-service-chatbots-lie-to-their-custo","publishDate":"2024-02-16T15:29:28.524Z","originalPublishDate":"2024-02-16T15:29:28.524Z"},{"title":"Scientists are extremely concerned about this rat's “dck.”","uid":"Entry:3ecd44a2-cbcb-4aec-b0c4-5e3a0f23d1e0","author":{"fullName":"Jess Weatherbed"},"promoHeadline":null,"url":"https://www.theverge.com/2024/2/16/24074816/scientists-are-extremely-concerned-about-this-rats-dck","publishDate":"2024-02-16T15:26:31.548Z","originalPublishDate":"2024-02-16T15:26:31.548Z"},{"title":"Sora’s AI-generated video looks cool, but it’s still bad with hands.","uid":"Entry:3f84004a-38be-4d9a-b295-577a6c6d7b10","author":{"fullName":"Emilia David"},"promoHeadline":null,"url":"https://www.theverge.com/2024/2/16/24074815/soras-ai-generated-video-looks-cool-but-its-still-bad-with-hands","publishDate":"2024-02-16T15:07:32.888Z","originalPublishDate":"2024-02-16T15:07:32.888Z"},{"title":"You sound like a bot","uid":"Entry:4915136c-e61c-4051-ba76-dba6753c7037","author":{"fullName":"Adi Robertson"},"promoHeadline":null,"url":"https://www.theverge.com/24067999/ai-bot-chatgpt-chatbot-dungeon","publishDate":"2024-02-16T14:30:00.000Z","originalPublishDate":"2024-02-16T14:30:00.000Z"},{"title":"How much electricity does AI consume?","uid":"Entry:5ac41b31-8a49-406a-9d84-6b000b151e37","author":{"fullName":"James Vincent"},"promoHeadline":null,"url":"https://www.theverge.com/24066646/ai-electricity-energy-watts-generative-consumption","publishDate":"2024-02-16T14:00:00.000Z","originalPublishDate":"2024-02-16T14:00:00.000Z"},{"title":"How AI copyright lawsuits could make the whole industry go extinct","uid":"Entry:d34d1b3d-c20b-4cf2-bac3-2f9f9c1ce1cc","author":{"fullName":"Nilay Patel"},"promoHeadline":null,"url":"https://www.theverge.com/24062159/ai-copyright-fair-use-lawsuits-new-york-times-openai-chatgpt-decoder-podcast","publishDate":"2024-02-15T15:00:00.000Z","originalPublishDate":"2024-02-15T15:00:00.000Z"}]}},"password":null}],"contributors":[],"primaryCampaignGroup":null,"campaignGroups":[],"communityGroups":[{"slug":"front-page","isInternal":false,"hubPage":{"slug":"","uid":"HubPage:270"},"isDisclaimer":false,"description":null,"uid":"EntryGroup:51","name":"Front Page","url":"https://www.theverge.com/","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The Nintendo Switch 2 will now reportedly arrive in 2025 instead of 2024","uid":"Entry:beee2677-e972-4e4e-898c-fa9f20cfc826","url":"https://www.theverge.com/2024/2/16/24075174/switch-2-launch-date-rumor-q1-2025","author":{"fullName":"Ash Parrish"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/lA9CG498doJGjG9JOisq1_T8jow=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/0mSe0c0D5D_NAUpnNO9RfWG7yqs=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg","asset":{"title":"Stock image illustration featuring the Nintendo logo stamped in black on a background of tan, blue, and black color blocking."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Nintendo","slug":"nintendo","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The best Presidents Day deals you can already get","uid":"Entry:ae3462ed-d729-4045-b0ee-fa4a4cc6cd0f","url":"https://www.theverge.com/24072881/best-presidents-day-sales-deals-2024-apple-tvs-gaming-headphones-smartwatches","author":{"fullName":"Quentyn Kennemer"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/44HX0exmF1grR1zLh7d_8sauDaA=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/m1tVM4z2Whd6IFJ-Vo8SNn_oMoY=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg","asset":{"title":"Apple AirPods Pro"},"caption":{"plaintext":"There’s plenty of tech on sale for Presidents Day, from AirPods to OLED TVs and everything in between."}},"promoImage":null,"communityGroups":[{"name":"Deals","slug":"good-deals","hubPage":{"uid":"HubPage:17413"},"isInternal":false,"isStarred":false},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Logitech","slug":"logitech","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Smart Home","slug":"smart-home","hubPage":{"uid":"HubPage:279"},"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"TVs","slug":"televisions","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Wearable","slug":"wearables","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Headphones","slug":"headphone","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Laptops","slug":"laptops","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"PC Gaming","slug":"pc-gaming","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Cameras and Photography","slug":"photography","hubPage":{"uid":"HubPage:280"},"isInternal":false,"isStarred":false},{"name":"Mobile","slug":"mobile","hubPage":{"uid":"HubPage:282"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Interview: Figma’s CEO on life after the company’s failed sale to Adobe","uid":"Entry:fdc979c4-8ca1-4529-9b87-73ff4e9fc771","url":"https://www.theverge.com/2024/2/16/24075126/figma-ceo-dylan-field-interview-after-adobe","author":{"fullName":"Alex Heath"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/_h6TOd1_tIgIDNFyrkYYvh_dn2A=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/GAN_VXedqCF0aB11s1jGNOkBgJQ=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","asset":{"title":"Figma CEO Dylan Field."},"caption":{"plaintext":"Figma CEO Dylan Field."}},"promoImage":null,"communityGroups":[{"name":"Command Line","slug":"command-line-newsletter","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Design","slug":"design","hubPage":{"uid":"HubPage:8137"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Adobe","slug":"adobe","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Vudu’s name is changing to ‘Fandango at Home’","uid":"Entry:fcb3c34d-db2e-4a74-bc4d-cb54ff107c67","url":"https://www.theverge.com/2024/2/16/24075041/vudu-fandango-at-home-rebranding-new-name","author":{"fullName":"Chris Welch"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/OfW7xmYlzZXLOKRrVJZn4j8QUwY=/0x0:1080x716/1080x716/filters:focal(540x358:541x359)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/DfDuP6neKkLLh9MLWj1y3SHqW94=/0x0:1080x716/100x100/filters:focal(540x358:541x359)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg","asset":{"title":"An image announcing Vudu’s rebranding to Fandango at Home."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Apps","slug":"apps","hubPage":{"uid":"HubPage:277"},"isInternal":false,"isStarred":false},{"name":"Streaming","slug":"streaming-wars","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Amazon — like SpaceX — claims the labor board is unconstitutional","uid":"Entry:0fa52d0e-c11f-4c47-a2fe-263bdccbc61e","url":"https://www.theverge.com/2024/2/16/24074954/amazon-labor-board-nlrb-unconstitutional","author":{"fullName":"Emma Roth"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/-DH_98tyCltbrWTMSUoI7BLSJ1g=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23935561/acastro_STK103__04.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/VMv_ykKU3cj2UPdBp71ECWSYPpI=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23935561/acastro_STK103__04.jpg","asset":{"title":"Illustration showing Amazon’s logo on a black, orange, and tan background, formed by outlines of the letter “A.”"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Amazon","slug":"amazon","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"SpaceX","slug":"spacex","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Space","slug":"space","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Science","slug":"science","hubPage":{"uid":"HubPage:6949"},"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP"},{"slug":"decoder-podcast-with-nilay-patel","isInternal":false,"hubPage":null,"isDisclaimer":false,"description":"Decoder is a new show from The Verge about big ideas – and other problems. Verge Editor-in-Chief Nilay Patel talks to a diverse cast of innovators and policy makers at the frontiers of business and technology to reveal how they’re navigating an ever-changing landscape, what keeps them up at night, and what it all means for our shared future. Subscribe \u003ca href=\"https://podcasts.apple.com/us/podcast/decoder-with-nilay-patel/id1011668648?i=1000496212371\"\u003ehere\u003c/a\u003e!","uid":"EntryGroup:100410","name":"Decoder","url":"https://www.theverge.com/decoder-podcast-with-nilay-patel","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How AI copyright lawsuits could make the whole industry go extinct","uid":"Entry:d34d1b3d-c20b-4cf2-bac3-2f9f9c1ce1cc","url":"https://www.theverge.com/24062159/ai-copyright-fair-use-lawsuits-new-york-times-openai-chatgpt-decoder-podcast","author":{"fullName":"Nilay Patel"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/1GaLsD1RllsYos7u9CP302kX6UA=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25286521/DCD_AI_Lawsuits_v2.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/7q4j1N1zox6Hz7RnWEuBWUEWbwA=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25286521/DCD_AI_Lawsuits_v2.jpg","asset":{"title":"Photo illustration of a statue of Lady Justice with pixelation and binary code texture"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Decoder","slug":"decoder-podcast-with-nilay-patel","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Decoder SAP AI Feb 2024 - internal","slug":"decoder-sap-ai-feb-2024","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Law","slug":"law","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Policy","slug":"policy","hubPage":{"uid":"HubPage:278"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"OpenAI","slug":"openai","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"DOJ’s Jonathan Kanter says the antitrust fight against Big Tech is just beginning","uid":"Entry:b4c3961f-7e70-4eba-95b9-ada34221d06b","url":"https://www.theverge.com/24067873/jonathan-kanter-doj-antitrust-google-policy-monopoly-big-tech","author":{"fullName":"Nilay Patel"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/DZfHykGO8jpno4J41P1uhjtrNzU=/0x0:2760x1839/2760x1839/filters:focal(1380x920:1381x921)/cdn.vox-cdn.com/uploads/chorus_asset/file/25277274/Decoder_US_Assistant_Attorney_General_Jonathan_Kanter.png","variantUrl":"https://cdn.vox-cdn.com/thumbor/dBwHo95-fraHq0ROBQPlb0ex2bY=/0x0:2760x1839/100x100/filters:focal(1380x920:1381x921)/cdn.vox-cdn.com/uploads/chorus_asset/file/25277274/Decoder_US_Assistant_Attorney_General_Jonathan_Kanter.png","asset":{"title":"A portrait of US Assistant Attorney General Jonathan Kanter."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Policy","slug":"policy","hubPage":{"uid":"HubPage:278"},"isInternal":false,"isStarred":false},{"name":"Antitrust","slug":"antitrust","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Regulation","slug":"regulation","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Politics","slug":"politics","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Decoder","slug":"decoder-podcast-with-nilay-patel","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Google","slug":"google","hubPage":{"uid":"HubPage:274"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Platformer’s Casey Newton on surviving the great media collapse and what comes next","uid":"Entry:6984e46e-2be9-404f-b55a-709c902a0195","url":"https://www.theverge.com/2024/2/5/24059524/platformer-casey-newton-substack-moderation-email-newsletters-media-layoffs","author":{"fullName":"Nilay Patel"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/ilPj_qjE5Gtm50Q4eNJ3eXIi03c=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25263748/DCD_Casey_Newton.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/KRfw51BCtA-BZsFho5gWlP_pHLM=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25263748/DCD_Casey_Newton.jpg","asset":{"title":"A portrait of Platformer’s Casey Newton."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Decoder","slug":"decoder-podcast-with-nilay-patel","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Web","slug":"web","hubPage":{"uid":"HubPage:275"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Why Sen. Brian Schatz thinks child safety bills can trump the First Amendment","uid":"Entry:10172495-1b50-4866-972e-634357e1a287","url":"https://www.theverge.com/24054658/senator-brian-schatz-congress-kosa-first-amendment-regulation-decoder-interview","author":{"fullName":"Nilay Patel"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/sV86Uju0S2vugikVa8jvxPar6wk=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25254957/VRG_DCD_Brian_Schatz.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/HicYOfepJXbWiUdYGETCIze1u_c=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25254957/VRG_DCD_Brian_Schatz.jpg","asset":{"title":"A portrait of Sen. Brian Schatz of Hawaii."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Policy","slug":"policy","hubPage":{"uid":"HubPage:278"},"isInternal":false,"isStarred":false},{"name":"Politics","slug":"politics","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Decoder","slug":"decoder-podcast-with-nilay-patel","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Regulation","slug":"regulation","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Rep. Ro Khanna on what it will take for Congress to regulate AI, privacy, and social media","uid":"Entry:c8d4baaf-0dea-4cbd-b481-56374a6a6f0d","url":"https://www.theverge.com/24046797/ro-khanna-congress-tech-tiktok-regulation-california-politics-decoder-interview","author":{"fullName":"Nilay Patel"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/6JjfaLJV9WloCGkp5WjNoi8YIFY=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25241477/VRG_DCD_RoKhanna.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/jn3IRhS3vx3DI48CbLE2GGbV4_E=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25241477/VRG_DCD_RoKhanna.jpg","asset":{"title":null},"caption":{"plaintext":"A portrait of Rep. Ro Khanna."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Politics","slug":"politics","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Policy","slug":"policy","hubPage":{"uid":"HubPage:278"},"isInternal":false,"isStarred":false},{"name":"Regulation","slug":"regulation","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Decoder","slug":"decoder-podcast-with-nilay-patel","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"TikTok","slug":"tiktok","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Privacy","slug":"privacy","hubPage":null,"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP"},{"slug":"podcast","isInternal":false,"hubPage":null,"isDisclaimer":false,"description":"","uid":"EntryGroup:488","name":"Podcasts","url":"https://www.theverge.com/podcast","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The shine comes off the Vision Pro","uid":"Entry:f2db6c56-0102-4d83-952a-db4ff3d5a61b","url":"https://www.theverge.com/24074795/vision-pro-returns-xbox-future-gemini-open-ai-vergecast","author":{"fullName":"David Pierce"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/SOQWyhCJJvFnlEsKZ8gmUVMXHZU=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289245/VST_0216_Site_post.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/DqAb_g1MopjSr7PbSEfYE6yqXig=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289245/VST_0216_Site_post.jpg","asset":{"title":"An illustration of The Vergecast team, with a Vision Pro over top."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Vergecast","slug":"the-vergecast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How AI copyright lawsuits could make the whole industry go extinct","uid":"Entry:d34d1b3d-c20b-4cf2-bac3-2f9f9c1ce1cc","url":"https://www.theverge.com/24062159/ai-copyright-fair-use-lawsuits-new-york-times-openai-chatgpt-decoder-podcast","author":{"fullName":"Nilay Patel"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/1GaLsD1RllsYos7u9CP302kX6UA=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25286521/DCD_AI_Lawsuits_v2.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/7q4j1N1zox6Hz7RnWEuBWUEWbwA=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25286521/DCD_AI_Lawsuits_v2.jpg","asset":{"title":"Photo illustration of a statue of Lady Justice with pixelation and binary code texture"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Decoder","slug":"decoder-podcast-with-nilay-patel","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Decoder SAP AI Feb 2024 - internal","slug":"decoder-sap-ai-feb-2024","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Law","slug":"law","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Policy","slug":"policy","hubPage":{"uid":"HubPage:278"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"OpenAI","slug":"openai","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Passkeys might really kill passwords","uid":"Entry:787a97f4-3fca-4198-8249-fe2c083c66d9","url":"https://www.theverge.com/24071753/passkeys-password-manager-wearables-vergecast","author":{"fullName":"David Pierce"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/Yre0fqkR55Jyn2mgVdsHgyZY4cI=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283637/VST_0213_SitePost.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/7kMEFh1uJfLYBKg1ZTJM3raMEuw=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283637/VST_0213_SitePost.jpg","asset":{"title":"An illustration showing passkeys, smart rings, and a watch."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Vergecast","slug":"the-vergecast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Wearable","slug":"wearables","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Security","slug":"cyber-security","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"DOJ’s Jonathan Kanter says the antitrust fight against Big Tech is just beginning","uid":"Entry:b4c3961f-7e70-4eba-95b9-ada34221d06b","url":"https://www.theverge.com/24067873/jonathan-kanter-doj-antitrust-google-policy-monopoly-big-tech","author":{"fullName":"Nilay Patel"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/DZfHykGO8jpno4J41P1uhjtrNzU=/0x0:2760x1839/2760x1839/filters:focal(1380x920:1381x921)/cdn.vox-cdn.com/uploads/chorus_asset/file/25277274/Decoder_US_Assistant_Attorney_General_Jonathan_Kanter.png","variantUrl":"https://cdn.vox-cdn.com/thumbor/dBwHo95-fraHq0ROBQPlb0ex2bY=/0x0:2760x1839/100x100/filters:focal(1380x920:1381x921)/cdn.vox-cdn.com/uploads/chorus_asset/file/25277274/Decoder_US_Assistant_Attorney_General_Jonathan_Kanter.png","asset":{"title":"A portrait of US Assistant Attorney General Jonathan Kanter."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Policy","slug":"policy","hubPage":{"uid":"HubPage:278"},"isInternal":false,"isStarred":false},{"name":"Antitrust","slug":"antitrust","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Regulation","slug":"regulation","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Politics","slug":"politics","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Decoder","slug":"decoder-podcast-with-nilay-patel","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Google","slug":"google","hubPage":{"uid":"HubPage:274"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":null,"type":"STORY","promoHeadline":null,"title":"Disney’s big bets on sports, streaming, and Fortnite","uid":"Entry:436dc135-c1fb-473c-9f85-d44bd44d985b","url":"https://www.theverge.com/24067383/disney-sports-fortnite-hulu-vision-pro-vergecast","author":{"fullName":"David Pierce"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/qzvovJMPX3x2Q89GLzNIcBjgugc=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25276371/VST_0209_site.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/miyemWP3xhL82hvKQm-R5plW4MY=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25276371/VST_0209_site.jpg","asset":{"title":"An image of Bob Iger on top of a screenshot from The Vergecast."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Disney","slug":"disney","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Streaming","slug":"streaming-wars","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Vergecast","slug":"the-vergecast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP"},{"slug":"business","isInternal":false,"hubPage":{"slug":"business","uid":"HubPage:8139"},"isDisclaimer":false,"description":"","uid":"EntryGroup:20237","name":"Business","url":"https://www.theverge.com/business","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Microsoft’s gaming chief on Xbox games coming to PS5, next-gen hardware, and more","uid":"Entry:9bdaa1d2-131d-4617-b437-1cc6d5429e19","url":"https://www.theverge.com/24073666/microsoft-gaming-phil-spencer-interview-ps5-switch-games","author":{"fullName":"Tom Warren"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/A5m2UlEjzYD_nMaTin7rmG_kZ0k=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23951566/VRG_Illo_STK184_L_Normand_PhilSpencer_Neutral.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/Icz0U_IvuTAl27Qfmi2aXYdciGo=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23951566/VRG_Illo_STK184_L_Normand_PhilSpencer_Neutral.jpg","asset":{"title":"Illustration of Phil Spencer"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Microsoft","slug":"microsoft","hubPage":{"uid":"HubPage:273"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Xbox","slug":"microsoft-xbox","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Business","slug":"business","hubPage":{"uid":"HubPage:8139"},"isInternal":false,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Microsoft’s Xbox Game Pass service grows to 34 million subscribers","uid":"Entry:3e8e7098-1a05-43f6-8068-f242fe77f67e","url":"https://www.theverge.com/2024/2/15/23570040/microsoft-xbox-game-pass-subscriber-numbers-34-million","author":{"fullName":"Tom Warren"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/2E0SCvlleyS469irAzieu_klYuk=/0x0:2040x1334/2040x1334/filters:focal(1020x667:1021x668)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283724/STK048_XBOX_C.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/_22LaVpmcytH-wMV0Cb_BCE6PgU=/0x0:2040x1334/100x100/filters:focal(1020x667:1021x668)/cdn.vox-cdn.com/uploads/chorus_asset/file/25283724/STK048_XBOX_C.jpg","asset":{"title":"Vector illustration of the Xbox logo."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Microsoft","slug":"microsoft","hubPage":{"uid":"HubPage:273"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Xbox","slug":"microsoft-xbox","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"PC Gaming","slug":"pc-gaming","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Business","slug":"business","hubPage":{"uid":"HubPage:8139"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Walmart might buy Vizio to win the fight over cheap TVs","uid":"Entry:78c8bda4-1f6a-47c7-90d0-115c8be4c9f6","url":"https://www.theverge.com/2024/2/13/24072191/walmart-vizio-smart-tv-acquisition-rumor","author":{"fullName":"Emma Roth"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/2JJvzTN33lr15FW0W_l4cT-34Bw=/0x0:3800x2533/3800x2533/filters:focal(2181x1427:2182x1428)/cdn.vox-cdn.com/uploads/chorus_asset/file/25284648/1519962805.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/NfFYwvQTsoGUJlhNOgtor6pQviU=/0x0:3800x2533/100x100/filters:focal(2181x1427:2182x1428)/cdn.vox-cdn.com/uploads/chorus_asset/file/25284648/1519962805.jpg","asset":{"title":"A photo showing the TV aisle at Walmart"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"TVs","slug":"televisions","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Amazon","slug":"amazon","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Business","slug":"business","hubPage":{"uid":"HubPage:8139"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The US government makes a $42 million bet on open cell networks","uid":"Entry:1e44ea53-7959-4334-99f8-b6e5e68be187","url":"https://www.theverge.com/2024/2/12/24070550/open-ran-standard-us-funding-5g-huawei","author":{"fullName":"Wes Davis"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/jR8xgg0RtLV_xHmLdl8W3vtITvI=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/20015711/VRG_ILLO_4037_5G_001.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/wG4H4hNxpi5gX6PZgYMRa8TMuqo=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/20015711/VRG_ILLO_4037_5G_001.jpg","asset":{"title":"A stylized image of a 5G cell tower."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Business","slug":"business","hubPage":{"uid":"HubPage:8139"},"isInternal":false,"isStarred":false},{"name":"Regulation","slug":"regulation","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Politics","slug":"politics","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Policy","slug":"policy","hubPage":{"uid":"HubPage:278"},"isInternal":false,"isStarred":false},{"name":"AT\u0026T","slug":"att","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Mobile","slug":"mobile","hubPage":{"uid":"HubPage:282"},"isInternal":false,"isStarred":false},{"name":"Verizon","slug":"verizon","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Slackers","uid":"Entry:0e1a979a-9070-4343-81b9-bf06192be7cf","url":"https://www.theverge.com/24070725/slack-ten-year-anniversary-retrospective-groupchat-workplace","author":{"fullName":"Elizabeth Lopatto"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/eB_I9xnL49Z5PYh5Dc1rWEVx3kQ=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25277622/246983_Slack_10_Year_Anniversary_final_CVirginia.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/FE6_1klzOiiDSrg-EC2iksFyqJs=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25277622/246983_Slack_10_Year_Anniversary_final_CVirginia.jpg","asset":{"title":"Illustration of a water cooler surrounded by emoji reactions and speech bubbles."},"caption":{"plaintext":"[AC/DC voice] Back in Slack."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Slack","slug":"slack","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"Internet Culture","slug":"internet-culture","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Business","slug":"business","hubPage":{"uid":"HubPage:8139"},"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP"},{"slug":"featured-story","isInternal":false,"hubPage":null,"isDisclaimer":false,"description":"","uid":"EntryGroup:63067","name":"Featured Stories","url":"https://www.theverge.com/featured-story","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Microsoft’s gaming chief on Xbox games coming to PS5, next-gen hardware, and more","uid":"Entry:9bdaa1d2-131d-4617-b437-1cc6d5429e19","url":"https://www.theverge.com/24073666/microsoft-gaming-phil-spencer-interview-ps5-switch-games","author":{"fullName":"Tom Warren"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/A5m2UlEjzYD_nMaTin7rmG_kZ0k=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23951566/VRG_Illo_STK184_L_Normand_PhilSpencer_Neutral.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/Icz0U_IvuTAl27Qfmi2aXYdciGo=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23951566/VRG_Illo_STK184_L_Normand_PhilSpencer_Neutral.jpg","asset":{"title":"Illustration of Phil Spencer"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Microsoft","slug":"microsoft","hubPage":{"uid":"HubPage:273"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Xbox","slug":"microsoft-xbox","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Business","slug":"business","hubPage":{"uid":"HubPage:8139"},"isInternal":false,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How AI copyright lawsuits could make the whole industry go extinct","uid":"Entry:d34d1b3d-c20b-4cf2-bac3-2f9f9c1ce1cc","url":"https://www.theverge.com/24062159/ai-copyright-fair-use-lawsuits-new-york-times-openai-chatgpt-decoder-podcast","author":{"fullName":"Nilay Patel"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/1GaLsD1RllsYos7u9CP302kX6UA=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25286521/DCD_AI_Lawsuits_v2.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/7q4j1N1zox6Hz7RnWEuBWUEWbwA=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25286521/DCD_AI_Lawsuits_v2.jpg","asset":{"title":"Photo illustration of a statue of Lady Justice with pixelation and binary code texture"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Decoder","slug":"decoder-podcast-with-nilay-patel","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Decoder SAP AI Feb 2024 - internal","slug":"decoder-sap-ai-feb-2024","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Law","slug":"law","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Policy","slug":"policy","hubPage":{"uid":"HubPage:278"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"OpenAI","slug":"openai","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"In defense of busywork","uid":"Entry:af6d2816-25d0-4dbe-8732-8380b8071152","url":"https://www.theverge.com/24066270/ai-automation-work-labor-busywork","author":{"fullName":"Lauren Larson"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/a0sSF7K3LQdbx8RvAS-hSzGp3Uc=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25284882/246992_AI_at_Work_BUSYWORK_ECarter.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/sW2YcWEfn_Il4jgPQ7wnlyRPtOs=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25284882/246992_AI_at_Work_BUSYWORK_ECarter.jpg","asset":{"title":"3D illustration of a robot bored at a desk."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Web","slug":"web","hubPage":{"uid":"HubPage:275"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Labor","slug":"labor","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How AI can make history","uid":"Entry:291d6974-79eb-4973-aa39-1cc359862e87","url":"https://www.theverge.com/24068716/ai-historians-academia-llm-chatgpt","author":{"fullName":"Josh Dzieza"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/5IjLi9B8cGcXyQufizLUvVb4KFE=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25284881/246992_AI_at_Work_HISTORIANS_ECarter.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/2Y2Q3VJ-tMxP7u4CFEyzydcwzXI=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25284881/246992_AI_at_Work_HISTORIANS_ECarter.jpg","asset":{"title":"3D illustration of a robot reading lots of books."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Web","slug":"web","hubPage":{"uid":"HubPage:275"},"isInternal":false,"isStarred":false},{"name":"Internet Culture","slug":"internet-culture","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Culture","slug":"culture","hubPage":{"uid":"HubPage:15811"},"isInternal":false,"isStarred":false},{"name":"OpenAI","slug":"openai","hubPage":null,"isInternal":false,"isStarred":false},{"name":"AI Business Week Feb 2024 - internal ","slug":"ai-business-week-feb-2024","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Apple fans are starting to return their Vision Pros","uid":"Entry:96b59ea1-73e0-4f45-b592-db77c6e478e2","url":"https://www.theverge.com/2024/2/14/24072792/apple-vision-pro-early-adopters-returns","author":{"fullName":"Victoria Song"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/EjivyEm3pfwG9BfmgeNPHwspwWw=/0x0:2700x1800/2700x1800/filters:focal(1350x900:1351x901)/cdn.vox-cdn.com/uploads/chorus_asset/file/25255195/246965_vision_pro_VPavic_0034.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/p2CbylhY2aE6JbVolC3OoNFSPjY=/0x0:2700x1800/100x100/filters:focal(1350x900:1351x901)/cdn.vox-cdn.com/uploads/chorus_asset/file/25255195/246965_vision_pro_VPavic_0034.jpg","asset":{"title":"The Vision Pro sitting next to its battery."},"caption":{"plaintext":"It doesn’t help that there’s no real killer app yet."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Gadgets","slug":"gadgets","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Virtual Reality","slug":"vr-virtual-reality","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Augmented Reality","slug":"augmented-reality","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Wearable","slug":"wearables","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP"},{"slug":"ai-artificial-intelligence","isInternal":false,"hubPage":{"slug":"ai-artificial-intelligence","uid":"HubPage:17957"},"isDisclaimer":false,"description":"Artificial intelligence is more a part of our lives than ever before. While some might call it hype and compare it to NFTs or 3D TVs, AI is causing a sea change in nearly every facet of life that technology touches. Bing wants to know you intimately, Bard wants to reduce websites to easy-to-read cards, and ChatGPT has infiltrated nearly every part of our lives. At The Verge, we’re exploring all the good AI is enabling and all the bad it’s bringing along.","uid":"EntryGroup:45647","name":"Artificial Intelligence","url":"https://www.theverge.com/ai-artificial-intelligence","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Interview: Figma’s CEO on life after the company’s failed sale to Adobe","uid":"Entry:fdc979c4-8ca1-4529-9b87-73ff4e9fc771","url":"https://www.theverge.com/2024/2/16/24075126/figma-ceo-dylan-field-interview-after-adobe","author":{"fullName":"Alex Heath"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/_h6TOd1_tIgIDNFyrkYYvh_dn2A=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/GAN_VXedqCF0aB11s1jGNOkBgJQ=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","asset":{"title":"Figma CEO Dylan Field."},"caption":{"plaintext":"Figma CEO Dylan Field."}},"promoImage":null,"communityGroups":[{"name":"Command Line","slug":"command-line-newsletter","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Design","slug":"design","hubPage":{"uid":"HubPage:8137"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Adobe","slug":"adobe","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The shine comes off the Vision Pro","uid":"Entry:f2db6c56-0102-4d83-952a-db4ff3d5a61b","url":"https://www.theverge.com/24074795/vision-pro-returns-xbox-future-gemini-open-ai-vergecast","author":{"fullName":"David Pierce"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/SOQWyhCJJvFnlEsKZ8gmUVMXHZU=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289245/VST_0216_Site_post.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/DqAb_g1MopjSr7PbSEfYE6yqXig=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289245/VST_0216_Site_post.jpg","asset":{"title":"An illustration of The Vergecast team, with a Vision Pro over top."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Vergecast","slug":"the-vergecast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":"Spike Jonze’s Her holds up a decade later","title":"Her?","uid":"Entry:6692a09c-7b1a-48c3-9aa5-cd3950f24d49","url":"https://www.theverge.com/24066233/her-ai-film-spike-jonze-joaquin-phoenix-scarlett-johansson","author":{"fullName":"Sheon Han"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/yPuezr_u7k4fJnjmWX4yKfBzIjU=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289339/246992_AI_at_Work_FILM_ECarter.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/FXaUCGeB1hxGGQnsNbNsexs_gyY=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289339/246992_AI_at_Work_FILM_ECarter.jpg","asset":{"title":"3D illustration of a robot version of “The Thinker”."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Film","slug":"film","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Internet Culture","slug":"internet-culture","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Culture","slug":"culture","hubPage":{"uid":"HubPage:15811"},"isInternal":false,"isStarred":false},{"name":"AI Business Week Feb 2024 - internal ","slug":"ai-business-week-feb-2024","hubPage":null,"isInternal":true,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"You sound like a bot","uid":"Entry:4915136c-e61c-4051-ba76-dba6753c7037","url":"https://www.theverge.com/24067999/ai-bot-chatgpt-chatbot-dungeon","author":{"fullName":"Adi Robertson"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/FUjMNb0KI3OkAHZEgVBbBjEfMN8=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25288449/246992_AI_at_Work_BORING_ECarter.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/8MQgX5gg6YEAtzJ0Rbcc_lf2jUg=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25288449/246992_AI_at_Work_BORING_ECarter.jpg","asset":{"title":"3D illustration of a robot rubber stamping a text file."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Web","slug":"web","hubPage":{"uid":"HubPage:275"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Internet Culture","slug":"internet-culture","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"OpenAI","slug":"openai","hubPage":null,"isInternal":false,"isStarred":false},{"name":"AI Business Week Feb 2024 - internal ","slug":"ai-business-week-feb-2024","hubPage":null,"isInternal":true,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How much electricity does AI consume?","uid":"Entry:5ac41b31-8a49-406a-9d84-6b000b151e37","url":"https://www.theverge.com/24066646/ai-electricity-energy-watts-generative-consumption","author":{"fullName":"James Vincent"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/dNYPsHwH0BlQzOXTa4zHHf6ttdE=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25288452/246992_AI_at_Work_REAL_COST_ECarter.png","variantUrl":"https://cdn.vox-cdn.com/thumbor/LnEd9SBhjnZs0PfUKLA1JUBIUCs=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25288452/246992_AI_at_Work_REAL_COST_ECarter.png","asset":{"title":"Pixel illustration of a computer generation an image connected to many electrical outlets at once."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Web","slug":"web","hubPage":{"uid":"HubPage:275"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Energy","slug":"energy","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Science","slug":"science","hubPage":{"uid":"HubPage:6949"},"isInternal":false,"isStarred":false},{"name":"OpenAI","slug":"openai","hubPage":null,"isInternal":false,"isStarred":false},{"name":"AI Business Week Feb 2024 - internal ","slug":"ai-business-week-feb-2024","hubPage":null,"isInternal":true,"isStarred":false}]}]},"type":"SITE_GROUP"},{"slug":"tech","isInternal":false,"hubPage":{"slug":"tech","uid":"HubPage:8135"},"isDisclaimer":false,"description":"The latest tech news about the world's best (and sometimes worst) hardware, apps, and much more. From top companies like Google and Apple to tiny startups vying for your attention, Verge Tech has the latest in what matters in technology daily.","uid":"EntryGroup:21019","name":"Tech","url":"https://www.theverge.com/tech","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The Nintendo Switch 2 will now reportedly arrive in 2025 instead of 2024","uid":"Entry:beee2677-e972-4e4e-898c-fa9f20cfc826","url":"https://www.theverge.com/2024/2/16/24075174/switch-2-launch-date-rumor-q1-2025","author":{"fullName":"Ash Parrish"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/lA9CG498doJGjG9JOisq1_T8jow=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/0mSe0c0D5D_NAUpnNO9RfWG7yqs=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg","asset":{"title":"Stock image illustration featuring the Nintendo logo stamped in black on a background of tan, blue, and black color blocking."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Nintendo","slug":"nintendo","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The best Presidents Day deals you can already get","uid":"Entry:ae3462ed-d729-4045-b0ee-fa4a4cc6cd0f","url":"https://www.theverge.com/24072881/best-presidents-day-sales-deals-2024-apple-tvs-gaming-headphones-smartwatches","author":{"fullName":"Quentyn Kennemer"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/44HX0exmF1grR1zLh7d_8sauDaA=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/m1tVM4z2Whd6IFJ-Vo8SNn_oMoY=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg","asset":{"title":"Apple AirPods Pro"},"caption":{"plaintext":"There’s plenty of tech on sale for Presidents Day, from AirPods to OLED TVs and everything in between."}},"promoImage":null,"communityGroups":[{"name":"Deals","slug":"good-deals","hubPage":{"uid":"HubPage:17413"},"isInternal":false,"isStarred":false},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Logitech","slug":"logitech","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Smart Home","slug":"smart-home","hubPage":{"uid":"HubPage:279"},"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"TVs","slug":"televisions","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Wearable","slug":"wearables","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Headphones","slug":"headphone","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Laptops","slug":"laptops","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"PC Gaming","slug":"pc-gaming","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Cameras and Photography","slug":"photography","hubPage":{"uid":"HubPage:280"},"isInternal":false,"isStarred":false},{"name":"Mobile","slug":"mobile","hubPage":{"uid":"HubPage:282"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Interview: Figma’s CEO on life after the company’s failed sale to Adobe","uid":"Entry:fdc979c4-8ca1-4529-9b87-73ff4e9fc771","url":"https://www.theverge.com/2024/2/16/24075126/figma-ceo-dylan-field-interview-after-adobe","author":{"fullName":"Alex Heath"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/_h6TOd1_tIgIDNFyrkYYvh_dn2A=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/GAN_VXedqCF0aB11s1jGNOkBgJQ=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","asset":{"title":"Figma CEO Dylan Field."},"caption":{"plaintext":"Figma CEO Dylan Field."}},"promoImage":null,"communityGroups":[{"name":"Command Line","slug":"command-line-newsletter","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Design","slug":"design","hubPage":{"uid":"HubPage:8137"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Adobe","slug":"adobe","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Vudu’s name is changing to ‘Fandango at Home’","uid":"Entry:fcb3c34d-db2e-4a74-bc4d-cb54ff107c67","url":"https://www.theverge.com/2024/2/16/24075041/vudu-fandango-at-home-rebranding-new-name","author":{"fullName":"Chris Welch"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/OfW7xmYlzZXLOKRrVJZn4j8QUwY=/0x0:1080x716/1080x716/filters:focal(540x358:541x359)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/DfDuP6neKkLLh9MLWj1y3SHqW94=/0x0:1080x716/100x100/filters:focal(540x358:541x359)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg","asset":{"title":"An image announcing Vudu’s rebranding to Fandango at Home."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Apps","slug":"apps","hubPage":{"uid":"HubPage:277"},"isInternal":false,"isStarred":false},{"name":"Streaming","slug":"streaming-wars","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Amazon — like SpaceX — claims the labor board is unconstitutional","uid":"Entry:0fa52d0e-c11f-4c47-a2fe-263bdccbc61e","url":"https://www.theverge.com/2024/2/16/24074954/amazon-labor-board-nlrb-unconstitutional","author":{"fullName":"Emma Roth"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/-DH_98tyCltbrWTMSUoI7BLSJ1g=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23935561/acastro_STK103__04.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/VMv_ykKU3cj2UPdBp71ECWSYPpI=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23935561/acastro_STK103__04.jpg","asset":{"title":"Illustration showing Amazon’s logo on a black, orange, and tan background, formed by outlines of the letter “A.”"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Amazon","slug":"amazon","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"SpaceX","slug":"spacex","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Space","slug":"space","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Science","slug":"science","hubPage":{"uid":"HubPage:6949"},"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP"},{"slug":"google","isInternal":false,"hubPage":{"slug":"google","uid":"HubPage:274"},"isDisclaimer":false,"description":"The name Google is synonymous with online searches, but over the years the company has grown beyond search and now builds multiple consumer products, including software like Gmail, Chrome, Maps, Android, and hardware like the Pixel smartphones, Google Home, and Chromebooks. Its name can also be found on internet services such as Google Fi, Flights, Checkout, and Google Fiber. Here is all of the latest news about one of the most influential tech companies in the world.","uid":"EntryGroup:55","name":"Google","url":"https://www.theverge.com/google","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Android 15’s first developer preview has arrived","uid":"Entry:7df5e8e7-3a59-4d6b-abf9-6674bf11cbfb","url":"https://www.theverge.com/2024/2/16/24074987/android-15-developer-preview-vanilla-ice-cream","author":{"fullName":"Allison Johnson"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/54In107GmPKV5pqRt0a_bP0hcg0=/0x0:1752x1314/1752x1314/filters:focal(876x657:877x658)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289658/vic_green_1024x1024.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/dqUmXwaE0PnbQEsBvZVTz9x1pBs=/0x0:1752x1314/100x100/filters:focal(876x657:877x658)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289658/vic_green_1024x1024.jpg","asset":{"title":"Android 15 logo with a v-shaped badge."},"caption":{"plaintext":"Android 15 is beaming down from the mother ship."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Google","slug":"google","hubPage":{"uid":"HubPage:274"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Android","slug":"android","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Mobile","slug":"mobile","hubPage":{"uid":"HubPage:282"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The OnePlus 12R is a $500 phone with flagship tendencies","uid":"Entry:4b789e61-1494-457d-a2db-8980ea673126","url":"https://www.theverge.com/24072383/oneplus-12r-review-screen-camera-price","author":{"fullName":"Allison Johnson"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/LazH2qZc6v6JpdgNL_l6SX0MLk0=/0x0:2000x1333/2000x1333/filters:focal(1000x667:1001x668)/cdn.vox-cdn.com/uploads/chorus_asset/file/25287583/DSC06615.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/lNmPj7BImrSiUA-aAE5xmjGKkdE=/0x0:2000x1333/100x100/filters:focal(1000x667:1001x668)/cdn.vox-cdn.com/uploads/chorus_asset/file/25287583/DSC06615.jpg","asset":{"title":"OnePlus 12R on a green background with back panel facing up surrounded by blue translucent squares."},"caption":{"plaintext":"The OnePlus 12R offers a sleek build and a fantastic screen for just $500."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Reviews","slug":"reviews","hubPage":{"uid":"HubPage:16727"},"isInternal":false,"isStarred":true},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Phone Reviews","slug":"phone-review","hubPage":{"uid":"HubPage:15817"},"isInternal":false,"isStarred":false},{"name":"OnePlus","slug":"oneplus","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Mobile","slug":"mobile","hubPage":{"uid":"HubPage:282"},"isInternal":false,"isStarred":false},{"name":"Android","slug":"android","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Google","slug":"google","hubPage":{"uid":"HubPage:274"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Google offers non-Pixel owners a way to avoid waiting on hold with latest test","uid":"Entry:f4043a6b-25f1-4c89-8c3b-597e05ae1b4f","url":"https://www.theverge.com/2024/2/16/24074715/google-talk-to-a-live-representative-assistant-hold-phone-call","author":{"fullName":"Jon Porter"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/6s0tJ99zTuYSV-8YuUP-H3a2jIg=/0x0:854x568/854x568/filters:focal(427x284:428x285)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289137/GGZZMDwXsAAUfIc.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/970FFat98CPriOBlm8QYTTPHhj4=/0x0:854x568/100x100/filters:focal(427x284:428x285)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289137/GGZZMDwXsAAUfIc.jpg","asset":{"title":"Screenshot of description of beta test."},"caption":{"plaintext":"Google’s description of the feature in Search Labs."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Google","slug":"google","hubPage":{"uid":"HubPage:274"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Google Assistant","slug":"google-assistant","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How to make the most of Google Keep","uid":"Entry:5c5012b3-110d-43a8-a1fa-9c560b4d5c62","url":"https://www.theverge.com/24073806/google-keep-how-to-note-app","author":{"fullName":"David Nield"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/MCSLGI2GbkS8KmTwKhby7PZXxvg=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25287814/HT012_Google_Keep.png","variantUrl":"https://cdn.vox-cdn.com/thumbor/BCA6XyYcswWyRTufiBbQ9NsdM5Y=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25287814/HT012_Google_Keep.png","asset":{"title":"Vector collage showing different aspects of Google Keep."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"How to","slug":"how-to","hubPage":null,"isInternal":false,"isStarred":true},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Google","slug":"google","hubPage":{"uid":"HubPage:274"},"isInternal":false,"isStarred":false},{"name":"Apps","slug":"apps","hubPage":{"uid":"HubPage:277"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Gemini 1.5 is Google’s next-gen AI model — and it’s already almost ready","uid":"Entry:4f829b0d-2228-4c61-99be-734d094279af","url":"https://www.theverge.com/2024/2/15/24073457/google-gemini-1-5-ai-model-llm","author":{"fullName":"David Pierce"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/d-2Z4TC_N3CiXCKsqw0B1u4Yk0Y=/0x0:2700x1800/2700x1800/filters:focal(1350x900:1351x901)/cdn.vox-cdn.com/uploads/chorus_asset/file/25276810/247017_Google_Gemini_AKrales_0004.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/xDfOzodBNYgARGny0BCuz4_InBA=/0x0:2700x1800/100x100/filters:focal(1350x900:1351x901)/cdn.vox-cdn.com/uploads/chorus_asset/file/25276810/247017_Google_Gemini_AKrales_0004.jpg","asset":{"title":"Phone in hand showing Google Gemini welcome screen."},"caption":{"plaintext":"Gemini is still new — and it’s already getting an upgrade."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Google","slug":"google","hubPage":{"uid":"HubPage:274"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false}]}]},"type":"SITE_GROUP"}],"primaryCommunityGroup":{"slug":"front-page","parentEntryGroup":null,"name":"Front Page","isInternal":false},"primaryPackageGroup":null,"__isEntryRevision":"Entry","body":{"components":[{"__typename":"EntryBodyParagraph","placement":{"id":"wueYn5","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Today, I’m talking to Demis Hassabis, the CEO of Google DeepMind, the newly created division of Google responsible for AI efforts across the company. Google DeepMind is the result of an internal merger: Google acquired Demis’ DeepMind startup in 2014 and ran it as a separate company inside its parent company, Alphabet, while Google itself had an AI team called Google Brain. "},"dropcap":true,"endmark":false,"lead":true},{"__typename":"EntryBodyParagraph","placement":{"id":"FBq5gj","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Google has been showing off AI demos for years now, but with the explosion of ChatGPT and a renewed threat from Microsoft in search, Google and Alphabet CEO Sundar Pichai made the decision to bring DeepMind into Google itself earlier this year to create… Google DeepMind."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"Ddvids","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"What’s interesting is that Google Brain and DeepMind were not necessarily compatible or even focused on the same things: DeepMind was famous for applying AI to things like games and protein-folding simulations. The \u003ca href=\"https://www.theverge.com/2019/11/27/20985260/ai-go-alphago-lee-se-dol-retired-deepmind-defeat\"\u003eAI that beat world champions at Go\u003c/a\u003e, the ancient board game? That was DeepMind’s AlphaGo. Meanwhile, Google Brain was more focused on what’s come to be the familiar generative AI toolset: large language models for chatbots, editing features in Google Photos, and so on. This was a culture clash and a big structure decision with the goal of being more competitive and faster to market with AI products."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"bToi4k","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"And the competition isn’t just OpenAI and Microsoft — you might have seen \u003ca href=\"https://fortune.com/2023/05/09/a-leaked-google-memo-raises-questions-about-open-source-a-i-but-the-white-house-doesnt-seem-to-have-gotten-it/\"\u003ea memo from a Google engineer\u003c/a\u003e floating around the web recently claiming that Google has no competitive moat in AI because open-source models running on commodity hardware are rapidly evolving and catching up to the tools run by the giants. Demis confirmed that the memo was real but said it was part of Google’s debate culture, and he disagreed with it because he has other ideas about where Google’s competitive edge might come into play."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"StQkSZ","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Of course, we also talked about AI risk and especially artificial general intelligence. Demis is not shy that his goal is building an AGI, and we talked through what risks and regulations should be in place and on what timeline. Demis recently signed onto a \u003ca href=\"https://www.theverge.com/2023/5/30/23742005/ai-risk-warning-22-word-statement-google-deepmind-openai\"\u003e22-word statement about AI risk\u003c/a\u003e with OpenAI’s Sam Altman and others that simply reads, “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.” That’s pretty chill, but is that the real risk right now? Or is it just a distraction from other more tangible problems like AI replacing a bunch of labor in various creative industries? We also talked about the new kinds of labor AI is \u003cem\u003ecreating\u003c/em\u003e — armies of low-paid taskers classifying data in countries like Kenya and India in order to train AI systems. We just published a big feature on these taskers. I wanted to know if Demis thought these jobs were here to stay or just a temporary side effect of the AI boom."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"iMNorG","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"This one really hits all the \u003cem\u003eDecoder\u003c/em\u003e high points: there’s the big idea of AI, a lot of problems that come with it, an infinite array of complicated decisions to be made, and of course, a gigantic org chart decision in the middle of it all. Demis and I got pretty in the weeds, and I still don’t think we covered it all, so we’ll have to have him back soon."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"gV1VDc","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Alright, Demis Hassabis, CEO of Google DeepMind. Here we go."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHTML","placement":{"id":"XHVOH8","alignment":null},"__isEntryBodyComponent":"EntryBodyHTML","rawHtml":"\u003ciframe frameborder=\"0\" height=\"200\" scrolling=\"no\" src=\"https://playlist.megaphone.fm/?e=VMP3975282129\" width=\"100%\"\u003e\u003c/iframe\u003e"},{"__typename":"EntryBodyParagraph","placement":{"id":"tW3PzM","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cem\u003eThis transcript has been lightly edited for length and clarity\u003c/em\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"jaunZb","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eDemis Hassabis, you are the CEO of Google DeepMind. Welcome to \u003cem\u003eDecoder\u003c/em\u003e.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"4CirGd","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Thanks for having me."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"61nGwL","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eI don’t think we have ever had a more perfect \u003cem\u003eDecoder\u003c/em\u003e guest. There’s a big idea in AI. It comes with challenges and problems, and then, with you in particular, there’s a gigantic org chart move and a set of high-stakes decisions to be made. I am thrilled that you are here.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"CSsC2p","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Glad to be here."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"M6Az3x","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eLet’s start with Google DeepMind itself. Google DeepMind is a new part of Google that is constructed of two existing parts of Google. There was Google Brain, which was the AI team we were familiar with as we covered Google that was run by Jeff Dean. And there was DeepMind, which was your company that you founded. You sold it to Alphabet in 2014. You were outside of Google. It was run as a separate company inside that holding company Alphabet structure until just now. Start at the very beginning. Why were DeepMind and Google Brain separate to begin with?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"kSN0J9","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"As you mentioned, we started DeepMind actually back in 2010, a long time ago now, especially in the age of AI. So that’s sort of like prehistory. Myself and the co-founders, we realized coming from academia and seeing what was going on there, things like deep learning had just been invented. We were big proponents of reinforcement learning. We could see GPUs and other hardware was coming online, that a lot of great progress could be made with a focused effort on general learning systems and also taking some ideas from neuroscience and how the brain works. So we put all those ingredients together back in 2010. We had this thesis we’d make fast progress, and that’s what happened with our initial game systems. And then, we decided in 2014 to join forces with Google at the time because we could see that a lot more compute was going to be needed. Obviously, Google has the most computers and had the most computers in the world. That was the obvious home for us to be able to focus on pushing the research as fast as possible. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"QTYRnG","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eSo you were acquired by Google, and then somewhere along the way, Google reoriented itself. They turned into Alphabet, and Google became a division of Alphabet. There are other divisions of Alphabet, and DeepMind was out of it. That’s just the part I want to focus on here at the beginning, because there was what Google was doing with Google Brain, which is a lot of LLM research. I recall, six years ago, Google was showing off LLMs at Google I/O, but DeepMind was focused on winning the game [Go] and protein folding, a very different kind of AI research wholly outside of Google. Why was that outside of Google? Why was that in Alphabet proper?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodySidebar","placement":{"id":"UjjDkP","alignment":"HANG_LEFT"},"__isEntryBodyComponent":"EntryBodySidebar","sidebar":{"body":[{"__typename":"EntryBodyParagraph","contents":{"html":""},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyImage","contentWarning":"","image":{"url":"https://cdn.vox-cdn.com/thumbor/ROZOugNkLXkQJVP30tl2R8ozzbc=/0x0:3000x3000/3000x3000/filters:focal(1500x1500:1501x1501)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg","height":3000,"width":3000,"hideCredit":false,"caption":null,"credit":null,"asset":{"title":null}},"placement":{"alignment":null}},{"__typename":"EntryBodyParagraph","contents":{"html":"Listen to \u003cem\u003eDecoder\u003c/em\u003e, a show hosted by \u003cem\u003eThe Verge\u003c/em\u003e’s Nilay Patel about big ideas — and other problems. Subscribe \u003ca href=\"https://podcasts.apple.com/us/podcast/welcome-to-decoder/id1011668648?i=1000496212371\u0026itsct=podcast_box\u0026itscg=30200\u0026ls=1\u0026at=1001l7uV\u0026ct=verge091322\"\u003ehere\u003c/a\u003e!"},"dropcap":false,"endmark":false,"lead":false}]}},{"__typename":"EntryBodyParagraph","placement":{"id":"qBauTF","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"That was part of the agreement as we were acquired was that we would pursue pushing forward research into general AI, or sometimes called AGI, a system that out of the box can operate across a wide range of cognitive tasks and basically has all the cognitive capabilities that humans have."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"gLzH6g","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"And also using AI to accelerate scientific discovery, that’s one of my personal passions. And that explains projects like AlphaFold that I’m sure we’re going to get back to. But also, from the start of DeepMind and actually prior to even DeepMind starting, I believe that games was a perfect testing or proving ground for developing AI algorithms efficiently, quickly, and you can generate a lot of data and the objective functions are very clear: obviously, winning games or maximizing the score. There were a lot of reasons to use games in the early days of AI research, and that was a big part of why we were so successful and why we were able to advance so quickly with things like AlphaGo, the program that beat the world champion at the ancient game of Go."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"O5RWEu","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Those were all really important proof points for the whole field really that these general learning techniques would work. And of course we’ve done a lot of work on deep learning and neural networks as well. And our specialty, I suppose, was combining that with reinforcement learning to allow these systems to actively solve problems and make plans and do things like win games. And in terms of the differences, we always had that remit to push the research agenda and push things, advanced science. And that was very much the focus we were given and very much the focus that I wanted to have. And then, the internal Google AI teams like Google Brain, they had slightly different remits and were a bit closer to product and obviously to the rest of Google and infusing Google with amazing AI technology. And we also had an applied division that was introducing DeepMind technology into Google products, too. But the cultures were quite different, and the remits were quite different."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyRelatedList","placement":{"id":"616gbd","alignment":"HANG_LEFT"},"__isEntryBodyComponent":"EntryBodyRelatedList","items":[{"title":"Bing, Bard, and ChatGPT: AI chatbots are rewriting the internet ","url":"https://www.theverge.com/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai"},{"title":"Google confirms it’s training Bard on scraped web data, too","url":"https://www.theverge.com/2023/7/5/23784257/google-ai-bard-privacy-policy-train-web-scraping"}]},{"__typename":"EntryBodyParagraph","placement":{"id":"Yw3tKW","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eFrom the outside, the timeline looks like this: everyone’s been working on this for ages, we’ve all been talking about it for ages. It is a topic of conversation for a bunch of nerdy journalists like me, a bunch of researchers, we talk about it in the corner at Google events. \u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"kkzv0H","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eThen ChatGPT is released, not even as a product. I don’t even think Sam [Altman] would call it a great product when it was released, but it was just released, and people could use it. And everyone freaked out, and Microsoft releases Bing based on ChatGPT, and the world goes upside down, and Google reacts by merging DeepMind and Google Brain. That’s what it looks like from the outside. Is that what it felt like from the inside?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"vcMjGY","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"That timeline is correct, but it’s not these direct consequences; it’s more indirect in a sense. So, Google and Alphabet have always run like this. They let many flowers bloom, and I think that’s always been the way that even from Larry [Page] and Sergey [Brin] from the beginning set up Google. And it served them very well, and it’s allowed them to organically create incredible things and become the amazing company that it is today. On the research side, I think it’s very compatible with doing research, which is another reason we chose Google as our partners back in 2014. I felt they really understood what fundamental and blue sky research was, ambitious research was, and they were going to facilitate us being and enable us to be super ambitious with our research. And you’ve seen the results of that, right?"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyPullquote","placement":{"id":"omdHoP","alignment":"HANG_LEFT"},"__isEntryBodyComponent":"EntryBodyPullquote","quote":{"html":"“...AI has entered a new era.”"}},{"__typename":"EntryBodyParagraph","placement":{"id":"N8tYVD","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"By any measure, AlphaGo, AlphaFold, but more than 20 nature and science papers and so on — all the normal metrics one would use for really delivering amazing cutting-edge research we were able to do. But in a way, what ChatGPT and the large models and the public reaction to that confirmed is that AI has entered a new era. And by the way, it was a little bit surprising for all of us \u003ca href=\"https://dictionary.cambridge.org/us/dictionary/english/at-the-coalface\"\u003eat the coalface\u003c/a\u003e, including OpenAI, how viral that went because — us and some other startups like Anthropic and OpenAI — we all had these large language models. They were roughly the same capabilities. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"6xDNv0","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"And so, it was surprising, not so much what the technology was because we all understood that, but the public’s appetite for that and obviously the buzz that generated. And I think that’s indicative of something we’ve all been feeling for the last, I would say, two, three years, which is these systems are reaching a level of maturity now and sophistication where it can really come out of the research phase and the lab and go into powering incredible next-generation products and experiences and also breakthroughs, things like AlphaFold directly being useful for biologists. And so, to me, this is just indicative of a new phase that AI is in of being practically useful to people in their everyday lives and actually being able to solve really hard real-world problems that really matter, not just the curiosities or fun, like games."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"2uKD2S","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"When you recognize that shift, then I think that necessitates a change in your approach as to how you’re approaching the research and how much focus you’re having on products and those kinds of things. And I think that’s what we all came to the realization of, which was: now was the time to streamline our AI efforts and focus them more. And the obvious conclusion of that was to do the merger."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"SfOM78","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eI want to just stop there for one second and ask a philosophical question.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"oW3y7A","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Sure."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"howM30","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eIt feels like the ChatGPT moment that led to this AI explosion this year was really rooted in the AI being able to do something that regular people could do. I want you to write me an email, I want you to write me a screenplay, and maybe the output of the LLM is a C+, but it’s still something I can do. People can see it. I want you to fill out the rest of this photo. That’s something people can imagine doing. Maybe they don’t have the skills to do it, but they can imagine doing it. All the previous AI demos that we have gotten, even yours, AlphaFold, you’re like, this is going to model all the proteins in the world.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"mDQjwi","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eBut I can’t do that; a computer should do that. Even a microbiologist might think, “That is great. I’m very excited that a computer can do that because I’m just looking at how much time it would take us, and there’s no way we could ever do it.” “I want to beat the world champion at Go. I can’t do that. It’s like, fine. A computer can do that.” \u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"hBgopw","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eThere’s this turn where the computer is starting to do things I can do, and they’re not even necessarily the most complicated tasks. Read this webpage and deliver a summary of it to me. But that’s the thing that unlocked everyone’s brain. And I’m wondering why you think the industry didn’t see that turn coming because we’ve been very focused on these very difficult things that people couldn’t do, and it seems like what got everyone is when the computer started doing things people do all the time.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"DbSeGE","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"I think that analysis is correct. I think that is why the large language models have really entered the public consciousness because it’s something the average person, that the “Joe Public,” can actually understand and interact with. And, of course, language is core to human intelligence and our everyday lives. I think that does explain why chatbots specifically have gone viral in the way they have. Even though I would say things like AlphaFold, I mean of course I’d be biased in saying this, but I think it’s actually had the most unequivocally biggest beneficial effects so far in AI on the world because if you talk to any biologist or there’s a million biologists now, researchers and medical researchers, have used AlphaFold. I think that’s nearly every biologist in the world. Every Big Pharma company is using it to advance their drug discovery programs. I’ve had multiple, dozens, of Nobel Prize-winner-level biologists and chemists talk to me about how they’re using AlphaFold."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"jZ4Xhu","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"So a certain set of all the world’s scientists, let’s say, they all know AlphaFold, and it’s affected and massively accelerated their important research work. But of course, the average person in the street doesn’t know what proteins are even and doesn’t know what the importance of those things are for things like drug discovery. Whereas obviously, for a chatbot, everyone can understand, this is incredible. And it’s very visceral to get it to write you a poem or something that everybody can understand and process and measure compared to what they do or are able to do. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"VohSDr","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eIt seems like that is the focus of productized AI: these chatbot-like interfaces or these generative products that are going to make stuff for people, and that’s where the risk has been focused. But even the conversation about risk has escalated because people can now see, “Oh, these tools can do stuff.” Did you perceive the same level of scrutiny when you were working on AlphaFold? It doesn’t seem like anyone thought, “Oh, AlphaFold’s going to destroy humanity.”\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"Tu2odf","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"No, but there was a lot of scrutiny, but again, it was in a very specialized area, right? With renowned experts, and actually, we did talk to over 30 experts in the field, from top biologists to bioethicists to biosecurity people, and actually our partners — we partnered with the European Bioinformatics Institute to release the AlphaFold database of all the protein structures, and they guided us as well on how this could be safely put out there. So there was a lot of scrutiny, and the overwhelming conclusion from the people we consulted was that the benefits far outweighed any risks. Although we did make some small adjustments based on their feedback about which structures to release. But there was a lot of scrutiny, but again, it’s just in a very expert domain. And just going back to your first question about the generative models, I do think we are right at the beginning of an incredible new era that’s going to play out over the next five, 10 years."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"KkomMP","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Not only in advancing science with AI but in terms of the types of products we can build to improve people’s everyday lives, billions of people in their everyday lives, and help them to be more efficient and to enrich their lives. And I think what we’re seeing today with these chatbots is literally just scratching the surface. There are a lot more types of AI than generative AI.  Generative AI is now the “in” thing, but I think that planning and deep reinforcement learning and problem-solving and reasoning, those kinds of capabilities are going to come back in the next wave after this, along with the current capabilities of the current systems. So I think, in a year or two’s time, if we were to talk again, we are going to be talking about entirely new types of products and experiences and services with never-seen-before capabilities. And I’m very excited about building those things, actually. And that’s one of the reasons I’m very excited about leading Google DeepMind now in this new era and focusing on building these AI-powered next-generation products."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"YULO3I","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eLet’s stay in the weeds of Google DeepMind itself, for one more turn. Sundar Pichai comes to you and says, “All right, I’m the CEO of Alphabet and the CEO of Google. I can just make this call. I’m going to bring DeepMind into Google, merge you with Google Brain, you’re going to be the CEO.” How did you react to that prompt?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"S5nf2O","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"It wasn’t like that. It was much more of a conversation between the leaders of the various different relevant groups and Sundar about pretty much the inflection point that we’re seeing, the maturity of the systems, what could be possible with those in the product space, and how to improve experiences for our users, our billions of users, and how exciting that might be, and what that all requires in totality. Both the change in focus, a change in the approach to research, the combination of resources that are required, like compute resources. So there was a big collection of factors to take into account that we all discussed as a leadership group, and then, conclusions from that then result in actions, including the merger and also what the plans are then for the next couple of years and what the focus should be of that merged unit."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"JIXVbI","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eDo you perceive a difference being a CEO inside of Google versus being a CEO inside of Alphabet?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"OSI7HH","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"It’s still early days, but I think it’s been pretty similar because, although DeepMind was an Alphabet company, it was very unusual for another bet, as they call it an “alpha bet,” which is that we already were very closely integrated and collaborating with many of the Google product area teams and groups. We had an applied team at DeepMind whose job it was to translate our research work into features in products by collaborating with the Google product teams. And so, we’ve had hundreds of successful launches already actually over the last few years, just quiet ones behind the scenes. So, in fact, many of the services or devices or systems that you use every day at Google will have some DeepMind technology under the hood as a component. So we already had that integrative structure, and then, of course, what we were famous for was doing the scientific advances and gaming advances, but behind the scenes, there was a lot of bread and butter work going on that was affecting all parts of Google."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"TN8f2p","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"We were different from other bets where they have to make a business outside of Google and become an independent business. That was never the goal or the remit for us, even as an independent bet company. And now, within Google, we’re just more tightly integrated in terms of the product services, and I see that as an advantage because we can actually go deeper and do more exciting and ambitious things in much closer collaboration with these other product teams than we could from outside of Google. But we still retain some latitude to pick the processes and the systems that optimize our mission of producing the most capable and general AI systems in the world."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"UCbOD4","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eThere’s been \u003c/strong\u003e\u003ca href=\"https://www.theverge.com/2023/5/4/23750910/command-line-inside-googles-culture-clash\"\u003e\u003cstrong\u003ereporting that this is actually a culture clash\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e. You’re now in charge of both. How have you structured the group? How has Google DeepMind structured under you as CEO, and how are you managing that culture integration?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"dbNS2y","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Actually, it turns out that the culture’s a lot more similar than perhaps has been reported externally. And in the end, it’s actually been surprisingly smooth and pleasant because you’re talking about two world-class research groups, two of the best AI research organizations in the world, incredible talent on both sides, storied histories. As we were thinking about the merger and planning it, we were looking at some document where we listed the top 10 breakthroughs from each group. And when you take that in totality, it’s like 80–90 percent of over the last decade, of the breakthroughs that underpin the modern AI industry, from deep reinforcement learning to \u003ca href=\"https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/\"\u003etransformers\u003c/a\u003e, of course. It’s an incredible set of people and talent, and there’s massive respect for both groups on both sides. And there was actually a lot of collaboration on a project-based level ongoing over the last decade."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"3P3eo0","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Of course, we all know each other very well. I just think it’s a question of focus and a bit of coordination across both groups, actually, and more in terms of what are we going to focus on, other places that it makes sense for the two separate teams to collaborate on, and maybe de-duplicate some efforts that basically are overlapping. So fairly obvious stuff, to be honest, but it’s important moving into this new phase now of where we are into more of an engineering phase of AI, and that requires huge resources, both compute, engineering, and other things. And, even as a company the size of Google, we’ve got to pick our bets carefully and be clear about which arrows we are going to put our wood behind and then focus on those and then massively deliver on those things. So I think it’s part of the natural course of evolution as to where we are in the AI journey."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"Y5EUst","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eThat thing you talked about, “We’re going to combine these groups, we’re going to pick what we’re doing, we’re going to de-duplicate some efforts.” Those are structure questions. Have you decided on a structure yet, and what do you think that structure will be?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"aixwPZ","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"The structure’s still evolving. We’re only a couple of months into it. We wanted to make sure we didn’t break anything, that it was working. Both teams are incredibly productive, doing super amazing research, but also plugging in to very important product things that are going on. All of that needs to continue."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"Q0aqSw","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eYou keep saying both teams. Do you think of it as two teams, or are you trying to make one team?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"LGiuyw","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"No, no, for sure it’s one unified team. I like to call it a “super unit,” and I’m very excited about that. But obviously, we’re still combining that and forming the new culture and forming the new grouping, including the organizational structures. It’s a complex thing — putting two big research groups together like this. But I think, by the end of the summer, we’ll be a single unified entity, and I think that’ll be very exciting. And we’re already feeling, even a couple of months in, the benefits and the strengths of that with projects like \u003ca href=\"https://www.tomsguide.com/news/googles-new-gemini-ai-could-beat-chatgpt-heres-why\"\u003eGemini\u003c/a\u003e that you may have heard of, which is our next-generation multimodal large models — very, very exciting work going on there, combining all the best ideas from across both world-class research groups. It’s pretty impressive to see."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"Z15lC6","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eYou have a lot of decisions to make. What you’re describing is a bunch of complicated decisions and then, out in the world, how should we regulate this? Another set of very complicated decisions. You are a chess champion, you are a person who has made games. What is your framework for making decisions? I suspect it is much more rigorous than the other ones I hear about.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyPullquote","placement":{"id":"FSGGb3","alignment":"HANG_LEFT"},"__isEntryBodyComponent":"EntryBodyPullquote","quote":{"html":"“Chess is basically decision-making under pressure with an opponent.”"}},{"__typename":"EntryBodyParagraph","placement":{"id":"Jhb51P","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Yes, I think it probably is. And I think if you play a game like chess that seriously — effectively professionally — since all my childhood, since the age of four, I think it’s very formative for your brain. So I think, in chess, the problem-solving and strategizing, I find it a very useful framework for many things and decision-making. Chess is basically decision-making under pressure with an opponent, and it’s very complex, and I think it’s a great thing. I advocate it being taught at school, part of the school curriculum, because I think it’s a really fantastic training ground for problem-solving and decision-making. But then, I think actually the overarching approach is more of the scientific method."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"QM5OVP","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"So I think all my training is doing my PhDs and postdocs and so on, obviously I did it in neuroscience, so I was learning about the brain, but it also taught me how to do rigorous hypothesis testing and hypothesis generation and then update based on empirical evidence. The whole scientific method as well as the chess planning, both can be translated into the business domain. You have to be smart about how to translate that, you can’t be academic about these things. And often, in the real world, in business, there’s a lot of uncertainty and hidden information that you don’t know. So, in chess, obviously all the information’s there for you on the board. You can’t just directly translate those skills, but I think, in the background, they can be very helpful if applied in the right way."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"81lBaf","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eHow do you combine those two in some decisions you’ve made?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"bYs3eJ","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"There are so many decisions I make every day,it’s hard to come up with one now. But I tend to try and plan out and scenario a plan many, many years in advance. So I tell you the way I try to approach things is, I have an end goal. I’m quite good at imagining things, so that’s a different skill, visualizing or imagining what would a perfect end state look like, whether that’s organizational or it’s product-based or it’s research-based. And then, I work back from the end point and then figure out what all the steps would be required and in what order to make that outcome as likely as possible."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"f5QVbn","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"So that’s a little bit chess-like, right? In the sense of you have some plan that you would like to get to checkmate your opponent, but you’re many moves away from that. So what are the incremental things one must do to improve your position in order to increase the likelihood of that final outcome? And I found that extremely useful to do that search process from the end goal back to the current state that you find yourself in."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"MfJBtE","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eLet’s put that next to some products. You said there’s a lot of DeepMind technology and a lot of Google products. The ones that we can all look at are \u003c/strong\u003e\u003ca href=\"https://bard.google.com/\"\u003e\u003cstrong\u003eBard\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e and then your Search Generative Experience. There’s AI in Google Photos and all this stuff, but focused on the LLM moment, it’s Bard and the Search Generative Experience. Those can’t be the end state. They’re not finished. Gemini is coming, and we’ll probably improve both of those, and all that will happen. When you think about the end state of those products, what do you see?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"2QMnDI","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"The AI systems around Google are also not just in the consumer-facing things but also under the hood that you may not realize. So even, for example, one of the things we applied our AI systems to very initially was the cooling systems in Google’s data centers, enormous data centers, and actually reducing the energy they use by nearly 30 percent that the cooling systems use, which is obviously huge if you multiply that by all of the data centers and computers they have there. So there are actually a lot of things under the hood where AI is being used to improve the efficiency of those systems all the time. But you’re right, the current products are not the end state; they’re actually just waypoints. And in the case of chatbots and those kinds of systems, ultimately, they will become these incredible universal personal assistants that you use multiple times during the day for really useful and helpful things across your daily lives."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyPullquote","placement":{"id":"b1ISNm","alignment":"HANG_LEFT"},"__isEntryBodyComponent":"EntryBodyPullquote","quote":{"html":"“...today’s chatbots will look trivial by comparison to I think what’s coming in the next few years.”"}},{"__typename":"EntryBodyParagraph","placement":{"id":"xLWasw","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"From what books to read to recommendations on maybe live events and things like that to booking your travel to planning trips for you to assisting you in your everyday work. And I think we’re still far away from that with the current chatbots, and I think we know what’s missing: things like planning and reasoning and memory, and we are working really hard on those things. And I think what you’ll see in maybe a couple of years’ time is today’s chatbots will look trivial by comparison to I think what’s coming in the next few years."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"qGNsbs","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eMy background is as a person who’s reported on computers. I think of computers as somewhat modular systems. You look at a phone — it’s got a screen, it’s got a chip, it’s got a cell antenna, whatever. Should I look at AI systems that way — there’s an LLM, which is a very convincing human language interface, and behind it might be AlphaFold that’s actually doing the protein folding? Is that how you’re thinking about stitching these things together, or is it a different evolutionary pathway?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"CaStRv","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Actually, there’s a whole branch of research going into what’s called tool use. This is the idea that these large language models or large multimodal models, they’re expert at language, of course, and maybe a few other capabilities, like math and possibly coding. But when you ask them to do something specialized, like fold a protein or play a game of chess or something like this, then actually what they end up doing is calling a tool, which could be another AI system, that then provides the solution or the answer to that particular problem. And then that’s transmitted back to the user via language or pictorially through the central large language model system. So it may be actually invisible to the user because, to the user, it just looks like one big AI system that has many capabilities, but under the hood, it could be that actually the AI system is broken down into smaller ones that have specializations."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"H9Tbjv","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"And I actually think that probably is going to be the next era. The next generation of systems will use those kinds of capabilities. And then you can think of the central system as almost a switch statement that you effectively prompt with language, and it roots your query or your question or whatever it is you’re asking it to the right tool to solve that question for you or provide the solution for you. And then transmit that back in a very understandable way. Again, using through the interface, the best interface really, of natural language."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"KmA4Im","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eDoes that process get you closer to an AGI, or does that get you to some maximum state and you got to do something else?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"OVeK2B","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"I think that is on the critical path to AGI, and that’s another reason, by the way, I’m very excited about this new role and actually doing more products and things because I actually think the product roadmap from here and the research roadmap from here toward something like AGI or human-level AI is very complementary. The kinds of capabilities one would need to push in order to build those kinds of products that are useful in your everyday life like a universal assistant requires pushing on some of these capabilities, like planning and memory and reasoning, that I think are vital for us to get to AGI. So I actually think there’s a really neat feedback loop now between products and research where they can effectively help each other."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"yjJgJr","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eI feel like I had a lot of car CEOs on the show at the beginning of it. I asked all of them, “When do you think we’re going to get self-driving cars?” And they all said five years, and they’ve been saying five years for five years, right?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"9KNOoC","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Yes."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"EFrBUu","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eI’m going to ask you a version of that question about AGI, but I feel like the number has gotten smaller recently with people I’ve talked to. How many years until you think we have AGI?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"yDAdXl","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"I think there’s a lot of uncertainty over how many more breakthroughs are required to get to AGI, big, big breakthroughs — innovative breakthroughs — versus just scaling up existing solutions. And I think it very much depends on that in terms of timeframe. Obviously, if there are a lot of breakthroughs still required, those are a lot harder to do and take a lot longer. But right now, I would not be surprised if we approached something like AGI or AGI-like in the next decade."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"3hU7oO","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eIn the next decade. All right, I’m going to come back to you in 10 years. We’re going to see if that happens.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"UtcuNI","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Sure."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"4JWdmP","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eThat’s not a straight line, though. You called it the critical path, that’s not a straight line. There are breakthroughs along the way that might upset the train and send you along a different path, you think.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyPullquote","placement":{"id":"SJIXPo","alignment":"HANG_LEFT"},"__isEntryBodyComponent":"EntryBodyPullquote","quote":{"html":"“...research is never a straight line. If it is, then it’s not real research.”"}},{"__typename":"EntryBodyParagraph","placement":{"id":"tSJYY2","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Research is never a straight line. If it is, then it’s not real research. If you knew the answer before you started it, then that’s not research. So research and blue sky research at the frontier always has uncertainty around it, and that’s why you can’t really predict timelines with any certainty. But what you can look at is trends, and we can look at the quality of ideas and projects that are being worked on today, look at how they’re progressing. And I think that could go either way over the next five to 10 years where we might asymptote, we might hit a brick wall with current techniques and scaling. I wouldn’t be surprised if that happened, either: that we may find that just scaling the existing systems resulted in diminishing returns in terms of the performance of the system."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"UtQhcO","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"And actually, that would then signal some new innovations were really required to make further progress. At the moment, I think nobody knows which regime we’re in. So the answer to that is you have to push on both as hard as possible. So both the scaling and the engineering of existing systems and existing ideas as well as investing heavily into exploratory research directions that you think might deliver innovations that might solve some of the weaknesses in the current systems. And that’s one advantage of being a large research organization with a lot of resources is we can bet on both of those things maximally, both of those directions. In a way, I’m agnostic to that question of “do we need more breakthroughs or will existing systems just scale all the way?” My view is it’s an empirical question, and one should push both as hard as possible. And then the results will speak for themselves."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"X4PGal","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eThis is a real tension. When you were at DeepMind in Alphabet and you were very research-focused, and then the research was moved back into Google and Google’s engineers would turn it into products. And you can see how that relationship worked. Now, you’re inside of Google. Google is under a lot of pressure as a company to win this battle. And those are product concerns. Those are “Make it real for people and go win in the market.” There’s \u003c/strong\u003e\u003ca href=\"https://fortune.com/2023/05/09/a-leaked-google-memo-raises-questions-about-open-source-a-i-but-the-white-house-doesnt-seem-to-have-gotten-it/\"\u003e\u003cstrong\u003ea leaked memo\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e that went around. It was purportedly from inside Google. It said the company had no moat and open-source AI models or leaked models would run on people’s laptops, and they would outpace the company because the history of open computing would outpace a closed-source competitor. Was that memo real?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyPullquote","placement":{"id":"s515f7","alignment":"HANG_LEFT"},"__isEntryBodyComponent":"EntryBodyPullquote","quote":{"html":"“I think that memo was real.”"}},{"__typename":"EntryBodyParagraph","placement":{"id":"ygwjBY","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"I think that memo was real. I think engineers at Google often write various documents, and sometimes they get leaked and go viral. I think that’s just a thing that happens, but I wouldn’t take it too seriously. These are just opinions. I think it’s interesting to listen to them, and then you’ve got to chart your own course. And I haven’t read that specific memo in detail, but I disagree with the conclusions from that. And I think there’s obviously open source and publishing, and we’ve done tons of that in the history of DeepMind. I mean, AlphaFold was open sourced, right? So we obviously believe in open source and supporting research and open research. That’s a key thing of the scientific discourse, which we’ve been a huge part of. And so is Google, of course, publishing transformers and other things. And \u003ca href=\"https://www.theverge.com/2019/3/6/18253002/google-ai-data-privacy-tensorflow-differential-module-code\"\u003eTensorFlow\u003c/a\u003e and you look at all the things we’ve done."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"NezfMn","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"We do a huge amount in that space. But I also think there are other considerations that need to be had as well. Obviously commercial ones but also safety questions about access to these very powerful systems. What if bad actors can access it? Who maybe aren’t that technical, so they couldn’t have built it themselves, but they can certainly reconfigure a system that is out there? What do you do about those things? And I think that’s been quite theoretical till now, but I think that that is really important from here all the way to AGI as these systems become more general, more sophisticated, more powerful. That question is going to be very important about how does one stop bad actors just using these systems for things they weren’t intended for but for malicious purposes."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"3BMt9W","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"That’s something we need to increasingly come up with, but just back to your question, look at the history of what Google and DeepMind have done in terms of coming up with new innovations and breakthroughs and multiple, multiple breakthroughs over the last decade or more. And I would bet on us, and I’m certainly very confident that that will continue and actually be even more true over the next decade in terms of us producing the next key breakthroughs just like we did in the past."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"6ztre0","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eDo you think that’s the moat: we invented most of this stuff, so we’re going to invent most of the next stuff?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"fTgluv","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"I don’t really think about it as moats, but I’m an incredibly competitive person. That’s maybe another thing I got from chess, and many researchers are. Of course, they’re doing it to discover knowledge, and ultimately, that’s what we are here for is to improve the human condition. But also, we want to be first to do these things and do them responsibly and boldly. We have some of the world’s best researchers. I think we have the biggest collection of great researchers in the world, anywhere in the world, and an incredible track record. And there’s no reason why that shouldn’t continue in the future. And in fact, I think with our new organization and environment might be conducive to even more and faster-paced breakthroughs than we’ve done in the past."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"1wxFyq","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eYou’re leading me toward risk and regulation. I want to talk about that, but I want to start in with just a different spin on it. You’re talking about all the work that has to be done. You’re talking about deep mind reinforcement learning, how that works. We ran a gigantic cover story \u003c/strong\u003e\u003ca href=\"https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html\"\u003e\u003cstrong\u003ein collaboration with \u003cem\u003eNew York\u003c/em\u003e Magazine\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e about the taskers who are actually doing the training, who are actually labeling the data. There’s a lot of labor conversation with AI along the way. Hollywood writers are on strike right now because they don’t want ChatGPT to write a bunch of scripts. I think that’s appropriate.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"ZvHlMk","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eBut then there’s a new class of labor that’s being developed where a bunch of people around the world are sitting in front of computers and saying, “Yep, that’s a stop sign. No, that’s not a stop sign. Yep, that’s clothes you can wear. No, that’s not clothes you can wear.” Is that a forever state? Is that just a new class of work that needs to be done for these systems to operate? Or does that come to an end?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"wUQUm8","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"I think it’s hard to say. I think it’s definitely a moment in time and the current systems and what they’re requiring at the moment. We’ve been very careful just to say, from our part, and I think you quoted some of our researchers in that article, to be very careful to pay living wages and be very responsible about how we do that kind of work and which partners we use. And we also use internal teams as well. So actually, I’m very proud of how responsible we’ve been on that type of work. But going forward, I think there may be ways that these systems, especially once you have millions and millions of users, effectively can bootstrap themselves. Or one could imagine AI systems that are capable of actually conversing with themselves or critiquing themselves."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"otYOgM","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"This would be a bit like turning language systems into a game-like setting, which of course we’re very expert in and we’ve been thinking about where these reinforcement learning systems, different versions of them, can actually rate each other in some way. And it may not be as good as a human rater, but it’s actually a useful way to do some of the bread and butter rating and then maybe just calibrate it by checking those ratings with a human rater at the end, rather than getting human raters to rate everything. So I think there are lots of innovations I can see coming down the line that will help with this and potentially mean that there’s less requirement for this all to be done by human raters."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"59FVAk","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eBut you think there are always human raters in the mix? Even as you get closer to AGI, it seems like you need someone to tell the computer if it’s doing a good job or not.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"ES1NHe","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Let’s take AlphaZero as an example, our general games playing system that ended up learning, itself, how to play any two-player game, including chess and Go. And it’s interesting. What happened there is we set up the system so that it could play against itself tens of millions of times. So, in fact, it built up its own knowledge base. It started from random, played itself, bootstrapped itself, trained better versions of itself, and played those off each other in sort of mini-tournaments. But at the end, you still want to test it against the human world champion or something like this or an external computer program that was built in a conventional way so that you can just calibrate your own metrics, which are telling you these systems are improving according to these objectives or these metrics."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"1I27OX","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":""},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"yGjh0h","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"But you don’t know for sure until you calibrate it with an external benchmark or measure. And depending on what that is, a human rater or human benchmark — a human expert is often the best thing to calibrate your internal testing against. And you make sure that your internal tests are actually mapping reality. And again, that’s something quite exciting about products for researchers because, when you put your research into products and millions of people are using it every day, that’s when you get real-world feedback, and there’s no way around that, right? That’s the reality, and that’s the best test of any theories or any system that you’ve built."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"1zz2Gh","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eDo you think that work is rewarding or appropriate, the labeling of data for AI systems? There’s just something about that, which is, “I’m going to tell a computer how to understand the world so that it might go off in the future and displace other people.” There’s a loop in there that seems like it’s worth more just moral or philosophical consideration. Have you spent time thinking about that?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"aetkfQ","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Yeah, I do think about that. I think I don’t really see it like that. I think that what raters are doing is they’re part of the development cycle of making these systems safer, more useful for everybody, and more helpful and more reliable. So I think it’s a critical component. In many industries, we have safety testing of technologies and products. Today, that’s the best we can do for AI systems is to have human raters. I think, in the future, the next few years, I think we need a lot more research. And I’ve been calling for this, and we are doing this ourselves, but it needs more than just one organization to do this, is great, robust evaluation benchmarks for capabilities so that we know if a system passes these benchmarks, then it has certain properties, and it’s safe and it’s reliable in these particular ways."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"Qp2bu9","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"And right now, I think we are in the space of many researchers in academia and civil society and elsewhere, we have a lot of good suggestions for what those tests could be, but I don’t think they are robust or practical yet. I think they’re basically theoretical and philosophical in nature, and I think they need to be made practical so that we can measure our systems empirically against those tests and then that gives us some assurances about how the system will perform. And I think once we have those, then the need for this human rating testing feedback will be reduced. I just think that’s required in the volumes that’s required now because we don’t have these kinds of independent benchmarks yet. Partly because we haven’t rigorously defined what those properties are. I mean, it’s almost a neuroscience and psychology and philosophy area as well, right? A lot of these terms have not been defined properly, even for the human brain."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"jaAS0X","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eYou’ve \u003c/strong\u003e\u003ca href=\"https://www.theverge.com/2023/5/30/23742005/ai-risk-warning-22-word-statement-google-deepmind-openai\"\u003e\u003cstrong\u003esigned a letter from the Center for AI Safety\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e — OpenAI’s Sam Altman and others have also signed this letter — that warns against the risk from AI. And yet, you’re pushing on, Google’s in the market, you’ve got to win, you’ve described yourself as competitive. There’s a tension there: needing to win in the market with products and “Oh boy, please regulate us because raw capitalism will drive us off the cliff with AI if we don’t stop it in some way.” How do you balance that risk?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"MHVPrk","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"It is a tension. It’s a creative tension. What we like to say at Google is we want to be bold and responsible, and that’s exactly what we’re trying to do and live out and role model. So the bold part is being brave and optimistic about the benefits, the amazing benefits, incredible benefits, AI can bring to the world and to help humanity with our biggest challenges, whether that’s disease or climate or sustainability. AI has a huge part to play in helping our scientists and medical experts solve those problems. And we’re working hard on that  and all those areas. And AlphaFold, again, I’d point to as a poster child for that, what we want to do there. So that’s the bold part. And then, the responsible bit is to make sure we do that as thoughtfully as possible with as much foresight as possible ahead of time."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"4JPHVh","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Try and anticipate what the issues might be if one was successful ahead of time. Not in hindsight, and perhaps this happened with social media, for example, where it is this incredible growth story. Obviously, it’s done a lot of good in the world, but then it turns out 15 years later we realize there are some unintended consequences as well to those types of systems. And I would like to chart a different path with AI. And I think it’s such a profound and important and powerful technology. I think we have to do that with something as potentially as transformative as AI. And it doesn’t mean no mistakes will be made. It’s very new, anything new, you can’t predict everything ahead of time, but I think we can try and do the best job we can."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyPullquote","placement":{"id":"kamFf8","alignment":"HANG_LEFT"},"__isEntryBodyComponent":"EntryBodyPullquote","quote":{"html":"“It’s very new. You can’t predict everything ahead of time, but I think we can try and do the best job we can.”"}},{"__typename":"EntryBodyParagraph","placement":{"id":"WWwfKU","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"And that’s what signing that letter was for was just to point out that I don’t think it’s likely, I don’t know on the timescales, but it’s something that we should consider, too, in the limit is what these systems can do and might be able to do as we get closer to AGI. We are nowhere near that now. So this is not a question of today’s technologies or even the next few years’, but at some point, and given the technology’s accelerating very fast, we will need to think about those questions, and we don’t want to be thinking about them on the eve of them happening. We need to use the time now, the next five, 10, whatever it is, years, to do the research and to do the analysis and to engage with various stakeholders, civil society, academia, government, to figure out, as this stuff is developing very rapidly, what the best way is of making sure we maximize the benefits and minimize any risks."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"gOBXIN","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"And that includes mostly, at this stage, doing more research into these areas, like coming up with better evaluations and benchmarks to rigorously test the capabilities of these frontier systems."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"2wxBJS","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eYou talked about tool usage for AI models, you ask an LLM to do something, it goes off and asks AlphaFold to fold the protein for you. Combining systems like that, integrating systems like that, historically that’s where emergent behaviors appear, things you couldn’t have predicted start happening. Are you worried about that? There’s not a rigorous way to test that. \u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"3RD9bw","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Right, exactly. I think that’s exactly the sort of thing we should be researching and thinking about ahead of time is: as tool use becomes more sophisticated and you can combine different AI systems together in different ways, there is scope for emergent behavior. Of course, that emergent behavior may be very desirable and be extremely useful, but it could also potentially be harmful in the wrong hands and in the hands of bad actors, whether that’s individuals or even nation-states."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"C1MO4Y","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eLet’s say the United States and the EU and China all agree on some framework to regulate AI, and then North Korea or Iran says, “Fuck it, no rules.” And that becomes a center of bad actor AI research. How does that play out? Do you foresee a world in which that’s possible?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"yHAWQg","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Yeah, I think that is a possible world. This is why I’ve been talking to governments — UK, US mostly, but also EU — on I think whatever regulations or guardrails or whatever that is that transpires over the next few years, and tests. They ideally would be international, and there would be international cooperation around those safeguards and international agreement around deployment of these systems and other things. Now, I don’t know how likely that is given the geopolitical tensions around the world, but that is by far the best state. And I think what we should be aiming for if we can."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"5sFG6c","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eIf the government here passes a rule. It says, “Here’s what Google is allowed to do, here’s what Microsoft is allowed to do. You are in charge, you are accountable.” And you can go say, “All right, we’re just not running this code in our data center. We are not going to have these capabilities; it’s not legal.” If I’m just a person with a MacBook, would you accept some limitation on what a MacBook could do because the threat from AI is so scary? That’s the thing I worry about. Practically, if you have open-source models and people are going to use them for weird things, are we going to tell Intel to restrict what its chips can do? How would we implement that such that it actually affects everyone? And not just, we’re going to throw Demis in jail if Google does stuff we don’t like.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"YW74k5","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"I think those are the big questions that are being debated right now. And I do worry about that. On the one hand, there are a lot of benefits of open-sourcing and accelerating scientific discourse and lots of advances happen there and it gives access to many developers. On the other hand, there could be some negative consequences with that if there are bad individual actors that do bad things with that access and that proliferates. And I think that’s a question for the next few years that will need to be resolved. Because right now, I think it’s okay because the systems are not that sophisticated or that powerful and therefore not that risky."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"wP7qIk","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"But I think, as systems increase in their power and generality, the access question will need to be thought about from government and how they want to restrict that or control that or monitor that is going to be an important question. I don’t have any answers for you because I think this is a societal question actually that requires stakeholders from right across society to come together and weigh up the benefits with the risks there."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"6HCuZ7","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eGoogle’s own work, you said we’re not there yet, but Google’s own work in AI certainly had some controversy associated with this around responsibility, around what the models can do or can’t do. There’s a famous “\u003c/strong\u003e\u003ca href=\"https://dl.acm.org/doi/10.1145/3442188.3445922\"\u003e\u003cstrong\u003eStochastic Parrots\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e” paper from Emily Bender and Timnit Gebru and Margaret Mitchell that led to a lot of controversy inside of Google. It led to them leaving. Did you read that paper and think, “Okay, this is correct. LLMs are going to lie to people and Google will be responsible for that”? And how do you think about that now with all of the scrutiny?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"JcdL1Y","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Yeah, look, the large language models, and I think this is one reason that Google’s been very responsible with this, is that we know that they hallucinate and they can be inaccurate. And that’s one of the key areas that has to be improved over the next few years is factuality and grounding and making sure that they don’t spread disinformation, these kinds of things. And that’s very much top of mind for us. And we have many ideas of how to improve that. And our old DeepMind’s Sparrow language model, which we published a couple of years ago, was an experiment into just how good can we get factuality and rules adherence in these systems. And turns out, we can maybe make it an order of magnitude better, but it sometimes comes at the expense of lucidness or creativity on the part of the language model and therefore usefulness."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"9pZcvP","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"So it’s a bit of a \u003ca href=\"https://en.wikipedia.org/wiki/Pareto_efficiency\"\u003ePareto\u003c/a\u003e frontier where, if you improve one dimension, you reduce the capability in another dimension. And ideally, what we want to do in the next phases and the next generations of systems is combine the best of both worlds — keep the creativity and lucidness and funness of the current systems but improve their factuality and reliability. And we’ve got a long way to go on that. But I can see things improving, and I don’t see any theoretical reason why these systems can’t get to extremely high levels of accuracy and reliability in the next few years."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"kNQyKJ","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eWhen you’re using the Google Search Generative Experience, do you believe what it says?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"D2ia4S","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"I do. I sometimes double-check things, especially in the scientific domain where I’ve had very funny situations where, actually all of these models do this, where you ask them to summarize an area of research, which I think would be super useful if they could do that, and then say, “Well, what are the key papers I should read?” And they come up with very plausible sounding papers with very plausible author lists. But then, when you go and look into it, it turns out that they’re just like the most famous people in that field or the titles from two different papers combined together. But of course, they’re extremely plausible as a collection of words. And I think, there what needs to happen is these systems need to understand that citations and papers and author lists are a unitary block rather than a word-by-word prediction. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"8D7Xtk","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"There are interesting cases like that where we need to improve, and there’s something which is, of course, us as wanting to advance the frontiers of science, that’s a particularly interesting use case that we would like to improve and fix — for our own needs as well. I’d love these systems to better summarize for me “here are the top five papers to read about a particular disease” or something like that to just quickly onboard you in that particular area. I think it would be incredibly useful."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"oNnN6o","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eI’ll tell you, I googled my friend John Gruber, and \u003c/strong\u003e\u003ca href=\"https://www.theverge.com/2023/5/12/23720396/google-search-generative-experience-blue-links\"\u003e\u003cstrong\u003eSGE\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e confidently told me that he pioneered the use of a Mac in newspapers and invented WebKit. I don’t know where that came from. Is there a quality level, a truthfulness level that you need to hit before you roll that out to the mass audience?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"4Yap6H","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Yeah, we think about this all the time, especially at Google because of the incredibly high standards Google holds itself to on things like search and that we all rely on every day and every moment of every day, really, and we want to get toward that level of reliability. Obviously, we’re a long, long, long way away from that at the moment with not just us but anybody with their generative systems. But that’s the gold standard. And actually, things like tool use can come in very handy here where you could, in effect, build these systems so that they fact-check themselves, perhaps even using search or other reliable sources, cross-reference, just like a good researcher would, cross-reference your facts. Also having a better understanding of the world. What are research papers? What entities are they? "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"6JD3zZ","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"So these systems need to have a better understanding of the media they’re dealing with. And maybe also give these systems the ability to reason and plan because then they could potentially turn that on their own outputs and critique themselves. And again, this is something we have a lot of experience in in games programs. They don’t just output the first move that you think of in chess or Go. You actually plan and do some search around that and then back up. And sometimes they change their minds and switch to a better move. And you could imagine some process like that with words and language as well."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"KM72vX","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eThere’s the concept of model collapse. That we’re going to train LLMs on LLM-generated data, and that’s going to go into a circle. When you talk about cross-referencing facts, and I think about Google — Google going out in the web and trying to cross-reference a bunch of stuff but maybe all that stuff has been generated by LLMs that were hallucinating in 2023. How do you guard against that?\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"9JKYBJ","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"We are working on some pretty cool solutions to that. I think the answer is, and this is an answer to deepfakes as well, is to do some encrypted watermarking, sophisticated watermarking, that can’t be removed easily or at all, and it’s probably built into the generative models themselves, so it’s part of the generative process. We hope to release that and maybe provide it to third parties as well as a generic solution. But I think that the industry in the field needs those types of solutions where we can mark generated media, be that images, audio, perhaps even text with some Kitemark that says to the user and future AI systems that these were AI-generated. And I think that’s a very, very pressing need right now for near-term issues with AI like deepfakes and disinformation and so on. But I actually think a solution is on the horizon now."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"cmX97h","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eI had Microsoft CTO and EVP of AI Kevin Scott on the show a few weeks ago. He said something very similar. I promised him that we would do a one-hour episode on metadata. So you’re coming for that one. If I know this audience, a full hour on metadata ideas will be our most popular episode ever.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"Kx157m","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Okay, sounds perfect."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"oAWS7J","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003cstrong\u003eDemis, thank you so much for coming on \u003cem\u003eDecoder\u003c/em\u003e. You have to come back soon.\u003c/strong\u003e"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"CrZHnh","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Thanks so much."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyActionbox","placement":{"id":"toPFLV","alignment":null},"__isEntryBodyComponent":"EntryBodyActionbox","heading":{"html":"Decoder with Nilay Patel"},"description":{"html":"A podcast about big ideas and other problems"},"label":{"html":"SUBSCRIBE NOW!"},"url":"http://pod.link/decoder"}]},"liveCoverageStart":null,"slug":"23778745/demis-hassabis-google-deepmind-ai-alphafold-risks","layoutTemplate":"SPLIT_LEFT","styles":null,"seoSchema":[{"@context":"http://schema.org/","@type":"NewsArticle","headline":"Google DeepMind CEO Demis Hassabis on ChatGPT, AI, LLMs, and more","description":"Demis Hassabis talks about the future of AI, why the merger between DeepMind and Google Brain will advance tech research, and why AlphaFold was a scientific breakthrough.","datePublished":"2023-07-10T19:42:50.519Z","dateModified":"2023-07-10T19:42:50.519Z","thumbnailUrl":"https://cdn.vox-cdn.com/thumbor/iLAMKg1KOgXmjUV1SPpix14HB4o=/0x0:3000x2000/1400x788/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg","author":[{"@type":"Person","name":"Nilay Patel","url":"https://www.theverge.com/authors/nilay-patel"}],"publisher":{"@type":"Organization","name":"The Verge","logo":{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png","width":250,"height":50}},"image":[{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/iLAMKg1KOgXmjUV1SPpix14HB4o=/0x0:3000x2000/1400x788/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg","width":1400,"height":788},{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/7_Dhv03l6b1HpaHIKhJvL65hcW8=/0x0:3000x2000/1400x1050/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg","width":1400,"height":1050},{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/oaA61v3nf8X7NZfPcIsPW9DlCPo=/0x0:3000x2000/1400x1400/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg","width":1400,"height":1400}],"url":"https://www.theverge.com/23778745/demis-hassabis-google-deepmind-ai-alphafold-risks","articleBody":"Today, I’m talking to Demis Hassabis, the CEO of Google DeepMind, the newly created division of Google responsible for AI efforts across the company. Google DeepMind is the result of an internal merger: Google acquired Demis’ DeepMind startup in 2014 and ran it as a separate company inside its parent company, Alphabet, while Google itself had an AI team called Google Brain. \n\nGoogle has been showing off AI demos for years now, but with the explosion of ChatGPT and a renewed threat from Microsoft in search, Google and Alphabet CEO Sundar Pichai made the decision to bring DeepMind into Google itself earlier this year to create… Google DeepMind.\n\nWhat’s interesting is that Google Brain and DeepMind were not necessarily compatible or even focused on the same things: DeepMind was famous for applying AI to things like games and protein-folding simulations. The AI that beat world champions at Go, the ancient board game? That was DeepMind’s AlphaGo. Meanwhile, Google Brain was more focused on what’s come to be the familiar generative AI toolset: large language models for chatbots, editing features in Google Photos, and so on. This was a culture clash and a big structure decision with the goal of being more competitive and faster to market with AI products.\n\nAnd the competition isn’t just OpenAI and Microsoft — you might have seen a memo from a Google engineer floating around the web recently claiming that Google has no competitive moat in AI because open-source models running on commodity hardware are rapidly evolving and catching up to the tools run by the giants. Demis confirmed that the memo was real but said it was part of Google’s debate culture, and he disagreed with it because he has other ideas about where Google’s competitive edge might come into play.\n\nOf course, we also talked about AI risk and especially artificial general intelligence. Demis is not shy that his goal is building an AGI, and we talked through what risks and regulations should be in place and on what timeline. Demis recently signed onto a 22-word statement about AI risk with OpenAI’s Sam Altman and others that simply reads, “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.” That’s pretty chill, but is that the real risk right now? Or is it just a distraction from other more tangible problems like AI replacing a bunch of labor in various creative industries? We also talked about the new kinds of labor AI is creating — armies of low-paid taskers classifying data in countries like Kenya and India in order to train AI systems. We just published a big feature on these taskers. I wanted to know if Demis thought these jobs were here to stay or just a temporary side effect of the AI boom.\n\nThis one really hits all the Decoder high points: there’s the big idea of AI, a lot of problems that come with it, an infinite array of complicated decisions to be made, and of course, a gigantic org chart decision in the middle of it all. Demis and I got pretty in the weeds, and I still don’t think we covered it all, so we’ll have to have him back soon.\n\nAlright, Demis Hassabis, CEO of Google DeepMind. Here we go.\n\nThis transcript has been lightly edited for length and clarity\n\nDemis Hassabis, you are the CEO of Google DeepMind. Welcome to Decoder.\n\nThanks for having me.\n\nI don’t think we have ever had a more perfect Decoder guest. There’s a big idea in AI. It comes with challenges and problems, and then, with you in particular, there’s a gigantic org chart move and a set of high-stakes decisions to be made. I am thrilled that you are here.\n\nGlad to be here.\n\nLet’s start with Google DeepMind itself. Google DeepMind is a new part of Google that is constructed of two existing parts of Google. There was Google Brain, which was the AI team we were familiar with as we covered Google that was run by Jeff Dean. And there was DeepMind, which was your company that you founded. You sold it to Alphabet in 2014. You were outside of Google. It was run as a separate company inside that holding company Alphabet structure until just now. Start at the very beginning. Why were DeepMind and Google Brain separate to begin with?\n\nAs you mentioned, we started DeepMind actually back in 2010, a long time ago now, especially in the age of AI. So that’s sort of like prehistory. Myself and the co-founders, we realized coming from academia and seeing what was going on there, things like deep learning had just been invented. We were big proponents of reinforcement learning. We could see GPUs and other hardware was coming online, that a lot of great progress could be made with a focused effort on general learning systems and also taking some ideas from neuroscience and how the brain works. So we put all those ingredients together back in 2010. We had this thesis we’d make fast progress, and that’s what happened with our initial game systems. And then, we decided in 2014 to join forces with Google at the time because we could see that a lot more compute was going to be needed. Obviously, Google has the most computers and had the most computers in the world. That was the obvious home for us to be able to focus on pushing the research as fast as possible. \n\nSo you were acquired by Google, and then somewhere along the way, Google reoriented itself. They turned into Alphabet, and Google became a division of Alphabet. There are other divisions of Alphabet, and DeepMind was out of it. That’s just the part I want to focus on here at the beginning, because there was what Google was doing with Google Brain, which is a lot of LLM research. I recall, six years ago, Google was showing off LLMs at Google I/O, but DeepMind was focused on winning the game [Go] and protein folding, a very different kind of AI research wholly outside of Google. Why was that outside of Google? Why was that in Alphabet proper?\n\n---\n\n[Image: https://cdn.vox-cdn.com/thumbor/ROZOugNkLXkQJVP30tl2R8ozzbc=/0x0:3000x3000/3000x3000/filters:focal(1500x1500:1501x1501)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg]\n\nListen to Decoder, a show hosted by The Verge’s Nilay Patel about big ideas — and other problems. Subscribe here!\n---\n\nThat was part of the agreement as we were acquired was that we would pursue pushing forward research into general AI, or sometimes called AGI, a system that out of the box can operate across a wide range of cognitive tasks and basically has all the cognitive capabilities that humans have.\n\nAnd also using AI to accelerate scientific discovery, that’s one of my personal passions. And that explains projects like AlphaFold that I’m sure we’re going to get back to. But also, from the start of DeepMind and actually prior to even DeepMind starting, I believe that games was a perfect testing or proving ground for developing AI algorithms efficiently, quickly, and you can generate a lot of data and the objective functions are very clear: obviously, winning games or maximizing the score. There were a lot of reasons to use games in the early days of AI research, and that was a big part of why we were so successful and why we were able to advance so quickly with things like AlphaGo, the program that beat the world champion at the ancient game of Go.\n\nThose were all really important proof points for the whole field really that these general learning techniques would work. And of course we’ve done a lot of work on deep learning and neural networks as well. And our specialty, I suppose, was combining that with reinforcement learning to allow these systems to actively solve problems and make plans and do things like win games. And in terms of the differences, we always had that remit to push the research agenda and push things, advanced science. And that was very much the focus we were given and very much the focus that I wanted to have. And then, the internal Google AI teams like Google Brain, they had slightly different remits and were a bit closer to product and obviously to the rest of Google and infusing Google with amazing AI technology. And we also had an applied division that was introducing DeepMind technology into Google products, too. But the cultures were quite different, and the remits were quite different.\n\nFrom the outside, the timeline looks like this: everyone’s been working on this for ages, we’ve all been talking about it for ages. It is a topic of conversation for a bunch of nerdy journalists like me, a bunch of researchers, we talk about it in the corner at Google events. \n\nThen ChatGPT is released, not even as a product. I don’t even think Sam [Altman] would call it a great product when it was released, but it was just released, and people could use it. And everyone freaked out, and Microsoft releases Bing based on ChatGPT, and the world goes upside down, and Google reacts by merging DeepMind and Google Brain. That’s what it looks like from the outside. Is that what it felt like from the inside?\n\nThat timeline is correct, but it’s not these direct consequences; it’s more indirect in a sense. So, Google and Alphabet have always run like this. They let many flowers bloom, and I think that’s always been the way that even from Larry [Page] and Sergey [Brin] from the beginning set up Google. And it served them very well, and it’s allowed them to organically create incredible things and become the amazing company that it is today. On the research side, I think it’s very compatible with doing research, which is another reason we chose Google as our partners back in 2014. I felt they really understood what fundamental and blue sky research was, ambitious research was, and they were going to facilitate us being and enable us to be super ambitious with our research. And you’ve seen the results of that, right?\n\n\"“...AI has entered a new era.”\"\n\nBy any measure, AlphaGo, AlphaFold, but more than 20 nature and science papers and so on — all the normal metrics one would use for really delivering amazing cutting-edge research we were able to do. But in a way, what ChatGPT and the large models and the public reaction to that confirmed is that AI has entered a new era. And by the way, it was a little bit surprising for all of us at the coalface, including OpenAI, how viral that went because — us and some other startups like Anthropic and OpenAI — we all had these large language models. They were roughly the same capabilities. \n\nAnd so, it was surprising, not so much what the technology was because we all understood that, but the public’s appetite for that and obviously the buzz that generated. And I think that’s indicative of something we’ve all been feeling for the last, I would say, two, three years, which is these systems are reaching a level of maturity now and sophistication where it can really come out of the research phase and the lab and go into powering incredible next-generation products and experiences and also breakthroughs, things like AlphaFold directly being useful for biologists. And so, to me, this is just indicative of a new phase that AI is in of being practically useful to people in their everyday lives and actually being able to solve really hard real-world problems that really matter, not just the curiosities or fun, like games.\n\nWhen you recognize that shift, then I think that necessitates a change in your approach as to how you’re approaching the research and how much focus you’re having on products and those kinds of things. And I think that’s what we all came to the realization of, which was: now was the time to streamline our AI efforts and focus them more. And the obvious conclusion of that was to do the merger.\n\nI want to just stop there for one second and ask a philosophical question.\n\nSure.\n\nIt feels like the ChatGPT moment that led to this AI explosion this year was really rooted in the AI being able to do something that regular people could do. I want you to write me an email, I want you to write me a screenplay, and maybe the output of the LLM is a C+, but it’s still something I can do. People can see it. I want you to fill out the rest of this photo. That’s something people can imagine doing. Maybe they don’t have the skills to do it, but they can imagine doing it. All the previous AI demos that we have gotten, even yours, AlphaFold, you’re like, this is going to model all the proteins in the world.\n\nBut I can’t do that; a computer should do that. Even a microbiologist might think, “That is great. I’m very excited that a computer can do that because I’m just looking at how much time it would take us, and there’s no way we could ever do it.” “I want to beat the world champion at Go. I can’t do that. It’s like, fine. A computer can do that.” \n\nThere’s this turn where the computer is starting to do things I can do, and they’re not even necessarily the most complicated tasks. Read this webpage and deliver a summary of it to me. But that’s the thing that unlocked everyone’s brain. And I’m wondering why you think the industry didn’t see that turn coming because we’ve been very focused on these very difficult things that people couldn’t do, and it seems like what got everyone is when the computer started doing things people do all the time.\n\nI think that analysis is correct. I think that is why the large language models have really entered the public consciousness because it’s something the average person, that the “Joe Public,” can actually understand and interact with. And, of course, language is core to human intelligence and our everyday lives. I think that does explain why chatbots specifically have gone viral in the way they have. Even though I would say things like AlphaFold, I mean of course I’d be biased in saying this, but I think it’s actually had the most unequivocally biggest beneficial effects so far in AI on the world because if you talk to any biologist or there’s a million biologists now, researchers and medical researchers, have used AlphaFold. I think that’s nearly every biologist in the world. Every Big Pharma company is using it to advance their drug discovery programs. I’ve had multiple, dozens, of Nobel Prize-winner-level biologists and chemists talk to me about how they’re using AlphaFold.\n\nSo a certain set of all the world’s scientists, let’s say, they all know AlphaFold, and it’s affected and massively accelerated their important research work. But of course, the average person in the street doesn’t know what proteins are even and doesn’t know what the importance of those things are for things like drug discovery. Whereas obviously, for a chatbot, everyone can understand, this is incredible. And it’s very visceral to get it to write you a poem or something that everybody can understand and process and measure compared to what they do or are able to do. \n\nIt seems like that is the focus of productized AI: these chatbot-like interfaces or these generative products that are going to make stuff for people, and that’s where the risk has been focused. But even the conversation about risk has escalated because people can now see, “Oh, these tools can do stuff.” Did you perceive the same level of scrutiny when you were working on AlphaFold? It doesn’t seem like anyone thought, “Oh, AlphaFold’s going to destroy humanity.”\n\nNo, but there was a lot of scrutiny, but again, it was in a very specialized area, right? With renowned experts, and actually, we did talk to over 30 experts in the field, from top biologists to bioethicists to biosecurity people, and actually our partners — we partnered with the European Bioinformatics Institute to release the AlphaFold database of all the protein structures, and they guided us as well on how this could be safely put out there. So there was a lot of scrutiny, and the overwhelming conclusion from the people we consulted was that the benefits far outweighed any risks. Although we did make some small adjustments based on their feedback about which structures to release. But there was a lot of scrutiny, but again, it’s just in a very expert domain. And just going back to your first question about the generative models, I do think we are right at the beginning of an incredible new era that’s going to play out over the next five, 10 years.\n\nNot only in advancing science with AI but in terms of the types of products we can build to improve people’s everyday lives, billions of people in their everyday lives, and help them to be more efficient and to enrich their lives. And I think what we’re seeing today with these chatbots is literally just scratching the surface. There are a lot more types of AI than generative AI.  Generative AI is now the “in” thing, but I think that planning and deep reinforcement learning and problem-solving and reasoning, those kinds of capabilities are going to come back in the next wave after this, along with the current capabilities of the current systems. So I think, in a year or two’s time, if we were to talk again, we are going to be talking about entirely new types of products and experiences and services with never-seen-before capabilities. And I’m very excited about building those things, actually. And that’s one of the reasons I’m very excited about leading Google DeepMind now in this new era and focusing on building these AI-powered next-generation products.\n\nLet’s stay in the weeds of Google DeepMind itself, for one more turn. Sundar Pichai comes to you and says, “All right, I’m the CEO of Alphabet and the CEO of Google. I can just make this call. I’m going to bring DeepMind into Google, merge you with Google Brain, you’re going to be the CEO.” How did you react to that prompt?\n\nIt wasn’t like that. It was much more of a conversation between the leaders of the various different relevant groups and Sundar about pretty much the inflection point that we’re seeing, the maturity of the systems, what could be possible with those in the product space, and how to improve experiences for our users, our billions of users, and how exciting that might be, and what that all requires in totality. Both the change in focus, a change in the approach to research, the combination of resources that are required, like compute resources. So there was a big collection of factors to take into account that we all discussed as a leadership group, and then, conclusions from that then result in actions, including the merger and also what the plans are then for the next couple of years and what the focus should be of that merged unit.\n\nDo you perceive a difference being a CEO inside of Google versus being a CEO inside of Alphabet?\n\nIt’s still early days, but I think it’s been pretty similar because, although DeepMind was an Alphabet company, it was very unusual for another bet, as they call it an “alpha bet,” which is that we already were very closely integrated and collaborating with many of the Google product area teams and groups. We had an applied team at DeepMind whose job it was to translate our research work into features in products by collaborating with the Google product teams. And so, we’ve had hundreds of successful launches already actually over the last few years, just quiet ones behind the scenes. So, in fact, many of the services or devices or systems that you use every day at Google will have some DeepMind technology under the hood as a component. So we already had that integrative structure, and then, of course, what we were famous for was doing the scientific advances and gaming advances, but behind the scenes, there was a lot of bread and butter work going on that was affecting all parts of Google.\n\nWe were different from other bets where they have to make a business outside of Google and become an independent business. That was never the goal or the remit for us, even as an independent bet company. And now, within Google, we’re just more tightly integrated in terms of the product services, and I see that as an advantage because we can actually go deeper and do more exciting and ambitious things in much closer collaboration with these other product teams than we could from outside of Google. But we still retain some latitude to pick the processes and the systems that optimize our mission of producing the most capable and general AI systems in the world.\n\nThere’s been reporting that this is actually a culture clash. You’re now in charge of both. How have you structured the group? How has Google DeepMind structured under you as CEO, and how are you managing that culture integration?\n\nActually, it turns out that the culture’s a lot more similar than perhaps has been reported externally. And in the end, it’s actually been surprisingly smooth and pleasant because you’re talking about two world-class research groups, two of the best AI research organizations in the world, incredible talent on both sides, storied histories. As we were thinking about the merger and planning it, we were looking at some document where we listed the top 10 breakthroughs from each group. And when you take that in totality, it’s like 80–90 percent of over the last decade, of the breakthroughs that underpin the modern AI industry, from deep reinforcement learning to transformers, of course. It’s an incredible set of people and talent, and there’s massive respect for both groups on both sides. And there was actually a lot of collaboration on a project-based level ongoing over the last decade.\n\nOf course, we all know each other very well. I just think it’s a question of focus and a bit of coordination across both groups, actually, and more in terms of what are we going to focus on, other places that it makes sense for the two separate teams to collaborate on, and maybe de-duplicate some efforts that basically are overlapping. So fairly obvious stuff, to be honest, but it’s important moving into this new phase now of where we are into more of an engineering phase of AI, and that requires huge resources, both compute, engineering, and other things. And, even as a company the size of Google, we’ve got to pick our bets carefully and be clear about which arrows we are going to put our wood behind and then focus on those and then massively deliver on those things. So I think it’s part of the natural course of evolution as to where we are in the AI journey.\n\nThat thing you talked about, “We’re going to combine these groups, we’re going to pick what we’re doing, we’re going to de-duplicate some efforts.” Those are structure questions. Have you decided on a structure yet, and what do you think that structure will be?\n\nThe structure’s still evolving. We’re only a couple of months into it. We wanted to make sure we didn’t break anything, that it was working. Both teams are incredibly productive, doing super amazing research, but also plugging in to very important product things that are going on. All of that needs to continue.\n\nYou keep saying both teams. Do you think of it as two teams, or are you trying to make one team?\n\nNo, no, for sure it’s one unified team. I like to call it a “super unit,” and I’m very excited about that. But obviously, we’re still combining that and forming the new culture and forming the new grouping, including the organizational structures. It’s a complex thing — putting two big research groups together like this. But I think, by the end of the summer, we’ll be a single unified entity, and I think that’ll be very exciting. And we’re already feeling, even a couple of months in, the benefits and the strengths of that with projects like Gemini that you may have heard of, which is our next-generation multimodal large models — very, very exciting work going on there, combining all the best ideas from across both world-class research groups. It’s pretty impressive to see.\n\nYou have a lot of decisions to make. What you’re describing is a bunch of complicated decisions and then, out in the world, how should we regulate this? Another set of very complicated decisions. You are a chess champion, you are a person who has made games. What is your framework for making decisions? I suspect it is much more rigorous than the other ones I hear about.\n\n\"“Chess is basically decision-making under pressure with an opponent.”\"\n\nYes, I think it probably is. And I think if you play a game like chess that seriously — effectively professionally — since all my childhood, since the age of four, I think it’s very formative for your brain. So I think, in chess, the problem-solving and strategizing, I find it a very useful framework for many things and decision-making. Chess is basically decision-making under pressure with an opponent, and it’s very complex, and I think it’s a great thing. I advocate it being taught at school, part of the school curriculum, because I think it’s a really fantastic training ground for problem-solving and decision-making. But then, I think actually the overarching approach is more of the scientific method.\n\nSo I think all my training is doing my PhDs and postdocs and so on, obviously I did it in neuroscience, so I was learning about the brain, but it also taught me how to do rigorous hypothesis testing and hypothesis generation and then update based on empirical evidence. The whole scientific method as well as the chess planning, both can be translated into the business domain. You have to be smart about how to translate that, you can’t be academic about these things. And often, in the real world, in business, there’s a lot of uncertainty and hidden information that you don’t know. So, in chess, obviously all the information’s there for you on the board. You can’t just directly translate those skills, but I think, in the background, they can be very helpful if applied in the right way.\n\nHow do you combine those two in some decisions you’ve made?\n\nThere are so many decisions I make every day,it’s hard to come up with one now. But I tend to try and plan out and scenario a plan many, many years in advance. So I tell you the way I try to approach things is, I have an end goal. I’m quite good at imagining things, so that’s a different skill, visualizing or imagining what would a perfect end state look like, whether that’s organizational or it’s product-based or it’s research-based. And then, I work back from the end point and then figure out what all the steps would be required and in what order to make that outcome as likely as possible.\n\nSo that’s a little bit chess-like, right? In the sense of you have some plan that you would like to get to checkmate your opponent, but you’re many moves away from that. So what are the incremental things one must do to improve your position in order to increase the likelihood of that final outcome? And I found that extremely useful to do that search process from the end goal back to the current state that you find yourself in.\n\nLet’s put that next to some products. You said there’s a lot of DeepMind technology and a lot of Google products. The ones that we can all look at are Bard and then your Search Generative Experience. There’s AI in Google Photos and all this stuff, but focused on the LLM moment, it’s Bard and the Search Generative Experience. Those can’t be the end state. They’re not finished. Gemini is coming, and we’ll probably improve both of those, and all that will happen. When you think about the end state of those products, what do you see?\n\nThe AI systems around Google are also not just in the consumer-facing things but also under the hood that you may not realize. So even, for example, one of the things we applied our AI systems to very initially was the cooling systems in Google’s data centers, enormous data centers, and actually reducing the energy they use by nearly 30 percent that the cooling systems use, which is obviously huge if you multiply that by all of the data centers and computers they have there. So there are actually a lot of things under the hood where AI is being used to improve the efficiency of those systems all the time. But you’re right, the current products are not the end state; they’re actually just waypoints. And in the case of chatbots and those kinds of systems, ultimately, they will become these incredible universal personal assistants that you use multiple times during the day for really useful and helpful things across your daily lives.\n\n\"“...today’s chatbots will look trivial by comparison to I think what’s coming in the next few years.”\"\n\nFrom what books to read to recommendations on maybe live events and things like that to booking your travel to planning trips for you to assisting you in your everyday work. And I think we’re still far away from that with the current chatbots, and I think we know what’s missing: things like planning and reasoning and memory, and we are working really hard on those things. And I think what you’ll see in maybe a couple of years’ time is today’s chatbots will look trivial by comparison to I think what’s coming in the next few years.\n\nMy background is as a person who’s reported on computers. I think of computers as somewhat modular systems. You look at a phone — it’s got a screen, it’s got a chip, it’s got a cell antenna, whatever. Should I look at AI systems that way — there’s an LLM, which is a very convincing human language interface, and behind it might be AlphaFold that’s actually doing the protein folding? Is that how you’re thinking about stitching these things together, or is it a different evolutionary pathway?\n\nActually, there’s a whole branch of research going into what’s called tool use. This is the idea that these large language models or large multimodal models, they’re expert at language, of course, and maybe a few other capabilities, like math and possibly coding. But when you ask them to do something specialized, like fold a protein or play a game of chess or something like this, then actually what they end up doing is calling a tool, which could be another AI system, that then provides the solution or the answer to that particular problem. And then that’s transmitted back to the user via language or pictorially through the central large language model system. So it may be actually invisible to the user because, to the user, it just looks like one big AI system that has many capabilities, but under the hood, it could be that actually the AI system is broken down into smaller ones that have specializations.\n\nAnd I actually think that probably is going to be the next era. The next generation of systems will use those kinds of capabilities. And then you can think of the central system as almost a switch statement that you effectively prompt with language, and it roots your query or your question or whatever it is you’re asking it to the right tool to solve that question for you or provide the solution for you. And then transmit that back in a very understandable way. Again, using through the interface, the best interface really, of natural language.\n\nDoes that process get you closer to an AGI, or does that get you to some maximum state and you got to do something else?\n\nI think that is on the critical path to AGI, and that’s another reason, by the way, I’m very excited about this new role and actually doing more products and things because I actually think the product roadmap from here and the research roadmap from here toward something like AGI or human-level AI is very complementary. The kinds of capabilities one would need to push in order to build those kinds of products that are useful in your everyday life like a universal assistant requires pushing on some of these capabilities, like planning and memory and reasoning, that I think are vital for us to get to AGI. So I actually think there’s a really neat feedback loop now between products and research where they can effectively help each other.\n\nI feel like I had a lot of car CEOs on the show at the beginning of it. I asked all of them, “When do you think we’re going to get self-driving cars?” And they all said five years, and they’ve been saying five years for five years, right?\n\nYes.\n\nI’m going to ask you a version of that question about AGI, but I feel like the number has gotten smaller recently with people I’ve talked to. How many years until you think we have AGI?\n\nI think there’s a lot of uncertainty over how many more breakthroughs are required to get to AGI, big, big breakthroughs — innovative breakthroughs — versus just scaling up existing solutions. And I think it very much depends on that in terms of timeframe. Obviously, if there are a lot of breakthroughs still required, those are a lot harder to do and take a lot longer. But right now, I would not be surprised if we approached something like AGI or AGI-like in the next decade.\n\nIn the next decade. All right, I’m going to come back to you in 10 years. We’re going to see if that happens.\n\nSure.\n\nThat’s not a straight line, though. You called it the critical path, that’s not a straight line. There are breakthroughs along the way that might upset the train and send you along a different path, you think.\n\n\"“...research is never a straight line. If it is, then it’s not real research.”\"\n\nResearch is never a straight line. If it is, then it’s not real research. If you knew the answer before you started it, then that’s not research. So research and blue sky research at the frontier always has uncertainty around it, and that’s why you can’t really predict timelines with any certainty. But what you can look at is trends, and we can look at the quality of ideas and projects that are being worked on today, look at how they’re progressing. And I think that could go either way over the next five to 10 years where we might asymptote, we might hit a brick wall with current techniques and scaling. I wouldn’t be surprised if that happened, either: that we may find that just scaling the existing systems resulted in diminishing returns in terms of the performance of the system.\n\nAnd actually, that would then signal some new innovations were really required to make further progress. At the moment, I think nobody knows which regime we’re in. So the answer to that is you have to push on both as hard as possible. So both the scaling and the engineering of existing systems and existing ideas as well as investing heavily into exploratory research directions that you think might deliver innovations that might solve some of the weaknesses in the current systems. And that’s one advantage of being a large research organization with a lot of resources is we can bet on both of those things maximally, both of those directions. In a way, I’m agnostic to that question of “do we need more breakthroughs or will existing systems just scale all the way?” My view is it’s an empirical question, and one should push both as hard as possible. And then the results will speak for themselves.\n\nThis is a real tension. When you were at DeepMind in Alphabet and you were very research-focused, and then the research was moved back into Google and Google’s engineers would turn it into products. And you can see how that relationship worked. Now, you’re inside of Google. Google is under a lot of pressure as a company to win this battle. And those are product concerns. Those are “Make it real for people and go win in the market.” There’s a leaked memo that went around. It was purportedly from inside Google. It said the company had no moat and open-source AI models or leaked models would run on people’s laptops, and they would outpace the company because the history of open computing would outpace a closed-source competitor. Was that memo real?\n\n\"“I think that memo was real.”\"\n\nI think that memo was real. I think engineers at Google often write various documents, and sometimes they get leaked and go viral. I think that’s just a thing that happens, but I wouldn’t take it too seriously. These are just opinions. I think it’s interesting to listen to them, and then you’ve got to chart your own course. And I haven’t read that specific memo in detail, but I disagree with the conclusions from that. And I think there’s obviously open source and publishing, and we’ve done tons of that in the history of DeepMind. I mean, AlphaFold was open sourced, right? So we obviously believe in open source and supporting research and open research. That’s a key thing of the scientific discourse, which we’ve been a huge part of. And so is Google, of course, publishing transformers and other things. And TensorFlow and you look at all the things we’ve done.\n\nWe do a huge amount in that space. But I also think there are other considerations that need to be had as well. Obviously commercial ones but also safety questions about access to these very powerful systems. What if bad actors can access it? Who maybe aren’t that technical, so they couldn’t have built it themselves, but they can certainly reconfigure a system that is out there? What do you do about those things? And I think that’s been quite theoretical till now, but I think that that is really important from here all the way to AGI as these systems become more general, more sophisticated, more powerful. That question is going to be very important about how does one stop bad actors just using these systems for things they weren’t intended for but for malicious purposes.\n\nThat’s something we need to increasingly come up with, but just back to your question, look at the history of what Google and DeepMind have done in terms of coming up with new innovations and breakthroughs and multiple, multiple breakthroughs over the last decade or more. And I would bet on us, and I’m certainly very confident that that will continue and actually be even more true over the next decade in terms of us producing the next key breakthroughs just like we did in the past.\n\nDo you think that’s the moat: we invented most of this stuff, so we’re going to invent most of the next stuff?\n\nI don’t really think about it as moats, but I’m an incredibly competitive person. That’s maybe another thing I got from chess, and many researchers are. Of course, they’re doing it to discover knowledge, and ultimately, that’s what we are here for is to improve the human condition. But also, we want to be first to do these things and do them responsibly and boldly. We have some of the world’s best researchers. I think we have the biggest collection of great researchers in the world, anywhere in the world, and an incredible track record. And there’s no reason why that shouldn’t continue in the future. And in fact, I think with our new organization and environment might be conducive to even more and faster-paced breakthroughs than we’ve done in the past.\n\nYou’re leading me toward risk and regulation. I want to talk about that, but I want to start in with just a different spin on it. You’re talking about all the work that has to be done. You’re talking about deep mind reinforcement learning, how that works. We ran a gigantic cover story in collaboration with New York Magazine about the taskers who are actually doing the training, who are actually labeling the data. There’s a lot of labor conversation with AI along the way. Hollywood writers are on strike right now because they don’t want ChatGPT to write a bunch of scripts. I think that’s appropriate.\n\nBut then there’s a new class of labor that’s being developed where a bunch of people around the world are sitting in front of computers and saying, “Yep, that’s a stop sign. No, that’s not a stop sign. Yep, that’s clothes you can wear. No, that’s not clothes you can wear.” Is that a forever state? Is that just a new class of work that needs to be done for these systems to operate? Or does that come to an end?\n\nI think it’s hard to say. I think it’s definitely a moment in time and the current systems and what they’re requiring at the moment. We’ve been very careful just to say, from our part, and I think you quoted some of our researchers in that article, to be very careful to pay living wages and be very responsible about how we do that kind of work and which partners we use. And we also use internal teams as well. So actually, I’m very proud of how responsible we’ve been on that type of work. But going forward, I think there may be ways that these systems, especially once you have millions and millions of users, effectively can bootstrap themselves. Or one could imagine AI systems that are capable of actually conversing with themselves or critiquing themselves.\n\nThis would be a bit like turning language systems into a game-like setting, which of course we’re very expert in and we’ve been thinking about where these reinforcement learning systems, different versions of them, can actually rate each other in some way. And it may not be as good as a human rater, but it’s actually a useful way to do some of the bread and butter rating and then maybe just calibrate it by checking those ratings with a human rater at the end, rather than getting human raters to rate everything. So I think there are lots of innovations I can see coming down the line that will help with this and potentially mean that there’s less requirement for this all to be done by human raters.\n\nBut you think there are always human raters in the mix? Even as you get closer to AGI, it seems like you need someone to tell the computer if it’s doing a good job or not.\n\nLet’s take AlphaZero as an example, our general games playing system that ended up learning, itself, how to play any two-player game, including chess and Go. And it’s interesting. What happened there is we set up the system so that it could play against itself tens of millions of times. So, in fact, it built up its own knowledge base. It started from random, played itself, bootstrapped itself, trained better versions of itself, and played those off each other in sort of mini-tournaments. But at the end, you still want to test it against the human world champion or something like this or an external computer program that was built in a conventional way so that you can just calibrate your own metrics, which are telling you these systems are improving according to these objectives or these metrics.\n\nBut you don’t know for sure until you calibrate it with an external benchmark or measure. And depending on what that is, a human rater or human benchmark — a human expert is often the best thing to calibrate your internal testing against. And you make sure that your internal tests are actually mapping reality. And again, that’s something quite exciting about products for researchers because, when you put your research into products and millions of people are using it every day, that’s when you get real-world feedback, and there’s no way around that, right? That’s the reality, and that’s the best test of any theories or any system that you’ve built.\n\nDo you think that work is rewarding or appropriate, the labeling of data for AI systems? There’s just something about that, which is, “I’m going to tell a computer how to understand the world so that it might go off in the future and displace other people.” There’s a loop in there that seems like it’s worth more just moral or philosophical consideration. Have you spent time thinking about that?\n\nYeah, I do think about that. I think I don’t really see it like that. I think that what raters are doing is they’re part of the development cycle of making these systems safer, more useful for everybody, and more helpful and more reliable. So I think it’s a critical component. In many industries, we have safety testing of technologies and products. Today, that’s the best we can do for AI systems is to have human raters. I think, in the future, the next few years, I think we need a lot more research. And I’ve been calling for this, and we are doing this ourselves, but it needs more than just one organization to do this, is great, robust evaluation benchmarks for capabilities so that we know if a system passes these benchmarks, then it has certain properties, and it’s safe and it’s reliable in these particular ways.\n\nAnd right now, I think we are in the space of many researchers in academia and civil society and elsewhere, we have a lot of good suggestions for what those tests could be, but I don’t think they are robust or practical yet. I think they’re basically theoretical and philosophical in nature, and I think they need to be made practical so that we can measure our systems empirically against those tests and then that gives us some assurances about how the system will perform. And I think once we have those, then the need for this human rating testing feedback will be reduced. I just think that’s required in the volumes that’s required now because we don’t have these kinds of independent benchmarks yet. Partly because we haven’t rigorously defined what those properties are. I mean, it’s almost a neuroscience and psychology and philosophy area as well, right? A lot of these terms have not been defined properly, even for the human brain.\n\nYou’ve signed a letter from the Center for AI Safety — OpenAI’s Sam Altman and others have also signed this letter — that warns against the risk from AI. And yet, you’re pushing on, Google’s in the market, you’ve got to win, you’ve described yourself as competitive. There’s a tension there: needing to win in the market with products and “Oh boy, please regulate us because raw capitalism will drive us off the cliff with AI if we don’t stop it in some way.” How do you balance that risk?\n\nIt is a tension. It’s a creative tension. What we like to say at Google is we want to be bold and responsible, and that’s exactly what we’re trying to do and live out and role model. So the bold part is being brave and optimistic about the benefits, the amazing benefits, incredible benefits, AI can bring to the world and to help humanity with our biggest challenges, whether that’s disease or climate or sustainability. AI has a huge part to play in helping our scientists and medical experts solve those problems. And we’re working hard on that  and all those areas. And AlphaFold, again, I’d point to as a poster child for that, what we want to do there. So that’s the bold part. And then, the responsible bit is to make sure we do that as thoughtfully as possible with as much foresight as possible ahead of time.\n\nTry and anticipate what the issues might be if one was successful ahead of time. Not in hindsight, and perhaps this happened with social media, for example, where it is this incredible growth story. Obviously, it’s done a lot of good in the world, but then it turns out 15 years later we realize there are some unintended consequences as well to those types of systems. And I would like to chart a different path with AI. And I think it’s such a profound and important and powerful technology. I think we have to do that with something as potentially as transformative as AI. And it doesn’t mean no mistakes will be made. It’s very new, anything new, you can’t predict everything ahead of time, but I think we can try and do the best job we can.\n\n\"“It’s very new. You can’t predict everything ahead of time, but I think we can try and do the best job we can.”\"\n\nAnd that’s what signing that letter was for was just to point out that I don’t think it’s likely, I don’t know on the timescales, but it’s something that we should consider, too, in the limit is what these systems can do and might be able to do as we get closer to AGI. We are nowhere near that now. So this is not a question of today’s technologies or even the next few years’, but at some point, and given the technology’s accelerating very fast, we will need to think about those questions, and we don’t want to be thinking about them on the eve of them happening. We need to use the time now, the next five, 10, whatever it is, years, to do the research and to do the analysis and to engage with various stakeholders, civil society, academia, government, to figure out, as this stuff is developing very rapidly, what the best way is of making sure we maximize the benefits and minimize any risks.\n\nAnd that includes mostly, at this stage, doing more research into these areas, like coming up with better evaluations and benchmarks to rigorously test the capabilities of these frontier systems.\n\nYou talked about tool usage for AI models, you ask an LLM to do something, it goes off and asks AlphaFold to fold the protein for you. Combining systems like that, integrating systems like that, historically that’s where emergent behaviors appear, things you couldn’t have predicted start happening. Are you worried about that? There’s not a rigorous way to test that. \n\nRight, exactly. I think that’s exactly the sort of thing we should be researching and thinking about ahead of time is: as tool use becomes more sophisticated and you can combine different AI systems together in different ways, there is scope for emergent behavior. Of course, that emergent behavior may be very desirable and be extremely useful, but it could also potentially be harmful in the wrong hands and in the hands of bad actors, whether that’s individuals or even nation-states.\n\nLet’s say the United States and the EU and China all agree on some framework to regulate AI, and then North Korea or Iran says, “Fuck it, no rules.” And that becomes a center of bad actor AI research. How does that play out? Do you foresee a world in which that’s possible?\n\nYeah, I think that is a possible world. This is why I’ve been talking to governments — UK, US mostly, but also EU — on I think whatever regulations or guardrails or whatever that is that transpires over the next few years, and tests. They ideally would be international, and there would be international cooperation around those safeguards and international agreement around deployment of these systems and other things. Now, I don’t know how likely that is given the geopolitical tensions around the world, but that is by far the best state. And I think what we should be aiming for if we can.\n\nIf the government here passes a rule. It says, “Here’s what Google is allowed to do, here’s what Microsoft is allowed to do. You are in charge, you are accountable.” And you can go say, “All right, we’re just not running this code in our data center. We are not going to have these capabilities; it’s not legal.” If I’m just a person with a MacBook, would you accept some limitation on what a MacBook could do because the threat from AI is so scary? That’s the thing I worry about. Practically, if you have open-source models and people are going to use them for weird things, are we going to tell Intel to restrict what its chips can do? How would we implement that such that it actually affects everyone? And not just, we’re going to throw Demis in jail if Google does stuff we don’t like.\n\nI think those are the big questions that are being debated right now. And I do worry about that. On the one hand, there are a lot of benefits of open-sourcing and accelerating scientific discourse and lots of advances happen there and it gives access to many developers. On the other hand, there could be some negative consequences with that if there are bad individual actors that do bad things with that access and that proliferates. And I think that’s a question for the next few years that will need to be resolved. Because right now, I think it’s okay because the systems are not that sophisticated or that powerful and therefore not that risky.\n\nBut I think, as systems increase in their power and generality, the access question will need to be thought about from government and how they want to restrict that or control that or monitor that is going to be an important question. I don’t have any answers for you because I think this is a societal question actually that requires stakeholders from right across society to come together and weigh up the benefits with the risks there.\n\nGoogle’s own work, you said we’re not there yet, but Google’s own work in AI certainly had some controversy associated with this around responsibility, around what the models can do or can’t do. There’s a famous “Stochastic Parrots” paper from Emily Bender and Timnit Gebru and Margaret Mitchell that led to a lot of controversy inside of Google. It led to them leaving. Did you read that paper and think, “Okay, this is correct. LLMs are going to lie to people and Google will be responsible for that”? And how do you think about that now with all of the scrutiny?\n\nYeah, look, the large language models, and I think this is one reason that Google’s been very responsible with this, is that we know that they hallucinate and they can be inaccurate. And that’s one of the key areas that has to be improved over the next few years is factuality and grounding and making sure that they don’t spread disinformation, these kinds of things. And that’s very much top of mind for us. And we have many ideas of how to improve that. And our old DeepMind’s Sparrow language model, which we published a couple of years ago, was an experiment into just how good can we get factuality and rules adherence in these systems. And turns out, we can maybe make it an order of magnitude better, but it sometimes comes at the expense of lucidness or creativity on the part of the language model and therefore usefulness.\n\nSo it’s a bit of a Pareto frontier where, if you improve one dimension, you reduce the capability in another dimension. And ideally, what we want to do in the next phases and the next generations of systems is combine the best of both worlds — keep the creativity and lucidness and funness of the current systems but improve their factuality and reliability. And we’ve got a long way to go on that. But I can see things improving, and I don’t see any theoretical reason why these systems can’t get to extremely high levels of accuracy and reliability in the next few years.\n\nWhen you’re using the Google Search Generative Experience, do you believe what it says?\n\nI do. I sometimes double-check things, especially in the scientific domain where I’ve had very funny situations where, actually all of these models do this, where you ask them to summarize an area of research, which I think would be super useful if they could do that, and then say, “Well, what are the key papers I should read?” And they come up with very plausible sounding papers with very plausible author lists. But then, when you go and look into it, it turns out that they’re just like the most famous people in that field or the titles from two different papers combined together. But of course, they’re extremely plausible as a collection of words. And I think, there what needs to happen is these systems need to understand that citations and papers and author lists are a unitary block rather than a word-by-word prediction. \n\nThere are interesting cases like that where we need to improve, and there’s something which is, of course, us as wanting to advance the frontiers of science, that’s a particularly interesting use case that we would like to improve and fix — for our own needs as well. I’d love these systems to better summarize for me “here are the top five papers to read about a particular disease” or something like that to just quickly onboard you in that particular area. I think it would be incredibly useful.\n\nI’ll tell you, I googled my friend John Gruber, and SGE confidently told me that he pioneered the use of a Mac in newspapers and invented WebKit. I don’t know where that came from. Is there a quality level, a truthfulness level that you need to hit before you roll that out to the mass audience?\n\nYeah, we think about this all the time, especially at Google because of the incredibly high standards Google holds itself to on things like search and that we all rely on every day and every moment of every day, really, and we want to get toward that level of reliability. Obviously, we’re a long, long, long way away from that at the moment with not just us but anybody with their generative systems. But that’s the gold standard. And actually, things like tool use can come in very handy here where you could, in effect, build these systems so that they fact-check themselves, perhaps even using search or other reliable sources, cross-reference, just like a good researcher would, cross-reference your facts. Also having a better understanding of the world. What are research papers? What entities are they? \n\nSo these systems need to have a better understanding of the media they’re dealing with. And maybe also give these systems the ability to reason and plan because then they could potentially turn that on their own outputs and critique themselves. And again, this is something we have a lot of experience in in games programs. They don’t just output the first move that you think of in chess or Go. You actually plan and do some search around that and then back up. And sometimes they change their minds and switch to a better move. And you could imagine some process like that with words and language as well.\n\nThere’s the concept of model collapse. That we’re going to train LLMs on LLM-generated data, and that’s going to go into a circle. When you talk about cross-referencing facts, and I think about Google — Google going out in the web and trying to cross-reference a bunch of stuff but maybe all that stuff has been generated by LLMs that were hallucinating in 2023. How do you guard against that?\n\nWe are working on some pretty cool solutions to that. I think the answer is, and this is an answer to deepfakes as well, is to do some encrypted watermarking, sophisticated watermarking, that can’t be removed easily or at all, and it’s probably built into the generative models themselves, so it’s part of the generative process. We hope to release that and maybe provide it to third parties as well as a generic solution. But I think that the industry in the field needs those types of solutions where we can mark generated media, be that images, audio, perhaps even text with some Kitemark that says to the user and future AI systems that these were AI-generated. And I think that’s a very, very pressing need right now for near-term issues with AI like deepfakes and disinformation and so on. But I actually think a solution is on the horizon now.\n\nI had Microsoft CTO and EVP of AI Kevin Scott on the show a few weeks ago. He said something very similar. I promised him that we would do a one-hour episode on metadata. So you’re coming for that one. If I know this audience, a full hour on metadata ideas will be our most popular episode ever.\n\nOkay, sounds perfect.\n\nDemis, thank you so much for coming on Decoder. You have to come back soon.\n\nThanks so much.\n"}],"leadComponent":{"__typename":"EntryLeadImage","standard":{"hideCredit":false,"asset":{"title":"Demis Hassabis smiles at the camera"},"caption":null,"credit":{"html":"Photo illustration by Alex Parkin / The Verge"},"variantUrl":"https://cdn.vox-cdn.com/thumbor/IlXJhdsnUQKCY0Ja2cXjgpCw_V4=/0x0:3000x2000/2000x1333/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg"},"square":{"hideCredit":false,"asset":{"title":"Demis Hassabis smiles at the camera"},"caption":null,"credit":{"html":"Photo illustration by Alex Parkin / The Verge"},"variantUrl":"https://cdn.vox-cdn.com/thumbor/QbzI0fKpReFEfl1UrzFsUVHpGUI=/0x0:3000x2000/1000x1000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg"},"standardBg":{"hideCredit":false,"asset":{"title":"Demis Hassabis smiles at the camera"},"caption":null,"credit":{"html":"Photo illustration by Alex Parkin / The Verge"},"variantUrl":"https://cdn.vox-cdn.com/thumbor/lY0Ec0Y_T6ouGK1KAeP5BttROqU=/0x0:3000x2000/2400x1356/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg"},"portraitBg":{"hideCredit":false,"asset":{"title":"Demis Hassabis smiles at the camera"},"caption":null,"credit":{"html":"Photo illustration by Alex Parkin / The Verge"},"variantUrl":"https://cdn.vox-cdn.com/thumbor/g2z5vu-P2WRcXB0G_AdD70QH0Yw=/0x0:3000x2000/1000x1429/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg"}},"package":null,"url":"https://www.theverge.com/23778745/demis-hassabis-google-deepmind-ai-alphafold-risks","commentsClosed":false,"railComponents":[{"__typename":"EntryRailNewsletter","entryRailNewsletter":{"name":"Verge Deals","slug":"deals"}}],"dek":{"plaintext":"Google invented a lot of core AI technology, and now the company’s turning to Demis to get back in front of the AI race for AI breakthroughs.","html":"Google invented a lot of core AI technology, and now the company’s turning to Demis to get back in front of the AI race for AI breakthroughs."},"leadImage":{"defaultImageUrl":"https://cdn.vox-cdn.com/thumbor/YplCPWLGEe8tmfSGj2nBwBlGZBs=/0x0:3000x2000/1200x628/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24761299/AParkin_DHassabis_Decoder_071123.jpg","asset":{"title":"Demis Hassabis smiles at the camera","contentType":"image/jpeg"}},"seoDescription":{"plaintext":"Demis Hassabis talks about the future of AI, why the merger between DeepMind and Google Brain will advance tech research, and why AlphaFold was a scientific breakthrough."},"socialDescription":{"plaintext":"The buzz around AI has moved from science research to chatbots, but Google DeepMind’s CEO says it’s all relevant to progress."},"socialImage":null,"shouldUseHTMLNoindex":false,"shouldUseHTMLNofollow":false,"password":null,"additionalContributors":null,"_id":23542786,"liveCoverageEnd":null,"seoArticleBody":"Today, I’m talking to Demis Hassabis, the CEO of Google DeepMind, the newly created division of Google responsible for AI efforts across the company. Google DeepMind is the result of an internal merger: Google acquired Demis’ DeepMind startup in 2014 and ran it as a separate company inside its parent company, Alphabet, while Google itself had an AI team called Google Brain. \n\nGoogle has been showing off AI demos for years now, but with the explosion of ChatGPT and a renewed threat from Microsoft in search, Google and Alphabet CEO Sundar Pichai made the decision to bring DeepMind into Google itself earlier this year to create… Google DeepMind.\n\nWhat’s interesting is that Google Brain and DeepMind were not necessarily compatible or even focused on the same things: DeepMind was famous for applying AI to things like games and protein-folding simulations. The AI that beat world champions at Go, the ancient board game? That was DeepMind’s AlphaGo. Meanwhile, Google Brain was more focused on what’s come to be the familiar generative AI toolset: large language models for chatbots, editing features in Google Photos, and so on. This was a culture clash and a big structure decision with the goal of being more competitive and faster to market with AI products.\n\nAnd the competition isn’t just OpenAI and Microsoft — you might have seen a memo from a Google engineer floating around the web recently claiming that Google has no competitive moat in AI because open-source models running on commodity hardware are rapidly evolving and catching up to the tools run by the giants. Demis confirmed that the memo was real but said it was part of Google’s debate culture, and he disagreed with it because he has other ideas about where Google’s competitive edge might come into play.\n\nOf course, we also talked about AI risk and especially artificial general intelligence. Demis is not shy that his goal is building an AGI, and we talked through what risks and regulations should be in place and on what timeline. Demis recently signed onto a 22-word statement about AI risk with OpenAI’s Sam Altman and others that simply reads, “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.” That’s pretty chill, but is that the real risk right now? Or is it just a distraction from other more tangible problems like AI replacing a bunch of labor in various creative industries? We also talked about the new kinds of labor AI is creating — armies of low-paid taskers classifying data in countries like Kenya and India in order to train AI systems. We just published a big feature on these taskers. I wanted to know if Demis thought these jobs were here to stay or just a temporary side effect of the AI boom.\n\nThis one really hits all the Decoder high points: there’s the big idea of AI, a lot of problems that come with it, an infinite array of complicated decisions to be made, and of course, a gigantic org chart decision in the middle of it all. Demis and I got pretty in the weeds, and I still don’t think we covered it all, so we’ll have to have him back soon.\n\nAlright, Demis Hassabis, CEO of Google DeepMind. Here we go.\n\nThis transcript has been lightly edited for length and clarity\n\nDemis Hassabis, you are the CEO of Google DeepMind. Welcome to Decoder.\n\nThanks for having me.\n\nI don’t think we have ever had a more perfect Decoder guest. There’s a big idea in AI. It comes with challenges and problems, and then, with you in particular, there’s a gigantic org chart move and a set of high-stakes decisions to be made. I am thrilled that you are here.\n\nGlad to be here.\n\nLet’s start with Google DeepMind itself. Google DeepMind is a new part of Google that is constructed of two existing parts of Google. There was Google Brain, which was the AI team we were familiar with as we covered Google that was run by Jeff Dean. And there was DeepMind, which was your company that you founded. You sold it to Alphabet in 2014. You were outside of Google. It was run as a separate company inside that holding company Alphabet structure until just now. Start at the very beginning. Why were DeepMind and Google Brain separate to begin with?\n\nAs you mentioned, we started DeepMind actually back in 2010, a long time ago now, especially in the age of AI. So that’s sort of like prehistory. Myself and the co-founders, we realized coming from academia and seeing what was going on there, things like deep learning had just been invented. We were big proponents of reinforcement learning. We could see GPUs and other hardware was coming online, that a lot of great progress could be made with a focused effort on general learning systems and also taking some ideas from neuroscience and how the brain works. So we put all those ingredients together back in 2010. We had this thesis we’d make fast progress, and that’s what happened with our initial game systems. And then, we decided in 2014 to join forces with Google at the time because we could see that a lot more compute was going to be needed. Obviously, Google has the most computers and had the most computers in the world. That was the obvious home for us to be able to focus on pushing the research as fast as possible. \n\nSo you were acquired by Google, and then somewhere along the way, Google reoriented itself. They turned into Alphabet, and Google became a division of Alphabet. There are other divisions of Alphabet, and DeepMind was out of it. That’s just the part I want to focus on here at the beginning, because there was what Google was doing with Google Brain, which is a lot of LLM research. I recall, six years ago, Google was showing off LLMs at Google I/O, but DeepMind was focused on winning the game [Go] and protein folding, a very different kind of AI research wholly outside of Google. Why was that outside of Google? Why was that in Alphabet proper?\n\n---\n\n[Image: https://cdn.vox-cdn.com/thumbor/ROZOugNkLXkQJVP30tl2R8ozzbc=/0x0:3000x3000/3000x3000/filters:focal(1500x1500:1501x1501)/cdn.vox-cdn.com/uploads/chorus_asset/file/24792604/The_Verge_Decoder_Tileart.jpg]\n\nListen to Decoder, a show hosted by The Verge’s Nilay Patel about big ideas — and other problems. Subscribe here!\n---\n\nThat was part of the agreement as we were acquired was that we would pursue pushing forward research into general AI, or sometimes called AGI, a system that out of the box can operate across a wide range of cognitive tasks and basically has all the cognitive capabilities that humans have.\n\nAnd also using AI to accelerate scientific discovery, that’s one of my personal passions. And that explains projects like AlphaFold that I’m sure we’re going to get back to. But also, from the start of DeepMind and actually prior to even DeepMind starting, I believe that games was a perfect testing or proving ground for developing AI algorithms efficiently, quickly, and you can generate a lot of data and the objective functions are very clear: obviously, winning games or maximizing the score. There were a lot of reasons to use games in the early days of AI research, and that was a big part of why we were so successful and why we were able to advance so quickly with things like AlphaGo, the program that beat the world champion at the ancient game of Go.\n\nThose were all really important proof points for the whole field really that these general learning techniques would work. And of course we’ve done a lot of work on deep learning and neural networks as well. And our specialty, I suppose, was combining that with reinforcement learning to allow these systems to actively solve problems and make plans and do things like win games. And in terms of the differences, we always had that remit to push the research agenda and push things, advanced science. And that was very much the focus we were given and very much the focus that I wanted to have. And then, the internal Google AI teams like Google Brain, they had slightly different remits and were a bit closer to product and obviously to the rest of Google and infusing Google with amazing AI technology. And we also had an applied division that was introducing DeepMind technology into Google products, too. But the cultures were quite different, and the remits were quite different.\n\nFrom the outside, the timeline looks like this: everyone’s been working on this for ages, we’ve all been talking about it for ages. It is a topic of conversation for a bunch of nerdy journalists like me, a bunch of researchers, we talk about it in the corner at Google events. \n\nThen ChatGPT is released, not even as a product. I don’t even think Sam [Altman] would call it a great product when it was released, but it was just released, and people could use it. And everyone freaked out, and Microsoft releases Bing based on ChatGPT, and the world goes upside down, and Google reacts by merging DeepMind and Google Brain. That’s what it looks like from the outside. Is that what it felt like from the inside?\n\nThat timeline is correct, but it’s not these direct consequences; it’s more indirect in a sense. So, Google and Alphabet have always run like this. They let many flowers bloom, and I think that’s always been the way that even from Larry [Page] and Sergey [Brin] from the beginning set up Google. And it served them very well, and it’s allowed them to organically create incredible things and become the amazing company that it is today. On the research side, I think it’s very compatible with doing research, which is another reason we chose Google as our partners back in 2014. I felt they really understood what fundamental and blue sky research was, ambitious research was, and they were going to facilitate us being and enable us to be super ambitious with our research. And you’ve seen the results of that, right?\n\n\"“...AI has entered a new era.”\"\n\nBy any measure, AlphaGo, AlphaFold, but more than 20 nature and science papers and so on — all the normal metrics one would use for really delivering amazing cutting-edge research we were able to do. But in a way, what ChatGPT and the large models and the public reaction to that confirmed is that AI has entered a new era. And by the way, it was a little bit surprising for all of us at the coalface, including OpenAI, how viral that went because — us and some other startups like Anthropic and OpenAI — we all had these large language models. They were roughly the same capabilities. \n\nAnd so, it was surprising, not so much what the technology was because we all understood that, but the public’s appetite for that and obviously the buzz that generated. And I think that’s indicative of something we’ve all been feeling for the last, I would say, two, three years, which is these systems are reaching a level of maturity now and sophistication where it can really come out of the research phase and the lab and go into powering incredible next-generation products and experiences and also breakthroughs, things like AlphaFold directly being useful for biologists. And so, to me, this is just indicative of a new phase that AI is in of being practically useful to people in their everyday lives and actually being able to solve really hard real-world problems that really matter, not just the curiosities or fun, like games.\n\nWhen you recognize that shift, then I think that necessitates a change in your approach as to how you’re approaching the research and how much focus you’re having on products and those kinds of things. And I think that’s what we all came to the realization of, which was: now was the time to streamline our AI efforts and focus them more. And the obvious conclusion of that was to do the merger.\n\nI want to just stop there for one second and ask a philosophical question.\n\nSure.\n\nIt feels like the ChatGPT moment that led to this AI explosion this year was really rooted in the AI being able to do something that regular people could do. I want you to write me an email, I want you to write me a screenplay, and maybe the output of the LLM is a C+, but it’s still something I can do. People can see it. I want you to fill out the rest of this photo. That’s something people can imagine doing. Maybe they don’t have the skills to do it, but they can imagine doing it. All the previous AI demos that we have gotten, even yours, AlphaFold, you’re like, this is going to model all the proteins in the world.\n\nBut I can’t do that; a computer should do that. Even a microbiologist might think, “That is great. I’m very excited that a computer can do that because I’m just looking at how much time it would take us, and there’s no way we could ever do it.” “I want to beat the world champion at Go. I can’t do that. It’s like, fine. A computer can do that.” \n\nThere’s this turn where the computer is starting to do things I can do, and they’re not even necessarily the most complicated tasks. Read this webpage and deliver a summary of it to me. But that’s the thing that unlocked everyone’s brain. And I’m wondering why you think the industry didn’t see that turn coming because we’ve been very focused on these very difficult things that people couldn’t do, and it seems like what got everyone is when the computer started doing things people do all the time.\n\nI think that analysis is correct. I think that is why the large language models have really entered the public consciousness because it’s something the average person, that the “Joe Public,” can actually understand and interact with. And, of course, language is core to human intelligence and our everyday lives. I think that does explain why chatbots specifically have gone viral in the way they have. Even though I would say things like AlphaFold, I mean of course I’d be biased in saying this, but I think it’s actually had the most unequivocally biggest beneficial effects so far in AI on the world because if you talk to any biologist or there’s a million biologists now, researchers and medical researchers, have used AlphaFold. I think that’s nearly every biologist in the world. Every Big Pharma company is using it to advance their drug discovery programs. I’ve had multiple, dozens, of Nobel Prize-winner-level biologists and chemists talk to me about how they’re using AlphaFold.\n\nSo a certain set of all the world’s scientists, let’s say, they all know AlphaFold, and it’s affected and massively accelerated their important research work. But of course, the average person in the street doesn’t know what proteins are even and doesn’t know what the importance of those things are for things like drug discovery. Whereas obviously, for a chatbot, everyone can understand, this is incredible. And it’s very visceral to get it to write you a poem or something that everybody can understand and process and measure compared to what they do or are able to do. \n\nIt seems like that is the focus of productized AI: these chatbot-like interfaces or these generative products that are going to make stuff for people, and that’s where the risk has been focused. But even the conversation about risk has escalated because people can now see, “Oh, these tools can do stuff.” Did you perceive the same level of scrutiny when you were working on AlphaFold? It doesn’t seem like anyone thought, “Oh, AlphaFold’s going to destroy humanity.”\n\nNo, but there was a lot of scrutiny, but again, it was in a very specialized area, right? With renowned experts, and actually, we did talk to over 30 experts in the field, from top biologists to bioethicists to biosecurity people, and actually our partners — we partnered with the European Bioinformatics Institute to release the AlphaFold database of all the protein structures, and they guided us as well on how this could be safely put out there. So there was a lot of scrutiny, and the overwhelming conclusion from the people we consulted was that the benefits far outweighed any risks. Although we did make some small adjustments based on their feedback about which structures to release. But there was a lot of scrutiny, but again, it’s just in a very expert domain. And just going back to your first question about the generative models, I do think we are right at the beginning of an incredible new era that’s going to play out over the next five, 10 years.\n\nNot only in advancing science with AI but in terms of the types of products we can build to improve people’s everyday lives, billions of people in their everyday lives, and help them to be more efficient and to enrich their lives. And I think what we’re seeing today with these chatbots is literally just scratching the surface. There are a lot more types of AI than generative AI.  Generative AI is now the “in” thing, but I think that planning and deep reinforcement learning and problem-solving and reasoning, those kinds of capabilities are going to come back in the next wave after this, along with the current capabilities of the current systems. So I think, in a year or two’s time, if we were to talk again, we are going to be talking about entirely new types of products and experiences and services with never-seen-before capabilities. And I’m very excited about building those things, actually. And that’s one of the reasons I’m very excited about leading Google DeepMind now in this new era and focusing on building these AI-powered next-generation products.\n\nLet’s stay in the weeds of Google DeepMind itself, for one more turn. Sundar Pichai comes to you and says, “All right, I’m the CEO of Alphabet and the CEO of Google. I can just make this call. I’m going to bring DeepMind into Google, merge you with Google Brain, you’re going to be the CEO.” How did you react to that prompt?\n\nIt wasn’t like that. It was much more of a conversation between the leaders of the various different relevant groups and Sundar about pretty much the inflection point that we’re seeing, the maturity of the systems, what could be possible with those in the product space, and how to improve experiences for our users, our billions of users, and how exciting that might be, and what that all requires in totality. Both the change in focus, a change in the approach to research, the combination of resources that are required, like compute resources. So there was a big collection of factors to take into account that we all discussed as a leadership group, and then, conclusions from that then result in actions, including the merger and also what the plans are then for the next couple of years and what the focus should be of that merged unit.\n\nDo you perceive a difference being a CEO inside of Google versus being a CEO inside of Alphabet?\n\nIt’s still early days, but I think it’s been pretty similar because, although DeepMind was an Alphabet company, it was very unusual for another bet, as they call it an “alpha bet,” which is that we already were very closely integrated and collaborating with many of the Google product area teams and groups. We had an applied team at DeepMind whose job it was to translate our research work into features in products by collaborating with the Google product teams. And so, we’ve had hundreds of successful launches already actually over the last few years, just quiet ones behind the scenes. So, in fact, many of the services or devices or systems that you use every day at Google will have some DeepMind technology under the hood as a component. So we already had that integrative structure, and then, of course, what we were famous for was doing the scientific advances and gaming advances, but behind the scenes, there was a lot of bread and butter work going on that was affecting all parts of Google.\n\nWe were different from other bets where they have to make a business outside of Google and become an independent business. That was never the goal or the remit for us, even as an independent bet company. And now, within Google, we’re just more tightly integrated in terms of the product services, and I see that as an advantage because we can actually go deeper and do more exciting and ambitious things in much closer collaboration with these other product teams than we could from outside of Google. But we still retain some latitude to pick the processes and the systems that optimize our mission of producing the most capable and general AI systems in the world.\n\nThere’s been reporting that this is actually a culture clash. You’re now in charge of both. How have you structured the group? How has Google DeepMind structured under you as CEO, and how are you managing that culture integration?\n\nActually, it turns out that the culture’s a lot more similar than perhaps has been reported externally. And in the end, it’s actually been surprisingly smooth and pleasant because you’re talking about two world-class research groups, two of the best AI research organizations in the world, incredible talent on both sides, storied histories. As we were thinking about the merger and planning it, we were looking at some document where we listed the top 10 breakthroughs from each group. And when you take that in totality, it’s like 80–90 percent of over the last decade, of the breakthroughs that underpin the modern AI industry, from deep reinforcement learning to transformers, of course. It’s an incredible set of people and talent, and there’s massive respect for both groups on both sides. And there was actually a lot of collaboration on a project-based level ongoing over the last decade.\n\nOf course, we all know each other very well. I just think it’s a question of focus and a bit of coordination across both groups, actually, and more in terms of what are we going to focus on, other places that it makes sense for the two separate teams to collaborate on, and maybe de-duplicate some efforts that basically are overlapping. So fairly obvious stuff, to be honest, but it’s important moving into this new phase now of where we are into more of an engineering phase of AI, and that requires huge resources, both compute, engineering, and other things. And, even as a company the size of Google, we’ve got to pick our bets carefully and be clear about which arrows we are going to put our wood behind and then focus on those and then massively deliver on those things. So I think it’s part of the natural course of evolution as to where we are in the AI journey.\n\nThat thing you talked about, “We’re going to combine these groups, we’re going to pick what we’re doing, we’re going to de-duplicate some efforts.” Those are structure questions. Have you decided on a structure yet, and what do you think that structure will be?\n\nThe structure’s still evolving. We’re only a couple of months into it. We wanted to make sure we didn’t break anything, that it was working. Both teams are incredibly productive, doing super amazing research, but also plugging in to very important product things that are going on. All of that needs to continue.\n\nYou keep saying both teams. Do you think of it as two teams, or are you trying to make one team?\n\nNo, no, for sure it’s one unified team. I like to call it a “super unit,” and I’m very excited about that. But obviously, we’re still combining that and forming the new culture and forming the new grouping, including the organizational structures. It’s a complex thing — putting two big research groups together like this. But I think, by the end of the summer, we’ll be a single unified entity, and I think that’ll be very exciting. And we’re already feeling, even a couple of months in, the benefits and the strengths of that with projects like Gemini that you may have heard of, which is our next-generation multimodal large models — very, very exciting work going on there, combining all the best ideas from across both world-class research groups. It’s pretty impressive to see.\n\nYou have a lot of decisions to make. What you’re describing is a bunch of complicated decisions and then, out in the world, how should we regulate this? Another set of very complicated decisions. You are a chess champion, you are a person who has made games. What is your framework for making decisions? I suspect it is much more rigorous than the other ones I hear about.\n\n\"“Chess is basically decision-making under pressure with an opponent.”\"\n\nYes, I think it probably is. And I think if you play a game like chess that seriously — effectively professionally — since all my childhood, since the age of four, I think it’s very formative for your brain. So I think, in chess, the problem-solving and strategizing, I find it a very useful framework for many things and decision-making. Chess is basically decision-making under pressure with an opponent, and it’s very complex, and I think it’s a great thing. I advocate it being taught at school, part of the school curriculum, because I think it’s a really fantastic training ground for problem-solving and decision-making. But then, I think actually the overarching approach is more of the scientific method.\n\nSo I think all my training is doing my PhDs and postdocs and so on, obviously I did it in neuroscience, so I was learning about the brain, but it also taught me how to do rigorous hypothesis testing and hypothesis generation and then update based on empirical evidence. The whole scientific method as well as the chess planning, both can be translated into the business domain. You have to be smart about how to translate that, you can’t be academic about these things. And often, in the real world, in business, there’s a lot of uncertainty and hidden information that you don’t know. So, in chess, obviously all the information’s there for you on the board. You can’t just directly translate those skills, but I think, in the background, they can be very helpful if applied in the right way.\n\nHow do you combine those two in some decisions you’ve made?\n\nThere are so many decisions I make every day,it’s hard to come up with one now. But I tend to try and plan out and scenario a plan many, many years in advance. So I tell you the way I try to approach things is, I have an end goal. I’m quite good at imagining things, so that’s a different skill, visualizing or imagining what would a perfect end state look like, whether that’s organizational or it’s product-based or it’s research-based. And then, I work back from the end point and then figure out what all the steps would be required and in what order to make that outcome as likely as possible.\n\nSo that’s a little bit chess-like, right? In the sense of you have some plan that you would like to get to checkmate your opponent, but you’re many moves away from that. So what are the incremental things one must do to improve your position in order to increase the likelihood of that final outcome? And I found that extremely useful to do that search process from the end goal back to the current state that you find yourself in.\n\nLet’s put that next to some products. You said there’s a lot of DeepMind technology and a lot of Google products. The ones that we can all look at are Bard and then your Search Generative Experience. There’s AI in Google Photos and all this stuff, but focused on the LLM moment, it’s Bard and the Search Generative Experience. Those can’t be the end state. They’re not finished. Gemini is coming, and we’ll probably improve both of those, and all that will happen. When you think about the end state of those products, what do you see?\n\nThe AI systems around Google are also not just in the consumer-facing things but also under the hood that you may not realize. So even, for example, one of the things we applied our AI systems to very initially was the cooling systems in Google’s data centers, enormous data centers, and actually reducing the energy they use by nearly 30 percent that the cooling systems use, which is obviously huge if you multiply that by all of the data centers and computers they have there. So there are actually a lot of things under the hood where AI is being used to improve the efficiency of those systems all the time. But you’re right, the current products are not the end state; they’re actually just waypoints. And in the case of chatbots and those kinds of systems, ultimately, they will become these incredible universal personal assistants that you use multiple times during the day for really useful and helpful things across your daily lives.\n\n\"“...today’s chatbots will look trivial by comparison to I think what’s coming in the next few years.”\"\n\nFrom what books to read to recommendations on maybe live events and things like that to booking your travel to planning trips for you to assisting you in your everyday work. And I think we’re still far away from that with the current chatbots, and I think we know what’s missing: things like planning and reasoning and memory, and we are working really hard on those things. And I think what you’ll see in maybe a couple of years’ time is today’s chatbots will look trivial by comparison to I think what’s coming in the next few years.\n\nMy background is as a person who’s reported on computers. I think of computers as somewhat modular systems. You look at a phone — it’s got a screen, it’s got a chip, it’s got a cell antenna, whatever. Should I look at AI systems that way — there’s an LLM, which is a very convincing human language interface, and behind it might be AlphaFold that’s actually doing the protein folding? Is that how you’re thinking about stitching these things together, or is it a different evolutionary pathway?\n\nActually, there’s a whole branch of research going into what’s called tool use. This is the idea that these large language models or large multimodal models, they’re expert at language, of course, and maybe a few other capabilities, like math and possibly coding. But when you ask them to do something specialized, like fold a protein or play a game of chess or something like this, then actually what they end up doing is calling a tool, which could be another AI system, that then provides the solution or the answer to that particular problem. And then that’s transmitted back to the user via language or pictorially through the central large language model system. So it may be actually invisible to the user because, to the user, it just looks like one big AI system that has many capabilities, but under the hood, it could be that actually the AI system is broken down into smaller ones that have specializations.\n\nAnd I actually think that probably is going to be the next era. The next generation of systems will use those kinds of capabilities. And then you can think of the central system as almost a switch statement that you effectively prompt with language, and it roots your query or your question or whatever it is you’re asking it to the right tool to solve that question for you or provide the solution for you. And then transmit that back in a very understandable way. Again, using through the interface, the best interface really, of natural language.\n\nDoes that process get you closer to an AGI, or does that get you to some maximum state and you got to do something else?\n\nI think that is on the critical path to AGI, and that’s another reason, by the way, I’m very excited about this new role and actually doing more products and things because I actually think the product roadmap from here and the research roadmap from here toward something like AGI or human-level AI is very complementary. The kinds of capabilities one would need to push in order to build those kinds of products that are useful in your everyday life like a universal assistant requires pushing on some of these capabilities, like planning and memory and reasoning, that I think are vital for us to get to AGI. So I actually think there’s a really neat feedback loop now between products and research where they can effectively help each other.\n\nI feel like I had a lot of car CEOs on the show at the beginning of it. I asked all of them, “When do you think we’re going to get self-driving cars?” And they all said five years, and they’ve been saying five years for five years, right?\n\nYes.\n\nI’m going to ask you a version of that question about AGI, but I feel like the number has gotten smaller recently with people I’ve talked to. How many years until you think we have AGI?\n\nI think there’s a lot of uncertainty over how many more breakthroughs are required to get to AGI, big, big breakthroughs — innovative breakthroughs — versus just scaling up existing solutions. And I think it very much depends on that in terms of timeframe. Obviously, if there are a lot of breakthroughs still required, those are a lot harder to do and take a lot longer. But right now, I would not be surprised if we approached something like AGI or AGI-like in the next decade.\n\nIn the next decade. All right, I’m going to come back to you in 10 years. We’re going to see if that happens.\n\nSure.\n\nThat’s not a straight line, though. You called it the critical path, that’s not a straight line. There are breakthroughs along the way that might upset the train and send you along a different path, you think.\n\n\"“...research is never a straight line. If it is, then it’s not real research.”\"\n\nResearch is never a straight line. If it is, then it’s not real research. If you knew the answer before you started it, then that’s not research. So research and blue sky research at the frontier always has uncertainty around it, and that’s why you can’t really predict timelines with any certainty. But what you can look at is trends, and we can look at the quality of ideas and projects that are being worked on today, look at how they’re progressing. And I think that could go either way over the next five to 10 years where we might asymptote, we might hit a brick wall with current techniques and scaling. I wouldn’t be surprised if that happened, either: that we may find that just scaling the existing systems resulted in diminishing returns in terms of the performance of the system.\n\nAnd actually, that would then signal some new innovations were really required to make further progress. At the moment, I think nobody knows which regime we’re in. So the answer to that is you have to push on both as hard as possible. So both the scaling and the engineering of existing systems and existing ideas as well as investing heavily into exploratory research directions that you think might deliver innovations that might solve some of the weaknesses in the current systems. And that’s one advantage of being a large research organization with a lot of resources is we can bet on both of those things maximally, both of those directions. In a way, I’m agnostic to that question of “do we need more breakthroughs or will existing systems just scale all the way?” My view is it’s an empirical question, and one should push both as hard as possible. And then the results will speak for themselves.\n\nThis is a real tension. When you were at DeepMind in Alphabet and you were very research-focused, and then the research was moved back into Google and Google’s engineers would turn it into products. And you can see how that relationship worked. Now, you’re inside of Google. Google is under a lot of pressure as a company to win this battle. And those are product concerns. Those are “Make it real for people and go win in the market.” There’s a leaked memo that went around. It was purportedly from inside Google. It said the company had no moat and open-source AI models or leaked models would run on people’s laptops, and they would outpace the company because the history of open computing would outpace a closed-source competitor. Was that memo real?\n\n\"“I think that memo was real.”\"\n\nI think that memo was real. I think engineers at Google often write various documents, and sometimes they get leaked and go viral. I think that’s just a thing that happens, but I wouldn’t take it too seriously. These are just opinions. I think it’s interesting to listen to them, and then you’ve got to chart your own course. And I haven’t read that specific memo in detail, but I disagree with the conclusions from that. And I think there’s obviously open source and publishing, and we’ve done tons of that in the history of DeepMind. I mean, AlphaFold was open sourced, right? So we obviously believe in open source and supporting research and open research. That’s a key thing of the scientific discourse, which we’ve been a huge part of. And so is Google, of course, publishing transformers and other things. And TensorFlow and you look at all the things we’ve done.\n\nWe do a huge amount in that space. But I also think there are other considerations that need to be had as well. Obviously commercial ones but also safety questions about access to these very powerful systems. What if bad actors can access it? Who maybe aren’t that technical, so they couldn’t have built it themselves, but they can certainly reconfigure a system that is out there? What do you do about those things? And I think that’s been quite theoretical till now, but I think that that is really important from here all the way to AGI as these systems become more general, more sophisticated, more powerful. That question is going to be very important about how does one stop bad actors just using these systems for things they weren’t intended for but for malicious purposes.\n\nThat’s something we need to increasingly come up with, but just back to your question, look at the history of what Google and DeepMind have done in terms of coming up with new innovations and breakthroughs and multiple, multiple breakthroughs over the last decade or more. And I would bet on us, and I’m certainly very confident that that will continue and actually be even more true over the next decade in terms of us producing the next key breakthroughs just like we did in the past.\n\nDo you think that’s the moat: we invented most of this stuff, so we’re going to invent most of the next stuff?\n\nI don’t really think about it as moats, but I’m an incredibly competitive person. That’s maybe another thing I got from chess, and many researchers are. Of course, they’re doing it to discover knowledge, and ultimately, that’s what we are here for is to improve the human condition. But also, we want to be first to do these things and do them responsibly and boldly. We have some of the world’s best researchers. I think we have the biggest collection of great researchers in the world, anywhere in the world, and an incredible track record. And there’s no reason why that shouldn’t continue in the future. And in fact, I think with our new organization and environment might be conducive to even more and faster-paced breakthroughs than we’ve done in the past.\n\nYou’re leading me toward risk and regulation. I want to talk about that, but I want to start in with just a different spin on it. You’re talking about all the work that has to be done. You’re talking about deep mind reinforcement learning, how that works. We ran a gigantic cover story in collaboration with New York Magazine about the taskers who are actually doing the training, who are actually labeling the data. There’s a lot of labor conversation with AI along the way. Hollywood writers are on strike right now because they don’t want ChatGPT to write a bunch of scripts. I think that’s appropriate.\n\nBut then there’s a new class of labor that’s being developed where a bunch of people around the world are sitting in front of computers and saying, “Yep, that’s a stop sign. No, that’s not a stop sign. Yep, that’s clothes you can wear. No, that’s not clothes you can wear.” Is that a forever state? Is that just a new class of work that needs to be done for these systems to operate? Or does that come to an end?\n\nI think it’s hard to say. I think it’s definitely a moment in time and the current systems and what they’re requiring at the moment. We’ve been very careful just to say, from our part, and I think you quoted some of our researchers in that article, to be very careful to pay living wages and be very responsible about how we do that kind of work and which partners we use. And we also use internal teams as well. So actually, I’m very proud of how responsible we’ve been on that type of work. But going forward, I think there may be ways that these systems, especially once you have millions and millions of users, effectively can bootstrap themselves. Or one could imagine AI systems that are capable of actually conversing with themselves or critiquing themselves.\n\nThis would be a bit like turning language systems into a game-like setting, which of course we’re very expert in and we’ve been thinking about where these reinforcement learning systems, different versions of them, can actually rate each other in some way. And it may not be as good as a human rater, but it’s actually a useful way to do some of the bread and butter rating and then maybe just calibrate it by checking those ratings with a human rater at the end, rather than getting human raters to rate everything. So I think there are lots of innovations I can see coming down the line that will help with this and potentially mean that there’s less requirement for this all to be done by human raters.\n\nBut you think there are always human raters in the mix? Even as you get closer to AGI, it seems like you need someone to tell the computer if it’s doing a good job or not.\n\nLet’s take AlphaZero as an example, our general games playing system that ended up learning, itself, how to play any two-player game, including chess and Go. And it’s interesting. What happened there is we set up the system so that it could play against itself tens of millions of times. So, in fact, it built up its own knowledge base. It started from random, played itself, bootstrapped itself, trained better versions of itself, and played those off each other in sort of mini-tournaments. But at the end, you still want to test it against the human world champion or something like this or an external computer program that was built in a conventional way so that you can just calibrate your own metrics, which are telling you these systems are improving according to these objectives or these metrics.\n\nBut you don’t know for sure until you calibrate it with an external benchmark or measure. And depending on what that is, a human rater or human benchmark — a human expert is often the best thing to calibrate your internal testing against. And you make sure that your internal tests are actually mapping reality. And again, that’s something quite exciting about products for researchers because, when you put your research into products and millions of people are using it every day, that’s when you get real-world feedback, and there’s no way around that, right? That’s the reality, and that’s the best test of any theories or any system that you’ve built.\n\nDo you think that work is rewarding or appropriate, the labeling of data for AI systems? There’s just something about that, which is, “I’m going to tell a computer how to understand the world so that it might go off in the future and displace other people.” There’s a loop in there that seems like it’s worth more just moral or philosophical consideration. Have you spent time thinking about that?\n\nYeah, I do think about that. I think I don’t really see it like that. I think that what raters are doing is they’re part of the development cycle of making these systems safer, more useful for everybody, and more helpful and more reliable. So I think it’s a critical component. In many industries, we have safety testing of technologies and products. Today, that’s the best we can do for AI systems is to have human raters. I think, in the future, the next few years, I think we need a lot more research. And I’ve been calling for this, and we are doing this ourselves, but it needs more than just one organization to do this, is great, robust evaluation benchmarks for capabilities so that we know if a system passes these benchmarks, then it has certain properties, and it’s safe and it’s reliable in these particular ways.\n\nAnd right now, I think we are in the space of many researchers in academia and civil society and elsewhere, we have a lot of good suggestions for what those tests could be, but I don’t think they are robust or practical yet. I think they’re basically theoretical and philosophical in nature, and I think they need to be made practical so that we can measure our systems empirically against those tests and then that gives us some assurances about how the system will perform. And I think once we have those, then the need for this human rating testing feedback will be reduced. I just think that’s required in the volumes that’s required now because we don’t have these kinds of independent benchmarks yet. Partly because we haven’t rigorously defined what those properties are. I mean, it’s almost a neuroscience and psychology and philosophy area as well, right? A lot of these terms have not been defined properly, even for the human brain.\n\nYou’ve signed a letter from the Center for AI Safety — OpenAI’s Sam Altman and others have also signed this letter — that warns against the risk from AI. And yet, you’re pushing on, Google’s in the market, you’ve got to win, you’ve described yourself as competitive. There’s a tension there: needing to win in the market with products and “Oh boy, please regulate us because raw capitalism will drive us off the cliff with AI if we don’t stop it in some way.” How do you balance that risk?\n\nIt is a tension. It’s a creative tension. What we like to say at Google is we want to be bold and responsible, and that’s exactly what we’re trying to do and live out and role model. So the bold part is being brave and optimistic about the benefits, the amazing benefits, incredible benefits, AI can bring to the world and to help humanity with our biggest challenges, whether that’s disease or climate or sustainability. AI has a huge part to play in helping our scientists and medical experts solve those problems. And we’re working hard on that  and all those areas. And AlphaFold, again, I’d point to as a poster child for that, what we want to do there. So that’s the bold part. And then, the responsible bit is to make sure we do that as thoughtfully as possible with as much foresight as possible ahead of time.\n\nTry and anticipate what the issues might be if one was successful ahead of time. Not in hindsight, and perhaps this happened with social media, for example, where it is this incredible growth story. Obviously, it’s done a lot of good in the world, but then it turns out 15 years later we realize there are some unintended consequences as well to those types of systems. And I would like to chart a different path with AI. And I think it’s such a profound and important and powerful technology. I think we have to do that with something as potentially as transformative as AI. And it doesn’t mean no mistakes will be made. It’s very new, anything new, you can’t predict everything ahead of time, but I think we can try and do the best job we can.\n\n\"“It’s very new. You can’t predict everything ahead of time, but I think we can try and do the best job we can.”\"\n\nAnd that’s what signing that letter was for was just to point out that I don’t think it’s likely, I don’t know on the timescales, but it’s something that we should consider, too, in the limit is what these systems can do and might be able to do as we get closer to AGI. We are nowhere near that now. So this is not a question of today’s technologies or even the next few years’, but at some point, and given the technology’s accelerating very fast, we will need to think about those questions, and we don’t want to be thinking about them on the eve of them happening. We need to use the time now, the next five, 10, whatever it is, years, to do the research and to do the analysis and to engage with various stakeholders, civil society, academia, government, to figure out, as this stuff is developing very rapidly, what the best way is of making sure we maximize the benefits and minimize any risks.\n\nAnd that includes mostly, at this stage, doing more research into these areas, like coming up with better evaluations and benchmarks to rigorously test the capabilities of these frontier systems.\n\nYou talked about tool usage for AI models, you ask an LLM to do something, it goes off and asks AlphaFold to fold the protein for you. Combining systems like that, integrating systems like that, historically that’s where emergent behaviors appear, things you couldn’t have predicted start happening. Are you worried about that? There’s not a rigorous way to test that. \n\nRight, exactly. I think that’s exactly the sort of thing we should be researching and thinking about ahead of time is: as tool use becomes more sophisticated and you can combine different AI systems together in different ways, there is scope for emergent behavior. Of course, that emergent behavior may be very desirable and be extremely useful, but it could also potentially be harmful in the wrong hands and in the hands of bad actors, whether that’s individuals or even nation-states.\n\nLet’s say the United States and the EU and China all agree on some framework to regulate AI, and then North Korea or Iran says, “Fuck it, no rules.” And that becomes a center of bad actor AI research. How does that play out? Do you foresee a world in which that’s possible?\n\nYeah, I think that is a possible world. This is why I’ve been talking to governments — UK, US mostly, but also EU — on I think whatever regulations or guardrails or whatever that is that transpires over the next few years, and tests. They ideally would be international, and there would be international cooperation around those safeguards and international agreement around deployment of these systems and other things. Now, I don’t know how likely that is given the geopolitical tensions around the world, but that is by far the best state. And I think what we should be aiming for if we can.\n\nIf the government here passes a rule. It says, “Here’s what Google is allowed to do, here’s what Microsoft is allowed to do. You are in charge, you are accountable.” And you can go say, “All right, we’re just not running this code in our data center. We are not going to have these capabilities; it’s not legal.” If I’m just a person with a MacBook, would you accept some limitation on what a MacBook could do because the threat from AI is so scary? That’s the thing I worry about. Practically, if you have open-source models and people are going to use them for weird things, are we going to tell Intel to restrict what its chips can do? How would we implement that such that it actually affects everyone? And not just, we’re going to throw Demis in jail if Google does stuff we don’t like.\n\nI think those are the big questions that are being debated right now. And I do worry about that. On the one hand, there are a lot of benefits of open-sourcing and accelerating scientific discourse and lots of advances happen there and it gives access to many developers. On the other hand, there could be some negative consequences with that if there are bad individual actors that do bad things with that access and that proliferates. And I think that’s a question for the next few years that will need to be resolved. Because right now, I think it’s okay because the systems are not that sophisticated or that powerful and therefore not that risky.\n\nBut I think, as systems increase in their power and generality, the access question will need to be thought about from government and how they want to restrict that or control that or monitor that is going to be an important question. I don’t have any answers for you because I think this is a societal question actually that requires stakeholders from right across society to come together and weigh up the benefits with the risks there.\n\nGoogle’s own work, you said we’re not there yet, but Google’s own work in AI certainly had some controversy associated with this around responsibility, around what the models can do or can’t do. There’s a famous “Stochastic Parrots” paper from Emily Bender and Timnit Gebru and Margaret Mitchell that led to a lot of controversy inside of Google. It led to them leaving. Did you read that paper and think, “Okay, this is correct. LLMs are going to lie to people and Google will be responsible for that”? And how do you think about that now with all of the scrutiny?\n\nYeah, look, the large language models, and I think this is one reason that Google’s been very responsible with this, is that we know that they hallucinate and they can be inaccurate. And that’s one of the key areas that has to be improved over the next few years is factuality and grounding and making sure that they don’t spread disinformation, these kinds of things. And that’s very much top of mind for us. And we have many ideas of how to improve that. And our old DeepMind’s Sparrow language model, which we published a couple of years ago, was an experiment into just how good can we get factuality and rules adherence in these systems. And turns out, we can maybe make it an order of magnitude better, but it sometimes comes at the expense of lucidness or creativity on the part of the language model and therefore usefulness.\n\nSo it’s a bit of a Pareto frontier where, if you improve one dimension, you reduce the capability in another dimension. And ideally, what we want to do in the next phases and the next generations of systems is combine the best of both worlds — keep the creativity and lucidness and funness of the current systems but improve their factuality and reliability. And we’ve got a long way to go on that. But I can see things improving, and I don’t see any theoretical reason why these systems can’t get to extremely high levels of accuracy and reliability in the next few years.\n\nWhen you’re using the Google Search Generative Experience, do you believe what it says?\n\nI do. I sometimes double-check things, especially in the scientific domain where I’ve had very funny situations where, actually all of these models do this, where you ask them to summarize an area of research, which I think would be super useful if they could do that, and then say, “Well, what are the key papers I should read?” And they come up with very plausible sounding papers with very plausible author lists. But then, when you go and look into it, it turns out that they’re just like the most famous people in that field or the titles from two different papers combined together. But of course, they’re extremely plausible as a collection of words. And I think, there what needs to happen is these systems need to understand that citations and papers and author lists are a unitary block rather than a word-by-word prediction. \n\nThere are interesting cases like that where we need to improve, and there’s something which is, of course, us as wanting to advance the frontiers of science, that’s a particularly interesting use case that we would like to improve and fix — for our own needs as well. I’d love these systems to better summarize for me “here are the top five papers to read about a particular disease” or something like that to just quickly onboard you in that particular area. I think it would be incredibly useful.\n\nI’ll tell you, I googled my friend John Gruber, and SGE confidently told me that he pioneered the use of a Mac in newspapers and invented WebKit. I don’t know where that came from. Is there a quality level, a truthfulness level that you need to hit before you roll that out to the mass audience?\n\nYeah, we think about this all the time, especially at Google because of the incredibly high standards Google holds itself to on things like search and that we all rely on every day and every moment of every day, really, and we want to get toward that level of reliability. Obviously, we’re a long, long, long way away from that at the moment with not just us but anybody with their generative systems. But that’s the gold standard. And actually, things like tool use can come in very handy here where you could, in effect, build these systems so that they fact-check themselves, perhaps even using search or other reliable sources, cross-reference, just like a good researcher would, cross-reference your facts. Also having a better understanding of the world. What are research papers? What entities are they? \n\nSo these systems need to have a better understanding of the media they’re dealing with. And maybe also give these systems the ability to reason and plan because then they could potentially turn that on their own outputs and critique themselves. And again, this is something we have a lot of experience in in games programs. They don’t just output the first move that you think of in chess or Go. You actually plan and do some search around that and then back up. And sometimes they change their minds and switch to a better move. And you could imagine some process like that with words and language as well.\n\nThere’s the concept of model collapse. That we’re going to train LLMs on LLM-generated data, and that’s going to go into a circle. When you talk about cross-referencing facts, and I think about Google — Google going out in the web and trying to cross-reference a bunch of stuff but maybe all that stuff has been generated by LLMs that were hallucinating in 2023. How do you guard against that?\n\nWe are working on some pretty cool solutions to that. I think the answer is, and this is an answer to deepfakes as well, is to do some encrypted watermarking, sophisticated watermarking, that can’t be removed easily or at all, and it’s probably built into the generative models themselves, so it’s part of the generative process. We hope to release that and maybe provide it to third parties as well as a generic solution. But I think that the industry in the field needs those types of solutions where we can mark generated media, be that images, audio, perhaps even text with some Kitemark that says to the user and future AI systems that these were AI-generated. And I think that’s a very, very pressing need right now for near-term issues with AI like deepfakes and disinformation and so on. But I actually think a solution is on the horizon now.\n\nI had Microsoft CTO and EVP of AI Kevin Scott on the show a few weeks ago. He said something very similar. I promised him that we would do a one-hour episode on metadata. So you’re coming for that one. If I know this audience, a full hour on metadata ideas will be our most popular episode ever.\n\nOkay, sounds perfect.\n\nDemis, thank you so much for coming on Decoder. You have to come back soon.\n\nThanks so much.\n","stream":null,"visibleNetworkIds":[],"scheduledForExpirationAt":null}}}]},"uid":"Entry:aead0074-0a38-4e37-a342-5dbfaab046b5","mostPopular":[{"author":{"fullName":"Andrew J. Hawkins"},"publishDate":"2024-05-06T16:40:06","title":"More Tesla employees laid off as bloodbath enters its fourth week","url":"https://www.theverge.com/2024/5/6/24150274/tesla-layoffs-employee-fourth-week-elon-musk-ev-demand","uid":"0"},{"author":{"fullName":"Chris Welch"},"publishDate":"2024-05-06T20:57:39","title":"These are the upcoming Sonos Ace wireless headphones","url":"https://www.theverge.com/2024/5/6/24150573/sonos-ace-headphones-reveal-leak-wireless","uid":"1"},{"author":{"fullName":"David Pierce"},"publishDate":"2024-05-05T12:00:00","title":"The best new browser for Windows","url":"https://www.theverge.com/2024/5/5/24148223/arc-browser-windows-claude-sofa-bose-beats-hacks-coffee-installer","uid":"2"},{"author":{"fullName":"David Pierce"},"publishDate":"2024-05-05T13:00:00","title":"Better Siri is coming: what Apple’s research says about its AI plans","url":"https://www.theverge.com/2024/5/5/24147995/apple-siri-ai-research-chatbot-creativity","uid":"3"},{"author":{"fullName":"Emma Roth"},"publishDate":"2024-05-06T15:55:52","title":"‘Apple Pencil Pro’ spotted in code on Apple’s Japanese site","url":"https://www.theverge.com/2024/5/6/24150198/apple-pencil-pro-japan-website-code-leak","uid":"4"}],"navProps":{"navContainerClassName":"","campaignGroup":null,"stickyNav":true,"logoColor":"white","lightText":false},"_sentryTraceData":"9dfa8d6f37a244c6809e076c6e9c43fb-b27a014e8b1fbc74-0","_sentryBaggage":"sentry-environment=production,sentry-release=TIjH7e7ABna7etOOsIsVO,sentry-public_key=6547365f9d98454ba8daa58e42013d33,sentry-trace_id=9dfa8d6f37a244c6809e076c6e9c43fb"},"__N_SSP":true},"page":"/entry/feature/[uid]","query":{"uid":"Entry:aead0074-0a38-4e37-a342-5dbfaab046b5"},"buildId":"TIjH7e7ABna7etOOsIsVO","isFallback":false,"gssp":true,"scriptLoader":[{"src":"https://theverge.coral.coralproject.net/assets/js/count.js?v=0","strategy":"lazyOnload","className":"coral-script","defer":true}]}</script></body></html> contentType 9 text/html url 102 https://www.theverge.com:443/23778745/demis-hassabis-google-deepmind-ai-alphafold-risks?showComments=1 responseCode 3 200 