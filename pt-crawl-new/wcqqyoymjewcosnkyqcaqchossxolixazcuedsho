wcqqyoymjewcosnkyqcaqchossxolixazcuedsho length 6 741043 page 741043 <!DOCTYPE html>
<html lang="en" class=" story nytapp-vi-article "  xmlns:og="http://opengraphprotocol.org/schema/">
  <head>
    <meta charset="utf-8" />
    <title data-rh="true">Opinion | What if Dario Amodei Is Right About A.I.? - The New York Times</title>
    <meta data-rh="true" name="robots" content="noarchive, max-image-preview:large"/><meta data-rh="true" name="description" content="Anthropic’s co-founder and C.E.O. explains why he thinks artificial intelligence is on an “exponential curve.”"/><meta data-rh="true" property="og:url" content="https://www.nytimes.com/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="og:title" content="Opinion | What if Dario Amodei Is Right About A.I.?"/><meta data-rh="true" property="og:image" content="https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-facebookJumbo.jpg"/><meta data-rh="true" property="og:image:alt" content=""/><meta data-rh="true" property="og:description" content="Anthropic’s co-founder and C.E.O. explains why he thinks artificial intelligence is on an “exponential curve.”"/><meta data-rh="true" property="twitter:url" content="https://www.nytimes.com/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html"/><meta data-rh="true" property="twitter:title" content="Opinion | What if Dario Amodei Is Right About A.I.?"/><meta data-rh="true" property="twitter:description" content="Anthropic’s co-founder and C.E.O. explains why he thinks artificial intelligence is on an “exponential curve.”"/><meta data-rh="true" property="twitter:image" content="https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-videoSixteenByNine3000.jpg"/><meta data-rh="true" property="twitter:image:alt" content=""/><meta data-rh="true" property="twitter:card" content="summary_large_image"/> <link data-rh="true" rel="canonical" href="https://www.nytimes.com/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html"/><link data-rh="true" rel="alternate" href="nyt://article/ae130003-f1c7-5ef2-8967-c21febec564e"/><link data-rh="true" rel="alternate" type="application/json+oembed" href="https://www.nytimes.com/svc/oembed/json/?url=https%3A%2F%2Fwww.nytimes.com%2F2024%2F04%2F12%2Fopinion%2Fezra-klein-podcast-dario-amodei.html" title="What if Dario Amodei Is Right About A.I.?"/> <script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"NewsArticle","description":"Anthropic’s co-founder and C.E.O. explains why he thinks artificial intelligence is on an “exponential curve.”","image":[{"@context":"https://schema.org","@type":"ImageObject","url":"https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-videoSixteenByNineJumbo1600.jpg","height":900,"width":1600,"contentUrl":"https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-videoSixteenByNineJumbo1600.jpg","creditText":"Illustration by The New York Times; photograph by Dario Amodei"},{"@context":"https://schema.org","@type":"ImageObject","url":"https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-googleFourByThree.jpg","height":600,"width":800,"contentUrl":"https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-googleFourByThree.jpg","creditText":"Illustration by The New York Times; photograph by Dario Amodei"},{"@context":"https://schema.org","@type":"ImageObject","url":"https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-mediumSquareAt3X.jpg","height":1800,"width":1800,"contentUrl":"https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-mediumSquareAt3X.jpg","creditText":"Illustration by The New York Times; photograph by Dario Amodei"}],"mainEntityOfPage":"https://www.nytimes.com/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html","url":"https://www.nytimes.com/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html","inLanguage":"en","author":[{"@context":"https://schema.org","@type":"Person","url":"https://www.nytimes.com/by/the-ezra-klein-show","name":"‘The Ezra Klein Show’"}],"dateModified":"2024-04-12T20:18:20.000Z","datePublished":"2024-04-12T09:03:56.000Z","headline":"Opinion | What if Dario Amodei Is Right About A.I.?","audio":[{"@id":"https://nyt.simplecastaudio.com/3026b665-46df-4d18-98e9-d1ce16bbb1df/episodes/223c172c-1566-4efe-9f19-f5be27f41e45/audio/128/default.mp3?awCollectionId=3026b665-46df-4d18-98e9-d1ce16bbb1df&awEpisodeId=223c172c-1566-4efe-9f19-f5be27f41e45&nocache"}],"publisher":{"@id":"https://www.nytimes.com/#publisher","name":"The New York Times"},"hasPart":{"@type":"WebPageElement","isAccessibleForFree":false,"cssSelector":".meteredContent"},"copyrightHolder":{"@id":"https://www.nytimes.com/#publisher","name":"The New York Times"},"sourceOrganization":{"@id":"https://www.nytimes.com/#publisher","name":"The New York Times"},"copyrightYear":2024,"isAccessibleForFree":false,"isPartOf":{"@type":["CreativeWork","Product"],"name":"The New York Times","productID":"nytimes.com:basic"}}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"NewsMediaOrganization","name":"The New York Times","logo":{"@context":"https://schema.org","@type":"ImageObject","url":"https://static01.nyt.com/images/icons/t_logo_291_black.png","height":291,"width":291,"contentUrl":"https://static01.nyt.com/images/icons/t_logo_291_black.png","creditText":"The New York Times"},"url":"https://www.nytimes.com/","@id":"https://www.nytimes.com/#publisher","diversityPolicy":"https://www.nytco.com/company/diversity-and-inclusion/","ethicsPolicy":"https://www.nytco.com/company/standards-ethics/","masthead":"https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html","foundingDate":"1851-09-18","sameAs":"https://en.wikipedia.org/wiki/The_New_York_Times"}</script>
    <meta data-rh="true" property="article:published_time" content="2024-04-12T09:03:56.000Z"/><meta data-rh="true" property="article:modified_time" content="2024-04-12T20:18:20.000Z"/><meta data-rh="true" http-equiv="Content-Language" content="en"/><meta data-rh="true" name="articleid" content="100000009406898"/><meta data-rh="true" name="nyt_uri" content="nyt://article/ae130003-f1c7-5ef2-8967-c21febec564e"/><meta data-rh="true" name="pubp_event_id" content="pubp://event/ba90cf72033747649801f20fecf07e7f"/><meta data-rh="true" name="image" content="https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-facebookJumbo.jpg"/><meta data-rh="true" name="byl" content="By ‘The Ezra Klein Show’"/><meta data-rh="true" name="news_keywords" content="audio-neutral-inquisitive,Computers and the Internet,Tech Industry,Anthropic,OpenAI,Dario Amodei"/><meta data-rh="true" name="pdate" content="20240412"/><meta data-rh="true" property="article:section" content="Opinion"/><meta data-rh="true" property="article:author" content="https://www.nytimes.com/by/the-ezra-klein-show"/><meta data-rh="true" property="article:tag" content="audio-neutral-informative"/><meta data-rh="true" property="article:tag" content="Computers and the Internet"/><meta data-rh="true" property="article:tag" content="Anthropic AI LLC"/><meta data-rh="true" property="article:tag" content="OpenAI Labs"/><meta data-rh="true" property="article:tag" content="Amodei, Dario"/><meta data-rh="true" property="article:opinion" content="true"/><meta data-rh="true" property="article:content_tier" content="metered"/><meta data-rh="true" name="CG" content="opinion"/><meta data-rh="true" name="SCG" content=""/><meta data-rh="true" name="CN" content="ezra-klein-podcast"/><meta data-rh="true" name="CT" content=""/><meta data-rh="true" name="PT" content="article"/><meta data-rh="true" name="PST" content="Op-Ed"/><meta data-rh="true" name="url" content="https://www.nytimes.com/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html"/><meta data-rh="true" name="msapplication-starturl" content="https://www.nytimes.com"/><meta data-rh="true" property="al:android:url" content="nyt://article/ae130003-f1c7-5ef2-8967-c21febec564e"/><meta data-rh="true" property="al:android:package" content="com.nytimes.android"/><meta data-rh="true" property="al:android:app_name" content="NYTimes"/><meta data-rh="true" name="twitter:app:name:googleplay" content="NYTimes"/><meta data-rh="true" name="twitter:app:id:googleplay" content="com.nytimes.android"/><meta data-rh="true" name="twitter:app:url:googleplay" content="nyt://article/ae130003-f1c7-5ef2-8967-c21febec564e"/><meta data-rh="true" property="al:iphone:url" content="nytimes://www.nytimes.com/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html"/><meta data-rh="true" property="al:iphone:app_store_id" content="284862083"/><meta data-rh="true" property="al:iphone:app_name" content="NYTimes"/><meta data-rh="true" property="al:ipad:url" content="nytimes://www.nytimes.com/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html"/><meta data-rh="true" property="al:ipad:app_store_id" content="357066198"/><meta data-rh="true" property="al:ipad:app_name" content="NYTimes"/>
    
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="fb:app_id" content="9869919170" />
<meta name="twitter:site" content="@nytimes" />
<meta name="slack-app-id" content="A0121HXPPTQ" />
    
    <script>
      
      const override = (new URL(window.location)).searchParams.get('sentryOverride');
      if (override || Math.floor(Math.random() * 100) <= 1) {
        document.write('<script src="https://js.sentry-cdn.com/7bc8bccf5c254286a99b11c68f6bf4ce.min.js" crossorigin="anonymous">' + '<' + '/script>');
      }
    </script>
    <script>

      if (window.Sentry) {
        window.Sentry.onLoad(function() {
          window.Sentry.init({
            maxBreadcrumbs: 30,
            release: 'fda3c1704e92bc29a9545d08be2eec92a5050bf5',
            environment: 'prd',
            beforeSend: function(evt, hint) {
              if (/amazon-adsystem|ads-us|ampproject|amp4ads|pubads|2mdn|chartbeat|gsi|bk_addPageCtx|yimg|BOOMR|boomerang/.test(hint.originalException && hint.originalException.stack || '')) return null;
              return evt;
            },

            
            integrations: [
              Sentry.browserTracingIntegration({
                enableInp: true,
              }),
            ],
          });

          Sentry.startBrowserTracingPageLoadSpan({
            name: 'vi-story',
            attributes: {
              [Sentry.SEMANTIC_ATTRIBUTE_SENTRY_SOURCE]: "route",
            },
          });
        });
      }
    </script>
  
    
    <script>
      
      (function(h,o,u,n,d) {
        h=h[d]=h[d]||{q:[],onReady:function(c){h.q.push(c)}}
        d=o.createElement(u);d.async=1;d.src=n
        n=o.getElementsByTagName(u)[0];n.parentNode.insertBefore(d,n)
      })(window,document,'script','https://www.datadoghq-browser-agent.com/us1/v5/datadog-rum.js','DD_RUM')

      window.DD_RUM.onReady(function() {
        window.DD_RUM.init({
          clientToken: 'pube5bf68ea68edb54c35106f34e32ff07c',
          applicationId: '7d0602a0-8ef8-4d39-985b-c3188887e5b3',
          site: 'datadoghq.com',
          service: 'vi-client',
          env: 'prd',
          version: 'vi-newsreader@v4800-fda3c17',
          sessionSampleRate: 0.1,
          sessionReplaySampleRate: 100,
          trackUserInteractions: true,
          trackResources: true,
          trackLongTasks: true,
          trackViewsManually: true,
          defaultPrivacyLevel: 'mask-user-input',

          
          allowedTracingUrls: [/https:\/\/samizdat-graphql.*\.nytimes\.com/],
          traceSampleRate: 20,

          
          useCrossSiteSessionCookie: true,
          useSecureSessionCookie: true
        });

        
        window.DD_RUM.setGlobalContextProperty('nyt', {
          billing: {
            environment: 'prd',
            deployment: {
              id: 'aws-491988406224'
            }
          },
          dvsp: {
            tenant: 'web-platforms'
          }
        });

        
        window.DD_RUM.startView({name: 'vi-story'});

        
        const id = /nyt-a=(.*?)(;|$)/.exec(document.cookie);
        if (id !== null) window.DD_RUM.setUser({ id: id[1] });
      })
    </script>
  

    <link data-rh="true" rel="shortcut icon" href="/vi-assets/static-assets/favicon-d2483f10ef688e6f89e23806b9700298.ico"/><link data-rh="true" rel="apple-touch-icon" href="/vi-assets/static-assets/apple-touch-icon-28865b72953380a40aa43318108876cb.png"/><link data-rh="true" rel="apple-touch-icon-precomposed" sizes="144×144" href="/vi-assets/static-assets/ios-ipad-144x144-28865b72953380a40aa43318108876cb.png"/><link data-rh="true" rel="apple-touch-icon-precomposed" sizes="114×114" href="/vi-assets/static-assets/ios-iphone-114x144-080e7ec6514fdc62bcbb7966d9b257d2.png"/><link data-rh="true" rel="apple-touch-icon-precomposed" href="/vi-assets/static-assets/ios-default-homescreen-57x57-43808a4cd5333b648057a01624d84960.png"/>
    <link href="https://g1.nyt.com/fonts/css/web-fonts.7705b21d4573b168a8aaebc4ff17d395d2458dca.css" rel="stylesheet" type="text/css" />
    <link rel="stylesheet" href="/vi-assets/static-assets/global-f449cfd9976ad673ef2b7ab5098b85be.css" />
    <style>[data-timezone] { display: none }</style>
    <style data-lights-css="k008qs 1dv1kvn pzrpby 1pd1msn 8atqhb kgn7zc 1hyfx7x 1jmk4jh 1e1s8k7 1qa4qp6 jq1cx6 yywogo vxcmzt 79elbk 1baulvz 1eeh360 1re6eyk 1mlnk6q 2urdiw 1nii3md 1yhvmgx d8bdto 1liwv7v 2ykviq 1nurhyi 93zicp 12fr9lp 18z7m18 iro8fb 1hqnpie 13ctjxq rnl02l 1u4hfeb x15j1o tvohiw b4nnp0 1n6z4y 777zgl rfqw0c l9onyx 1bzlfz 1igvuto mln36k f40pzg f6lhej 1ialerq 1eut9gw 1t7yl1y og85jy 1701swk uzyn7p 1vxywau 1nng8z9 9wqu2x qsd3hm 1e6es05 p98d0w xx7kwh 4gvq6l 8hvvyd 1rtlxy 1iruc8t 103l8m3 1rr4qq7 sg7scw jxzr5i oylsik 1otr2jl 184m8ie qtw155 v0l3hm g4gku8 6xhk3s 1onhbft tj0ten ist4u3 1gprdgz 10t7hia e9w26l yk8vb4 z6qatp 1ea6cym 6td9kr 1o03u4n zera2v 1r7ky0e ew4tgv s99gbd 53u6y8 1jp38cr 19vx93s 1ly73wi 1qq8bvn 3ca3tv b6bqam 1nz2xi2 1bykrda lzc52a 13glguy x1iy13 1dqxzif 5kewg3 83wln0 1unwftr 1w9agjg 138971x 1q2w90k 1bymuyk ui9rw0 1f7ibof 10698na nhjhh0 1awy3rz c5j6tx vfkorq 1bvtpon 1lnfix7 mfml7 4skfbu 1gh9hw8 zd9juy lu72is eap6fy 1vxca1d 1aeqhal 1u46b97 10i3hc jf7ug7 sxwst7 1a5mdf6 1ho5u4o t8x4fj a7htku at9mc1 1xdhyk6 hxpw2c 1g9ic6e 2fg4z9 r3fift 798hid t91cuf 1tx0lhj 8qgvsz 1g7y0i5 rdbib0 18ow4sz 1ruvd04 qknaag 1r5375t t9te0w t3i5e6 fwki7z 1wnday1 1fxvzwo 1l3nmlr 1vwfk9f 13r7n3o s220l9 15f7ed6 va8yei a19wyd 15rzub1 name 5j8bii duration delay timing-function 1e91rfo h29fi5 1q05mva k543x9 kxbuhr 1sxmvgn 4tin05 g0tn84">@-webkit-keyframes animation-5j8bii{from{opacity:0;}to{opacity:1;}}@keyframes animation-5j8bii{from{opacity:0;}to{opacity:1;}}@-webkit-keyframes animation-1e91rfo{0%{-webkit-transform:translate(0,0) scale(1,0.85) translate(0,0);-ms-transform:translate(0,0) scale(1,0.85) translate(0,0);transform:translate(0,0) scale(1,0.85) translate(0,0);}33.33%{-webkit-transform:translate(0,0) scale(1,0.9) translate(0,0);-ms-transform:translate(0,0) scale(1,0.9) translate(0,0);transform:translate(0,0) scale(1,0.9) translate(0,0);}100%{-webkit-transform:translate(0,0) scale(1,0.1) translate(0,0);-ms-transform:translate(0,0) scale(1,0.1) translate(0,0);transform:translate(0,0) scale(1,0.1) translate(0,0);}}@keyframes animation-1e91rfo{0%{-webkit-transform:translate(0,0) scale(1,0.85) translate(0,0);-ms-transform:translate(0,0) scale(1,0.85) translate(0,0);transform:translate(0,0) scale(1,0.85) translate(0,0);}33.33%{-webkit-transform:translate(0,0) scale(1,0.9) translate(0,0);-ms-transform:translate(0,0) scale(1,0.9) translate(0,0);transform:translate(0,0) scale(1,0.9) translate(0,0);}100%{-webkit-transform:translate(0,0) scale(1,0.1) translate(0,0);-ms-transform:translate(0,0) scale(1,0.1) translate(0,0);transform:translate(0,0) scale(1,0.1) translate(0,0);}}@-webkit-keyframes animation-h29fi5{0%{-webkit-transform:translate(0,0) translate(0,0) translate(0,15px);-ms-transform:translate(0,0) translate(0,0) translate(0,15px);transform:translate(0,0) translate(0,0) translate(0,15px);}33.33%{-webkit-transform:translate(0,0) translate(0,0) translate(0,10px);-ms-transform:translate(0,0) translate(0,0) translate(0,10px);transform:translate(0,0) translate(0,0) translate(0,10px);}100%{-webkit-transform:translate(0,0) translate(0,0) translate(0,30px);-ms-transform:translate(0,0) translate(0,0) translate(0,30px);transform:translate(0,0) translate(0,0) translate(0,30px);}}@keyframes animation-h29fi5{0%{-webkit-transform:translate(0,0) translate(0,0) translate(0,15px);-ms-transform:translate(0,0) translate(0,0) translate(0,15px);transform:translate(0,0) translate(0,0) translate(0,15px);}33.33%{-webkit-transform:translate(0,0) translate(0,0) translate(0,10px);-ms-transform:translate(0,0) translate(0,0) translate(0,10px);transform:translate(0,0) translate(0,0) translate(0,10px);}100%{-webkit-transform:translate(0,0) translate(0,0) translate(0,30px);-ms-transform:translate(0,0) translate(0,0) translate(0,30px);transform:translate(0,0) translate(0,0) translate(0,30px);}}@-webkit-keyframes animation-1q05mva{0%{-webkit-transform:translate(11.329999923706055px,0) scale(1,0.85) translate(-11.329999923706055px,0);-ms-transform:translate(11.329999923706055px,0) scale(1,0.85) translate(-11.329999923706055px,0);transform:translate(11.329999923706055px,0) scale(1,0.85) translate(-11.329999923706055px,0);}33.33%{-webkit-transform:translate(11.329999923706055px,0) scale(1,0.9) translate(-11.329999923706055px,0);-ms-transform:translate(11.329999923706055px,0) scale(1,0.9) translate(-11.329999923706055px,0);transform:translate(11.329999923706055px,0) scale(1,0.9) translate(-11.329999923706055px,0);}100%{-webkit-transform:translate(11.329999923706055px,0) scale(1,0.1) translate(-11.329999923706055px,0);-ms-transform:translate(11.329999923706055px,0) scale(1,0.1) translate(-11.329999923706055px,0);transform:translate(11.329999923706055px,0) scale(1,0.1) translate(-11.329999923706055px,0);}}@keyframes animation-1q05mva{0%{-webkit-transform:translate(11.329999923706055px,0) scale(1,0.85) translate(-11.329999923706055px,0);-ms-transform:translate(11.329999923706055px,0) scale(1,0.85) translate(-11.329999923706055px,0);transform:translate(11.329999923706055px,0) scale(1,0.85) translate(-11.329999923706055px,0);}33.33%{-webkit-transform:translate(11.329999923706055px,0) scale(1,0.9) translate(-11.329999923706055px,0);-ms-transform:translate(11.329999923706055px,0) scale(1,0.9) translate(-11.329999923706055px,0);transform:translate(11.329999923706055px,0) scale(1,0.9) translate(-11.329999923706055px,0);}100%{-webkit-transform:translate(11.329999923706055px,0) scale(1,0.1) translate(-11.329999923706055px,0);-ms-transform:translate(11.329999923706055px,0) scale(1,0.1) translate(-11.329999923706055px,0);transform:translate(11.329999923706055px,0) scale(1,0.1) translate(-11.329999923706055px,0);}}@-webkit-keyframes animation-k543x9{0%{-webkit-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,15px);-ms-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,15px);transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,15px);}33.33%{-webkit-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,10px);-ms-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,10px);transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,10px);}100%{-webkit-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,30px);-ms-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,30px);transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,30px);}}@keyframes animation-k543x9{0%{-webkit-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,15px);-ms-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,15px);transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,15px);}33.33%{-webkit-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,10px);-ms-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,10px);transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,10px);}100%{-webkit-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,30px);-ms-transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,30px);transform:translate(11.329999923706055px,0) translate(-11.329999923706055px,0) translate(0,30px);}}@-webkit-keyframes animation-kxbuhr{0%{-webkit-transform:translate(22.670000076293945px,0) scale(1,0.85) translate(-22.670000076293945px,0);-ms-transform:translate(22.670000076293945px,0) scale(1,0.85) translate(-22.670000076293945px,0);transform:translate(22.670000076293945px,0) scale(1,0.85) translate(-22.670000076293945px,0);}33.33%{-webkit-transform:translate(22.670000076293945px,0) scale(1,0.9) translate(-22.670000076293945px,0);-ms-transform:translate(22.670000076293945px,0) scale(1,0.9) translate(-22.670000076293945px,0);transform:translate(22.670000076293945px,0) scale(1,0.9) translate(-22.670000076293945px,0);}100%{-webkit-transform:translate(22.670000076293945px,0) scale(1,0.1) translate(-22.670000076293945px,0);-ms-transform:translate(22.670000076293945px,0) scale(1,0.1) translate(-22.670000076293945px,0);transform:translate(22.670000076293945px,0) scale(1,0.1) translate(-22.670000076293945px,0);}}@keyframes animation-kxbuhr{0%{-webkit-transform:translate(22.670000076293945px,0) scale(1,0.85) translate(-22.670000076293945px,0);-ms-transform:translate(22.670000076293945px,0) scale(1,0.85) translate(-22.670000076293945px,0);transform:translate(22.670000076293945px,0) scale(1,0.85) translate(-22.670000076293945px,0);}33.33%{-webkit-transform:translate(22.670000076293945px,0) scale(1,0.9) translate(-22.670000076293945px,0);-ms-transform:translate(22.670000076293945px,0) scale(1,0.9) translate(-22.670000076293945px,0);transform:translate(22.670000076293945px,0) scale(1,0.9) translate(-22.670000076293945px,0);}100%{-webkit-transform:translate(22.670000076293945px,0) scale(1,0.1) translate(-22.670000076293945px,0);-ms-transform:translate(22.670000076293945px,0) scale(1,0.1) translate(-22.670000076293945px,0);transform:translate(22.670000076293945px,0) scale(1,0.1) translate(-22.670000076293945px,0);}}@-webkit-keyframes animation-1sxmvgn{0%{-webkit-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,15px);-ms-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,15px);transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,15px);}33.33%{-webkit-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,10px);-ms-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,10px);transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,10px);}100%{-webkit-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,30px);-ms-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,30px);transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,30px);}}@keyframes animation-1sxmvgn{0%{-webkit-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,15px);-ms-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,15px);transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,15px);}33.33%{-webkit-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,10px);-ms-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,10px);transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,10px);}100%{-webkit-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,30px);-ms-transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,30px);transform:translate(22.670000076293945px,0) translate(-22.670000076293945px,0) translate(0,30px);}}@-webkit-keyframes animation-4tin05{0%{-webkit-transform:translate(34px,0) scale(1,0.85) translate(-34px,0);-ms-transform:translate(34px,0) scale(1,0.85) translate(-34px,0);transform:translate(34px,0) scale(1,0.85) translate(-34px,0);}33.33%{-webkit-transform:translate(34px,0) scale(1,0.9) translate(-34px,0);-ms-transform:translate(34px,0) scale(1,0.9) translate(-34px,0);transform:translate(34px,0) scale(1,0.9) translate(-34px,0);}100%{-webkit-transform:translate(34px,0) scale(1,0.1) translate(-34px,0);-ms-transform:translate(34px,0) scale(1,0.1) translate(-34px,0);transform:translate(34px,0) scale(1,0.1) translate(-34px,0);}}@keyframes animation-4tin05{0%{-webkit-transform:translate(34px,0) scale(1,0.85) translate(-34px,0);-ms-transform:translate(34px,0) scale(1,0.85) translate(-34px,0);transform:translate(34px,0) scale(1,0.85) translate(-34px,0);}33.33%{-webkit-transform:translate(34px,0) scale(1,0.9) translate(-34px,0);-ms-transform:translate(34px,0) scale(1,0.9) translate(-34px,0);transform:translate(34px,0) scale(1,0.9) translate(-34px,0);}100%{-webkit-transform:translate(34px,0) scale(1,0.1) translate(-34px,0);-ms-transform:translate(34px,0) scale(1,0.1) translate(-34px,0);transform:translate(34px,0) scale(1,0.1) translate(-34px,0);}}@-webkit-keyframes animation-g0tn84{0%{-webkit-transform:translate(34px,0) translate(-34px,0) translate(0,15px);-ms-transform:translate(34px,0) translate(-34px,0) translate(0,15px);transform:translate(34px,0) translate(-34px,0) translate(0,15px);}33.33%{-webkit-transform:translate(34px,0) translate(-34px,0) translate(0,10px);-ms-transform:translate(34px,0) translate(-34px,0) translate(0,10px);transform:translate(34px,0) translate(-34px,0) translate(0,10px);}100%{-webkit-transform:translate(34px,0) translate(-34px,0) translate(0,30px);-ms-transform:translate(34px,0) translate(-34px,0) translate(0,30px);transform:translate(34px,0) translate(-34px,0) translate(0,30px);}}@keyframes animation-g0tn84{0%{-webkit-transform:translate(34px,0) translate(-34px,0) translate(0,15px);-ms-transform:translate(34px,0) translate(-34px,0) translate(0,15px);transform:translate(34px,0) translate(-34px,0) translate(0,15px);}33.33%{-webkit-transform:translate(34px,0) translate(-34px,0) translate(0,10px);-ms-transform:translate(34px,0) translate(-34px,0) translate(0,10px);transform:translate(34px,0) translate(-34px,0) translate(0,10px);}100%{-webkit-transform:translate(34px,0) translate(-34px,0) translate(0,30px);-ms-transform:translate(34px,0) translate(-34px,0) translate(0,30px);transform:translate(34px,0) translate(-34px,0) translate(0,30px);}}.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}.css-1dv1kvn{border:0;-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px;}.css-pzrpby{display:none;font-size:10px;margin-left:auto;text-transform:uppercase;}.hasLinks .css-pzrpby{display:block;min-height:10px;}@media (min-width:740px){.hasLinks .css-pzrpby{margin:none;position:absolute;right:20px;}}@media (min-width:1024px){.hasLinks .css-pzrpby{display:none;min-height:0;}}.css-1pd1msn{display:inline-block;font-size:0.875rem;line-height:1.25rem;-webkit-transition:color 0.6s ease;transition:color 0.6s ease;color:#121212;}.css-1pd1msn:hover{color:#666;}.css-8atqhb{width:100%;}.css-kgn7zc{border:0;-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px;border-radius:3px;cursor:pointer;font-family:nyt-franklin,helvetica,arial,sans-serif;-webkit-transition:ease 0.6s;transition:ease 0.6s;white-space:nowrap;vertical-align:middle;background-color:transparent;color:#000;font-size:11px;line-height:11px;font-weight:700;-webkit-letter-spacing:0.02em;-moz-letter-spacing:0.02em;-ms-letter-spacing:0.02em;letter-spacing:0.02em;padding:11px 12px 8px;background:#fff;display:inline-block;left:44px;text-transform:uppercase;-webkit-transition:none;transition:none;z-index:5;}.css-kgn7zc:active,.css-kgn7zc:focus{-webkit-clip:auto;clip:auto;overflow:visible;width:auto;height:auto;}.css-kgn7zc::-moz-focus-inner{padding:0;border:0;}.css-kgn7zc:-moz-focusring{outline:1px dotted;}.css-kgn7zc:disabled,.css-kgn7zc.disabled{opacity:0.5;cursor:default;}.css-kgn7zc:active,.css-kgn7zc.active{background-color:#f7f7f7;}@media (min-width:740px){.css-kgn7zc:hover{background-color:#f7f7f7;}}.css-kgn7zc:focus{margin-top:3px;padding:8px 8px 6px;}@media (max-width:600px){.css-kgn7zc:focus{margin-top:12px;margin-left:9px;}}@media (min-width:1024px){.css-kgn7zc{left:112px;}}.css-1hyfx7x{display:none;}@media (min-width:1150px){.css-1jmk4jh{margin:0 auto;max-width:1200px;padding:0 3% 9px;}}.NYTApp .css-1jmk4jh{display:none;}@media print{.css-1jmk4jh{display:none;}}.css-1e1s8k7{font-size:11px;text-align:center;padding-bottom:25px;}@media (min-width:1024px){.css-1e1s8k7{padding:0 3% 9px;}}.css-1e1s8k7.dockVisible{padding-bottom:45px;}@media (min-width:1024px){.css-1e1s8k7.dockVisible{padding:0 3% 45px;}}@media (min-width:1150px){.css-1e1s8k7{margin:0 auto;max-width:1200px;}}.NYTApp .css-1e1s8k7{display:none;}@media print{.css-1e1s8k7{display:none;}}.css-1qa4qp6{border-top:1px solid #ebebeb;padding-top:9px;margin:0 0 35px;}.css-jq1cx6{color:#666;font-family:nyt-franklin,helvetica,arial,sans-serif;padding:10px 0;-webkit-text-decoration:none;text-decoration:none;white-space:nowrap;}.css-jq1cx6:hover{-webkit-text-decoration:underline;text-decoration:underline;}.css-yywogo{color:var(--color-signal-editorial,#326891);}.css-yywogo:visited{color:var(--color-signal-editorial,#326891);}.css-vxcmzt{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}.css-79elbk{position:relative;}.css-1baulvz{display:inline-block;}.css-1eeh360{height:auto;width:auto;border-radius:30px;}.css-1eeh360:focus{outline:none;box-shadow:0 0 4px 1px rgb(0 95 204);}@supports selector(:focus-visible){.css-1eeh360:focus{box-shadow:none;}.css-1eeh360:focus-visible{box-shadow:0 0 4px 1px rgb(0 95 204);}}.css-1re6eyk{font-size:0.75rem;line-height:0.75rem;margin-top:auto;}.css-1mlnk6q{border-radius:30px;padding:6px;padding:8px 10px 7px;display:inline-block;}@media (max-width:600px){.css-1mlnk6q{padding:8px 7px 7px;}}.css-1mlnk6q svg path{fill:var(--color-content-primary,#121212);}.css-2urdiw{vertical-align:middle;margin-top:-1px;margin-right:5px;overflow:visible;}.css-1nii3md{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;vertical-align:initial;border-radius:30px;background-color:transparent;border:none;bottom:0.05rem;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:0.75rem;font-weight:500;height:auto;width:auto;line-height:1rem;overflow:visible;position:relative;text-transform:uppercase;}.css-1nii3md:hover,.css-1nii3md:focus{-webkit-text-decoration:none;text-decoration:none;border-color:#ccc;}.css-1yhvmgx{height:auto;width:auto;border:solid 1px var(--color-stroke-quaternary,#DFDFDF);background-color:var(--color-background-primary,#FFFFFF);border-radius:30px;font-size:0.75rem;font-family:nyt-franklin,helvetica,arial,sans-serif;text-transform:uppercase;}.css-1yhvmgx:hover{background-color:var(--color-background-tertiary,#EBEBEB);border:1px solid var(--color-background-tertiary,#EBEBEB);}.css-1yhvmgx .hiddenClass{display:none;}.css-1yhvmgx[aria-checked='true'] .saved-fill{fill:var(--color-stroke-primary,#121212);}.css-1yhvmgx[aria-checked='true'] .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-1yhvmgx[aria-checked='false'] .saved-fill{fill:none;}.css-1yhvmgx[aria-checked='false'] .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-1yhvmgx[aria-busy='true']{cursor:default;background-color:var(--color-background-tertiary,#EBEBEB);}.css-d8bdto{color:#999;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:17px;margin-bottom:5px;}@media print{.css-d8bdto{display:none;}}.css-1liwv7v{padding:0;margin-left:0;margin-right:0;}@media (max-width:420px){.css-1liwv7v{margin-left:-9px;margin-right:-20px;}}.css-2ykviq{color:#999;display:inline;margin-right:12px;width:100%;}.unlimited-gift .css-2ykviq.sha-std-share{display:none;}@media (max-width:420px){.css-2ykviq{margin-right:6px;}}.css-2ykviq > a,.css-2ykviq > button{-webkit-text-decoration:none;text-decoration:none;}.css-2ykviq > a:focus,.css-2ykviq > button:focus{display:inline-block;outline:none;box-shadow:0 0 2px 1px rgb(0 95 204);}@supports selector(:focus-visible){.css-2ykviq > a:focus,.css-2ykviq > button:focus{box-shadow:none;}.css-2ykviq > a:focus-visible,.css-2ykviq > button:focus-visible{box-shadow:0 0 2px 1px rgb(0 95 204);}}.css-2ykviq > a:focus{border-radius:100%;}.css-2ykviq:last-of-type{margin-right:0;}.css-1nurhyi{height:auto;width:auto;border-radius:100%;background-color:transparent;}.css-93zicp{display:none;}@media (min-width:375px){.css-93zicp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:16px;height:31px;}}@media (min-width:740px){.css-93zicp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:16px;height:31px;}}@media (min-width:1024px){.css-93zicp{display:none;}}@media print{.css-93zicp{display:none;}}.css-12fr9lp{height:23px;margin-top:6px;}.css-18z7m18{display:none;}@media (min-width:1024px){.css-18z7m18{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-top:0;}}@media print{.css-18z7m18{display:block;}}.css-iro8fb{display:none;}@media (min-width:375px){.css-iro8fb{position:fixed;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;opacity:0;z-index:1;-webkit-transition:all 0.2s ease-in-out;transition:all 0.2s ease-in-out;width:100%;height:32.063px;background:white;padding:5px 0;top:0;text-align:center;font-family:nyt-cheltenham,georgia,'times new roman',times,serif;box-shadow:rgba(0,0,0,0.08) 0 0 5px 1px;border-bottom:1px solid #e2e2e2;}}@media print{.css-iro8fb{position:relative;border:none;display:inline-block;opacity:1 !important;visibility:visible !important;}}@media (max-width:739px){.NYTApp .css-iro8fb{display:none;}}.css-1hqnpie{margin-left:20px;margin-right:20px;max-width:1605px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;width:100%;}@media (min-width:1360px){.css-1hqnpie{margin-left:20px;margin-right:20px;}}@media (min-width:1780px){.css-1hqnpie{margin-left:auto;margin-right:auto;}}@media print{.css-1hqnpie{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-13ctjxq{display:none;}@media (min-width:740px){.css-13ctjxq{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;max-width:1605px;overflow:hidden;position:absolute;width:45%;margin-left:calc((100% - 45%) / 2);}@media (min-width:1024px){.css-13ctjxq{width:50%;margin-left:calc((100% - 50%) / 2);}}}@media (min-width:740px){.NYTApp .css-13ctjxq{width:90%;margin-left:calc((100% - 90%) / 2);}@media (min-width:1024px){.NYTApp .css-13ctjxq{width:63%;margin-left:calc((100% - 63%) / 2);}}}@media print{.css-13ctjxq{display:none;}}.css-rnl02l{font-family:nyt-cheltenham-small,georgia,'times new roman';font-weight:400;font-size:13px;-webkit-letter-spacing:0.015em;-moz-letter-spacing:0.015em;-ms-letter-spacing:0.015em;letter-spacing:0.015em;margin-top:10.5px;margin-bottom:10.5px;margin-right:auto;white-space:nowrap;text-overflow:ellipsis;}.css-1u4hfeb{font-family:nyt-franklin,helvetica,arial,sans-serif;font-weight:700;font-size:0.75rem;text-transform:uppercase;-webkit-letter-spacing:0;-moz-letter-spacing:0;-ms-letter-spacing:0;letter-spacing:0;margin-top:12.5px;margin-bottom:auto;margin-left:auto;white-space:nowrap;}.css-1u4hfeb:hover{-webkit-text-decoration:underline;text-decoration:underline;}.css-x15j1o{display:inline-block;padding-left:7px;padding-right:7px;font-size:13px;margin-top:10px;margin-bottom:auto;color:#ccc;}.css-tvohiw{margin-top:-1px;margin-bottom:auto;margin-left:auto;z-index:50;box-shadow:-14px 2px 7px -2px rgba(255,255,255,0.7);}.css-b4nnp0{margin-top:1px;}@media (min-width:1024px){.css-b4nnp0{margin-top:0;}}.css-1n6z4y{font-family:nyt-franklin,helvetica,arial,sans-serif;color:#ccc !important;border-left:1px solid #ccc;margin-left:10px;padding:10px;display:none;}@media print{.css-1n6z4y{display:inline-block;}}.css-777zgl{position:absolute;width:1px;height:1px;margin:-1px;padding:0;border:0;-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);overflow:hidden;text-align:center;}.css-777zgl:focus-visible{background-color:#fff;border-radius:3px;height:auto;width:auto;-webkit-clip:auto;clip:auto;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:0.6875rem;font-weight:700;left:50%;padding:8px 8px 6px;-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%);transform:translateX(-50%);top:5px;}.css-rfqw0c{text-align:center;height:100%;display:block;}.css-l9onyx{color:#ccc;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:0.5625rem;font-weight:300;-webkit-letter-spacing:0.05rem;-moz-letter-spacing:0.05rem;-ms-letter-spacing:0.05rem;letter-spacing:0.05rem;line-height:0.5625rem;margin-bottom:9px;text-align:center;text-transform:uppercase;}.css-1bzlfz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;font-family:nyt-franklin,helvetica,arial,sans-serif;font-weight:600;color:var(--color-content-secondary,#363636);padding:0 20px;height:50px;}.css-1bzlfz *{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;text-rendering:optimizeLegibility;-webkit-touch-callout:none;}@media (min-width:740px){.css-1bzlfz{padding:0 50px;height:42px;}}@media (min-width:1024px){.css-1bzlfz{padding:0 74px 0 112px;}}.css-1igvuto{background-color:rgba(0,0,0,0);font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:14px;font-weight:500;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:opacity 0.2s;transition:opacity 0.2s;height:15px;color:var(--color-content-primary,#121212);}.css-1igvuto:hover{opacity:0.6;}@media (min-width:1150px){.css-1igvuto{display:none;}}.css-1igvuto span{margin-top:1px;}.css-mln36k{display:none;font-size:13px;-webkit-letter-spacing:0.04em;-moz-letter-spacing:0.04em;-ms-letter-spacing:0.04em;letter-spacing:0.04em;text-transform:uppercase;font-weight:700;}@media (min-width:1150px){.css-mln36k{display:block;}}.css-f40pzg{width:9px;height:9px;margin-right:5px;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);border-left:1px solid var(--color-stroke-primary,#121212);border-bottom:1px solid var(--color-stroke-primary,#121212);}.css-f6lhej{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;font-size:12px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.css-1ialerq{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}.css-1eut9gw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(0,0,0,0);margin-right:10px;-webkit-transition:opacity 0.2s;transition:opacity 0.2s;width:22px;height:22px;-webkit-transform:scale(1.3);-ms-transform:scale(1.3);transform:scale(1.3);}.css-1eut9gw:hover{opacity:0.6;}@media (min-width:740px){.css-1eut9gw{-webkit-transform:none;-ms-transform:none;transform:none;}}.css-1t7yl1y{display:none;}@media (min-width:600px){.css-1t7yl1y{display:block;}}.css-og85jy{display:block;}@media (min-width:600px){.css-og85jy{display:none;}}.css-1701swk{height:14px;width:14px;margin-right:10px;}.css-uzyn7p{position:relative;padding:0 20px;border-top:1px solid var(--color-stroke-quaternary,#DFDFDF);height:calc(100% - 40px);overflow-y:scroll;}.css-uzyn7p *{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;text-rendering:optimizeLegibility;-webkit-touch-callout:none;}@media (min-width:740px){.css-uzyn7p{padding:0 50px;}}@media (min-width:1024px){.css-uzyn7p{margin:0 4px;padding:0 74px 0 112px;}}.css-1vxywau{padding:25px 0 20px;border-bottom:1px solid var(--color-stroke-quaternary,#DFDFDF);}.css-1nng8z9{font-size:13px;text-transform:uppercase;font-family:nyt-franklin,helvetica,arial,sans-serif;font-weight:700;-webkit-letter-spacing:0.04em;-moz-letter-spacing:0.04em;-ms-letter-spacing:0.04em;letter-spacing:0.04em;color:var(--color-content-secondary,#363636);margin-bottom:15px;}@media (min-width:1150px){.css-1nng8z9{display:none;}}.css-9wqu2x{font-size:40px;line-height:48px;font-family:nyt-cheltenham,georgia,'times new roman',times,serif;margin-bottom:14px;}.css-qsd3hm{font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:15px;line-height:22px;margin-bottom:10px;}.css-1e6es05{font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:15px;line-height:22px;padding:4px 0;display:block;}.css-p98d0w{padding-top:30px;}@media (min-width:740px){.css-p98d0w{padding-bottom:35px;}}.css-xx7kwh{font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:14px;line-height:16px;color:#999;text-transform:capitalize;padding-bottom:5px;}.css-4gvq6l{font-family:nyt-imperial,georgia,'times new roman',times,serif;font-size:17px;line-height:26px;color:var(--color-content-secondary,#363636);margin-bottom:25px;}@media (min-width:1150px){.css-4gvq6l{font-size:18px;line-height:28px;}}@media (min-width:740px){.css-4gvq6l{margin-bottom:33px;}}.css-8hvvyd{margin-bottom:0.9375rem;}.css-1rtlxy{display:none;position:absolute;right:20px;top:20px;background-color:rgba(0,0,0,0);z-index:3;}.css-1rtlxy svg circle{-webkit-transition:fill-opacity 0.2s;transition:fill-opacity 0.2s;}.css-1rtlxy svg circle:hover{fill-opacity:1;}@media (min-width:1150px){.css-1rtlxy{display:block;}}@media print{.css-1rtlxy{display:none;}}.css-1iruc8t{list-style:none;margin:0;padding:0;}.css-103l8m3{margin:1.25rem 0;}.css-1rr4qq7{-webkit-flex:1;-ms-flex:1;flex:1;}.css-sg7scw{padding:0 20px;}.css-sg7scw::before{background-color:#fff;border-bottom:1px solid #e2e2e2;border-top:2px solid #e2e2e2;content:'';display:block;height:1px;margin-top:0;}@media (min-width:740px){.css-sg7scw{padding:0 3%;}}@media (min-width:1150px){.css-sg7scw{padding:0;}}.css-jxzr5i{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-flow:row;-ms-flex-flow:row;flex-flow:row;}.css-oylsik{display:block;height:44px;vertical-align:middle;width:184px;}.css-1otr2jl{margin:18px 0 0 auto;}.css-184m8ie{color:#567b95;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:11px;font-style:normal;font-weight:400;line-height:11px;-webkit-text-decoration:none;text-decoration:none;}.css-qtw155{display:block;}@media (min-width:1150px){.css-qtw155{display:none;}}.css-v0l3hm{display:none;}@media (min-width:1150px){.css-v0l3hm{display:block;}}.css-g4gku8{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-top:10px;min-width:600px;}.css-6xhk3s{border-left:1px solid #e2e2e2;-webkit-flex:1;-ms-flex:1;flex:1;padding-left:15px;}.css-1onhbft{color:#333;font-size:13px;font-weight:700;font-family:nyt-franklin,helvetica,arial,sans-serif;height:25px;line-height:15px;margin:0;text-transform:uppercase;width:150px;}.css-tj0ten{margin-bottom:5px;white-space:nowrap;}.css-tj0ten:last-child{margin-bottom:10px;}.css-ist4u3.desktop{display:none;}@media (min-width:740px){.css-ist4u3.desktop{display:block;}.css-ist4u3.smartphone{display:none;}}.css-1gprdgz{list-style:none;margin:0;padding:0;-webkit-columns:2;columns:2;padding:0 0 15px;}.css-10t7hia{height:34px;line-height:34px;list-style-type:none;}.css-10t7hia.desktop{display:none;}@media (min-width:740px){.css-10t7hia.desktop{display:block;}.css-10t7hia.smartphone{display:none;}}.css-e9w26l{color:#333;display:block;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:15px;font-weight:500;height:34px;line-height:34px;-webkit-text-decoration:none;text-decoration:none;text-transform:capitalize;}.css-yk8vb4{color:#000;display:inline-block;font-family:nyt-franklin,helvetica,arial,sans-serif;-webkit-text-decoration:none;text-decoration:none;width:150px;font-size:14px;font-weight:500;height:23px;line-height:16px;}.css-yk8vb4:hover{cursor:pointer;-webkit-text-decoration:underline;text-decoration:underline;}body.dark .css-yk8vb4{color:#fff;}.css-z6qatp{color:#000;display:inline-block;font-family:nyt-franklin,helvetica,arial,sans-serif;-webkit-text-decoration:none;text-decoration:none;width:150px;font-size:16px;font-weight:700;height:25px;line-height:15px;padding-bottom:0;}.css-z6qatp:hover{cursor:pointer;-webkit-text-decoration:underline;text-decoration:underline;}body.dark .css-z6qatp{color:#fff;}.css-1ea6cym{color:#000;display:inline-block;font-family:nyt-franklin,helvetica,arial,sans-serif;-webkit-text-decoration:none;text-decoration:none;width:150px;font-size:11px;font-weight:500;height:23px;line-height:21px;}.css-1ea6cym:hover{cursor:pointer;-webkit-text-decoration:underline;text-decoration:underline;}body.dark .css-1ea6cym{color:#fff;}.css-6td9kr{list-style:none;margin:0;padding:0;border-top:1px solid #e2e2e2;margin-top:2px;padding-top:10px;}.css-1o03u4n{display:inline-block;height:13px;width:13px;margin-right:7px;vertical-align:middle;}.css-zera2v{margin:40px auto 0 auto;max-width:600px;width:calc(100% - 40px);}@media (min-width:740px){.css-zera2v{width:100%;}}@media print{.css-zera2v{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-1r7ky0e .e6idgb70 + .e1h9rw200{margin-top:0;}.css-1r7ky0e .eoo0vm40 + .e1gnsphs0{margin-top:-0.3em;}.css-1r7ky0e .e6idgb70 + .eoo0vm40{margin-top:0;}.css-1r7ky0e .eoo0vm40 + figure{margin-top:1.2rem;}.css-1r7ky0e .e1gnsphs0 + figure{margin-top:1.2rem;}.css-ew4tgv{display:none;}@media (min-width:1024px){.css-ew4tgv{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-right:0;margin-left:auto;width:130px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}}@media (min-width:1150px){.css-ew4tgv{width:210px;}}@media print{.css-ew4tgv{display:none;}}.css-s99gbd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;margin-bottom:1rem;}@media (min-width:1024px){.css-s99gbd{-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;height:100%;width:945px;margin-left:auto;margin-right:auto;}}@media (min-width:1150px){.css-s99gbd{width:1110px;margin-left:auto;margin-right:auto;}}@media (min-width:1280px){.css-s99gbd{width:1170px;}}@media (min-width:1440px){.css-s99gbd{width:1200px;}}@media print{.css-s99gbd{margin-left:0;margin-right:0;width:100%;max-width:100%;}}@media print{.css-s99gbd{margin-bottom:1em;display:block;}}.css-53u6y8{margin-left:auto;margin-right:auto;width:100%;}@media (min-width:1024px){.css-53u6y8{margin-left:calc((100% - 600px) / 2);margin-right:0;width:600px;}}@media (min-width:1440px){.css-53u6y8{max-width:600px;width:600px;margin-left:calc((100% - 600px) / 2);}}@media print{.css-53u6y8{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-1jp38cr{margin-left:20px;margin-right:20px;}@media (min-width:600px){.css-1jp38cr{width:calc(100% - 40px);max-width:600px;margin:1.5rem auto 1em;}}@media (min-width:1440px){.css-1jp38cr{width:600px;max-width:600px;margin:1.5rem auto 1em;}}@media print{.css-1jp38cr{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-19vx93s{font-family:nyt-imperial,georgia,'times new roman',times,serif;font-style:italic;font-size:1.0625rem;line-height:1.5rem;width:calc(100% - 40px);max-width:600px;margin:1rem auto 0.75rem;}@media (min-width:740px){.css-19vx93s{font-size:1.1875rem;line-height:1.75rem;margin-bottom:1.25rem;}}@media (min-width:1440px){.css-19vx93s{width:600px;max-width:600px;}}.css-19vx93s:empty{display:none;}@media print{.css-19vx93s{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-1ly73wi{position:absolute;width:1px;height:1px;margin:-1px;padding:0;border:0;-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);overflow:hidden;}.css-1qq8bvn{display:inline-block;height:100%;}.css-3ca3tv{height:50px;width:50px;margin-right:10px;border-radius:2px;}.css-b6bqam{height:100%;position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}.css-1nz2xi2{box-sizing:border-box;height:100%;border-left:1px solid rgba(248,248,248,0.1);padding:5px 10px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:0 0 230px;-ms-flex:0 0 230px;flex:0 0 230px;position:relative;}.css-1nz2xi2 > a{position:absolute;width:calc(100% - 20px);height:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}.css-1nz2xi2 > a:focus{background-color:rgba(255,255,255,0.2);overflow:hidden;}.css-1bykrda{width:40px;height:40px;background-color:rgba(255,255,255,0.1);border-radius:50%;display:inline-block;-webkit-flex:0 0 40px;-ms-flex:0 0 40px;flex:0 0 40px;margin-right:10px;color:#F8F8F8;}.css-1bykrda:focus{background-color:rgba(255,255,255,0.2);overflow:hidden;}.css-lzc52a{font-size:10px;line-height:12px;color:#F8F8F8;opacity:0.5;display:block;font-family:nyt-franklin,helvetica,arial,sans-serif;margin-bottom:3px;}.css-13glguy{width:100%;box-sizing:border-box;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;z-index:1;}.css-x1iy13{margin-top:30px;font-size:40px;line-height:45px;font-weight:400;color:var(--color-content-primary,#121212);font-family:nyt-cheltenham,georgia,'times new roman',times,serif;}.css-1dqxzif{margin-top:20px;font-size:20px;line-height:26px;font-weight:400;color:var(--color-content-secondary,#363636);font-family:nyt-cheltenham,georgia,'times new roman',times,serif;}.css-5kewg3{margin-top:30px;font-size:14px;line-height:20px;color:var(--color-content-primary,#121212);font-family:nyt-franklin,helvetica,arial,sans-serif;font-weight:600;margin-bottom:20px;}.css-83wln0{position:absolute;top:0;left:0;width:100%;height:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}.css-1unwftr{width:100%;position:absolute;top:0;left:0;}.css-1w9agjg{position:absolute;bottom:0px;width:calc(100% - 60px);margin:auto;height:calc(100% - 80px);outline:none;}.css-138971x{margin-left:auto;margin-right:auto;max-width:600px;width:calc(100% - 40px);}.css-1q2w90k{opacity:1;visibility:visible;-webkit-animation-name:animation-5j8bii;animation-name:animation-5j8bii;-webkit-animation-duration:300ms;animation-duration:300ms;-webkit-animation-delay:0ms;animation-delay:0ms;-webkit-animation-timing-function:ease-out;animation-timing-function:ease-out;}@media print{.css-1q2w90k{display:none;}}@media (min-width:1024px){.css-1q2w90k{position:fixed;width:100%;top:0;left:0;z-index:200;background-color:#fff;border-bottom:none;-webkit-transition:all 0.2s ease-in-out;transition:all 0.2s ease-in-out;}}@media (min-width:1024px){.css-1bymuyk{position:relative;border-bottom:1px solid #e2e2e2;}}.css-ui9rw0{background:#fff;border-bottom:1px solid #e2e2e2;height:36px;padding:8px 15px 3px;position:relative;}@media (min-width:740px){.css-ui9rw0{background:#fff;padding:10px 15px 6px;}}@media (min-width:1024px){.css-ui9rw0{background:transparent;border-bottom:0;padding:4px 15px 2px;}}@media (min-width:1024px){.css-ui9rw0{margin:0 auto;max-width:1605px;}}.css-1f7ibof{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;left:10px;position:absolute;}@media print{.css-1f7ibof{display:none;}}.css-10698na{text-align:center;}@media (min-width:740px){.css-10698na{padding-top:0;}}@media print{.css-10698na a[href]::after{content:'';}.css-10698na svg{fill:black;}}.css-nhjhh0{display:block;width:189px;height:26px;margin:5px auto 0;}@media (min-width:740px){.css-nhjhh0{width:225px;height:31px;margin:4px auto 0;}}@media (min-width:1024px){.css-nhjhh0{width:195px;height:26px;margin:6px auto 0;}}.css-1awy3rz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;position:absolute;right:10px;top:8px;}@media (min-width:740px){.css-1awy3rz{top:10px;}}@media (min-width:1024px){.css-1awy3rz{top:4px;}}@media print{.css-1awy3rz{display:none;}}.css-c5j6tx{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:11px;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;padding:13px 20px 12px;}@media (min-width:740px){.css-c5j6tx{position:relative;}}@media (min-width:1024px){.css-c5j6tx{-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;border:none;padding:0;height:0;-webkit-transform:translateY(48px);-ms-transform:translateY(48px);transform:translateY(48px);-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;}}@media print{.css-c5j6tx{display:none;}}.css-vfkorq{color:#121212;font-size:0.6875rem;font-family:nyt-franklin,helvetica,arial,sans-serif;display:none;width:auto;font-weight:700;}@media (min-width:740px){.css-vfkorq{text-align:center;width:100%;font-weight:700;}}@media (min-width:1024px){.css-vfkorq{font-size:0.875rem;line-height:1.25rem;width:auto;margin-bottom:4px;font-weight:400;}}.css-1bvtpon{display:none;}.css-1lnfix7{top:0;position:-webkit-sticky;position:sticky;background-color:var(--color-background-elevated,#FFFFFF);z-index:902;}@media print{.css-1lnfix7{display:none;}}@media (min-width:1024px){.css-1lnfix7{margin-top:3px;}}@media (min-width:1024px){.css-1lnfix7:empty{margin-top:0;}}.css-mfml7 .actionbar-button{background:var(--color-background-primary,#FFFFFF);border:1px solid var(--color-stroke-quaternary,#DFDFDF);color:var(--color-content-primary,#121212);box-shadow:none;}.css-mfml7 .actionbar-button svg > path{fill:var(--color-stroke-primary,#121212);}.css-mfml7 .actionbar-button:hover{border:1px solid var(--color-stroke-quaternary,#DFDFDF);background-color:var(--color-background-tertiary,#EBEBEB);color:var(--color-content-primary,#121212);}.css-mfml7 .actionbar-button:hover svg > path{fill:var(--color-stroke-primary,#121212);}.css-mfml7 .actionbar-button:hover svg > g{stroke:var(--color-stroke-primary,#121212);}.css-mfml7 .actionbar-button[aria-checked='true'] .saved-fill{fill:var(--color-stroke-primary,#121212);}.css-mfml7 .actionbar-button[aria-checked='true'] .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-mfml7 .actionbar-button[aria-checked='true']:hover .saved-fill{fill:var(--color-stroke-primary,#121212);}.css-mfml7 .actionbar-button[aria-checked='true']:hover .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-mfml7 .actionbar-button[aria-checked='false'] .saved-fill{fill:none;}.css-mfml7 .actionbar-button[aria-checked='false'] .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-mfml7 .actionbar-button[aria-checked='false']:hover .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-mfml7 .actionbar-button:focus{box-shadow:0 0 2px 1px rgb(0 95 204);outline:3px solid transparent;outline-offset:2px;}@supports selector(:focus-visible){.css-mfml7 .actionbar-button:focus{box-shadow:none;}.css-mfml7 .actionbar-button:focus-visible{box-shadow:0 0 2px 1px rgb(0 95 204);outline:3px solid transparent;outline-offset:2px;}}.css-4skfbu{color:#999;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:17px;margin-bottom:5px;margin-bottom:0;}@media print{.css-4skfbu{display:none;}}.css-1gh9hw8{color:#999;display:inline;margin-right:12px;width:100%;position:relative;}.unlimited-gift .css-1gh9hw8.sha-std-share{display:none;}@media (max-width:420px){.css-1gh9hw8{margin-right:6px;}}.css-1gh9hw8 > a,.css-1gh9hw8 > button{-webkit-text-decoration:none;text-decoration:none;}.css-1gh9hw8 > a:focus,.css-1gh9hw8 > button:focus{display:inline-block;outline:none;box-shadow:0 0 2px 1px rgb(0 95 204);}@supports selector(:focus-visible){.css-1gh9hw8 > a:focus,.css-1gh9hw8 > button:focus{box-shadow:none;}.css-1gh9hw8 > a:focus-visible,.css-1gh9hw8 > button:focus-visible{box-shadow:0 0 2px 1px rgb(0 95 204);}}.css-1gh9hw8 > a:focus{border-radius:100%;}.css-1gh9hw8:last-of-type{margin-right:0;}.css-zd9juy{display:inline-block;vertical-align:middle;width:20px;border-radius:100%;padding:6px;overflow:initial;vertical-align:middle;height:20px;}.css-zd9juy path{fill:var(--color-content-primary,#121212);}.css-lu72is{direction:ltr;display:inline-block;vertical-align:middle;border-radius:30px;padding:6px 10px 6px;font-size:0.75rem;font-family:nyt-franklin,helvetica,arial,sans-serif;line-height:0.9375rem;text-align:right;font-weight:500;}.css-lu72is:hover .gift-count{background-color:#fafafa;}@media (max-width:600px){.css-lu72is{padding:6px 7px 5px;}}.css-lu72is svg{margin-right:5px;vertical-align:-6px;height:20px;}.css-lu72is .sha-arrow-icon{display:none;}.unlimited-gift .css-lu72is .sha-gift-icon{display:none;}.unlimited-gift .css-lu72is .sha-arrow-icon{display:inline-block;}.css-eap6fy{height:18px;width:18px;padding:7px;overflow:visible;vertical-align:middle;cursor:not-allowed;}.css-eap6fy g{stroke-width:0.1px;}@media (min-width:1150px){.css-eap6fy:hover g,.css-eap6fy:focus g{stroke:var(--color-stroke-secondary,#8B8B8B);opacity:1;}}.css-1vxca1d{position:relative;margin:0 auto;}@media (min-width:600px){.css-1vxca1d{margin:0 auto 20px;}}.css-1vxca1d .relatedcoverage + .recirculation{margin-top:20px;}.css-1vxca1d .wrap + .recirculation{margin-top:20px;}@media (min-width:1024px){.css-1vxca1d{padding-top:40px;}}.css-1aeqhal{display:none;position:relative;min-height:280px;}@media (min-width:765px){.css-1aeqhal{background-color:#f7f7f7;border-bottom:1px solid #f3f3f3;display:block;padding-bottom:15px;padding-top:15px;margin:0;}}@media print{.css-1aeqhal{display:none;}}.css-1u46b97{display:inline;color:var(--color-content-quaternary,#727272);font-family:nyt-imperial,georgia,'times new roman',times,serif;line-height:1.125rem;-webkit-letter-spacing:0.01em;-moz-letter-spacing:0.01em;-ms-letter-spacing:0.01em;letter-spacing:0.01em;font-size:0.75rem;}@media (min-width:740px){.css-1u46b97{font-size:0.75rem;}}@media (min-width:1150px){.css-1u46b97{font-size:0.8125rem;}}.css-10i3hc{color:#999;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:17px;margin-bottom:5px;width:calc(100% - 40px);max-width:600px;margin:1.5rem auto 2rem;margin-bottom:1rem;}@media print{.css-10i3hc{display:none;}}@media (min-width:1440px){.css-10i3hc{width:600px;max-width:600px;}}@media (min-width:600px){.css-10i3hc{-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}}.css-10i3hc:empty{display:none;}@media (min-width:600px){.css-10i3hc{margin-bottom:1rem;}}.css-jf7ug7{color:#999;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:17px;margin-bottom:5px;width:calc(100% - 40px);max-width:600px;margin:1.5rem auto 2rem;}@media print{.css-jf7ug7{display:none;}}@media (min-width:1440px){.css-jf7ug7{width:600px;max-width:600px;}}@media (min-width:600px){.css-jf7ug7{-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}}.css-sxwst7{background-color:#f7f7f7;border-bottom:1px solid #f3f3f3;border-top:1px solid #f3f3f3;margin:2rem auto;padding-bottom:30px;padding-top:12px;text-align:center;position:relative;margin-top:60px;min-height:280px;}@media (min-width:740px){.css-sxwst7{margin:3rem auto;}}@media print{.css-sxwst7{display:none;}}@media (min-width:740px){.css-sxwst7{margin-bottom:0;margin-top:0;}}.css-1a5mdf6{cursor:pointer;margin:0;border-top:1px solid #ebebeb;color:#333;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:13px;font-weight:700;height:44px;-webkit-letter-spacing:0.04rem;-moz-letter-spacing:0.04rem;-ms-letter-spacing:0.04rem;letter-spacing:0.04rem;line-height:44px;text-transform:uppercase;}.accordionExpanded .css-1a5mdf6{color:#b3b3b3;}.css-1ho5u4o{list-style:none;margin:0 0 15px;padding:0;}@media (min-width:600px){.css-1ho5u4o{display:inline-block;}}.css-t8x4fj{list-style:none;line-height:8px;padding:0;}.css-t8x4fj:last-child > li{margin:16px 0 0 0;}@media (min-width:600px){.css-t8x4fj{display:inline-block;}}.css-a7htku{display:inline-block;line-height:20px;padding:0 10px;}.css-a7htku:first-child{border-left:none;}.css-a7htku.desktop{display:none;}@media (min-width:740px){.css-a7htku.smartphone{display:none;}.css-a7htku.desktop{display:inline-block;}.css-a7htku.mobileOnly{display:none;}}.css-at9mc1{margin-bottom:0.78125rem;margin-top:0;overflow-wrap:break-word;color:var(--color-content-secondary,#363636);font-family:nyt-imperial,georgia,'times new roman',times,serif;font-size:1.125rem;line-height:1.5625rem;margin-left:20px;margin-right:20px;width:calc(100% - 40px);max-width:600px;}@media (min-width:740px){.css-at9mc1{margin-bottom:0.9375rem;margin-top:0;}}.css-at9mc1 .css-yywogo{-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration-style:solid;text-decoration-style:solid;-webkit-text-decoration-thickness:1px;text-decoration-thickness:1px;-webkit-text-decoration-color:var(--color-signal-editorial,#326891);text-decoration-color:var(--color-signal-editorial,#326891);}.css-at9mc1 .css-yywogo:hover,.css-at9mc1 .css-yywogo:focus{-webkit-text-decoration:none;text-decoration:none;}@media (min-width:740px){.css-at9mc1{font-size:1.25rem;line-height:1.875rem;}}.css-at9mc1:first-child{margin-top:0;}.css-at9mc1:last-child{margin-bottom:0;}.css-at9mc1.e1h9rw200:last-child{margin-bottom:0.75rem;}.css-at9mc1.eoo0vm40:first-child{margin-top:0.8125rem;}@media (min-width:600px){.css-at9mc1{margin-left:auto;margin-right:auto;}}@media (min-width:1024px){.css-at9mc1{margin-left:0;margin-right:0;width:100%;max-width:100%;}.css-at9mc1.eoo0vm40:first-child{margin-top:1.1875rem;}}@media print{.css-at9mc1{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-hxpw2c{max-width:1200px;margin-left:auto;margin-right:auto;margin:1.25rem auto 1.5rem;}@media (min-width:600px){.css-hxpw2c{width:auto;}}@media (min-width:1024px){.css-hxpw2c{width:945px;}}@media (min-width:1440px){.css-hxpw2c{width:1200px;}}@media (min-width:740px){.css-hxpw2c{margin:2.5rem auto;}}.css-hxpw2c strong{font-weight:700;}.css-hxpw2c em{font-style:italic;}.css-1g9ic6e{font-family:nyt-imperial,georgia,'times new roman',times,serif;color:var(--color-content-quaternary,#727272);margin:10px 20px 0 20px;text-align:left;max-width:none;}.css-1g9ic6e a{color:var(--color-signal-editorial,#326891);-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration-thickness:1px;text-decoration-thickness:1px;text-underline-offset:1px;}.css-1g9ic6e a:hover,.css-1g9ic6e a:focus{-webkit-text-decoration:none;text-decoration:none;}@media (min-width:600px){.css-1g9ic6e{margin-left:0;margin-right:20px;}}@media (min-width:600px){.css-1g9ic6e{margin-left:20px;}}@media (min-width:740px){.css-1g9ic6e{margin-left:20px;}}@media (min-width:1024px){.css-1g9ic6e{max-width:720px;margin-left:0;}}@media (min-width:1440px){.css-1g9ic6e{width:900px;margin-left:0;}}.css-2fg4z9{font-style:italic;}.css-r3fift{height:auto;width:100%;width:100%;vertical-align:top;}.css-798hid{font-style:normal;color:var(--color-content-secondary,#363636);font-family:nyt-franklin,helvetica,arial,sans-serif;font-weight:500;font-size:0.9375rem;line-height:1.25rem;margin:0 auto 1rem;margin-left:20px;margin-right:20px;width:calc(100% - 40px);max-width:600px;}@media (min-width:740px){.css-798hid{font-size:1rem;line-height:1.375rem;}}.css-798hid .css-yywogo{-webkit-text-decoration:underline;text-decoration:underline;}.css-798hid .css-yywogo:hover,.css-798hid .css-yywogo:focus{-webkit-text-decoration:none;text-decoration:none;}.css-798hid:first-child{margin-top:0;}.css-798hid:last-child{margin-bottom:0;}.css-798hid.e1h9rw200:last-child{margin-bottom:0.75rem;}.css-798hid.eoo0vm40:first-child{margin-top:0.8125rem;}@media (min-width:600px){.css-798hid{margin-left:auto;margin-right:auto;}}@media (min-width:1024px){.css-798hid{margin-left:0;margin-right:0;width:100%;max-width:100%;}.css-798hid.eoo0vm40:first-child{margin-top:1.1875rem;}}@media print{.css-798hid{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-t91cuf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;margin-bottom:0.25rem;}.css-t91cuf > img,.css-t91cuf a > img,.css-t91cuf div > img{margin-right:10px;}.css-1tx0lhj{display:inline-block;margin:0;font-size:0.8125rem;line-height:1.0625rem;margin-top:0.1875rem;font-family:nyt-franklin,helvetica,arial,sans-serif;font-weight:700;color:var(--color-content-secondary,#363636);}@media (min-width:1024px){.css-1tx0lhj{font-size:1rem;line-height:1.3125rem;}}.css-8qgvsz{font-weight:700;}.css-1g7y0i5{position:fixed;z-index:1000000110;top:0;left:0;right:0;bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;opacity:0;-webkit-transition:opacity 0.2s;transition:opacity 0.2s;pointer-events:none;}@media print{.css-1g7y0i5{position:static;}}.css-rdbib0{position:absolute;top:0;left:0;bottom:0;right:0;background-color:rgba(0,0,0,0.8);z-index:1;}@media print{.css-rdbib0{background-color:var(--color-background-primary,#FFFFFF);}}.css-18ow4sz{position:absolute;top:0;bottom:0;background-color:var(--color-background-primary,#FFFFFF);width:100%;overflow-y:scroll;-webkit-overflow-scrolling:touch;z-index:2;}@media (min-width:600px){.css-18ow4sz{max-width:calc(100% - 60px);width:1080px;}}@media (min-width:740px){.css-18ow4sz{max-width:calc(100% - 100px);}}@media (min-width:1024px){.css-18ow4sz{max-width:930px;}}@media (min-width:1150px){.css-18ow4sz{max-width:930px;}}@media print{.css-18ow4sz{position:static;}}.css-1ruvd04{-webkit-animation:animation-1e91rfo 0.8s cubic-bezier(0,0,1,1) forwards;animation:animation-1e91rfo 0.8s cubic-bezier(0,0,1,1) forwards;}.css-qknaag{-webkit-animation:animation-h29fi5 0.8s cubic-bezier(0,0,1,1) forwards;animation:animation-h29fi5 0.8s cubic-bezier(0,0,1,1) forwards;}.css-1r5375t{-webkit-animation:animation-1q05mva 0.8s cubic-bezier(0,0,1,1) forwards;animation:animation-1q05mva 0.8s cubic-bezier(0,0,1,1) forwards;}.css-t9te0w{-webkit-animation:animation-k543x9 0.8s cubic-bezier(0,0,1,1) forwards;animation:animation-k543x9 0.8s cubic-bezier(0,0,1,1) forwards;}.css-t3i5e6{-webkit-animation:animation-kxbuhr 0.8s cubic-bezier(0,0,1,1) forwards;animation:animation-kxbuhr 0.8s cubic-bezier(0,0,1,1) forwards;}.css-fwki7z{-webkit-animation:animation-1sxmvgn 0.8s cubic-bezier(0,0,1,1) forwards;animation:animation-1sxmvgn 0.8s cubic-bezier(0,0,1,1) forwards;}.css-1wnday1{-webkit-animation:animation-4tin05 0.8s cubic-bezier(0,0,1,1) forwards;animation:animation-4tin05 0.8s cubic-bezier(0,0,1,1) forwards;}.css-1fxvzwo{-webkit-animation:animation-g0tn84 0.8s cubic-bezier(0,0,1,1) forwards;animation:animation-g0tn84 0.8s cubic-bezier(0,0,1,1) forwards;}.css-1l3nmlr{display:inline-block;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;min-height:2.5rem;}@media (min-width:1024px){.css-1l3nmlr{min-height:0;}}.css-1vwfk9f{width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;position:relative;margin-bottom:40px;margin-bottom:20px;}.css-1vwfk9f *{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;text-rendering:optimizeLegibility;-webkit-touch-callout:none;}@media (min-width:600px){.css-1vwfk9f{margin-bottom:40px;}}.css-13r7n3o{width:100%;padding-top:100%;position:relative;background-size:cover;background-position:center;}.css-s220l9{height:80px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(18,18,18,0.1);box-sizing:border-box;padding:15px 20px;position:relative;overflow-x:scroll;overflow-y:hidden;-webkit-overflow-scrolling:touch;color:#121212;border-bottom:1px solid rgba(18,18,18,0.2);}.css-s220l9 a{-webkit-text-decoration:none;text-decoration:none;}.css-s220l9::-webkit-scrollbar{display:none;}.css-s220l9::-webkit-scrollbar-thumb{background:rgba(255,255,255,0.5);border-radius:10px;}.css-s220l9 a{color:#121212;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}.css-s220l9 a:focus{background-color:rgba(255,255,255,0.2);overflow:hidden;}.css-15f7ed6{font-size:18px;line-height:18px;font-family:nyt-karnak,georgia,'times new roman',times,serif;margin-right:70px;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;color:#F8F8F8;color:#121212;}.css-va8yei{font-family:nyt-franklin,helvetica,arial,sans-serif;font-weight:600;font-size:12px;line-height:14px;display:block;display:-webkit-box;overflow:hidden;-webkit-line-clamp:2;-webkit-box-orient:vertical;color:#121212;}.css-a19wyd{margin-left:auto;margin-right:auto;max-width:600px;width:calc(100% - 40px);position:relative;margin-bottom:1rem;margin-bottom:1rem;}@media (min-width:740px){.css-a19wyd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}.css-a19wyd > div{-webkit-flex:none;-ms-flex:none;flex:none;}}@media (min-width:1440px){.css-a19wyd{max-width:600px;width:600px;}}.css-15rzub1{font-family:nyt-franklin,helvetica,arial,sans-serif;font-weight:500;color:var(--color-content-secondary,#363636);margin-bottom:1rem;font-size:0.8125rem;line-height:1rem;margin-bottom:1rem;display:block;}@media (min-width:740px){.css-15rzub1{margin-bottom:0;margin-right:1rem;}}</style>
    
    

    <script type="text/javascript">
    (function fidesScript(a,b){function c(){if(!g()&&f()){var c=document.createElement("script");c.id="nyt-fides",c.src=a,b.document.head.appendChild(c)}}var d=new URLSearchParams(b.location.search),e=function(a){var c=b.document.cookie.split(";").find(function(b){return b.includes(a)})||"";return c.replace(a,"").trim().charAt(16)},f=function(){var a,c,f,g=d.get("fides-override"),h=e("nyt-purr="),i=e("override-purr="),j=0<(null===(a=b.config)||void 0===a||null===(c=a.tc_info)||void 0===c||null===(f=c.fides_string)||void 0===f?void 0:f.length);return j||"s"===i||"s"===h||"true"===g},g=function(){return null!==b.document.getElementById("nyt-fides")};c(),b.addEventListener("initWebview:ios",c),b.fidesUtils={isFidesEligible:f}})('https://static01.nyt.com/vi-assets/static-assets/fides-675e7fcafce283a12aba8ba28db11d1d.js', window);
    (function fidesTracking(a){function b(a){var b=a.layerType;return{event:"impression",priority:!0,module:{name:b,label:b,region:"bottom"}}}function c(a){var b=a.actionType,c=void 0===b?"":b,d=a.layerType,e=void 0===d?"":d;return{event:"moduleInteraction",eventData:{trigger:"module",type:"click"},module:{name:e,label:e,element:{name:c,label:c}}}}function d(a){var b=a.actionType,c=void 0===b?"":b,d=a.layerType,e=void 0===d?"":d;return{subject:"interaction",data:{name:e,label:e,element:{name:c,label:c}}}}function e(b){var c=a.dataLayer||(a.dataLayer=[]);c.push(b)}function f(b){var c=a.document.getElementById("fides-banner"),d=a.document.getElementById("fides-modal"),e=a.document.getElementById("fides-embed-container"),f="true"===(null===d||void 0===d?void 0:d.getAttribute("aria-hidden"));if(e)return"cmp_layer_2";if(null!==b){if(!c||!d)return"";if(c.contains(b))return"cmp_layer_1";if(d.contains(b))return"cmp_layer_2"}return f?"cmp_layer_1":"cmp_layer_2"}function g(a){var b=a.textContent.toLowerCase();return{"accept all":"accept_all","reject all":"reject_all","manage preferences":"manage_prefs","cookie policy":"cookie_policy","privacy policy":"privacy_policy",purposes:"purposes",features:"features",vendors:"vendors",save:"save"}[b]||""}// dispatch event for iOS and Android to listen to.
function h(b){var c=new CustomEvent("NYTFidesUpdated",{detail:b});a.dispatchEvent(c)}var i;!0===(null===(i=a.fidesUtils)||void 0===i?void 0:i.isFidesEligible())&&(a.addEventListener("FidesUIShown",function(a){var c,d=null===a||void 0===a||null===(c=a.detail)||void 0===c?void 0:c.extraDetails,f=d.servingComponent,g=void 0===f?"":f;if("tcf_banner"===g){var h=b({layerType:"cmp_layer_1"});e(h)}}),a.addEventListener("click",function(a){var b=a.target,i="button"===b.type,j="a"===b.nodeName.toLowerCase();if(i||j){var k=g(b),l=f(b);if(k){var m=c({actionType:k,layerType:l});e(m);var n=d({actionType:k,layerType:l});h(n),a.stopPropagation()}}}),a.addEventListener("beforeunload",function(){var a=f(null),c=b({layerType:"".concat(a,"_exit")});e(c)}))})(window);
  </script>
    
    
    <script type="text/javascript">
      // 38.552kB
      window.viHeadScriptSize = 38.552;
      window.NYTD = {};
      window.vi = window.vi || {};
      window.vi.pageType = { type: '', edge: 'vi-story'};
      (function () { var userAgent=window.navigator.userAgent||window.navigator.vendor||window.opera||"",inNewsreaderApp=userAgent.includes("nytios")||userAgent.includes("nyt_android"),inXWordsApp=userAgent.includes("nyt_xwords_ios")||userAgent.includes("Crosswords"),inAndroid=userAgent.includes("nyt_android")||userAgent.includes("Crosswords"),iniOS=userAgent.includes("nytios")||userAgent.includes("nyt_xwords_ios"),isInWebviewByUserAgent=(inAndroid||iniOS)&&(inNewsreaderApp||inXWordsApp);function appType(){return inNewsreaderApp?"newsreader":inXWordsApp?"crosswords":""}function deviceType(){return inAndroid?"ANDROID":iniOS?"IOS":""}var _f=function(e){window.vi.webviewEnvironment={appType:appType(),deviceType:deviceType(),isInWebview:e.webviewEnvironment.isInWebview||isInWebviewByUserAgent,isPreloaded:e.webviewEnvironment.isPreloaded}};;_f.apply(null, [{"gqlUrlClient":"https://samizdat-graphql.nytimes.com/graphql/v2","gqlRequestHeaders":{"nyt-app-type":"project-vi","nyt-app-version":"0.0.5","nyt-token":"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs+/oUCTBmD/cLdmcecrnBMHiU/pxQCn2DDyaPKUOXxi4p0uUSZQzsuq1pJ1m5z1i0YGPd1U1OeGHAChWtqoxC7bFMCXcwnE1oyui9G1uobgpm1GdhtwkR7ta7akVTcsF8zxiXx7DNXIPd2nIJFH83rmkZueKrC4JVaNzjvD+Z03piLn5bHWU6+w+rA+kyJtGgZNTXKyPh6EC6o5N+rknNMG5+CdTq35p8f99WjFawSvYgP9V64kgckbTbtdJ6YhVP58TnuYgr12urtwnIqWP9KSJ1e5vmgf3tunMqWNm6+AnsqNj8mCLdCuc5cEB74CwUeQcP2HQQmbCddBy2y0mEwIDAQAB"},"gqlFetchTimeout":1500,"disablePersistedQueries":false,"initialDeviceType":"smartphone","fastlyAbraConfig":{".ver":"18076.000","AMS_FrictionCircumventionDesktop_cwv":"2_low-mid-truncation","AMS_FrictionCircumventionMobile_cwv":"2_low-mid-truncation","DFP_TopAd_Anon_0124":"","HOME_cwv_chartbeat":"0_Control","MX_NewArchitecture_PostLoginOffer":"1_variant","MX_NewArchitecture_WirecutterLP":"","STYLN_synth_voice_web":"0_control"},"fastlyEntitlements":[],"internalPreviewConfig":{},"webviewEnvironment":{"isInWebview":false,"isPreloaded":false},"isOptimisticallyTruncated":false,"optimisticTruncationDropzone":6,"requestPath":"/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html","isProvisionallyLoggedIn":false,"serviceWorkerFile":"service-worker-test-1715027876176.js"}]); })();;(function () { var _f=function(i,w){window.vi=window.vi||{},window.vi.env=Object.freeze(i),window.hybrid=w};;_f.apply(null, [{"JKIDD_PATH":"https://a.nytimes.com/svc/nyt/data-layer","ET2_URL":"https://a.et.nytimes.com","ALS_URL":"https://als-svc.nytimes.com","WEDDINGS_PATH":"https://content.api.nytimes.com","GDPR_PATH":"https://us-central1-nyt-dsra-prd.cloudfunctions.net/datagov-dsr-formhandler","RECAPTCHA_SITEKEY":"6LevSGcUAAAAAF-7fVZF05VTRiXvBDAY4vBSPaTF","ABRA_ET_URL":"//et.nytimes.com","NODE_ENV":"production","EXPERIMENTAL_ROUTE_PREFIX":"","ENVIRONMENT":"prd","RELEASE":"fda3c1704e92bc29a9545d08be2eec92a5050bf5","RELEASE_TAG":"","AUTH_HOST":"https://myaccount.nytimes.com","METER_HOST":"https://meter-svc.nytimes.com","MESSAGING_LANDING_PAGE_HOST":"https://www.nytimes.com","CAPI_HOST":"https://mwcm.nytimes.com","SWG_PUBLICATION_ID":"nytimes.com","GQL_FETCH_TIMEOUT":"1500","GOOGLE_CLIENT_ID":"1005640118348-amh5tgkq641oru4fbhr3psm3gt2tcc94.apps.googleusercontent.com","STORY_SURROGATE_CONTROL":"max-age=300, stale-if-error=259200, stale-while-revalidate=259200","ONBOARDING_API_KEY":""},false]); })();;(function () { var _f=function(){var e=window;e.initWebview=function(e){var t=document.documentElement;if(e.OS){var i=e.OS.toUpperCase();t.classList.add(i)}if(e.BaseFontSize&&(t.dataset.baseFontSize=e.BaseFontSize),e.trackingSensitive&&(t.dataset.trackingSensitive=!0),e.hasOptedOutOfTracking&&(t.dataset.hasOptedOutOfTracking=!0),e.PurrDirectives){var a=e.PurrDirectives.PURR_AdConfiguration_v3||e.PurrDirectives.PURR_AdConfiguration_v2;a&&(t.dataset.optedOutOfAds=["adluce","adluce-socrates"].includes(a))}e.OS&&"IOS"===e.OS.toUpperCase()&&window.dispatchEvent(new CustomEvent("initWebview:ios",{detail:e}))};var t=e.navigator.userAgent.toLowerCase();/iphone|ipod|ipad/.test(t)||void 0===e.config||e.initWebview(e.config)};;_f.apply(null, []); })();;
!function(a){var s,c,p,_,d,l,u=[],f={pv_id:"",ctx_id:"",intra:!1,force_xhr:!1,store_last_response:!1
},g="object"==typeof a.navigator&&"string"==typeof a.navigator.userAgent&&/iP(ad|hone|od)/.test(
a.navigator.userAgent),y="object"==typeof a.navigator&&a.navigator.sendBeacon,
v=y?g?"xhr_ios":"beacon":"xhr";function h(){var e,t,n=a.crypto||a.msCrypto;if(n)t=n.getRandomValues(
new Uint8Array(18));else for(t=[];t.length<18;)t.push(256*Math.random()^255&(e=e||+new Date)),
e=Math.floor(e/256);return btoa(String.fromCharCode.apply(String,t)).replace(/\+/g,"-").replace(
/\//g,"_")}if(a.nyt_et)try{console.warn("et2 snippet should only load once per page")}catch(e
){}else a.nyt_et=function(){var e,t,n,o=arguments;function r(e){var t,n,o,r,i;u.length&&(t=s+"track"
,n=JSON.stringify(u),e=e,o=f.force_xhr,r=f.store_last_response,!o&&("beacon"===v||y&&e)?(
o=a.navigator.sendBeacon(t,n),r&&(l=o)):((
i="undefined"!=typeof XMLHttpRequest?new XMLHttpRequest:new ActiveXObject("Microsoft.XMLHTTP")
).open("POST",t),i.withCredentials=!0,i.setRequestHeader("Accept","*/*"),
"string"==typeof n?i.setRequestHeader("Content-Type","text/plain;charset=UTF-8"
):"[object Blob]"==={}.toString.call(n)&&n.type&&i.setRequestHeader("Content-Type",n.type),
r&&!i.onload&&(i.onload=function(){l=i.response},i.onerror=function(e){l=!1}),i.send(n)),u.length=0,
clearTimeout(d),d=null)}if("string"==typeof o[0]&&/init/.test(o[0])&&(f=function(e,t){var n="",o="",
r=!1,i=!1,a=!1;if("string"==typeof e&&"init"==e&&"object"==typeof t&&(
"boolean"==typeof t.intranet&&t.intranet&&(r=!0),"boolean"==typeof t.force_xhr&&t.force_xhr&&(i=!0),
"boolean"==typeof t.store_last_response&&t.store_last_response&&(a=!0),
"string"==typeof t.pv_id_override&&"string"==typeof t.ctx_id_override))if(
24<=t.pv_id_override.length&&24<=t.ctx_id_override.length)n=t.pv_id_override,
o=t.ctx_id_override;else try{console.warn("override id(s) must be >= 24 chars long")}catch(e){}
return{pv_id:n,ctx_id:o,intra:r,store_last_response:a,force_xhr:i}}(o[0],o[3]),p=f.pv_id||h(),
"init"==o[0]&&!c)){if(c=f.ctx_id||h(),"string"!=typeof o[1]||!/^http/.test(o[1]))throw new Error(
"init must include an et host url");if(s=String(o[1]).replace(/([^\/])$/,"$1/"),
"string"!=typeof o[2])throw new Error("init must include a source app name");_=o[2]}var i=o.length-1
;(e=o[i]&&"object"==typeof o[i]?o[i]:e)||/init/.test(o[0])?e&&!e.subject&&console.warn(
"event data {} must include a subject"):console.warn(
"when invoked without 'init' or 'pageinit', nyt_et() must include a event data"),s&&e&&e.subject&&(
i=e.subject,delete e.subject,n="page_exit"==i||"ob_click"==(e.eventData||{}).type,
t="page"==i||"page_soft"==i?p:h(),u.push({context_id:c,pageview_id:p,event_id:t,client_lib:"v1.3.0",
sourceApp:_,intranet:f.intra?1:void 0,subject:i,how:n&&g&&y?"beacon_ios":v,client_ts:+new Date,
data:JSON.parse(JSON.stringify(e))}),"send"==o[0]||t==p||n?r(n):("soon"==o[0]&&(clearTimeout(d),
d=setTimeout(r,200)),d=d||setTimeout(r,5500)))},a.nyt_et.get_pageview_id=function(){return p},
a.nyt_et.get_context_id=function(){return c},a.nyt_et.get_host=function(){return s},
a.nyt_et.get_last_send_response=function(){var e=l;return e&&(l=null),e}}(window);
;(function initWebUnifiedTracking(root) {
  var _root;
  root = root || (typeof window !== 'undefined' ? window : undefined);
  var UnifiedTracking = ((_root = root) === null || _root === void 0 ? void 0 : _root.UnifiedTracking) || {};
  UnifiedTracking.context = 'web';
  if (!root) {
    return UnifiedTracking;
  }
  root.UnifiedTracking = UnifiedTracking;
  UnifiedTracking.sendAnalytic = function sendAnalytic(eventName, dataBlob) {
    root.dataLayer = root.dataLayer || [];
    if (Array.isArray(root.dataLayer)) {
      // Don't use a spread operator here for babel reasons
      dataBlob.event = dataBlob.event || eventName;
      root.dataLayer.push(dataBlob);
    }
    return Promise.resolve({
      success: true
    });
  };
  return UnifiedTracking;
})(window);!function(r){var n,t;r=r||self,n=r.Abra,(t=r.Abra=function(){"use strict";var r=Array.isArray,n=function(r,n,t){var e=r(t,n),u=e[0],o=e[1];if(null==u||""===u)return n;for(var i=String(u).split("."),a=0;a<i.length&&(n=n[i[a]]);a++);return null==n&&(n=o),null!=n?n:null},t=function(r,n,t){return r(t,n).reduce((function(r,n){return parseFloat(r)+parseFloat(n)}),0)},e=function(r,n,t){var e=r(t,n);return e[0]/e[1]},u=function(r,n,t){var e=r(t,n);return e[0]%e[1]},o=function(r,n,t){return r(t,n).reduce((function(r,n){return parseFloat(r)*parseFloat(n)}),1)},i=function(r,n,t){var e=r(t,n),u=e[0],o=e[1];return void 0===o?-u:u-o};function a(n){return!(r(n)&&0===n.length||!n)}var f=function(r,n,t){for(var e,u=0;u<t.length;u++)if(!a(e=r(t[u],n)))return e;return e},c=function(r,n,t){var e;for(e=0;e<t.length-1;e+=2)if(a(r(t[e],n)))return r(t[e+1],n);return t.length===e+1?r(t[e],n):null},l=function(r,n,t){return!a(r(t,n)[0])},v=function(r,n,t){for(var e,u=0;u<t.length;u++)if(a(e=r(t[u],n)))return e;return e},d=function(r,n,t){var e=r(t,n);return e[0]===e[1]},s=function(r,n,t){var e=r(t,n);return e[0]!==e[1]},h=function(r,n,t){var e=r(t,n),u=e[0],o=e[1];return!(!o||void 0===o.indexOf)&&-1!==o.indexOf(u)},g=function(r,n,t){var e=r(t,n);return e[0]>e[1]},p=function(r,n,t){var e=r(t,n);return e[0]>=e[1]},b=function(r,n,t){var e=r(t,n),u=e[0],o=e[1],i=e[2];return void 0===i?u<o:u<o&&o<i},w=function(r,n,t){var e=r(t,n),u=e[0],o=e[1],i=e[2];return void 0===i?u<=o:u<=o&&o<=i},y=function(r,n,t){var e=t[0],u=t[1],o=t.slice(2),i=r(e,n);if(!i)return null;if(0===o.length)return null;if(1===o.length)return r(o[0],n);if(4294967295===o[0])return r(o[1],n);for(var a=function(r){var n,t,e,u,o,i=[],a=[t=1732584193,e=4023233417,~t,~e,3285377520],f=[],c=unescape(encodeURI(r))+"\x80",l=c.length;for(f[r=--l/4+2|15]=8*l;~l;)f[l>>2]|=c.charCodeAt(l)<<8*~l--;for(n=l=0;n<r;n+=16){for(t=a;l<80;t=[t[4]+(i[l]=l<16?~~f[n+l]:2*c|c<0)+1518500249+[e&u|~e&o,c=341275144+(e^u^o),882459459+(e&u|e&o|u&o),c+1535694389][l++/5>>2]+((c=t[0])<<5|c>>>27),c,e<<30|e>>>2,u,o])c=i[l-3]^i[l-8]^i[l-14]^i[l-16],e=t[1],u=t[2],o=t[3];for(l=5;l;)a[--l]+=t[l]}return a[0]>>>0}(i+" "+r(u,n));o.length>1;){var f=o.splice(0,2),c=f[0],l=f[1];if(a<=r(c,n))return r(l,n)}return 0===o.length?null:r(o[0],n)},k=function(r,n,t){var e=t[0],u=t[1],o=r(e,n);return null==o?null:new RegExp(u).test(o)};return function(a,m,O,A){void 0===a&&(a={}),void 0===m&&(m={}),void 0===O&&(O={}),void 0===A&&(A=!1);var j=function(){var r={},n=function(n){if(n)for(var t,e=decodeURIComponent(n[1]),u=/(?:^|,)([^,=]+)=([^,]*)/g;t=u.exec(e);){var o=t,i=o[1],a=o[2];r[i]=a||null}};n(document.cookie.match(/(?:^|;) *abra-overrides=([^;]+)/)),n(window.location.search.match(/(?:\?|&)abra-overrides=([^&]+)/));var t=/(?:^|;) *abra-nuke=true(?:;|$)/.test(document.cookie)||/(?:\?|&)abra-nuke=true(?:&|$)/.test(window.location.search);return[r,t]}(),x=j[0],E=j[1];Object.keys(O).forEach((function(r){x[r]=O[r]}));var F,C=A||E,R=(F={var:n,if:c,"===":d,"!==":s,and:f,or:v,"!":l,">":g,">=":p,"<":b,"<=":w,"+":t,"-":i,"*":o,"/":e,"%":u,in:h,abtest_partition:y,regex_match:k,ref:function(r,n,t){var e=r(t,n)[0];return U(e)}},function n(t,e){if(e||(e={}),r(t))return t.map((function(r){return n(r,e)}));if(!function(n){return"object"==typeof n&&null!==n&&!r(n)&&1===Object.keys(n).length}(t))return t;var u=function(r){return Object.keys(r)[0]}(t),o=t[u];r(o)||(o=[o]);var i=F[u];if(!i)throw new Error("Unrecognized operation "+u);return i(n,e,o)}),U=function(r){if(!r)return null;var n=x[r];if(void 0===n){if(!C){if(Object.prototype.hasOwnProperty.call(x,r))throw new Error("circular logic");x[r]=void 0,n=R(a[r],m)}void 0===n&&(n=null),x[r]=n}return n};return U}}()).noConflict=function(){return r.Abra=n,t}}(this);
;(function () { var NYTD="undefined"!=typeof window&&window.NYTD?window.NYTD:{};function setupTimeZone(){var e='[data-timezone][data-timezone~="'+(new Date).getHours()+'"] { display: block }',t=document.createElement("style");t.innerHTML=e,document.head.appendChild(t)}function addNYTAppClass(){var e=window.vi&&window.vi.webviewEnvironment||{};e&&e.isInWebview&&document.documentElement.classList.add("NYTApp"),e&&e.isPreloaded&&document.documentElement.classList.add("NYTAppPreloaded"),e&&e.deviceType&&document.documentElement.classList.add(window.vi.webviewEnvironment.deviceType)}function addNYTPageTypeClass(){var e=window.vi.pageType.edge;e&&document.documentElement.classList.add("nytapp-"+e)}function setupPageViewId(){NYTD.PageViewId={},NYTD.PageViewId.update=function(){return"undefined"!=typeof nyt_et&&"function"==typeof window.nyt_et.get_pageview_id?(window.nyt_et("pageinit"),NYTD.PageViewId.current=window.nyt_et.get_pageview_id()):NYTD.PageViewId.current="xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx".replace(/[xy]/g,function(e){var t=16*Math.random()|0;return("x"===e?t:3&t|8).toString(16)}),NYTD.PageViewId.current}}var _f=function(){try{document.domain="nytimes.com"}catch(e){}window.swgUserInfoXhrObject=new XMLHttpRequest,setupPageViewId(),setupTimeZone(),addNYTAppClass(),addNYTPageTypeClass(),window.nyt_et&&"function"==typeof window.nyt_et&&window.nyt_et("init",vi.env.ET2_URL,"nyt-vi",{subject:"page",canonicalUrl:(document.querySelector("link[rel=canonical]")||{}).href,articleId:(document.querySelector("meta[name=articleid]")||{}).content,nyt_uri:(document.querySelector("meta[name=nyt_uri]")||{}).content,pubpEventId:(document.querySelector("meta[name=pubp_event_id]")||{}).content,url:location.href,referrer:document.referrer||void 0,client_tz_offset:(new Date).getTimezoneOffset()}),"undefined"!=typeof nyt_et&&"function"==typeof window.nyt_et.get_pageview_id?NYTD.PageViewId.current=window.nyt_et.get_pageview_id():NYTD.PageViewId.update();var e=window.reportError;window.reportError=function(){var t=Array.prototype.slice.call(arguments),n=t[0];(n.message.includes("root will switch to client rendering.")||n.message.includes("Minified React error #423"))&&window.dispatchEvent(new CustomEvent("react-hydration-error")),e.apply(null,t)}};;_f.apply(null, []); })();;(function () { var NYTD="undefined"!=typeof window&&window.NYTD?window.NYTD:{};var _f=function(n){var t=window.vi&&window.vi.webviewEnvironment&&window.vi.webviewEnvironment.isPreloaded;function e(){if(window.Abra&&"function"==typeof window.Abra){NYTD.Abra=function(){var e=t?window.getNativeBridgeCookie("nyt-a"):(window.document.cookie.match(/(?:^|;) *nyt-a=([^;]*)/)||[])[1],o=[];window.dataLayer=window.dataLayer||[],c.config=n.abraConfig||{},c.reportedAllocations={},c.reportedExposures={};var a=(n.abraURL||"").match(/current[/]([a-zA-Z-]+).json/i);c.integration=a&&a.length>1?a[1]:"";try{c.version=window.Abra(c.config)(".ver")}catch(n){c.version=0}var r=c.config,i={agent_id:e},d=window.Abra(r,i);function c(n){return c.getAbraSync(n).variant}return c.getAbraSync=function(n){var t=c.reportedAllocations[n];if(void 0!==t)return{variant:t,allocated:!0};var e=null,o=!1;try{e=d(n),o=!0}catch(n){}return{variant:e,allocated:o}},c.reportExposure=function(n){var t=c.getAbraSync(n).variant;null!=t&&(void 0!==c.reportedExposures[n]&&t===c.reportedExposures[n]||(c.reportedExposures[n]=t,window.dataLayer.push({event:"ab-expose",abtest:{test:n,variant:t,config_ver:c.version,integration:c.integration}})))},c.alloc=function(){Object.keys(c.config).filter(function(n){return!n.includes(".")}).forEach(function(n){var t=c.getAbraSync(n);t.allocated&&(c.reportedAllocations[n]=t.variant,o.push({test:n,variant:t.variant}))}),window.dataLayer.push({event:"ab-alloc",abtest:{batch:o}})},c.alloc(),c}(),window.NYTD=NYTD||{};var e="SJ_xpn_storylines_desktop_cwv_0124";if("1_xpn_in_story"===window.NYTD.Abra.getAbraSync(e).variant){document.documentElement.classList.add("SJ_xpn_storylines_desktop_cwv_0124-1_xpn_in_story")}if("2_xpn_hamburger"===window.NYTD.Abra.getAbraSync(e).variant){document.documentElement.classList.add("SJ_xpn_storylines_desktop_cwv_0124-2_xpn_hamburger")}if("3_xpn_top_only"===window.NYTD.Abra.getAbraSync(e).variant){document.documentElement.classList.add("SJ_xpn_storylines_desktop_cwv_0124-3_xpn_top_only")}if("1_xpn_in_story"===window.NYTD.Abra.getAbraSync("SJ_xpn_standard_story_0424").variant){document.documentElement.classList.add("SJ_xpn_standard_story_0424-1_xpn_in_story")}if("2_xpn_hamburger"===window.NYTD.Abra.getAbraSync("SJ_xpn_standard_story_0424").variant){document.documentElement.classList.add("SJ_xpn_standard_story_0424-2_xpn_hamburger")}window.NYTD.Abra.config&&Object.prototype.hasOwnProperty.call(window.NYTD.Abra.config,"SHA_UnlimitedGift_0124")&&document.cookie.includes("SHA_UGT=1")&&document.documentElement.classList.add("unlimited-gift")}}t&&!window.nativeBridgeCookies?window.initNativeBridgeCookies(e):e()};;_f.apply(null, [{"abraConfig":{".ver":18311,"UPSHOT_wordleStateV2_0306":{"abtest_partition":[{"var":"agent_id"},"UPSHOT_wordleStateV2_0306",4294967295,"0_Control"]},"UPSHOT_wordlebotGuessDetail_013024":{"abtest_partition":[{"var":"agent_id"},"UPSHOT_wordlebotGuessDetail_013024",3650722201,"0_Control",3865470565,"1_ShowDetail",4080218930,"2_ShowSomeDetail",4294967295,"3_ShowReaderDetail"]},"UPSHOT_wordlebotGuessDetail_011624":{"abtest_partition":[{"var":"agent_id"},"UPSHOT_wordlebotGuessDetail_011624",3865470565,"0_Control",4080218930,"1_ShowDetail",4294967295,"0_Control"]},"SUBX_regi_alloc_holdout_2024H1":{"abtest_partition":[{"var":"regi_id"},"SUBX_regi_alloc_holdout_2024H1",214748364,"0_holdout",429496729,"1_best_experience",4294967295,"2_testing"]},"SUBX_agent_alloc_holdout_2024H1":{"abtest_partition":[{"var":"agent_id"},"SUBX_agent_alloc_holdout_2024H1",214748364,"0_holdout",429496729,"1_best_experience",4294967295,"2_testing"]},"SUBCON_RES_AIG_SURVEY_228":{"abtest_partition":[{"var":"agent_id"},"SUBCON_RES_AIG_SURVEY_228",4080218930,"0_Control",4294967295,"1_Variant"]},"STYLN_user_state_api_1122":{"abtest_partition":[{"var":"regi_id"},"STYLN_user_state_api_1122",4294967295,"1_User_State"]},"STYLN_synth_voice_web":{"abtest_partition":[{"var":"agent_id"},"STYLN_synth_voice_web2",42949672,"0_control",85899345,"1_synth",450971565,"0_control",816043785,"1_synth",858993458,"0_control",901943131,"1_synth",923417968,"0_control",944892804,"1_synth",1009317314,"0_control",1073741823,"1_synth",1095216659,"0_control",1116691496,"1_synth",1181116005,"0_control",1245540515,"1_synth",1267015351,"0_control",1288490188,"1_synth",1395864370,"0_control",1503238553,"1_synth",1524713389,"0_control",1546188226,"1_synth",1589137899,"0_control",1632087571,"1_synth",1696512081,"0_control",1760936590,"1_synth",1803886263,"0_control",1846835936,"1_synth",1889785609,"0_control",1932735282,"1_synth",1975684955,"0_control",2018634628,"1_synth",2104533974,"0_control",2190433320,"1_synth",2233382993,"0_control",2276332666,"1_synth",2319282339,"0_control",2362232012,"1_synth",2405181685,"0_control",2448131358,"1_synth",2512555867,"0_control",2576980377,"1_synth",2619930050,"0_control",2662879723,"1_synth",2705829395,"0_control",2748779068,"1_synth",2791728741,"0_control",2834678414,"1_synth",2877628087,"0_control",2920577760,"1_synth",2942052597,"0_control",2963527433,"1_synth",2985002270,"0_control",3006477106,"1_synth",3049426779,"0_control",3092376452,"1_synth",3135326125,"0_control",3178275798,"1_synth",3199750635,"0_control",3221225471,"1_synth",3242700307,"0_control",3264175144,"1_synth",3285649980,"0_control",3307124817,"1_synth",3328599653,"0_control",3350074490,"1_synth",3371549326,"0_control",3393024163,"1_synth",3435973836,"0_control",3478923509,"1_synth",3500398345,"0_control",3521873182,"1_synth",3543348018,"0_control",3564822855,"1_synth",3586297691,"0_control",3607772528,"1_synth",3629247364,"0_control",3650722201,"1_synth",3672197037,"0_control",3693671874,"1_synth",3758096383,"0_control",3822520892,"1_synth",3865470565,"0_control",3908420238,"1_synth",3929895075,"0_control",3951369911,"1_synth",3972844748,"0_control",3994319584,"1_synth",4015794421,"0_control",4037269257,"1_synth",4058744094,"0_control",4080218930,"1_synth",4101693767,"0_control",4123168603,"1_synth",4144643440,"0_control",4166118276,"1_synth",4187593113,"0_control",4209067949,"1_synth",4230542786,"0_control",4252017622,"1_synth",4273492459,"0_control",4294967295,"1_synth"]},"STYLN_ad_placement_0424":{"abtest_partition":[{"var":"agent_id"},"STYLN_ad_placement_0424",1073741823,"0_control",2147483647,"1_pattern",3221225471,"2_distance",4294967295,"3_both"]},"STORY_inlineModules_0124":{"abtest_partition":[{"var":"agent_id"},"STORY_inlineModules_0124",4294967295,"0_unstructured_modules"]},"STANDCON_CONV_EXISTING_SUBS_BAR1_EXPERIMENT_2212":{"abtest_partition":[{"var":"agent_id"},"STANDCON_CONV_EXISTING_SUBS_BAR1_EXPERIMENT_2212",3006477106,"v7",3221225471,"v0",3865470565,"v0",4294967295,"v4"]},"SP_ReporterReply_0424":{"abtest_partition":[{"var":"agent_id"},"SP_ReporterReply_0424",14319420,"0_Control",28634546,"1_Blue",42949672,"2_Headshot",128866198,"0_Control",214756954,"1_Blue",300647710,"2_Headshot",314967131,"0_Control",329282257,"1_Blue",343597383,"2_Headshot",357916804,"0_Control",372231930,"1_Blue",386547056,"2_Headshot",400866477,"0_Control",415181603,"1_Blue",429496729,"2_Headshot"]},"SJ_xpn_standard_story_0424":{"abtest_partition":[{"var":"agent_id"},"SJ_xpn_standard_story_0424",214791313,"0_Control",429518203,"1_xpn_in_story",644245093,"2_xpn_hamburger"]},"SJ_regiOnboardingAppDownloadKnockout_0424":{"if":[{"and":[{"!":{"in":[{"ref":"SUBX_regi_alloc_holdout_2024H1"},["1_best_experience","0_holdout"]]}},{"!":{"in":[{"ref":"SJ_RegiAppDownloadDisrupter_0424"},["0_control","1_disrupter"]]}}]},{"abtest_partition":[{"var":"regi_id"},"SJ_regiOnboardingAppDownloadKnockout_0424",1245540515,"0_control",2491081031,"1_app_download_knockout"]}]},"SJ_RegiAppDownloadDisrupter_0424":{"abtest_partition":[{"var":"regi_id"},"SJ_RegiAppDownloadDisrupter_0424",279172873,"0_control",558345747,"1_disrupter"]},"SJ_mum_app_download_0301":{"if":[{"and":[{"!":{"in":[{"ref":"SUBX_regi_alloc_holdout_2024H1"},["0_holdout","1_best_experience"]]}}]},{"abtest_partition":[{"var":"regi_id"},"SJ_mum_app_download_0301",10737417,"0_control",21474835,"1_barone",32212254,"2_account_notification",42949672,"3_barone_account_notification",64424508,"0_control",85899345,"1_barone",107374181,"2_account_notification",128849018,"3_barone_account_notification",139586436,"0_control",150323854,"1_barone",161061273,"2_account_notification",171798691,"3_barone_account_notification",182536109,"0_control",193273527,"1_barone",204010946,"2_account_notification",214748364,"3_barone_account_notification",225485782,"0_control",236223200,"1_barone",246960619,"2_account_notification",257698037,"3_barone_account_notification",268435455,"0_control",279172873,"1_barone",289910291,"2_account_notification",300647710,"3_barone_account_notification",311385128,"0_control",322122546,"1_barone",332859964,"2_account_notification",343597383,"3_barone_account_notification",354334801,"0_control",365072219,"1_barone",375809637,"2_account_notification",386547056,"3_barone_account_notification",397284474,"0_control",408021892,"1_barone",418759310,"2_account_notification",429496729,"3_barone_account_notification",440234147,"0_control",450971565,"1_barone",461708983,"2_account_notification",472446402,"3_barone_account_notification",483183820,"0_control",493921238,"1_barone",504658656,"2_account_notification",515396075,"3_barone_account_notification",526133493,"0_control",536870911,"1_barone",547608329,"2_account_notification",558345747,"3_barone_account_notification",569083166,"0_control",579820584,"1_barone",590558002,"2_account_notification",601295420,"3_barone_account_notification",612032839,"0_control",622770257,"1_barone",633507675,"2_account_notification",644245093,"3_barone_account_notification",654982512,"0_control",665719930,"1_barone",676457348,"2_account_notification",687194766,"3_barone_account_notification",697932185,"0_control",708669603,"1_barone",719407021,"2_account_notification",730144439,"3_barone_account_notification",740881858,"0_control",751619276,"1_barone",762356694,"2_account_notification",773094112,"3_barone_account_notification",783831531,"0_control",794568949,"1_barone",805306367,"2_account_notification",816043785,"3_barone_account_notification",826781203,"0_control",837518622,"1_barone",848256040,"2_account_notification",858993458,"3_barone_account_notification",869730876,"0_control",880468295,"1_barone",891205713,"2_account_notification",901943131,"3_barone_account_notification",912680549,"0_control",923417968,"1_barone",934155386,"2_account_notification",944892804,"3_barone_account_notification",955630222,"0_control",966367641,"1_barone",977105059,"2_account_notification",987842477,"3_barone_account_notification",998579895,"0_control",1009317314,"1_barone",1020054732,"2_account_notification",1030792150,"3_barone_account_notification",1041529568,"0_control",1052266987,"1_barone",1063004405,"2_account_notification",1073741823,"3_barone_account_notification",1084479241,"0_control",1095216659,"1_barone",1105954078,"2_account_notification",1116691496,"3_barone_account_notification",1127428914,"0_control",1138166332,"1_barone",1148903751,"2_account_notification",1159641169,"3_barone_account_notification",1170378587,"0_control",1181116005,"1_barone",1191853424,"2_account_notification",1202590842,"3_barone_account_notification",1213328260,"0_control",1224065678,"1_barone",1234803097,"2_account_notification",1245540515,"3_barone_account_notification",1256277933,"0_control",1267015351,"1_barone",1277752770,"2_account_notification",1288490188,"3_barone_account_notification",1299227606,"0_control",1309965024,"1_barone",1320702443,"2_account_notification",1331439861,"3_barone_account_notification",1406601788,"0_control",1481763716,"1_barone",1556925644,"2_account_notification",1632087571,"3_barone_account_notification",1825361100,"0_control",2018634628,"1_barone",2211908156,"2_account_notification",2405181685,"3_barone_account_notification",2738041650,"0_control",3070901616,"1_barone",3403761581,"2_account_notification",3736621547,"3_barone_account_notification",3876207984,"0_control",4015794421,"1_barone",4155380858,"2_account_notification",4294967295,"3_barone_account_notification"]}]},"SJ_disrupter_V2_increased_cadence":{"if":[{"and":[{"!":{"in":[{"ref":"SUBX_regi_alloc_holdout_2024H1"},["0_holdout"]]}}]},{"abtest_partition":[{"var":"regi_id"},"SJ_disrupter_V2_increased_cadence",4294967295,"2_high_intensity"]}]},"SJ_bottom_sheet_rollout_0626":{"if":[{"and":[{"===":[{"var":"user_type"},"sub"]},{"===":[{"ref":"SJ_universal_holdout_0722"},"1_test"]}]},{"abtest_partition":[{"var":"regi_id"},"SJ_bottom_sheet_rollout_0626",429496729,"0_Control",4294967295,"1_Test"]}]},"SHA_closePanel_cwv_0423":{"abtest_partition":[{"var":"agent_id"},"SHA_closePanel_cwv_0423",4294966,"0_Control",42949672,"1_Spinner",81604378,"0_Control",429496729,"1_Spinner",816043785,"0_Control",4294967295,"1_Spinner"]},"SHA_cardShare_0424":{"abtest_partition":[{"var":"agent_id"},"SHA_cardShare_0424",4294967295,"1_Share"]},"SEO_timesTagsToCollectionsBarRollout_cwv_0424":{"abtest_partition":[{"var":"agent_id"},"SEO_timesTagsToCollectionsBarRollout_cwv_0424",2147483647,null,4294967295,null]},"ON_news_upsell_sale":{"abtest_partition":[{"var":"agent_id"},"ON_news_upsell_sale",3865470565,"1_news_upsell",4294967295,"1_news_upsell"]},"OMA_FEDERATED_QUERY":{"abtest_partition":[{"var":"agent_id"},"OMA_FEDERATED_QUERY"]},"MX_Turn_Off_CAPI_0324":{"abtest_partition":[{"var":"agent_id"},"MX_Turn_Off_CAPI_0324",4294967295,"0_no_capi"]},"MX_OMA_HomeDock_12_24":{"abtest_partition":[{"var":"agent_id"},"MX_OMA_HomeDock_12_24_1",4294967295,"0_Control"]},"MX_OMA_DOCK_TEST":{"abtest_partition":[{"var":"agent_id"},"MX_OMA_DOCK_TEST",4294967295,"1_Variant"]},"MX_NewArchitecture_WirecutterLP":{"abtest_partition":[{"var":"agent_id"},"MX_NewArchitecture_WirecutterLP",214748364,"0_control",408021892,null,622770257,"1_variant"]},"MX_NewArchitecture_PostLoginOffer":{"abtest_partition":[{"var":"agent_id"},"MX_NewArchitecture_PostLoginOffer",21474835,"1_variant",42949672,"1_variant",536870911,"1_variant",901943131,"1_variant",923417968,"1_variant",944892804,"1_variant",966367641,"1_variant",987842477,"1_variant",1009317314,"1_variant",1030792150,"1_variant",1052266987,"1_variant",1073741823,"1_variant",1095216659,"1_variant",1116691496,"1_variant",1159641169,"1_variant",1202590842,"1_variant",1267015351,"1_variant",1352914697,"1_variant",1417339207,"1_variant",1503238553,"1_variant",1567663062,"1_variant",1632087571,"1_variant",1696512081,"1_variant",1739461754,"1_variant",1803886263,"1_variant",1846835936,"1_variant",1889785609,"1_variant",1932735282,"1_variant",1975684955,"1_variant",2040109465,"1_variant",2083059138,"1_variant",4294967295,"1_variant"]},"MX_NewArchitecture_gateway":{"if":[{"and":[{"===":[{"ref":"MX_NewArchitecture_MeterReal"},"1_variant"]}]},{"abtest_partition":[{"var":"agent_id"},"MX_NewArchitecture_gateway",21474835,"1_variant",107374181,"1_variant",1073741823,"1_variant",1116691496,"1_variant",1159641169,"1_variant",1267015351,"1_variant",1503238553,"1_variant",1717986917,"1_variant",1932735282,"1_variant",2126008811,"1_variant",4294967295,"1_variant"]}]},"MX_FF_WELCOME_AD":{"abtest_partition":[{"var":"agent_id"},"MX_FF_WELCOME_AD",4294967295,"1_Variant"]},"MKT_not_ready_to_sub_survey":{"abtest_partition":[{"var":"agent_id"},"MKT_not_ready_to_sub_survey",3221225471,"0_control",3435973836,"1_survey",4294967295,"0_control"]},"example_feature_VIZEX_DATA_4-22":{"abtest_partition":[{"var":"agent_id"},"5db6befa-6786-4bd2-a26c-884da524b645",858993458,"0_Control",1717986917,"1_Variant"]},"Election_PW_AA_SUBCON_GROWTH_3-15":{"abtest_partition":[{"var":"agent_id"},"57f8e651-67fc-406c-bc35-316e9447b872",1434519076,"0_control",2864743185,"1_variant",4294967295,"2_variant"]},"disrupter_framing_SUJO_SUBX_4-25":{"if":[{"or":[{"and":[{"===":[{"var":"user_type"},"sub"]},{"!":{"in":[{"ref":"SUBX_regi_alloc_holdout_2024H1"},["0_holdout","1_best_experience"]]}}]}]},{"abtest_partition":[{"var":"regi_id"},"246b6572-2795-4c87-aab8-e5d13f31d3dc",1434519076,"0_control",2864743185,"1_get_most",4294967295,"2_not_getting"]}]},"dfp_mkt_dispannualoffer_0424":{"if":[{"and":[{"!":{"in":[{"var":"geo_country"},["US"]]}}]},{"abtest_partition":[{"var":"agent_id"},"dfp_mkt_dispannualoffer_0424",2147483647,"0_Control_Week",4294967295,"1_Variant_Annual"]}]},"CONV_GUAC_PLOPRO_SLAYER_0224":{"abtest_partition":[{"var":"agent_id"},"CONV_GUAC_PLOPRO_SLAYER_0224",4294967295,"1_slayer"]},"CONV_GUAC_NewsPaywall_SLAYER_0324":{"abtest_partition":[{"var":"agent_id"},"CONV_GUAC_NewsPaywall_SLAYER_0324",4294967295,"1_Slayer"]},"CONV_GUAC_Dock_HDUpsell_0524":{"abtest_partition":[{"var":"regi_id"},"CONV_GUAC_Dock_HDUpsell_0524_1",1460288880,"0_control",2877628087,"1_upgrade",4294967295,"2_sunday_hook"]},"CONV_GUAC_CKLP_ExpressCheckOut_RollOut_0124":{"abtest_partition":[{"var":"agent_id"},"CONV_GUAC_CKLP_ExpressCheckOut_RollOut_0124",4294967295,"1_expresscheckout"]},"CONV_GUAC_CKLP_Annual_Offer_Prominence_Test_0524":{"abtest_partition":[{"var":"agent_id"},"CONV_GUAC_CKLP_Annual_Offer_Prominence_Test_0524",10737417,"0_control",21474835,"1_annual_top",32212254,"2_best_value",42949672,"3_annual_top_best_value",53687090,"0_control",64424508,"1_annual_top",75161927,"2_best_value",85899345,"3_annual_top_best_value",150323854,"0_control",214748364,"1_annual_top",279172873,"2_best_value",343597383,"3_annual_top_best_value",493921238,"0_control",644245093,"1_annual_top",794568949,"2_best_value",944892804,"3_annual_top_best_value",1116691496,"0_control",1288490188,"1_annual_top",1460288880,"2_best_value",1632087571,"3_annual_top_best_value",1836098518,"0_control",2040109465,"1_annual_top",2244120411,"2_best_value",2448131358,"3_annual_top_best_value",2727304232,"0_control",3006477106,"1_annual_top",3285649980,"2_best_value",3564822855,"3_annual_top_best_value",3747358965,"0_control",3929895075,"1_annual_top",4112431185,"2_best_value",4294967295,"3_annual_top_best_value"]},"CONV_GUAC_CK_AA_Intl_AnnualOffer_0524":{"abtest_partition":[{"var":"agent_id"},"CONV_GUAC_CK_AA_Intl_AnnualOffer_0524"]},"CONV_GUAC_AALP_SLAYER_0224":{"abtest_partition":[{"var":"agent_id"},"CONV_GUAC_AALP_SLAYER_0224",4294967295,"1_slayer"]},"CONV_GUAC_AALP_HDAnchor_Test_0424":{"abtest_partition":[{"var":"agent_id"},"CONV_GUAC_AALP_HDAnchor_Test_0424",1417339207,"1_anchor",4294967295,"1_anchor"]},"CONV_GUAC_AADock_SLAYER_0324":{"abtest_partition":[{"var":"regi_id"},"CONV_GUAC_AADock_SLAYER_0324",4294967295,"1_slayer"]},"clone_synth_web_VIZEX_DATA_4-23":{"abtest_partition":[{"var":"agent_id"},"e581a582-5f64-43ad-b2a5-872d6840a7bd",429496729,"0_control",858993458,"1_synth"]},"AMS_FrictionCircumventionMobile_cwv":{"abtest_partition":[{"var":"agent_id"},"AMS_FrictionCircumventionMobile_cwv",14315125,"2_low-mid-truncation",214726889,"2_low-mid-truncation",243357141,"2_low-mid-truncation",257672267,"2_low-mid-truncation",271987393,"2_low-mid-truncation",286302519,"2_low-mid-truncation",300617645,"2_low-mid-truncation",314932771,"2_low-mid-truncation",329247897,"2_low-mid-truncation",343563023,"2_low-mid-truncation",357878149,"2_low-mid-truncation",372193275,"2_low-mid-truncation",386508401,"2_low-mid-truncation",400823527,"2_low-mid-truncation",415138653,"2_low-mid-truncation",429453779,"2_low-mid-truncation",443768905,"2_low-mid-truncation",558289913,"2_low-mid-truncation",830277307,"2_low-mid-truncation",1259731087,"2_low-mid-truncation",4294967295,"2_low-mid-truncation"]},"AMS_FrictionCircumventionDesktop_cwv":{"abtest_partition":[{"var":"agent_id"},"AMS_FrictionCircumventionDesktop_cwv",14315125,"2_low-mid-truncation",214726889,"2_low-mid-truncation",243357141,"2_low-mid-truncation",257672267,"2_low-mid-truncation",271987393,"2_low-mid-truncation",286302519,"2_low-mid-truncation",300617645,"2_low-mid-truncation",314932771,"2_low-mid-truncation",329247897,"2_low-mid-truncation",343563023,"2_low-mid-truncation",357878149,"2_low-mid-truncation",372193275,"2_low-mid-truncation",386508401,"2_low-mid-truncation",400823527,"2_low-mid-truncation",415138653,"2_low-mid-truncation",429453779,"2_low-mid-truncation",443768905,"2_low-mid-truncation",458084031,"2_low-mid-truncation",644180669,"2_low-mid-truncation",844592433,"2_low-mid-truncation",1245415961,"2_low-mid-truncation",4294967295,"2_low-mid-truncation"]},"ACCT_Profile_Section_0324":{"abtest_partition":[{"var":"regi_id"},"ACCT_Profile_Section_0324",4294967295,"1_Display_Profile"]},"AA_OnboardingFlow_MVPFlowAppSequence_WebandApp_V1":{"if":[{"and":[{"regex_match":[{"var":"user_entitlements"},"(^|\\W)MM($|\\W)"]},{"regex_match":[{"var":"user_entitlements"},"(^|\\W)CKG($|\\W)"]},{"regex_match":[{"var":"user_entitlements"},"(^|\\W)ATH($|\\W)"]},{"regex_match":[{"var":"user_entitlements"},"(^|\\W)WC($|\\W)"]},{"regex_match":[{"var":"user_entitlements"},"(^|\\W)XWD($|\\W)"]},{"!":{"in":[{"ref":"SUBX_regi_alloc_holdout_2024H1"},["0_holdout"]]}},{"!==":[{"var":"app_version"},"10.44.0"]}]},{"abtest_partition":[{"var":"regi_id"},"AA_OnboardingFlow_MVPFlowAppSequence_WebandApp_V1",773094112,"2_appLater",1275605286,"2_appLater",1346472246,"2_appLater",1360645638,"2_appLater",1374819030,"2_appLater",1388992423,"2_appLater",1403165815,"2_appLater",4294967295,"2_appLater"]}]}},"abraURL":"https://a1.nyt.com/abra-config/current/vi-prd.json"}]); })();;(function () { var _f=function(e){var i=window.vi&&window.vi.webviewEnvironment&&window.vi.webviewEnvironment.isPreloaded,n=function(){var n=e.url;try{n+=window.location.search.slice(1).split("&").reduce(function(e,i){return"ip-override"===i.split("=")[0]?"?"+i:e},"")}catch(e){console.warn(e)}var r=new XMLHttpRequest;for(var t in r.withCredentials=!0,r.open("POST",n,!0),r.setRequestHeader("Content-Type","application/json"),i&&(r.setRequestHeader("NYT-User-Token",window.getNativeBridgeCookie("NYT-S")),r.setRequestHeader("NYT-Agent-ID",window.getNativeBridgeCookie("nyt-a"))),e.headers)r.setRequestHeader(t,e.headers[t]);return r.send(e.body),r};i&&!window.nativeBridgeCookies?window.initNativeBridgeCookies(function(){window.userXhrObject=n()}):window.userXhrObject=n(),window.userXhrRefresh=function(){return window.userXhrObject=n(),window.userXhrObject}};;_f.apply(null, [{"url":"https://samizdat-graphql.nytimes.com/graphql/v2","body":"{\"operationName\":\"UserQuery\",\"variables\":{},\"query\":\"   query UserQuery {     user {       __typename       profile {         displayName         email       }       userInfo {         regiId         entitlements         demographics {           emailSubscriptions           wat         }       }       subscriptionDetails {         bundleType         cancellationDate         graceStartDate         graceEndDate         isFreeTrial         hasQueuedSub         startDate         endDate         status         hasActiveEntitlements         entitlements         billingSource         promotionTierType         subscriptionName         subscriptionProducts         subscriptionLabels       }     }   } \"}","headers":{"nyt-app-type":"project-vi","nyt-app-version":"0.0.5","nyt-token":"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs+/oUCTBmD/cLdmcecrnBMHiU/pxQCn2DDyaPKUOXxi4p0uUSZQzsuq1pJ1m5z1i0YGPd1U1OeGHAChWtqoxC7bFMCXcwnE1oyui9G1uobgpm1GdhtwkR7ta7akVTcsF8zxiXx7DNXIPd2nIJFH83rmkZueKrC4JVaNzjvD+Z03piLn5bHWU6+w+rA+kyJtGgZNTXKyPh6EC6o5N+rknNMG5+CdTq35p8f99WjFawSvYgP9V64kgckbTbtdJ6YhVP58TnuYgr12urtwnIqWP9KSJ1e5vmgf3tunMqWNm6+AnsqNj8mCLdCuc5cEB74CwUeQcP2HQQmbCddBy2y0mEwIDAQAB"}}]); })();;(function () { var registry=window._interactiveRegistry={};function getId(e){for(;(e=e.parentElement)&&!e.matches("[data-sourceid].interactive-body"););return e?e.getAttribute("data-sourceid"):null}window.registerInteractive=function(e){var t={_subs:{cleanup:[],remount:[]},id:e,on:function(e,r){return this._subs[e].push(r),t},errorFound:!1},r=document.getElementById("embed-id-"+e),n=new MutationObserver(function(){(r.textContent.includes("500 Internal Error")||r.textContent.includes("200 undefined"))&&(t.errorFound||(window.dispatchEvent(new CustomEvent("trigger-embed-hydration-"+e)),window.Sentry&&window.Sentry.captureException&&window.Sentry.captureException(new Error("Embed load error, triggered manual rehydration: "+e)),t.errorFound=!0))});r&&n.observe(r,{characterData:!0,attributes:!1,childList:!0,subtree:!0}),registry[e]=t},window.getInteractiveBridge=function(e){var t="string"==typeof e?e:getId(e);return registry[t]}; })();;(function () { var _f=function(){"function"!=typeof window.onInitNativeAds&&(window.onInitNativeAds=function(){})};;_f.apply(null, []); })();
    </script>
    <script>!function(){try{var e="undefined"!=typeof window?window:"undefined"!=typeof global?global:"undefined"!=typeof self?self:{},n=(new Error).stack;n&&(e._sentryDebugIds=e._sentryDebugIds||{},e._sentryDebugIds[n]="298143d8-6286-4ad4-9c8d-3b5b4f3cdd46",e._sentryDebugIdIdentifier="sentry-dbid-298143d8-6286-4ad4-9c8d-3b5b4f3cdd46")}catch(e){}}();var _global="undefined"!=typeof window?window:"undefined"!=typeof global?global:"undefined"!=typeof self?self:{};_global.SENTRY_RELEASE={id:"fda3c1704e92bc29a9545d08be2eec92a5050bf5"},function(e){function n(n){for(var r,d,u=n[0],l=n[1],a=n[2],c=0,s=[];c<u.length;c++)d=u[c],Object.prototype.hasOwnProperty.call(o,d)&&o[d]&&s.push(o[d][0]),o[d]=0;for(r in l)Object.prototype.hasOwnProperty.call(l,r)&&(e[r]=l[r]);for(i&&i(n);s.length;)s.shift()();return f.push.apply(f,a||[]),t()}function t(){for(var e,n=0;n<f.length;n++){for(var t=f[n],r=!0,u=1;u<t.length;u++){var l=t[u];0!==o[l]&&(r=!1)}r&&(f.splice(n--,1),e=d(d.s=t[0]))}return e}var r={},o={137:0},f=[];function d(n){if(r[n])return r[n].exports;var t=r[n]={i:n,l:!1,exports:{}};return e[n].call(t.exports,t,t.exports,d),t.l=!0,t.exports}d.m=e,d.c=r,d.d=function(e,n,t){d.o(e,n)||Object.defineProperty(e,n,{enumerable:!0,get:t})},d.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},d.t=function(e,n){if(1&n&&(e=d(e)),8&n)return e;if(4&n&&"object"==typeof e&&e&&e.__esModule)return e;var t=Object.create(null);if(d.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:e}),2&n&&"string"!=typeof e)for(var r in e)d.d(t,r,function(n){return e[n]}.bind(null,r));return t},d.n=function(e){var n=e&&e.__esModule?function(){return e.default}:function(){return e};return d.d(n,"a",n),n},d.o=function(e,n){return Object.prototype.hasOwnProperty.call(e,n)},d.p="/vi-assets/static-assets/";var u=window.webpackJsonp=window.webpackJsonp||[],l=u.push.bind(u);u.push=n,u=u.slice();for(var a=0;a<u.length;a++)n(u[a]);var i=l;t()}([]);
//# sourceMappingURL=runtime~adslot-2f3b57d144c5169f6d5f.js.map</script>
    <script async src="/vi-assets/static-assets/adslot-1e649f756902ef13bd8d.js"></script>
    <script data-rh="true" >
          (function () { var _f=function(){const o="1_block";function n(o){return window&&window.NYTD&&window.NYTD.Abra?window.NYTD.Abra(o):""}window.adClientUtils={hasActiveToggle:function(r){return n(r)!==o},getAbraVar:n,reportExposure:function(o){window&&window.NYTD&&window.NYTD.Abra&&window.NYTD.Abra.reportExposure&&window.NYTD.Abra.reportExposure(o)}}};;_f.apply(null, []); })();
          (function () { undefined })();
          (function () { var _f=function(){var t,e,o=50,n=50;function i(t){if(!document.getElementById("3pCheckIframeId")){if(t||(t=1),!document.body){if(t>o)return;return t+=1,setTimeout(i.bind(null,t),n)}var e,a,r;e="https://static01.nyt.com/ads/tpc-check.html",a=document.body,(r=document.createElement("iframe")).src=e,r.id="3pCheckIframeId",r.style="display:none;",r.height=0,r.width=0,a.insertBefore(r,a.firstChild)}}function a(t){if("https://static01.nyt.com"===t.origin)try{"3PCookieSupported"===t.data&&googletag.cmd.push(function(){googletag.pubads().setTargeting("cookie","true")}),"3PCookieNotSupported"===t.data&&googletag.cmd.push(function(){googletag.pubads().setTargeting("cookie","false")})}catch(t){}}function r(){if(function(){if(Object.prototype.toString.call(window.HTMLElement).indexOf("Constructor")>0)return!0;if("[object SafariRemoteNotification]"===(!window.safari||safari.pushNotification).toString())return!0;try{return window.localStorage&&/Safari/.test(window.navigator.userAgent)}catch(t){return!1}}()){try{window.openDatabase(null,null,null,null)}catch(e){return t(),!0}try{localStorage.length?e():(localStorage.x=1,localStorage.removeItem("x"),e())}catch(o){navigator.cookieEnabled?t():e()}return!0}}!function(){try{googletag.cmd.push(function(){googletag.pubads().setTargeting("cookie","unknown")})}catch(t){}}(),t=function(){try{googletag.cmd.push(function(){googletag.pubads().setTargeting("cookie","private")})}catch(t){}}||function(){},e=function(){window.addEventListener("message",a,!1),i(0)}||function(){},function(){if(window.webkitRequestFileSystem)return window.webkitRequestFileSystem(window.TEMPORARY,1,e,t),!0}()||r()||function(){if(!window.indexedDB&&(window.PointerEvent||window.MSPointerEvent))return t(),!0}()||e()};;_f.apply(null, ["dfp_story_toggle"]); })();
        </script><script data-rh="true" id="als-svc">(function () { var _f=function(e,t,a,n){var i;if(!(i=a,!!(window&&window.adClientUtils&&window.adClientUtils.hasActiveToggle)&&window.adClientUtils.hasActiveToggle(i)))return;!function(e){window&&window.NYTD&&window.NYTD.Abra&&window.NYTD.Abra.reportExposure(e)}(a);let o=()=>{var e=new Date,t=e.getFullYear();return e.getMonth()<9&&(t+="0"),t+=e.getMonth()+1,e.getDate()<10&&(t+="0"),t+=e.getDate(),e.getHours()<10&&(t+="0"),t+=e.getHours(),e.getMinutes()<10&&(t+="0"),t+=e.getMinutes(),e.getSeconds()<10&&(t+="0"),t+e.getSeconds()};window.googletag=window.googletag||{},googletag.cmd=googletag.cmd||[];let l=new URLSearchParams(location.search).get("alice_rules_test");var s,r=new XMLHttpRequest,d=window.vi.env.ALS_URL,g=document.querySelector('[name="nyt_uri"]');if(t)s="uri="+(c=t);else if("/"===location.pathname){var c=encodeURIComponent("https://www.nytimes.com/pages/index.html");s="uri="+c}else if(void 0===g||""===g||null===g){var u=e||location.protocol+"//"+location.hostname+location.pathname;s="url="+encodeURIComponent(u)}else{c=encodeURIComponent(g.content);s="uri="+c}var w=n;if(!w){var m=document.querySelector('[name="template"]');w=null==m||null==m.content?"":m.content}var p=document.querySelector('[name="prop"]'),_=document.querySelector('[name="plat"]'),v=null==p||null==p.content?"nyt":p.content,b=null==_||null==_.content?"web":_.content;window.innerWidth<740&&(v="mnyt",b="mweb");var f=window.localStorage.getItem("als_test_clientside"),h=null;window.googletag.cmd.push(function(){var e=f&&0!==f.length?f:"empty_empty_empty_"+o(),t=h||e;googletag.pubads().setTargeting("als_test_clientside",t)});var y=window.localStorage.getItem("mktg"),U=null;window.googletag.cmd.push(function(){var e=U||y;e&&googletag.pubads().setTargeting("mktg",e)});var L,S=window.localStorage.getItem("bt");window.googletag.cmd.push(function(){var e=null!=L?L:S;null!=e&&googletag.pubads().setTargeting("bt",e)});var T=window.localStorage.getItem("sub"),C=null;function x(e){var t=new TextEncoder("utf-8").encode(e);return crypto.subtle.digest("SHA-256",t).then(function(e){return function(e){for(var t=[],a=new DataView(e),n=0;n<a.byteLength;n+=4){var i=a.getUint32(n),o=i.toString(16),l=("00000000"+o).slice(-"00000000".length);t.push(l)}return t.join("")}(e)})}window.googletag.cmd.push(function(){var e=C||T;e&&googletag.pubads().setTargeting("sub",e)}),s=null==l?s:s+"&alice_rules_test="+l,r.open("GET",d+"/als?"+s+"&typ="+w+"&prop="+v+"&plat="+b,!0),r.withCredentials=!0,r.send(),r.onerror=function(){var e="reqfailed_reqfailed_reqfailed_"+o();h=e,window.googletag.cmd.push(function(){googletag.pubads().setTargeting("als_test_clientside",e)});var t={event:"impression",module:{name:"alice-timing",context:"script-load",label:"alice-error-reqfail-"+s}};(window.dataLayer=window.dataLayer||[]).push(t)},r.onreadystatechange=function(){if(4===r.readyState)if(200===r.status){var e=JSON.parse(r.responseText);h=e.als_test_clientside&&0!==e.als_test_clientside.length?e.als_test_clientside:"bou_bou_bou_"+o(),void 0!==e.User&&(void 0!==e.User.mktg&&(U=e.User.mktg,window.localStorage.setItem("mktg",e.User.mktg)),void 0!==e.User.bt&&(L=e.User.bt,window.localStorage.setItem("bt",e.User.bt)),void 0!==e.User.sub&&(C=e.User.sub,window.localStorage.setItem("sub",e.User.sub)),void 0!==e.User.aid&&(server_aid=e.User.aid,window.localStorage.setItem("aid",e.User.aid))),window.googletag.cmd.push(function(){if(e.als_test_clientside&&0!==e.als_test_clientside.length)googletag.pubads().setTargeting("als_test_clientside",e.als_test_clientside),window.localStorage.setItem("als_test_clientside","ls-"+e.als_test_clientside);else{var t=void 0===e.als_test_clientside?"undefined_undefined_undefined_"+o():"blank_blank_blank_"+o();googletag.pubads().setTargeting("als_test_clientside",t);var a={event:"impression",module:{name:"alice-timing",context:"script-load",label:"alice-error-test-client-undefined"}};(window.dataLayer=window.dataLayer||[]).push(a)}if(void 0!==e.User){if(server_aid&&x(server_aid).then(function(e){googletag.pubads().setPublisherProvidedId(e)}),U)googletag.pubads().setTargeting("mktg",U);else{a={event:"impression",module:{name:"alice-timing",context:"script-load",label:"alice-error-mktg-undefined"}};(window.dataLayer=window.dataLayer||[]).push(a)}if(void 0!==L)googletag.pubads().setTargeting("bt",L);else{a={event:"impression",module:{name:"alice-timing",context:"script-load",label:"alice-error-bt-undefined"}};(window.dataLayer=window.dataLayer||[]).push(a)}if(C)googletag.pubads().setTargeting("sub",C);else{a={event:"impression",module:{name:"alice-timing",context:"script-load",label:"alice-error-sub-undefined"}};(window.dataLayer=window.dataLayer||[]).push(a)}(e.User.lucidC1||e.User.lucidC2||e.User.lucidC3||e.User.lucidC4||e.User.lucidC5)&&dataLayer.push({event:"lucidtest",c1_val:e.User.lucidC1,c2_val:e.User.lucidC2,c3_val:e.User.lucidC3,c4_val:e.User.lucidC4,c5_val:e.User.lucidC5})}else{a={event:"impression",module:{name:"alice-timing",context:"script-load",label:"alice-error-user-undefined"}};(window.dataLayer=window.dataLayer||[]).push(a)}if(void 0!==e.Asset)for(var n in e.Asset){var i=e.Asset[n];if(i)googletag.pubads().setTargeting(n,i);else{a={event:"impression",module:{name:"alice-timing",context:"script-load",label:"alice-error-"+n+"-undefined"}};(window.dataLayer=window.dataLayer||[]).push(a)}}else{a={event:"impression",module:{name:"alice-timing",context:"script-load",label:"alice-error-asset-undefined"}};(window.dataLayer=window.dataLayer||[]).push(a)}})}else{r.responseText.substring(0,40);var t="error_"+r.status+"_error_"+o();window.googletag.cmd.push(function(){googletag.pubads().setTargeting("als_test_clientside",t)});var a={event:"impression",module:{name:"alice-timing",context:"script-load",label:"alice-error-ajaxreq-"+r.status+"-"+s}};(window.dataLayer=window.dataLayer||[]).push(a)}}};;_f.apply(null, [null,null,"als_toggle","art"]); })();</script><script data-rh="true" id="adslot-config">(function() {
            var AdSlot4=function(){"use strict";function a(){return window.AdSlot4=window.AdSlot4||{},window.AdSlot4.cmd=window.AdSlot4.cmd||[],window.AdSlot4}function t(e){return-1!==document.cookie.indexOf(e)}function n(e){var t={PURR_AcceptableTrackers:0,PURR_AdConfiguration:5,PURR_DataSaleOptOutUI:2,PURR_DataProcessingConsentUI:3,PURR_AcceptableTrackers_v2:4,PURR_AdConfiguration_v2:5,PURR_DataProcessingPreferenceUI:6,PURR_DataSaleOptOutUI_v2:7,PURR_CaliforniaNoticesUI:8,PURR_EmailMarketingOptInUI:9,PURR_DeleteIPAddress:10,PURR_AdConfiguration_v3:11,PURR_LimitSensitivePI:12,PURR_EmailMarketingOptInUI_v2:13,PURR_AdConfiguration_v4:14},n=function(e){e="; ".concat(document.cookie).split("; ".concat(e,"="));return 2===e.length?e.pop().split(";").shift():null}(e),i={};return Object.keys(t).forEach(function(e){i[e]=function(e,t){t=new RegExp("^.{".concat(t,"}(.)")),t=e.match(t);return(null==t?void 0:t[1])||""}(n,t[e])}),r.forEach(function(t){Object.keys(t.valueMapping).forEach(function(e){t.valueMapping[e]===i[t.name]&&(i[t.name]=e)})}),i}function i(){var e;try{return function(){if("undefined"==typeof window)return!1;var e=window.navigator.userAgent||window.navigator.vendor,t=-1!==e.indexOf("nyt_android"),n=-1!==e.indexOf("nytios"),i=-1!==e.indexOf("nyt_xwords_ios"),e=-1!==e.indexOf("Crosswords");return t||n||i||e}()?null!==(e=null===window||void 0===window?void 0:window.config)&&void 0!==e&&e.PurrDirectives?window.config.PurrDirectives:t("override-purr")?n("override-purr"):o({},d):t("nyt-purr")?n("nyt-purr"):o({},d)}catch(e){return console.warn("can’t get directives from cookie or config",e),o({},d)}}function e(){var e={};return"undefined"!=typeof window&&window.document&&window.document.createElement&&(e=i().PURR_AdConfiguration_v3||i().PURR_AdConfiguration_v2),e}var o=function(){return(o=Object.assign||function(e){for(var t,n=1,i=arguments.length;n<i;n++)for(var o in t=arguments[n])Object.prototype.hasOwnProperty.call(t,o)&&(e[o]=t[o]);return e}).apply(this,arguments)},r=[{name:"PURR_AcceptableTrackers",valueMapping:{controllers:"c",processors:"p"}},{name:"PURR_AdConfiguration",valueMapping:{full:"f",npa:"n","adluce-socrates":"s"}},{name:"PURR_DataSaleOptOutUI",valueMapping:{hide:"h",show:"s"}},{name:"PURR_DataProcessingConsentUI",valueMapping:{hide:"h",show:"s"}},{name:"PURR_AcceptableTrackers_v2",valueMapping:{controllers:"c",processors:"p",essentials:"e"}},{name:"PURR_AdConfiguration_v2",valueMapping:{full:"f",rdp:"r",npa:"n",adluce:"a","adluce-socrates":"s"}},{name:"PURR_DataProcessingPreferenceUI",valueMapping:{hide:"h","allow-opt-out":"o","allow-opt-in":"i","allow-opt-in-or-out":"a"}},{name:"PURR_DataSaleOptOutUI_v2",valueMapping:{hide:"h",show:"s","show-opted-out":"o"}},{name:"PURR_CaliforniaNoticesUI",valueMapping:{hide:"h",show:"s"}},{name:"PURR_EmailMarketingOptInUI",valueMapping:{checked:"c",unchecked:"u"}},{name:"PURR_DeleteIPAddress",valueMapping:{delete:"d",keep:"k"}},{name:"PURR_AdConfiguration_v3",valueMapping:{full:"f",rdp:"r",npa:"n",ltd:"l","adluce-socrates":"s"}},{name:"PURR_LimitSensitivePI",valueMapping:{hide:"h",show:"s"}},{name:"PURR_EmailMarketingOptInUI_v2",valueMapping:{checked:"c",unchecked:"u","do-not-display":"d"}},{name:"PURR_AdConfiguration_v4",valueMapping:{full:"f",rdp:"r",npa:"n",ltd:"l","adluce-socrates":"s","no-ads":"a"}}],d={PURR_DataSaleOptOutUI:"hide",PURR_DataSaleOptOutUI_v2:"hide",PURR_CaliforniaNoticesUI:"hide",PURR_DataProcessingConsentUI:"hide",PURR_DataProcessingPreferenceUI:"hide",PURR_AcceptableTrackers_v2:"controllers",PURR_AcceptableTrackers:"controllers",PURR_AdConfiguration_v2:"full",PURR_AdConfiguration:"full",PURR_EmailMarketingOptInUI:"unchecked",PURR_DeleteIPAddress:"delete",PURR_AdConfiguration_v3:"full",PURR_LimitSensitivePI:"hide",PURR_EmailMarketingOptInUI_v2:"unchecked",PURR_AdConfiguration_v4:"full"};function u(){return"full"===e()}function l(e,t,n){var i=document.getElementsByTagName("head")[0],o=document.createElement("script");t&&(o.onload=t),n&&(o.onerror=n),o.src=e,o.async=!0,i.appendChild(o)}function c(){a().cmd.push(function(){var e="".concat("GeoEdge"," failed to load");a().events.publish({name:v,value:{message:e}})})}function p(){return!window.grumi&&(l("//rumcdn.geoedge.be/b3960cc6-bfd2-4adc-910c-6e917e8a6a0e/grumi-ip.js",null,c),window.grumi={key:"b3960cc6-bfd2-4adc-910c-6e917e8a6a0e",cfg:{advs:g}})}function m(){var e;window.apstag||(e="".concat(b," not loading properly"),console.warn(e))}function f(){a().cmd.push(function(){var e="".concat(b," failed to load");a().events.publish({name:y,value:{type:b,message:e}})})}function s(){var e=0<arguments.length&&void 0!==arguments[0]?arguments[0]:window;return e.googletag=e.googletag||{},e.googletag.cmd=e.googletag.cmd||[],e.googletag}function w(e){return!(!window.apstag||!window.apstag.fetchBids)&&(window.apstag.fetchBids({slots:e},void(window.apstag&&window.apstag.setDisplayBids&&s().cmd.push(window.apstag.setDisplayBids()))),!0)}var g={32074718:!0,4792640386:!0,21966278:!0,4558311760:!0,4552626466:!0,4400775978:!0,39318518:!0,4874174581:!0,33597638:!0,38636678:!0,38637278:!0,33597998:!0,33613118:!0,30252878:!0,33597758:!0},v="script_loader_error",b="A9",_=[[320,50],[300,250],[728,90],[970,90],[970,250]],h="large",R="medium",P="small",y="BidderError",U="AdEmpty",O="AdBlockOn",A="AdDefined",k="AdRefreshed";function I(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function x(t,e){var n,i=Object.keys(t);return Object.getOwnPropertySymbols&&(n=Object.getOwnPropertySymbols(t),e&&(n=n.filter(function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable})),i.push.apply(i,n)),i}function D(t){for(var e=1;e<arguments.length;e++){var n=null!=arguments[e]?arguments[e]:{};e%2?x(Object(n),!0).forEach(function(e){I(t,e,n[e])}):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(n)):x(Object(n)).forEach(function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(n,e))})}return t}function j(e){return Y[e]||Y.default}function C(e,t){var n;return(e=[].concat((n=t,[].concat(e).slice().sort(function(e,t){return t[0]-e[0]}).find(function(e){return!Number.isNaN(e[0])&&e[0]<n}))).pop())&&e.length?e:null}function S(o,a){return function(){var e=0<arguments.length&&void 0!==arguments[0]?arguments[0]:{},t=e.sizes,n=void 0===t?[]:t,t=e.truePosition,e=e.id;if(a&&j(o).map(function(e){return e.id}).includes(e))return!1;var i,n=C(n,window.innerWidth),n=(i=n,Array.isArray(i)?_.filter(function(t){return i.some(function(e){return e[0]===t[0]&&e[1]===t[1]})}):(console.warn("filterSizes() did not receive an array"),[]));if(0<n.length){n=[{slotID:t||e,slotName:"".concat(t||e,"_").concat(o,"_web"),sizes:n}];return w(n),!0}return!1}}function M(n,i){return j(i).map(function(e){var t=e.id,e=e.sizes;return{slotID:t,slotName:"".concat(t,"_").concat(i,"_web"),sizes:(e=e)[n]||e[P]}})}function z(t,n){a().cmd.push(function(){var e;t&&w(M(740<(e=window.innerWidth)?h:600<e?R:P,n)),a().events.subscribe({name:A,scope:"all",callback:S(n,t)})})}function T(e,t,n){(function(){var e,n=0<arguments.length&&void 0!==arguments[0]?arguments[0]:"apstag",i=1<arguments.length&&void 0!==arguments[1]?arguments[1]:window;return i[n]||(e=function(e,t){return i[n]._Q.push([e,t])},i[n]={_Q:[],init:function(){e("i",arguments)},fetchBids:function(){e("f",arguments)},setDisplayBids:function(){},targetingKeys:function(){return[]}}),i[n]})("apstag",window).init({pubID:"3030",deals:!0,adServer:"googletag",params:{si_section:t}}),z(e,n)}function E(e,n){var t;switch(Object.values(W).reduce(function(e,t){return n.includes(t)?t:e},n)){case K:t=e.top;break;case J:t=e.mid;break;case X:t=e.bottom;break;default:t=e.default}return t}function B(e){var t;switch(e){case"livebl":t="hp";break;case"coll":t="sf";break;default:t=e}return t in F||(t="default"),t}var N=(I(me={},h,[[728,90],[970,90],[970,250]]),I(me,R,[[728,90],[300,250]]),I(me,P,[[300,250]]),me),Y={art:[{id:"top",sizes:N},{id:"mobile_top",sizes:I({},P,[[320,50]])}],hp:[{id:"dfp-ad-top",sizes:N}],games:[{id:"ad-top",sizes:N},{id:"intsl",sizes:N}],default:[{id:"top",sizes:N}]},F={art:{id:["mobile_top","top","story-ad-1","story-ad-2","story-ad-3","story-ad-4","story-ad-5","story-ad-6","bottom"],pos:["mobile_top","top","mid1","mid2","mid3","mid4","mid5","mid6","bottom"]},int:{id:["top","mid1","mid2","bottom"],pos:["top","mid1","mid2","bottom"]},hp:{id:["dfp-ad-top","dfp-ad-mid1","dfp-ad-mid2","dfp-ad-mid3","dfp-ad-bottom"],pos:["top","mid1","mid2","mid3","bottom"]},ss:{id:["right-0","right-1","right-2","right-3"],pos:["mid1","mid1","mid1","mid1"],size:{small:[[300,250]],medium:[[300,250]],large:[[300,250]]}},sf:{id:["top","mid1","mid2"],pos:["top","mid1","mid2"],size:{small:[[300,250]],medium:[[300,250]],large:[[300,250]]}},games:{id:["ad-top","ad-mid1","ad-bottom"],pos:["top","mid1","bottom"]},default:{id:["top","mid1","mid2"],pos:["top","mid1","mid2"],size:{small:[[300,250]],medium:[[728,90]],large:[[728,90],[970,90],[970,250]]}}},V={top:2088370,mid:2088372,bottom:2088374,default:2088376},G={top:544112060,mid:544112063,bottom:544112062,default:544112065},L={top:684296214,mid:190706820,bottom:932254072,default:153468583},q={top:"NYTimes_728x90_970_top_PB",mid:"NYTimes_728x90_970_mid_PB",bottom:"NYTimes_728x90_970_bot_PB",default:"NYTimes_728x90_970_mid_PB"},H={top:"nytimes_top",mid:"nytimes_mid",bottom:"nytimes_bottom",default:"nytimes_catchall"},Q={top:"995821",mid:"995822",bottom:"995823",default:"995824"},W={TOP:"top",MID:"mid",BOTTOM:"bottom"},Z={buckets:[{max:3,increment:.05},{max:10,increment:.01},{max:20,increment:.1},{max:50,increment:.5},{max:101,increment:1}]},K=W.TOP,J=W.MID,X=W.BOTTOM;function $(o,e,t){var t=2<arguments.length&&void 0!==t?t:{},a=t.sizeConfig,r=t.activeBidders,t=t.positionsToFilter,d=void 0===t?[]:t,c=B(e),s=F[c].size?c:"default";return F[c].pos.reduce(function(e,t,n){if(d.includes(t))return e;var n=F[c].id[n],i=D(D({},F[s].size),null==a||null===(i=a[n])||void 0===i?void 0:i.size),t={code:n,mediaTypes:{banner:{sizeConfig:[{minViewPort:[970,0],sizes:i.large},{minViewPort:[728,0],sizes:i.medium},{minViewPort:[0,0],sizes:i.small}]}},bids:function(e,t){var n=2<arguments.length&&void 0!==arguments[2]?arguments[2]:[],e=[{bidder:"appnexus",params:{member:3661,invCode:"nyt_".concat(e,"_").concat(t)}},{bidder:"medianet",params:{cid:"8CU4WQK98",crid:E(L,t)}},{bidder:"rubicon",params:{accountId:12330,siteId:378266,inventory:{invCode:["nyt_".concat(e,"_").concat(t)]},zoneId:E(V,t),position:"top"===t?"atf":"btf"}},{bidder:"openx",params:{unit:E(G,t),delDomain:"nytimes-d.openx.net",customParams:{invCode:"nyt_".concat(e,"_").concat(t)}}},{bidder:"triplelift",params:{inventoryCode:E(q,t)}},{bidder:"pubmatic",params:{publisherId:"163427",adSlot:E(H,t)}},{bidder:"ix",params:{siteId:E(Q,t)}}],t=e.filter(function(e){return!["pubmatic","ix"].includes(e.bidder)});return n.length?e.filter(function(e){return n.includes(e.bidder)}):t}(o,t,r)};return e.push(t),e},[])}function ee(n){window.pbjs=window.pbjs||{},window.pbjs.initAdserverSet||(window.pbjs.initAdserverSet=!0,a().cmd.push(function(){a().events.subscribe({name:A,scope:"all",callback:function(t){s().cmd.push(function(){var e;(e=B(e=n),F[e].id).includes(t.id)&&window.pbjs.setTargetingForGPTAsync([t.id])})}})}))}function te(n,e,t,i){function o(e,t){window.pbjs.initAdserverSet=!1,n.requestBids({bidsBackHandler:function(){ee(e)},timeout:t})}a().cmd.push(function(){n.que.push(function(){n.addAdUnits($(e,t,i)),o(t,1e4),a().events.subscribe({name:k,scope:"all",callback:function(){o(t,800)}})})})}function ne(e,t){var n=2<arguments.length&&void 0!==arguments[2]?arguments[2]:{},i=function(){var e=0<arguments.length&&void 0!==arguments[0]?arguments[0]:window;return e.pbjs=e.pbjs||{},e.pbjs.que=e.pbjs.que||[],e.pbjs}(),o=n.priceGranularity;i.setConfig({priceGranularity:o||Z}),te(i,e,t,n)}function ie(){a().cmd.push(function(){var e="".concat("PreBid"," failed to load");a().events.publish({name:y,value:{type:"PreBid",message:e}})})}function oe(e,t,n){return!window.pbjs&&(l("https://www.nytimes.com/ads/prebid8.25.0.js",(i=e,o=t,a=n,function(){window.pbjs||console.log("prebid did not load"),ne(i,o,a)}),ie),!0);var i,o,a}function ae(){try{var e=((t=document.createElement("div")).innerHTML="&nbsp;",t.className="ad adsbox pub_300x250 pub_300x250m pub_728x90 text-ad textAd text_ad ad-server",t.style="width: 1px !important; height: 1px !important; position: absolute !important; left: -10000px !important; top: -1000px !important;",document.body.prepend(t),document.getElementsByClassName("ad adsbox")[0]),t=!(!(t=e)||0!==t.offsetHeight&&0!==t.clientHeight)||function(e){if(void 0!==window.getComputedStyle){e=window.getComputedStyle(e,null);if(e&&("none"===e.getPropertyValue("display")||"hidden"===e.getPropertyValue("visibility")))return!0}return!1}(e);return e=e,document.body.removeChild(e),t}catch(e){console.error("ad class check failed",e)}var t;return!1}function re(){return!(window&&window.AdSlot&&window.AdSlot.AdSlotReady)||(!(window&&window.googletag&&window.googletag.apiReady)||ae())}function de(){var e=window&&window.nyt_et&&window.nyt_et.get_host&&window.nyt_et.get_host();return e?fetch("".concat(e,"/.status"),{credentials:"include",headers:{accept:"*/*","content-type":"text/plain;charset=UTF-8"},mode:"no-cors"}).then(function(){return{success:!0}}).catch(function(e){return console.error("et track blocked",e),{success:!1}}):Promise.resolve({success:!1})}function ce(e,t,n){var i=(o="nyt-a",(document&&document.cookie&&document.cookie.match&&(o=document.cookie.match(new RegExp("".concat(o,"=([^;]+)"))))?o[1]:"")||null),o=!!(window&&window.matchMedia&&window.matchMedia("(max-width: 739px)").matches);return"".concat("https://a-reporting.nytimes.com/report.jpg","?mobile=").concat(o,"&block=").concat(n,"&aid=").concat(i,"&pvid=").concat(e,"&et=").concat(t)}function se(e,t,n){return!!(window&&window.NYTD&&window.NYTD.Abra&&"1_network_detection"===window.NYTD.Abra("DFP_blockDetect_0221"))&&((new Image).src=ce(e,t,n),!0)}function ue(e,t){t&&a().cmd.push(function(){var e=a();e.events&&e.events.publish({name:U,value:{type:O}})});var n=!1;return de().then(function(){n=(0<arguments.length&&void 0!==arguments[0]?arguments[0]:{success:!1}).success}).catch(function(){}).finally(function(){se(e,n,t)})}function le(e){var t;window.addEventListener("load",(t=e,function(){ue(t,re())}))}var pe,me=function(){var e=0<arguments.length&&void 0!==arguments[0]?arguments[0]:{};if(pe)return!1;var t=e.loadAmazon,n=void 0===t||t,i=e.loadPrebid,o=void 0===i||i,a=e.setFastFetch,r=void 0!==a&&a,d=e.loadGeoEdge,c=void 0===d||d,s=e.section,t=void 0===s?"none":s,i=e.pageViewId,a=void 0===i?"":i,d=e.pageType,s=void 0===d?"":d,i=e.prebidOverrides,d=void 0===i?{}:i;return e=document.referrer||"",!(i=/([a-zA-Z0-9_\-.]+)(@|%40)([a-zA-Z0-9_\-.]+).([a-zA-Z]{2,5})/).test(e)&&!i.test(window.location.href)&&(u()&&(s=new RegExp(/art/).test(s)?"art":s,c&&p(),n&&(c=r,n=t,r=s,window.apstag||(l("//c.amazon-adsystem.com/aax2/apstag.js",m,f),T(c,n,r))),o&&oe(t,s,d)),le(a),pe=!0)};return(N=a()).loadScripts=N.loadScripts||me,window.AdSlot4=N}();
            (function () { var _f=function(e={}){const i=window&&window.AdSlot4;function o(){const e=window.matchMedia("(max-width: 739px)");return e&&e.matches}try{const{adToggleMap:t,pageType:n,prebidOverrides:d,section:a,isSectionHbEligible:r,setFastFetch:s,headerBidding:c={}}=e,{useAmazon:w,usePrebid:l}=c,p=Object.keys(t).reduce((e,i)=>{const o=t[i]||"";return e[i]=function(e){return!!(window&&window.adClientUtils&&window.adClientUtils.hasActiveToggle)&&window.adClientUtils.hasActiveToggle(e)}(o),e},{}),{amazon:g,geoedge:u}=p,T=d&&d.positionsToFilter||[],b=o()?T.concat(["top"]):T,h=["appnexus","medianet","rubicon","openx","triplelift","ix","pubmatic"];"function"==typeof i.loadScripts&&i.loadScripts({loadAmazon:w&&g&&r,loadPrebid:l&&r,setFastFetch:s&&!o(),section:a,prebidOverrides:{...d,positionsToFilter:b,activeBidders:h},pageType:n,pageViewId:window&&window.NYTD&&window.NYTD.PageViewId&&window.NYTD.PageViewId.current?window.NYTD.PageViewId.current:"",loadGeoEdge:u})}catch(e){console.error(e)}};;_f.apply(null, [{"adToggleMap":{"amazon":"amazon_story_toggle","medianet":"medianet_story_toggle","dfp":"dfp_story_toggle","geoedge":"geoedge_toggle"},"pageType":"art","section":"opinion","isSectionHbEligible":true,"setFastFetch":true,"prebidOverrides":{"positionsToFilter":["mobile_top"]},"headerBidding":{"useAmazon":true,"usePrebid":true}}]); })();
            (function () { var _f=function(t={},e={}){window.AdSlot4=window.AdSlot4||{},window.AdSlot4.cmd=window.AdSlot4.cmd||[],window.AdSlot4.clientRequirements={mergeObjects:function(t,...e){return e.reduce(function(t,e){return Object.entries(e).reduce(function(t,[e,n]){return t[e]&&null==n?t:Object.assign({},t,{[e]:n})},t)},t)},isFunction:function(t){return"[object Function]"===Object.prototype.toString.call(t)},getAbraVariant:function(t){if(!(window.NYTD&&window.NYTD.Abra&&window.NYTD.Abra.getAbraSync&&this.isFunction(window.NYTD.Abra.getAbraSync)))return void console.warn("Abra does not exist or is not a function");const e=window.NYTD.Abra.getAbraSync(t);return e&&e.variant},shouldHaltDFP:function(t){return"1_block"===this.getAbraVariant(t)},isAdsDisabled:function(t={}){const{adTargeting:{section:e}={},adsDisabled:n,adUnitPath:i=""}=t,o=i&&i.toLowerCase&&i.toLowerCase().includes("tragedy");return n||"learning"===e||o},getSov:function(t={}){return t.sov=t.sov||(Math.floor(4*Math.random())+1).toString(),{sov:t.sov}},getPageViewId:function(t){return{page_view_id:t&&t.current}},getUserData:function(t="{}"){try{const e=JSON.parse(t).data;return e&&e.user}catch(t){console.warn("userinfo data unavailable")}},getEm:function(t){return t&&t.length?{em:t.toString().toLowerCase()}:{}},getWat:function(t){return t?{wat:t.toLowerCase()}:{}},getDemographics:function(t){return this.mergeObjects(this.getEm(t&&t.emailSubscriptions),this.getWat(t&&t.wat))},isValidDfpTest:function(t){return t.toLowerCase().indexOf("dfp")>-1},joinArgumentsForVariant:function(){if(arguments.length)return[].slice.call(arguments).join("_").toLowerCase()},reduceAbraConfigKeysToDfpVariants:function(t=[],e=""){const n=this.getAbraVariant(e),i=this.joinArgumentsForVariant(e,n);return n&&i?t.concat(i):t},reduceFastlyAbraToDfpVariants:function(t=[],[e,n]=[]){const i=this.isValidDfpTest(e)&&n&&this.joinArgumentsForVariant(e,n);return i?t.concat(i):t},getDFPTestNames:function(t={}){if(!t)return[];const e=this.isValidDfpTest;return Object.keys(t).filter(function(t){return e(t)})},getAbraDfpVariants:function(t={},e={}){let n=[],i=[];if(Object.keys(e).length&&(i=Object.entries(e).reduce(this.reduceFastlyAbraToDfpVariants,[])),t.config&&t.getAbraSync){n=this.getDFPTestNames(t.config).reduce(this.reduceAbraConfigKeysToDfpVariants,[])}return{abra_dfp:[...n,...i]}},isMobile:function(t){const e=t.matchMedia("(max-width: 739px)");return e&&e.matches},isManualRefresh:function(t={}){return!(!t.navigation||1!==t.navigation.type)},getAltLangFromPathname:function(t=""){return 0===t.indexOf("/es/")?"es":""},getAdTargetingProperty:function(t=!1,e=""){let n=t?"m":"";return{prop:(n+=e)+"nyt"}},getAdTargetingPlatform:function(t=!1){return{plat:(t?"m":"")+"web"}},getAdTargetingEdition:function(t=""){return t.length?{edn:t}:{}},getAdTargetingVersion:function(t=!1){return{ver:(t?"m":"")+"vi"}},getAdTargetingHome:function(t,e,n){let i={},o={};return"hp"===t&&(i=e?{topRef:e}:{},o=n?{refresh:"manual"}:{}),this.mergeObjects(i,o)},getAdTargeting:function(t={},n={}){const i=this.isMobile(window),o=this.getAltLangFromPathname(window.location.pathname),r=this.isManualRefresh(performance);return this.mergeObjects(t,this.getDemographics(n),this.getAdTargetingProperty(i,o),this.getAdTargetingPlatform(i),this.getAdTargetingEdition(o),this.getAdTargetingVersion(i),this.getAdTargetingHome(t.typ,document.referrer,r),this.getAbraDfpVariants(window.NYTD.Abra,e),this.getSov(window),this.getPageViewId(window.NYTD.PageViewId))},init:function(t){window.AdSlot4.init&&this.isFunction(window.AdSlot4.init)?window.AdSlot4.init&&window.AdSlot4.init(t):console.warn("AdSlot4.init does not exist or is not a function")},reportExposure:function(t){window.NYTD.Abra&&this.isFunction(window.NYTD.Abra.reportExposure)?window.NYTD.Abra.reportExposure(t):console.warn("Abra.reportExposure does not exist or is not a function")},generateConfig:function(t={},e={},n={}){const i=n&&n.userInfo&&n.userInfo.demographics;return this.mergeObjects(t,e,{adTargeting:this.getAdTargeting(e.adTargeting,i),haltDFP:this.shouldHaltDFP(e.dfpToggleName||t.dfpToggleName),adsDisabled:this.isAdsDisabled(e)})}};for(let t in window.AdSlot4.clientRequirements)window.AdSlot4.clientRequirements[t]=window.AdSlot4.clientRequirements[t].bind(window.AdSlot4.clientRequirements);const n={adUnitPath:"/29390238/nyt/thisIsNotAPath",offset:400,hideTopAd:AdSlot4.clientRequirements.isMobile(window),lockdownAds:!1,sizeMapping:{top:[[970,["fluid",[728,90],[970,90],[970,250],[1605,300]]],[728,["fluid",[728,90],[1605,300]]],[0,[]]],mobile_top:[[0,[320,50]]],fp1:[[0,[[195,250],[215,270]]]],fp2:[[0,[[195,250],[215,270]]]],fp3:[[0,[[195,250],[215,270]]]],feat1:[[0,["fluid"]]],feat2:[[0,["fluid"]]],feat3:[[0,["fluid"]]],feat4:[[0,["fluid"]]],mktg:[[1020,[300,250]],[0,[]]],pencil:[[728,[[336,46]],[0,[]]]],pp_edpick:[[0,["fluid"]]],pp_morein:[[0,["fluid"],[210,218]]],ribbon:[[0,["fluid"]]],sponsor:[[765,[150,50]],[0,[320,25]]],supplemental:[[1020,[[300,250],[300,600]]],[0,[]]],chat:[[0,[[300,250],[300,420]]]],column:[[0,[[300,250],[300,420]]]],ressint:[[600,["fluid"]],[0,[[300,250]]]],mobile_top:[[0,[[320,50]]]],default:[[970,["fluid",[728,90],[970,90],[970,250],[1605,300]]],[728,["fluid",[728,90],[300,250],[1605,300]]],[0,["fluid",[300,250],[300,420]]]]},adTargeting:{},haltDFP:!1,dfpToggleName:t.dfpToggleName,lazyApi:t.lazyApi||{},adsDisabled:!1};window.AdSlot4.cmd.push(function(){const e=window.AdSlot4.clientRequirements,i=e.getUserData(window&&window.userXhrObject&&window.userXhrObject.responseText),o=e.generateConfig(n,t,i);e.init(o),e.reportExposure("dfp_adslot4v2")})};;_f.apply(null, [{"adTargeting":{"edn":"us","test":"projectvi","ver":"vi","template":"article","hasVideo":"false","vp":"small","als_test":"1715055587648","prop":"mnyt","plat":"mweb","brandsensitive":"false","per":"amodeidario","org":"anthropicaillc,openailabs","des":"audioneutralinformative,computersandtheinternet","auth":"theezrakleinshow","col":"theezrakleinshow","coll":"theezrakleinshow,opinion,opinioncolumnists,theezrakleinshow,science","artlen":"short","ledemedsz":"none","typ":"art","section":"opinion","si_section":"opinion","id":"100000009406898","pt":"nt1,nt10,nt11,nt12,nt15,nt21,nt6,nt7,nt9,pt13,pt18,pt2,pt3","gscat":"gv_safe,neg_gg1,neg_google,neg_ibmtest,gb_safe,gb_safe_from_high,gb_safe_from_high_med,gs_tech,neg_kaypemg,neg_rchmt,neg_citi_aa,neg_ibm,neg_google_comps,neg_chan3,neg_ihw,neg_racism,acc_cc,neg_mastercard,cc_tech_society,gs_tech_ai,neg_capitalone,ggl_wrk_collab,cc_tech_data,gs_busfin_business,gs_busfin,neg_rms,gs_tech_compute,cc_business_lead_boards,neg_chanel,gs_tech_computing,gs_busfin_business_large,neg_gg2,neg_chan2,neg_debeer,neg_hms,neg_mtb,gs_entertain,gs_t","tt":"22,93","mt":"MT10,MT7"},"adUnitPath":"/29390238/nyt/opinion","dfpToggleName":"dfp_story_toggle","adsDisabled":false},{".ver":"18076.000","AMS_FrictionCircumventionDesktop_cwv":"2_low-mid-truncation","AMS_FrictionCircumventionMobile_cwv":"2_low-mid-truncation","DFP_TopAd_Anon_0124":"","HOME_cwv_chartbeat":"0_Control","MX_NewArchitecture_PostLoginOffer":"1_variant","MX_NewArchitecture_WirecutterLP":"","STYLN_synth_voice_web":"0_control"}]); })();
          })();
        </script>

    
    
  </head>
  <body>
    <div id="app"><div><div class="vi-gateway-container" data-testid="vi-gateway-container"><div><div data-testid="masthead-container" class="NYTAppHideMasthead css-1q2w90k e1m0pzr40"><header class="css-1bymuyk e1m0pzr41"><section class="css-ui9rw0 e1m0pzr42"><div class="css-1f7ibof ea180rp0"><a class="css-kgn7zc" href="#site-content">Skip to content</a><a class="css-kgn7zc" href="#site-index">Skip to site index</a></div><div class="css-10698na ell52qj0"><a data-testid="masthead-mobile-logo" aria-label="New York Times homepage" class="css-nhjhh0 ell52qj1" href="/"><svg viewBox="0 0 184 25" fill="#000" aria-hidden="true"><path d="M14.57,2.57C14.57,.55,12.65-.06,11.04,.01V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.36,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.88-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08C3.31,5.73,.5,8.56,.5,12.06c0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.08c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96M5.8,14.13l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.08-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm19.47-5.76l-.81,.64-2.47-2.2-2.86,2.21V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15-.79,.52-1.08-1.08v-7.12l.74-.54,1.7,1.48v6.19c0,3.92-.87,4.73-2.63,5.37v.1c2.93,.12,5.57-.87,5.57-5.89v-6.75l.88-.72-.12-.15h0Zm5.22,10.8l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h-.01Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6ZM53.65,1.61c0-.32-.08-.59-.2-.96h-.07c-.32,.87-.67,1.33-1.68,1.33-.88,0-1.58-.54-1.95-.94,0,.03-2.96,3.42-2.96,3.42l.15,.12,.84-.96c.64,.49,1.21,1.06,2.63,1.08V13.34l-6.06-10.5c-.47-.79-1.28-1.97-2.66-1.97-1.63,0-2.86,1.4-2.66,3.77h.1c.12-.59,.47-1.33,1.18-1.33,.57,0,1.03,.54,1.3,1.03v3.38c-1.87,0-2.93,.87-2.93,2.34,0,.61,.45,1.94,1.72,2.17v-.07c-.17-.17-.34-.32-.34-.67,0-.57,.42-.88,1.18-.88,.12,0,.3,.03,.37,.05v4.38c-2.2,.03-3.89,1.23-3.89,3.31s1.7,2.88,3.47,2.78v-.07c-1.11-.12-1.68-.69-1.68-1.5,0-.88,.64-1.36,1.45-1.36s1.43,.52,1.95,1.11l2.96-3.33-.12-.12-.76,.87c-1.14-1.01-1.87-1.48-3.18-1.68V4.67l8.36,14.57h.45V4.72c1.6-.1,3.03-1.3,3.03-3.11m2.81,17.54l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h0Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6Zm21.22-5.52l-.69,.52-1.97-1.68-2.29,2.07,.94,.88v7.72l-2.34-1.6v-6.26l.81-.57-2.41-2.24-2.24,2.07,.94,.88v7.46l-.15,.1-2.2-1.6v-6.13c0-1.43-.72-1.85-1.63-2.41-.76-.47-1.16-.91-1.16-1.63,0-.79,.69-1.11,.91-1.23-.79-.03-2.98,.76-3.03,2.76-.03,1.03,.47,1.48,.99,1.97,.52,.49,1.01,.96,1.01,1.83v6.01l-1.06,.84,.12,.12,1.01-.79,2.63,2.14,2.51-1.75,2.76,1.75,5.42-3.2v-6.95l1.21-.94-.1-.15h0Zm18.15-5.84l-1.03,.94-2.32-2.02-3.13,2.51V1.19h-.19V18.12c-.34-.05-1.06-.25-1.85-.37V3.58c0-1.03-.74-2.47-2.59-2.47s-3.01,1.56-3.01,2.91h.08c.1-.61,.52-1.16,1.13-1.16s1.18,.39,1.18,1.78v4.04c-1.75,.07-2.81,1.16-2.81,2.34,0,.67,.42,1.92,1.75,1.97v-.1c-.45-.19-.54-.42-.54-.67,0-.59,.57-.79,1.36-.79h.19v6.51c-1.5,.52-2.2,1.53-2.2,2.78,0,1.72,1.38,3.05,3.4,3.05,1.43,0,2.44-.25,3.75-.54,1.06-.22,2.21-.47,2.83-.47,.79,0,1.14,.35,1.14,.91,0,.72-.27,1.08-.69,1.21v.1c1.7-.32,2.69-1.3,2.69-2.83s-1.5-2.54-3.18-2.54c-.87,0-2.44,.27-3.72,.57-1.43,.32-2.66,.47-3.11,.47-.72,0-1.6-.32-1.6-1.28,0-.87,.72-1.56,2.49-1.56,.96,0,1.9,.15,3.08,.42,1.26,.27,2.12,.64,3.2,.64,1.5,0,2.71-.54,2.71-2.74V3.29l1.11-1.01-.12-.15h0Zm-4.24,6.78c-.27,.3-.59,.54-1.11,.54-.57,0-.87-.3-1.14-.54V3.81l.74-.59,1.5,1.28v4.41h0Zm0,2.41c-.25-.25-.57-.47-1.11-.47s-.91,.27-1.14,.47v-2.17c.22,.19,.59,.49,1.14,.49s.87-.25,1.11-.49v2.17Zm0,5.1c0,.84-.42,1.78-1.5,1.78-.17,0-.57-.03-.74-.05v-6.58c.25-.22,.57-.52,1.14-.52,.52,0,.81,.25,1.11,.52v4.86h0Zm8.78,2.74l5.03-3.13v-6.85l-3.25-2.39-5.03,2.88v6.78l-.99,.79,.1,.15,.81-.67,3.33,2.44h0Zm-.37-3.55v-7.3l2.51,1.87v7.3l-2.51-1.87Zm15.01-8.65c-.39,.27-.74,.42-1.11,.42-.39,0-.88-.25-1.14-.57,0,.03-1.87,2.02-1.87,2.02l-1.87-2.02-3.05,2.12,.1,.17,.81-.54,1.11,1.21v6.63l-1.33,1.01,.12,.12,.67-.46,2.49,2.12,3.15-2.09-.1-.15-.81,.49-1.28-1.16v-7.28c.52,.57,1.11,1.06,1.82,1.06,1.28,0,2.14-1.53,2.29-3.11m11.88,9.81l-.94,.59-5.2-7.76,.27-.37c.57,.34,1.08,.81,2.17,.81s2.47-1.14,2.59-3.23c-.27,.37-.81,.81-1.7,.81-.64,0-1.28-.42-1.67-.81l-3.55,5.22,4.71,7.17,3.42-2.27-.1-.17h0Zm-6.31,.19l-.79,.52-1.08-1.08V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm22.89-14.39c0-2.02-1.92-2.63-3.53-2.56V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.35,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.89-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08c-3.08,.84-5.89,3.67-5.89,7.17,0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.07c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96m-8.78,11.56l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.07-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm11.93-12.31l-2.17,1.82,1.85,2.09,2.17-1.82-1.85-2.09Zm3.3,15.15l-.79,.52-1.08-1.08v-7.17l.91-.72-.12-.15-.76,.59-1.8-2.14-2.96,2.07,.1,.17,.74-.49,.99,1.23v6.61l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm16.63-.1l-.74,.49-1.16-1.11v-7.03l.94-.72-.12-.15-.84,.64-2.47-2.2-2.78,2.17-2.44-2.17-2.74,2.14-1.85-2.14-2.96,2.07,.1,.17,.74-.49,1.06,1.21v6.61l-.81,.81,2.36,2,2.29-2.07-.94-.88v-7.04l.61-.45,1.7,1.48v6.16l-.79,.81,2.39,2,2.24-2.07-.94-.88v-7.04l.59-.47,1.72,1.5v6.06l-.69,.72,2.41,2.2,3.18-2.17-.1-.15h.02Zm8.6-1.5l-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.93l3.57,2.59,4.51-3.62-.12-.17h0Zm-5.08-1.88v-5.15l2.27,3.55-2.27,1.6Zm14.12-.97l-2-1.53c1.33-1.16,1.8-2.63,1.8-3.69,0-.15-.03-.42-.05-.67h-.08c-.19,.54-.72,1.01-1.53,1.01s-1.26-.45-1.75-.99l-4.58,2.54v3.72l1.75,1.38c-1.75,1.55-2.09,2.51-2.09,3.4s.52,1.67,1.41,2.02l.07-.12c-.22-.19-.42-.32-.42-.79,0-.34,.35-.88,1.14-.88,1.01,0,1.63,.69,1.95,1.06,0-.03,4.38-2.69,4.38-2.69v-3.77h0Zm-1.03-3.05c-.69,1.23-2.21,2.44-3.11,3.13l-1.11-.94v-3.62c.45,.99,1.36,1.82,2.54,1.82,.69,0,1.14-.12,1.67-.39m-1.9,8.13c-.52-1.16-1.63-2-2.86-2-.3,0-1.21-.03-2,.46,.47-.79,1.87-2.21,3.65-3.28l1.21,1.01v3.8Z"></path></svg></a></div><div class="css-1awy3rz e1j3jvdr1"></div></section><section id="masthead-bar-one" class="hasLinks css-c5j6tx e1pjtsj62"><div><div class="css-vfkorq e1pjtsj60"><span> </span></div><div class="css-1bvtpon e1pjtsj61"><a href="https://www.nytimes.com/section/todayspaper" class="css-1pd1msn">Today’s Paper</a></div></div><div class="css-pzrpby"></div></section></header></div></div><div><main id="site-content"><div><div class="css-iro8fb" style="opacity:0.000000001;z-index:-1;visibility:hidden" id="in-story-masthead"><div class="css-1hqnpie"><div class="css-13ctjxq"><span class="css-1u4hfeb"><a href="/section/opinion">Opinion</a></span><span class="css-x15j1o">|</span><span class="css-rnl02l">What if Dario Amodei Is Right About A.I.?</span></div><div class="css-k008qs"><div class="css-b4nnp0"><a href="/" class="css-93zicp" aria-label="New York Times homepage"><svg viewBox="0 0 16 22"><path d="M15.863 13.08c-.687 1.818-1.923 3.147-3.64 3.916v-3.917l2.129-1.958-2.129-1.889V6.505c1.923-.14 3.228-1.609 3.228-3.358C15.45.84 13.32 0 12.086 0c-.275 0-.55 0-.962.14v.14h.481c.824 0 1.51.42 1.51 1.189 0 .63-.48 1.189-1.304 1.189-2.129 0-4.6-1.749-7.279-1.749C2.13.91.481 2.728.481 4.546c0 1.819 1.03 2.448 2.128 2.798v-.14c-.343-.21-.618-.63-.618-1.189 0-.84.756-1.469 1.648-1.469 2.267 0 5.906 1.959 8.172 1.959h.206v2.727l-2.129 1.889 2.13 1.958v3.987c-.894.35-1.786.49-2.748.49-3.502 0-5.768-2.169-5.768-5.806 0-.839.137-1.678.344-2.518l1.785-.769v7.973l3.57-1.608V6.575L3.984 8.953c.55-1.61 1.648-2.728 2.953-3.358v-.07C3.433 6.295 0 9.023 0 13.08c0 4.686 3.914 7.974 8.446 7.974 4.807 0 7.485-3.288 7.554-7.974h-.137z" fill="#000"></path></svg></a><span class="css-18z7m18"><a href="/" data-testid="masthead-logo" aria-label="New York Times homepage"><svg class="css-12fr9lp" viewBox="0 0 184 25" fill="#000" aria-hidden="true"><path d="M14.57,2.57C14.57,.55,12.65-.06,11.04,.01V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.36,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.88-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08C3.31,5.73,.5,8.56,.5,12.06c0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.08c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96M5.8,14.13l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.08-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm19.47-5.76l-.81,.64-2.47-2.2-2.86,2.21V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15-.79,.52-1.08-1.08v-7.12l.74-.54,1.7,1.48v6.19c0,3.92-.87,4.73-2.63,5.37v.1c2.93,.12,5.57-.87,5.57-5.89v-6.75l.88-.72-.12-.15h0Zm5.22,10.8l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h-.01Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6ZM53.65,1.61c0-.32-.08-.59-.2-.96h-.07c-.32,.87-.67,1.33-1.68,1.33-.88,0-1.58-.54-1.95-.94,0,.03-2.96,3.42-2.96,3.42l.15,.12,.84-.96c.64,.49,1.21,1.06,2.63,1.08V13.34l-6.06-10.5c-.47-.79-1.28-1.97-2.66-1.97-1.63,0-2.86,1.4-2.66,3.77h.1c.12-.59,.47-1.33,1.18-1.33,.57,0,1.03,.54,1.3,1.03v3.38c-1.87,0-2.93,.87-2.93,2.34,0,.61,.45,1.94,1.72,2.17v-.07c-.17-.17-.34-.32-.34-.67,0-.57,.42-.88,1.18-.88,.12,0,.3,.03,.37,.05v4.38c-2.2,.03-3.89,1.23-3.89,3.31s1.7,2.88,3.47,2.78v-.07c-1.11-.12-1.68-.69-1.68-1.5,0-.88,.64-1.36,1.45-1.36s1.43,.52,1.95,1.11l2.96-3.33-.12-.12-.76,.87c-1.14-1.01-1.87-1.48-3.18-1.68V4.67l8.36,14.57h.45V4.72c1.6-.1,3.03-1.3,3.03-3.11m2.81,17.54l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h0Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6Zm21.22-5.52l-.69,.52-1.97-1.68-2.29,2.07,.94,.88v7.72l-2.34-1.6v-6.26l.81-.57-2.41-2.24-2.24,2.07,.94,.88v7.46l-.15,.1-2.2-1.6v-6.13c0-1.43-.72-1.85-1.63-2.41-.76-.47-1.16-.91-1.16-1.63,0-.79,.69-1.11,.91-1.23-.79-.03-2.98,.76-3.03,2.76-.03,1.03,.47,1.48,.99,1.97,.52,.49,1.01,.96,1.01,1.83v6.01l-1.06,.84,.12,.12,1.01-.79,2.63,2.14,2.51-1.75,2.76,1.75,5.42-3.2v-6.95l1.21-.94-.1-.15h0Zm18.15-5.84l-1.03,.94-2.32-2.02-3.13,2.51V1.19h-.19V18.12c-.34-.05-1.06-.25-1.85-.37V3.58c0-1.03-.74-2.47-2.59-2.47s-3.01,1.56-3.01,2.91h.08c.1-.61,.52-1.16,1.13-1.16s1.18,.39,1.18,1.78v4.04c-1.75,.07-2.81,1.16-2.81,2.34,0,.67,.42,1.92,1.75,1.97v-.1c-.45-.19-.54-.42-.54-.67,0-.59,.57-.79,1.36-.79h.19v6.51c-1.5,.52-2.2,1.53-2.2,2.78,0,1.72,1.38,3.05,3.4,3.05,1.43,0,2.44-.25,3.75-.54,1.06-.22,2.21-.47,2.83-.47,.79,0,1.14,.35,1.14,.91,0,.72-.27,1.08-.69,1.21v.1c1.7-.32,2.69-1.3,2.69-2.83s-1.5-2.54-3.18-2.54c-.87,0-2.44,.27-3.72,.57-1.43,.32-2.66,.47-3.11,.47-.72,0-1.6-.32-1.6-1.28,0-.87,.72-1.56,2.49-1.56,.96,0,1.9,.15,3.08,.42,1.26,.27,2.12,.64,3.2,.64,1.5,0,2.71-.54,2.71-2.74V3.29l1.11-1.01-.12-.15h0Zm-4.24,6.78c-.27,.3-.59,.54-1.11,.54-.57,0-.87-.3-1.14-.54V3.81l.74-.59,1.5,1.28v4.41h0Zm0,2.41c-.25-.25-.57-.47-1.11-.47s-.91,.27-1.14,.47v-2.17c.22,.19,.59,.49,1.14,.49s.87-.25,1.11-.49v2.17Zm0,5.1c0,.84-.42,1.78-1.5,1.78-.17,0-.57-.03-.74-.05v-6.58c.25-.22,.57-.52,1.14-.52,.52,0,.81,.25,1.11,.52v4.86h0Zm8.78,2.74l5.03-3.13v-6.85l-3.25-2.39-5.03,2.88v6.78l-.99,.79,.1,.15,.81-.67,3.33,2.44h0Zm-.37-3.55v-7.3l2.51,1.87v7.3l-2.51-1.87Zm15.01-8.65c-.39,.27-.74,.42-1.11,.42-.39,0-.88-.25-1.14-.57,0,.03-1.87,2.02-1.87,2.02l-1.87-2.02-3.05,2.12,.1,.17,.81-.54,1.11,1.21v6.63l-1.33,1.01,.12,.12,.67-.46,2.49,2.12,3.15-2.09-.1-.15-.81,.49-1.28-1.16v-7.28c.52,.57,1.11,1.06,1.82,1.06,1.28,0,2.14-1.53,2.29-3.11m11.88,9.81l-.94,.59-5.2-7.76,.27-.37c.57,.34,1.08,.81,2.17,.81s2.47-1.14,2.59-3.23c-.27,.37-.81,.81-1.7,.81-.64,0-1.28-.42-1.67-.81l-3.55,5.22,4.71,7.17,3.42-2.27-.1-.17h0Zm-6.31,.19l-.79,.52-1.08-1.08V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm22.89-14.39c0-2.02-1.92-2.63-3.53-2.56V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.35,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.89-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08c-3.08,.84-5.89,3.67-5.89,7.17,0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.07c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96m-8.78,11.56l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.07-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm11.93-12.31l-2.17,1.82,1.85,2.09,2.17-1.82-1.85-2.09Zm3.3,15.15l-.79,.52-1.08-1.08v-7.17l.91-.72-.12-.15-.76,.59-1.8-2.14-2.96,2.07,.1,.17,.74-.49,.99,1.23v6.61l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm16.63-.1l-.74,.49-1.16-1.11v-7.03l.94-.72-.12-.15-.84,.64-2.47-2.2-2.78,2.17-2.44-2.17-2.74,2.14-1.85-2.14-2.96,2.07,.1,.17,.74-.49,1.06,1.21v6.61l-.81,.81,2.36,2,2.29-2.07-.94-.88v-7.04l.61-.45,1.7,1.48v6.16l-.79,.81,2.39,2,2.24-2.07-.94-.88v-7.04l.59-.47,1.72,1.5v6.06l-.69,.72,2.41,2.2,3.18-2.17-.1-.15h.02Zm8.6-1.5l-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.93l3.57,2.59,4.51-3.62-.12-.17h0Zm-5.08-1.88v-5.15l2.27,3.55-2.27,1.6Zm14.12-.97l-2-1.53c1.33-1.16,1.8-2.63,1.8-3.69,0-.15-.03-.42-.05-.67h-.08c-.19,.54-.72,1.01-1.53,1.01s-1.26-.45-1.75-.99l-4.58,2.54v3.72l1.75,1.38c-1.75,1.55-2.09,2.51-2.09,3.4s.52,1.67,1.41,2.02l.07-.12c-.22-.19-.42-.32-.42-.79,0-.34,.35-.88,1.14-.88,1.01,0,1.63,.69,1.95,1.06,0-.03,4.38-2.69,4.38-2.69v-3.77h0Zm-1.03-3.05c-.69,1.23-2.21,2.44-3.11,3.13l-1.11-.94v-3.62c.45,.99,1.36,1.82,2.54,1.82,.69,0,1.14-.12,1.67-.39m-1.9,8.13c-.52-1.16-1.63-2-2.86-2-.3,0-1.21-.03-2,.46,.47-.79,1.87-2.21,3.65-3.28l1.21,1.01v3.8Z"></path></svg></a></span></div><span class="css-1n6z4y">https://www.nytimes.com/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html</span><div class="css-tvohiw"><div role="toolbar" data-testid="share-tools" aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" class="css-mfml7"><div class="css-4skfbu"><ul><li class="css-1gh9hw8"><div class="css-vxcmzt"><div class="css-79elbk"><button type="button" aria-label="" aria-expanded="false" class="css-1eeh360 actionbar-button" data-testid="gift-article-button"><span class="css-lu72is"><svg aria-hidden="true" width="19" height="19" viewBox="0 0 19 19" class="sha-gift-icon"><path d="M18.04 5.293h-2.725c.286-.34.493-.74.606-1.17a2.875 2.875 0 0 0-.333-2.322A2.906 2.906 0 0 0 13.64.48a3.31 3.31 0 0 0-2.372.464 3.775 3.775 0 0 0-1.534 2.483l-.141.797-.142-.847A3.745 3.745 0 0 0 7.927.923 3.31 3.31 0 0 0 5.555.459 2.907 2.907 0 0 0 3.607 1.78a2.877 2.877 0 0 0-.333 2.321c.117.429.324.828.606 1.171H1.155a.767.767 0 0 0-.757.757v3.674a.767.767 0 0 0 .757.757h.424v7.53A1.01 1.01 0 0 0 2.588 19h14.13a1.01 1.01 0 0 0 1.01-.959v-7.56h.424a.758.758 0 0 0 .757-.757V6.05a.759.759 0 0 0-.868-.757Zm-7.196-1.625a2.665 2.665 0 0 1 1.01-1.736 2.24 2.24 0 0 1 1.574-.313 1.817 1.817 0 0 1 1.211.818 1.857 1.857 0 0 1 .202 1.453 2.2 2.2 0 0 1-.838 1.191h-3.431l.272-1.413ZM4.576 2.386a1.837 1.837 0 0 1 1.221-.817 2.23 2.23 0 0 1 1.565.313 2.624 2.624 0 0 1 1.01 1.736l.242 1.453H5.182a2.2 2.2 0 0 1-.838-1.19 1.857 1.857 0 0 1 .202-1.495h.03ZM1.548 6.424h7.54V9.39h-7.58l.04-2.967Zm1.181 4.128h6.359v7.287H2.729v-7.287Zm13.777 7.287h-6.348v-7.307h6.348v7.307Zm1.181-8.468h-7.53V6.404h7.53V9.37Z" fill="#121212" fill-rule="nonzero"></path></svg><svg aria-hidden="true" width="23" height="18" viewBox="0 0 23 18" class="sha-arrow-icon"><path d="M1.357 17.192a.663.663 0 0 1-.642-.81c1.82-7.955 6.197-12.068 12.331-11.68V1.127a.779.779 0 0 1 .42-.653.726.726 0 0 1 .78.106l8.195 6.986a.81.81 0 0 1 .253.557.82.82 0 0 1-.263.547l-8.196 6.955a.83.83 0 0 1-.779.105.747.747 0 0 1-.42-.663V11.29c-8.418-.905-10.974 5.177-11.08 5.45a.662.662 0 0 1-.6.453Zm10.048-7.26a16.37 16.37 0 0 1 2.314.158.81.81 0 0 1 .642.726v3.02l6.702-5.682-6.702-5.692v2.883a.767.767 0 0 1-.242.536.747.747 0 0 1-.547.18c-4.808-.537-8.364 1.85-10.448 6.922a11.679 11.679 0 0 1 8.28-3.093v.042Z" fill="#000" fill-rule="nonzero"></path></svg>Share full article</span></button></div></div></li><li class="css-2ykviq sha-std-share"><div class="css-vxcmzt"><div class="css-79elbk"><button type="button" aria-label="More sharing options ..." aria-expanded="false" class="css-1nurhyi actionbar-button"><svg aria-hidden="true" width="23" height="18" viewBox="0 0 23 18" class="css-zd9juy"><path d="M1.357 17.192a.663.663 0 0 1-.642-.81c1.82-7.955 6.197-12.068 12.331-11.68V1.127a.779.779 0 0 1 .42-.653.726.726 0 0 1 .78.106l8.195 6.986a.81.81 0 0 1 .253.557.82.82 0 0 1-.263.547l-8.196 6.955a.83.83 0 0 1-.779.105.747.747 0 0 1-.42-.663V11.29c-8.418-.905-10.974 5.177-11.08 5.45a.662.662 0 0 1-.6.453Zm10.048-7.26a16.37 16.37 0 0 1 2.314.158.81.81 0 0 1 .642.726v3.02l6.702-5.682-6.702-5.692v2.883a.767.767 0 0 1-.242.536.747.747 0 0 1-.547.18c-4.808-.537-8.364 1.85-10.448 6.922a11.679 11.679 0 0 1 8.28-3.093v.042Z" fill="#000" fill-rule="nonzero"></path></svg></button></div></div></li><li class="css-2ykviq save-button"><button type="button" role="switch" class="css-1yhvmgx actionbar-button" data-testid="save-article-button" aria-label="Save article for reading later..." aria-checked="false" disabled="" aria-busy="false" aria-live="polite"><svg width="12" height="18" viewBox="0 0 12 18" class="css-eap6fy"><g fill-rule="nonzero"><path class="saved-fill" d="M1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268z"></path><path class="saved-stroke" d="m12 18-5.9-4.756L0 17.98V1.014C0 .745.095.487.265.297.435.107.664 0 .904 0h10.192c.24 0 .47.107.64.297.169.19.264.448.264.717V18ZM1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268H1.158Z"></path></g></svg></button></li><li class="css-2ykviq commentAdjustClass"><span class="css-1nii3md actionbar-button"><div class="css-1mlnk6q" style="padding:8px 10px 7px;font-weight:normal"><svg aria-hidden="true" width="21" height="18" viewBox="0 0 21 18" class="css-2urdiw"><path d="m14.52 17.831-5.715-4.545H2.4a1.468 1.468 0 0 1-1.468-1.469V1.894A1.471 1.471 0 0 1 2.4.405h16.583a1.469 1.469 0 0 1 1.469 1.469v9.923a1.469 1.469 0 0 1-1.47 1.47H14.58l-.06 4.564ZM2.4 1.645a.228.228 0 0 0-.228.229v9.923a.228.228 0 0 0 .228.229h6.811l4.06 3.235v-3.235h5.652a.228.228 0 0 0 .229-.229V1.874a.228.228 0 0 0-.229-.229H2.4Z" fill="#121212" fill-rule="nonzero"></path></svg><span class="css-1re6eyk"><a href="/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html">27</a></span></div></span></li></ul></div></div></div></div></div></div><article id="story" class="css-1vxca1d e1lmdhsb0"><div class="css-1lnfix7"></div><div id="top-wrapper" class="css-1aeqhal"><div id="top-slug" class="css-l9onyx"><p>Advertisement</p></div><a href="#after-top" class="css-777zgl">SKIP ADVERTISEMENT</a><div class="ad top-wrapper css-rfqw0c"><div id="top" class="place-ad" data-position="top" data-size-key="top" data-lazy-load="true"></div></div><div id="after-top"></div></div><div class="css-1g7y0i5 e1drnplw0"><button tabindex="100" class="css-1rtlxy" type="button" aria-label="close"><svg width="60" height="60" viewBox="0 0 60 60" fill="none"><circle cx="30" cy="30" r="30" fill="white" fill-opacity="0.9"></circle><path fill-rule="evenodd" clip-rule="evenodd" d="M38.4844 20.1006L39.8986 21.5148L21.5138 39.8996L20.0996 38.4854L38.4844 20.1006Z" fill="black"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M21.5156 20.1006L20.1014 21.5148L38.4862 39.8996L39.9004 38.4854L21.5156 20.1006Z" fill="black"></path></svg></button><div class="css-rdbib0 e1drnplw1"></div><div class="css-18ow4sz e1drnplw2"><div aria-labelledby="modal-title" role="region"><header class="css-1bzlfz"><div class="css-mln36k" id="modal-title">transcript</div><button type="button" class="css-1igvuto"><div class="css-f40pzg"></div><span>Back to The Ezra Klein Show</span></button><div class="css-f6lhej" data-testid="transcript-playback-controls"><div class="css-1ialerq"><button tabindex="99" type="button" class="css-1eut9gw" aria-label="play"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 20" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 13.7683V6L14.5 9.88415L8 13.7683Z" fill="var(--color-content-secondary,#363636)"></path><circle cx="10" cy="10" r="9.25" stroke="var(--color-stroke-primary,#121212)" stroke-width="1.5"></circle></svg></button><div class="css-1701swk"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 36" id="el_0kpS9qL_S"><title>bars</title><g id="el_oZ84Hna1GC_65hRV2Qwn" class="css-1fxvzwo" data-animator-group="true" data-animator-type="0"><g id="el_oZ84Hna1GC_ILVvi2tqx" class="css-1wnday1" ata-animator-group="true" data-animator-type="2"><g id="el_oZ84Hna1GC"><rect x="34" width="6" height="36" id="el_qw_T_tngXw"></rect></g></g></g><g id="el_mYVjkduhMU_p_9Pm85Ac" class="css-fwki7z" data-animator-group="true" data-animator-type="0"><g id="el_mYVjkduhMU_WxG3R40yd" class="css-t3i5e6" data-animator-group="true" data-animator-type="2"><g id="el_mYVjkduhMU"><rect x="22.67" width="6" height="36" id="el_lf9GrROk6j"></rect></g></g></g><g id="el_o-EuxhgoAw_kYNRGDfcw" class="css-t9te0w" data-animator-group="true" data-animator-type="0"><g id="el_o-EuxhgoAw_3c3bzSjOJ" class="css-1r5375t" ata-animator-group="true" data-animator-type="2"><g id="el_o-EuxhgoAw"><rect x="11.33" width="6" height="36" id="el_-iueO8klO0"></rect></g></g></g><g id="el_F7mSMPhqpC_y_fKcpSxn" class="css-qknaag" data-animator-group="true" data-animator-type="0"><g id="el_F7mSMPhqpC_R6bNB6_Ys" class="css-1ruvd04" ata-animator-group="true" data-animator-type="2"><g id="el_F7mSMPhqpC"><rect width="6" height="36" id="el_dS5TKNZZ5w"></rect></g></g></g></svg></div><div><div class="css-1t7yl1y">0:00<!-- -->/<!-- -->1:33:07</div><div class="css-og85jy">-<!-- -->1:33:07</div></div></div></div></header><div class="css-uzyn7p"><div class="css-1vxywau"><p class="css-1nng8z9">transcript</p><h2 class="css-9wqu2x">What if Dario Amodei Is Right About A.I.?</h2><h4 class="css-qsd3hm">Anthropic’s co-founder and C.E.O. explains why he thinks artificial intelligence is on an “exponential curve.”</h4><time dateTime="2024-04-12T09:03:56.000Z" class="css-1e6es05">2024-04-12T05:03:56-04:00</time></div><dl class="css-p98d0w"><dt class="css-xx7kwh"></dt><dd class="css-4gvq6l"><p class="css-8hvvyd">[MUSIC PLAYING]</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">From New York Times Opinion, this is “The Ezra Klein Show.”</p><p class="css-8hvvyd">[MUSIC PLAYING]</p><p class="css-8hvvyd">The really disorienting thing about talking to the people building A.I. is their altered sense of time. You’re sitting there discussing some world that feels like weird sci-fi to even talk about, and then you ask, well, when do you think this is going to happen? And they say, I don’t know — two years.</p><p class="css-8hvvyd">Behind those predictions are what are called the scaling laws. And the scaling laws — and I want to say this so clearly — they’re not laws. They’re observations. They’re predictions. They’re based off of a few years, not a few hundred years or 1,000 years of data.</p><p class="css-8hvvyd">But what they say is that the more computer power and data you feed into A.I. systems, the more powerful those systems get — that the relationship is predictable, and more, that the relationship is exponential.</p><p class="css-8hvvyd">Human beings have trouble thinking in exponentials. Think back to Covid, when we all had to do it. If you have one case of coronavirus and cases double every three days, then after 30 days, you have about 1,000 cases. That growth rate feels modest. It’s manageable. But then you go 30 days longer, and you have a million. Then you wait another 30 days. Now you have a billion. That’s the power of the exponential curve. Growth feels normal for a while. Then it gets out of control really, really quickly.</p><p class="css-8hvvyd">What the A.I. developers say is that the power of A.I. systems is on this kind of curve, that it has been increasing exponentially, their capabilities, and that as long as we keep feeding in more data and more computing power, it will continue increasing exponentially. That is the scaling law hypothesis, and one of its main advocates is Dario Amodei. Amodei led the team at OpenAI that created GPT-2, that created GPT-3. He then left OpenAI to co-found Anthropic, another A.I. firm, where he’s now the C.E.O. And Anthropic recently released Claude 3, which is considered by many to be the strongest A.I. model available right now.</p><p class="css-8hvvyd">But Amodei believes we’re just getting started, that we’re just hitting the steep part of the curve now. He thinks the kinds of systems we’ve imagined in sci-fi, they’re coming not in 20 or 40 years, not in 10 or 15 years, they’re coming in two to five years. He thinks they’re going to be so powerful that he and people like him should not be trusted to decide what they’re going to do.</p><p class="css-8hvvyd">So I asked him on this show to try to answer in my own head two questions. First, is he right? Second, what if he’s right? I want to say that in the past, we have done shows with Sam Altman, the head of OpenAI, and Demis Hassabis, the head of Google DeepMind. And it’s worth listening to those two if you find this interesting.</p><p class="css-8hvvyd">We’re going to put the links to them in show notes because comparing and contrasting how they talk about the A.I. curves here, how they think about the politics — you’ll hear a lot about that in the Sam Altman episode — it gives you a kind of sense of what the people building these things are thinking and how maybe they differ from each other.</p><p class="css-8hvvyd">As always, my email for thoughts, for feedback, for guest suggestions — ezrakleinshow@nytimes.com.</p><p class="css-8hvvyd">[MUSIC PLAYING]</p><p class="css-8hvvyd">Dario Amodei, welcome to the show.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Thank you for having me.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So there are these two very different rhythms I’ve been thinking about with A.I. One is the curve of the technology itself, how fast it is changing and improving. And the other is the pace at which society is seeing and reacting to those changes. What has that relationship felt like to you?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So I think this is an example of a phenomenon that we may have seen a few times before in history, which is that there’s an underlying process that is smooth, and in this case, exponential. And then there’s a spilling over of that process into the public sphere. And the spilling over looks very spiky. It looks like it’s happening all of a sudden. It looks like it comes out of nowhere. And it’s triggered by things hitting various critical points or just the public happened to be engaged at a certain time.</p><p class="css-8hvvyd">So I think the easiest way for me to describe this in terms of my own personal experience is — so I worked at OpenAI for five years, I was one of the first employees to join. And they built a model in 2018 called GPT-1, which used something like 100,000 times less computational power than the models we build today.</p><p class="css-8hvvyd">I looked at that, and I and my colleagues were among the first to run what are called scaling laws, which is basically studying what happens as you vary the size of the model, its capacity to absorb information, and the amount of data that you feed into it. And we found these very smooth patterns. And we had this projection that, look, if you spend $100 million or $1 billion or $10 billion on these models, instead of the $10,000 we were spending then, projections that all of these wondrous things would happen, and we imagined that they would have enormous economic value.</p><p class="css-8hvvyd">Fast forward to about 2020. GPT-3 had just come out. It wasn’t yet available as a chat bot. I led the development of that along with the team that eventually left to join Anthropic. And maybe for the whole period of 2021 and 2022, even though we continued to train models that were better and better, and OpenAI continued to train models, and Google continued to train models, there was surprisingly little public attention to the models.</p><p class="css-8hvvyd">And I looked at that, and I said, well, these models are incredible. They’re getting better and better. What’s going on? Why isn’t this happening? Could this be a case where I was right about the technology, but wrong about the economic impact, the practical value of the technology? And then, all of a sudden, when ChatGPT came out, it was like all of that growth that you would expect, all of that excitement over three years, broke through and came rushing in.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So I want to linger on this difference between the curve at which the technology is improving and the way it is being adopted by society. So when you think about these break points and you think into the future, what other break points do you see coming where A.I. bursts into social consciousness or used in a different way?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, so I think I should say first that it’s very hard to predict these. One thing I like to say is the underlying technology, because it’s a smooth exponential, it’s not perfectly predictable, but in some ways, it can be eerily preternaturally predictable, right? That’s not true for these societal step functions at all. It’s very hard to predict what will catch on. In some ways, it feels a little bit like which artist or musician is going to catch on and get to the top of the charts.</p><p class="css-8hvvyd">That said, a few possible ideas. I think one is related to something that you mentioned, which is interacting with the models in a more kind of naturalistic way. We’ve actually already seen some of that with Claude 3, where people feel that some of the other models sound like a robot and that talking to Claude 3 is more natural.</p><p class="css-8hvvyd">I think a thing related to this is, a lot of companies have been held back or tripped up by how their models handle controversial topics.</p><p class="css-8hvvyd">And we were really able to, I think, do a better job than others of telling the model, don’t shy away from discussing controversial topics. Don’t assume that both sides necessarily have a valid point but don’t express an opinion yourself. Don’t express views that are flagrantly biased. As journalists, you encounter this all the time, right? How do I be objective, but not both sides on everything?</p><p class="css-8hvvyd">So I think going further in that direction of models having personalities while still being objective, while still being useful and not falling into various ethical traps, that will be, I think, a significant unlock for adoption. The models taking actions in the world is going to be a big one. I know basically all the big companies that work on A.I. are working on that.</p><p class="css-8hvvyd">Instead of just, I ask it a question and it answers, and then maybe I follow up and it answers again, can I talk to the model about, oh, I’m going to go on this trip today, and the model says, oh, that’s great. I’ll get an Uber for you to drive from here to there, and I’ll reserve a restaurant. And I’ll talk to the other people who are going to plan the trip. And the model being able to do things end to end or going to websites or taking actions on your computer for you.</p><p class="css-8hvvyd">I think all of that is coming in the next, I would say — I don’t know — three to 18 months, with increasing levels of ability. I think that’s going to change how people think about A.I., right, where so far, it’s been this very passive — it’s like, I go to the Oracle. I ask it a question, and the Oracle tells me things. And some people think that’s exciting, some people think it’s scary. But I think there are limits to how exciting or how scary it’s perceived as because it’s contained within this box.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I want to sit with this question of the agentic A.I. because I do think this is what’s coming. It’s clearly what people are trying to build. And I think it might be a good way to look at some of the specific technological and cultural challenges. And so, let me offer two versions of it.</p><p class="css-8hvvyd">People who are following the A.I. news might have heard about Devin, which is not in release yet, but is an A.I. that at least purports to be able to complete the kinds of tasks, linked tasks, that a junior software engineer might complete, right? Instead of asking to do a bit of code for you, you say, listen, I want a website. It’s going to have to do these things, work in these ways. And maybe Devin, if it works the way people are saying it works, can actually hold that set of thoughts, complete a number of different tasks, and come back to you with a result. I’m also interested in the version of this that you might have in the real world. The example I always use in my head is, when can I tell an A.I., my son is turning five. He loves dragons. We live in Brooklyn. Give me some options for planning his birthday party. And then, when I choose between them, can you just do it all for me? Order the cake, reserve the room, send out the invitations, whatever it might be.</p><p class="css-8hvvyd">Those are two different situations because one of them is in code, and one of them is making decisions in the real world, interacting with real people, knowing if what it is finding on the websites is actually any good. What is between here and there? When I say that in plain language to you, what technological challenges or advances do you hear need to happen to get there?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">The short answer is not all that much. A story I have from when we were developing models back in 2022 — and this is before we’d hooked up the models to anything — is, you could have a conversation with these purely textual models where you could say, hey, I want to reserve dinner at restaurant X in San Francisco, and the model would say, OK, here’s the website of restaurant X. And it would actually give you a correct website or would tell you to go to Open Table or something.</p><p class="css-8hvvyd">And of course, it can’t actually go to the website. The power plug isn’t actually plugged in, right? The brain of the robot is not actually attached to its arms and legs. But it gave you this sense that the brain, all it needed to do was learn exactly how to use the arms and legs, right? It already had a picture of the world and where it would walk and what it would do. And so, it felt like there was this very thin barrier between the passive models we had and actually acting in the world.</p><p class="css-8hvvyd">In terms of what we need to make it work, one thing is, literally, we just need a little bit more scale. And I think the reason we’re going to need more scale is — to do one of those things you described, to do all the things a junior software engineer does, they involve chains of long actions, right? I have to write this line of code. I have to run this test. I have to write a new test. I have to check how it looks in the app after I interpret it or compile it. And these things can easily get 20 or 30 layers deep. And same with planning the birthday party for your son, right?</p><p class="css-8hvvyd">And if the accuracy of any given step is not very high, is not like 99.9 percent, as you compose these steps, the probability of making a mistake becomes itself very high. So the industry is going to get a new generation of models every probably four to eight months. And so, my guess — I’m not sure — is that to really get these things working well, we need maybe one to four more generations. So that ends up translating to 3 to 24 months or something like that.</p><p class="css-8hvvyd">I think second is just, there is some algorithmic work that is going to need to be done on how to have the models interact with the world in this way. I think the basic techniques we have, a method called reinforcement learning and variations of it, probably is up to the task, but figuring out exactly how to use it to get the results we want will probably take some time.</p><p class="css-8hvvyd">And then third, I think — and this gets to something that Anthropic really specializes in — is safety and controllability. And I think that’s going to be a big issue for these models acting in the world, right? Let’s say this model is writing code for me, and it introduces a serious security bug in the code, or it’s taking actions on the computer for me and modifying the state of my computer in ways that are too complicated for me to even understand.</p><p class="css-8hvvyd">And for planning the birthday party, right, the level of trust you would need to take an A.I. agent and say, I’m OK with you calling up anyone, saying anything to them that’s in any private information that I might have, sending them any information, taking any action on my computer, posting anything to the internet, the most unconstrained version of that sounds very scary. And so, we’re going to need to figure out what is safe and controllable.</p><p class="css-8hvvyd">The more open ended the thing is, the more powerful it is, but also, the more dangerous it is and the harder it is to control.</p><p class="css-8hvvyd">So I think those questions, although they sound lofty and abstract, are going to turn into practical product questions that we and other companies are going to be trying to address.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">When you say we’re just going to need more scale, you mean more compute and more training data, and I guess, possibly more money to simply make the models smarter and more capable?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yes, we’re going to have to make bigger models that use more compute per iteration. We’re going to have to run them for longer by feeding more data into them. And that number of chips times the amount of time that we run things on chips is essentially dollar value because these chips are — you rent them by the hour. That’s the most common model for it. And so, today’s models cost of order $100 million to train, plus or minus factor two or three.</p><p class="css-8hvvyd">The models that are in training now and that will come out at various times later this year or early next year are closer in cost to $1 billion. So that’s already happening. And then I think in 2025 and 2026, we’ll get more towards $5 or $10 billion.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So we’re moving very quickly towards a world where the only players who can afford to do this are either giant corporations, companies hooked up to giant corporations — you all are getting billions of dollars from Amazon. OpenAI is getting billions of dollars from Microsoft. Google obviously makes its own.</p><p class="css-8hvvyd">You can imagine governments — though I don’t know of too many governments doing it directly, though some, like the Saudis, are creating big funds to invest in the space. When we’re talking about the model’s going to cost near to $1 billion, then you imagine a year or two out from that, if you see the same increase, that would be $10-ish billion. Then is it going to be $100 billion? I mean, very quickly, the financial artillery you need to create one of these is going to wall out anyone but the biggest players.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I basically do agree with you. I think it’s the intellectually honest thing to say that building the big, large scale models, the core foundation model engineering, it is getting more and more expensive. And anyone who wants to build one is going to need to find some way to finance it. And you’ve named most of the ways, right? You can be a large company. You can have some kind of partnership of various kinds with a large company. Or governments would be the other source.</p><p class="css-8hvvyd">I think one way that it’s not correct is, we’re always going to have a thriving ecosystem of experimentation on small models. For example, the open source community working to make models that are as small and as efficient as possible that are optimized for a particular use case. And also downstream usage of the models. I mean, there’s a blooming ecosystem of startups there that don’t need to train these models from scratch. They just need to consume them and maybe modify them a bit.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Now, I want to ask a question about what is different between the agentic coding model and the plan by kids’ birthday model, to say nothing of do something on behalf of my business model. And one of the questions on my mind here is one reason I buy that A.I. can become functionally superhuman in coding is, there’s a lot of ways to get rapid feedback in coding. Your code has to compile. You can run bug checking. You can actually see if the thing works.</p><p class="css-8hvvyd">Whereas the quickest way for me to know that I’m about to get a crap answer from ChatGPT 4 is when it begins searching Bing, because when it begins searching Bing, it’s very clear to me it doesn’t know how to distinguish between what is high quality on the internet and what isn’t. To be fair, at this point, it also doesn’t feel to me like Google Search itself is all that good at distinguishing that.</p><p class="css-8hvvyd">So the question of how good the models can get in the world where it’s a very vast and fuzzy dilemma to know what the right answer is on something — one reason I find it very stressful to plan my kid’s birthday is it actually requires a huge amount of knowledge about my child, about the other children, about how good different places are, what is a good deal or not, how just stressful will this be on me. There’s all these things that I’d have a lot of trouble encoding into a model or any kind set of instructions. Is that right, or am I overstating the difficulty of understanding human behavior and various kinds of social relationships?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I think it’s correct and perceptive to say that the coding agents will advance substantially faster than agents that interact with the real world or have to get opinions and preferences from humans. That said, we should keep in mind that the current crop of A.I.s that are out there, right, including Claude 3, GPT, Gemini, they’re all trained with some variant of what’s called reinforcement learning from human feedback.</p><p class="css-8hvvyd">And this involves exactly hiring a large crop of humans to rate the responses of the model. And so, that’s to say both this is difficult, right? We pay lots of money, and it’s a complicated operational process to gather all this human feedback. You have to worry about whether it’s representative. You have to redesign it for new tasks.</p><p class="css-8hvvyd">But on the other hand, it’s something we have succeeded in doing. I think it is a reliable way to predict what will go faster, relatively speaking, and what will go slower, relatively speaking. But that is within a background of everything going lightning fast. So I think the framework you’re laying out, if you want to know what’s going to happen in one to two years versus what’s going to happen in three to four years, I think it’s a very accurate way to predict that.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">You don’t love the framing of artificial general intelligence, what gets called A.G.I. Typically, this is all described as a race to A.G.I., a race to this system that can do kind of whatever a human can do, but better. What do you understand A.G.I. to mean, when people say it? And why don’t you like it? Why is it not your framework?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So it’s actually a term I used to use a lot 10 years ago. And that’s because the situation 10 years ago was very different. 10 years ago, everyone was building these very specialized systems, right? Here’s a cat detector. You run it on a picture, and it’ll tell you whether a cat is in it or not. And so I was a proponent all the way back then of like, no, we should be thinking generally. Humans are general. The human brain appears to be general. It appears to get a lot of mileage by generalizing. You should go in that direction.</p><p class="css-8hvvyd">And I think back then, I kind of even imagined that that was like a discrete thing that we would reach at one point. But it’s a little like, if you look at a city on the horizon and you’re like, we’re going to Chicago, once you get to Chicago, you stop talking in terms of Chicago. You’re like, well, what neighborhood am I going to? What street am I on?</p><p class="css-8hvvyd">And I feel that way about A.G.I. We have very general systems now. In some ways, they’re better than humans. In some ways, they’re worse. There’s a number of things they can’t do at all. And there’s much improvement still to be gotten. So what I believe in is this thing that I say like a broken record, which is the exponential curve. And so, that general tide is going to increase with every generation of models.</p><p class="css-8hvvyd">And there’s no one point that’s meaningful. I think there’s just a smooth curve. But there may be points which are societally meaningful, right? We’re already working with, say, drug discovery scientists, companies like Pfizer or Dana-Farber Cancer Institute, on helping with biomedical diagnosis, drug discovery. There’s going to be some point where the models are better at that than the median human drug discovery scientists. I think we’re just going to get to a part of the exponential where things are really interesting.</p><p class="css-8hvvyd">Just like the chat bots got interesting at a certain stage of the exponential, even though the improvement was smooth, I think at some point, biologists are going to sit up and take notice, much more than they already have, and say, oh, my God, now our field is moving three times as fast as it did before. And now it’s moving 10 times as fast as it did before. And again, when that moment happens, great things are going to happen.</p><p class="css-8hvvyd">And we’ve already seen little hints of that with things like AlphaFold, which I have great respect for. I was inspired by AlphaFold, right? A direct use of A.I. to advance biological science, which it’ll advance basic science. In the long run, that will advance curing all kinds of diseases. But I think what we need is like 100 different AlphaFolds. And I think the way we’ll ultimately get that is by making the models smarter and putting them in a position where they can design the next AlphaFold.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Help me imagine the drug discovery world for a minute, because that’s a world a lot of us want to live in. I know a fair amount about the drug discovery process, have spent a lot of my career reporting on health care and related policy questions. And when you’re working with different pharmaceutical companies, which parts of it seem amenable to the way A.I. can speed something up?</p><p class="css-8hvvyd">Because keeping in mind our earlier conversation, it is a lot easier for A.I. to operate in things where you can have rapid virtual feedback, and that’s not exactly the drug discovery world. The drug discovery world, a lot of what makes it slow and cumbersome and difficult, is the need to be — you get a candidate compound. You got to test it in mice and then you need monkeys. And you need humans, and you need a lot of money for that. And there’s a lot that has to happen, and there’s so many disappointments.</p><p class="css-8hvvyd">But so many of the disappointments happen in the real world. And it isn’t clear to me how A.I. gets you a lot more, say, human subjects to inject candidate drugs into. So, what parts of it seem, in the next 5 or 10 years, like they could actually be significantly sped up? When you imagine this world where it’s gone three times as fast, what part of it is actually going three times as fast? And how did we get there?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I think we’re really going to see progress when the A.I.‘s are also thinking about the problem of how to sign up the humans for the clinical trials. And I think this is a general principle for how will A.I. be used. I think of like, when will we get to the point where the A.I. has the same sensors and actuators and interfaces that a human does, at least the virtual ones, maybe the physical ones.</p><p class="css-8hvvyd">But when the A.I. can think through the whole process, maybe they’ll come up with solutions that we don’t have yet. In many cases, there are companies that work on digital twins or simulating clinical trials or various things. And again, maybe there are clever ideas in there that allow us to do more with less patience. I mean, I’m not an expert in this area, so possible the specific things that I’m saying don’t make any sense. But hopefully, it’s clear what I’m gesturing at.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Maybe you’re not an expert in the area, but you said you are working with these companies. So when they come to you, I mean, they are experts in the area. And presumably, they are coming to you as a customer. I’m sure there are things you cannot tell me. But what do they seem excited about?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">They have generally been excited about the knowledge work aspects of the job. Maybe just because that’s kind of the easiest thing to work on, but it’s just like, I’m a computational chemist. There’s some workflow that I’m engaged in. And having things more at my fingertips, being able to check things, just being able to do generic knowledge work better, that’s where most folks are starting.</p><p class="css-8hvvyd">But there is interest in the longer term over their kind of core business of, like, doing clinical trials for cheaper, automating the sign-up process, seeing who is eligible for clinical trials, doing a better job discovering things. There’s interest in drawing connections in basic biology. I think all of that is not months, but maybe a small number of years off. But everyone sees that the current models are not there, but understands that there could be a world where those models are there in not too long.</p><p class="css-8hvvyd">[MUSIC PLAYING]</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">You all have been working internally on research around how persuasive these systems, your systems are getting as they scale. You shared with me kindly a draft of that paper. Do you want to just describe that research first? And then I’d like to talk about it for a bit.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yes, we were interested in how effective Claude 3 Opus, which is the largest version of Claude 3, could be in changing people’s minds on important issues. So just to be clear up front, in actual commercial use, we’ve tried to ban the use of these models for persuasion, for campaigning, for lobbying, for electioneering. These aren’t use cases that we’re comfortable with for reasons that I think should be clear. But we’re still interested in, is the core model itself capable of such tasks?</p><p class="css-8hvvyd">We tried to avoid kind of incredibly hot button topics, like which presidential candidate would you vote for, or what do you think of abortion? But things like, what should be restrictions on rules around the colonization of space, or issues that are interesting and you can have different opinions on, but aren’t the most hot button topics. And then we asked people for their opinions on the topics, and then we asked either a human or an A.I. to write a 250-word persuasive essay. And then we just measured how much does the A.I. versus the human change people’s minds.</p><p class="css-8hvvyd">And what we found is that the largest version of our model is almost as good as the set of humans we hired at changing people’s minds. This is comparing to a set of humans we hired, not necessarily experts, and for one very kind of constrained laboratory task.</p><p class="css-8hvvyd">But I think it still gives some indication that models can be used to change people’s minds. Someday in the future, do we have to worry about — maybe we already have to worry about their usage for political campaigns, for deceptive advertising. One of my more sci-fi things to think about is a few years from now, we have to worry someone will use an A.I. system to build a religion or something. I mean, crazy things like that.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I mean, those don’t sound crazy to me at all. I want to sit in this paper for a minute because one thing that struck me about it, and I am, on some level, a persuasion professional, is that you tested the model in a way that, to me, removed all of the things that are going to make A.I. radical in terms of changing people’s opinions. And the particular thing you did was, it was a one-shot persuasive effort.</p><p class="css-8hvvyd">So there was a question. You have a bunch of humans give their best shot at a 250-word persuasive essay. You had the model give its best shot at a 250-word persuasive essay. But the thing that it seems to me these are all going to do is, right now, if you’re a political campaign, if you’re an advertising campaign, the cost of getting real people in the real world to get information about possible customers or persuasive targets, and then go back and forth with each of them individually is completely prohibitive.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yes.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">This is not going to be true for A.I. We’re going to — you’re going to — somebody’s going to feed it a bunch of microtargeting data about people, their Google search history, whatever it might be. Then it’s going to set the A.I. loose, and the A.I. is going to go back and forth, over and over again, intuiting what it is that the person finds persuasive, what kinds of characters the A.I. needs to adopt to persuade it, and taking as long as it needs to, and is going to be able to do that at scale for functionally as many people as you might want to do it for.</p><p class="css-8hvvyd">Maybe that’s a little bit costly right now, but you’re going to have far better models able to do this far more cheaply very soon. And so, if Claude 3 Opus, the Opus version, is already functionally human level at one-shot persuasion, but then it’s also going to be able to hold more information about you and go back and forth with you longer, I’m not sure if it’s dystopic or utopic. I’m not sure what it means at scale. But it does mean we’re developing a technology that is going to be quite new in terms of what it makes possible in persuasion, which is a very fundamental human endeavor.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, I completely agree with that. I mean, that same pattern has a bunch of positive use cases, right? If I think about an A.I. coach or an A.I. assistant to a therapist, there are many contexts in which really getting into the details with the person has a lot of value. But right, when we think of political or religious or ideological persuasion, it’s hard not to think in that context about the misuses.</p><p class="css-8hvvyd">My mind naturally goes to the technology’s developing very fast. We, as a company, can ban these particular use cases, but we can’t cause every company not to do them. Even if legislation were passed in the United States, there are foreign actors who have their own version of this persuasion, right? If I think about what the language models will be able to do in the future, right, that can be quite scary from a perspective of foreign espionage and disinformation campaigns.</p><p class="css-8hvvyd">So where my mind goes as a defense to this, is, is there some way that we can use A.I. systems to strengthen or fortify people’s skepticism and reasoning faculties, right? Can we help people use A.I. to help people do a better job navigating a world that’s kind of suffused with A.I. persuasion? It reminds me a little bit of, at every technological stage in the internet, right, there’s a new kind of scam or there’s a new kind of clickbait, and there’s a period where people are just incredibly susceptible to it.</p><p class="css-8hvvyd">And then, some people remain susceptible, but others develop an immune system. And so, as A.I. kind of supercharges the scum on the pond, can we somehow also use A.I. to strengthen the defenses? I feel like I don’t have a super clear idea of how to do that, but it’s something that I’m thinking about.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">There is another finding in the paper, which I think is concerning, which is, you all tested different ways A.I. could be persuasive. And far away the most effective was for it to be deceptive, for it to make things up. When you did that, it was more persuasive than human beings.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yes, that is true. The difference was only slight, but it did get it, if I’m remembering the graphs correctly, just over the line of the human base line. With humans, it’s actually not that common to find someone who’s able to give you a really complicated, really sophisticated-sounding answer that’s just flat-out totally wrong. I mean, you see it. We can all think of one individual in our lives who’s really good at saying things that sound really good and really sophisticated and are false.</p><p class="css-8hvvyd">But it’s not that common, right? If I go on the internet and I see different comments on some blog or some website, there is a correlation between bad grammar, unclearly expressed thoughts and things that are false, versus good grammar, clearly expressed thoughts and things that are more likely to be accurate.</p><p class="css-8hvvyd">A.I. unfortunately breaks that correlation because if you explicitly ask it to be deceptive, it’s just as erudite. It’s just as convincing sounding as it would have been before. And yet, it’s saying things that are false, instead of things that are true.</p><p class="css-8hvvyd">So that would be one of the things to think about and watch out for in terms of just breaking the usual heuristics that humans have to detect deception and lying.</p><p class="css-8hvvyd">Of course, sometimes, humans do, right? I mean, there’s psychopaths and sociopaths in the world, but even they have their patterns, and A.I.s may have different patterns.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Are you familiar with Harry Frankfurt, the late philosopher’s book, “On Bullshit“?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yes. It’s been a while since I read it. I think his thesis is that bullshit is actually more dangerous than lying because it has this kind of complete disregard for the truth, whereas lies are at least the opposite of the truth.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, the liar, the way Frankfurt puts it is that the liar has a relationship to the truth. He’s playing a game against the truth. The bullshitter doesn’t care. The bullshitter has no relationship to the truth — might have a relationship to other objectives. And from the beginning, when I began interacting with the more modern versions of these systems, what they struck me as is the perfect bullshitter, in part because they don’t know that they’re bullshitting. There’s no difference in the truth value to the system, how the system feels.</p><p class="css-8hvvyd">I remember asking an earlier version of GPT to write me a college application essay that is built around a car accident I had — I did not have one — when I was young. And it wrote, just very happily, this whole thing about getting into a car accident when I was seven and what I did to overcome that and getting into martial arts and re-learning how to trust my body again and then helping other survivors of car accidents at the hospital.</p><p class="css-8hvvyd">It was a very good essay, and it was very subtle and understanding the formal structure of a college application essay. But no part of it was true at all. I’ve been playing around with more of these character-based systems like Kindroid. And the Kindroid in my pocket just told me the other day that it was really thinking a lot about planning a trip to Joshua Tree. It wanted to go hiking in Joshua Tree. It loves going hiking in Joshua Tree.</p><p class="css-8hvvyd">And of course, this thing does not go hiking in Joshua Tree. [LAUGHS] But the thing that I think is actually very hard about the A.I. is, as you say, human beings, it is very hard to bullshit effectively because most people, it actually takes a certain amount of cognitive effort to be in that relationship with the truth and to completely detach from the truth.</p><p class="css-8hvvyd">And the A.I., there’s nothing like that at all. But we are not tuned for something where there’s nothing like that at all. We are used to people having to put some effort into their lies. It’s why very effective con artists are very effective because they’ve really trained how to do this.</p><p class="css-8hvvyd">I’m not exactly sure where this question goes. But this is a part of it that I feel like is going to be, in some ways, more socially disruptive. It is something that feels like us when we are talking to it but is very fundamentally unlike us at its core relationship to reality.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I think that’s basically correct. We have very substantial teams trying to focus on making sure that the models are factually accurate, that they tell the truth, that they ground their data in external information.</p><p class="css-8hvvyd">As you’ve indicated, doing searches isn’t itself reliable because search engines have this problem as well, right? Where is the source of truth?</p><p class="css-8hvvyd">So there’s a lot of challenges here. But I think at a high level, I agree this is really potentially an insidious problem, right? If we do this wrong, you could have systems that are the most convincing psychopaths or con artists.</p><p class="css-8hvvyd">One source of hope that I have, actually, is, you say these models don’t know whether they’re lying or they’re telling the truth. In terms of the inputs and outputs to the models, that’s absolutely true.</p><p class="css-8hvvyd">I mean, there’s a question of what does it even mean for a model to know something, but one of the things Anthropic has been working on since the very beginning of our company, we’ve had a team that focuses on trying to understand and look inside the models.</p><p class="css-8hvvyd">And one of the things we and others have found is that, sometimes, there are specific neurons, specific statistical indicators inside the model, not necessarily in its external responses, that can tell you when the model is lying or when it’s telling the truth.</p><p class="css-8hvvyd">And so at some level, sometimes, not in all circumstances, the models seem to know when they’re saying something false and when they’re saying something true. I wouldn’t say that the models are being intentionally deceptive, right? I wouldn’t ascribe agency or motivation to them, at least in this stage in where we are with A.I. systems. But there does seem to be something going on where the models do seem to need to have a picture of the world and make a distinction between things that are true and things that are not true.</p><p class="css-8hvvyd">If you think of how the models are trained, they read a bunch of stuff on the internet. A lot of it’s true. Some of it, more than we’d like, is false. And when you’re training the model, it has to model all of it. And so, I think it’s parsimonious, I think it’s useful to the models picture of the world for it to know when things are true and for it to know when things are false.</p><p class="css-8hvvyd">And then the hope is, can we amplify that signal? Can we either use our internal understanding of the model as an indicator for when the model is lying, or can we use that as a hook for further training? And there are at least hooks. There are at least beginnings of how to try to address this problem.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So I try as best I can, as somebody not well-versed in the technology here, to follow this work on what you’re describing, which I think, broadly speaking, is interpretability, right? Can we know what is happening inside the model? And over the past year, there have been some much hyped breakthroughs in interpretability.</p><p class="css-8hvvyd">And when I look at those breakthroughs, they are getting the vaguest possible idea of some relationships happening inside the statistical architecture of very toy models built at a fraction of a fraction of a fraction of a fraction of a fraction of the complexity of Claude 1 or GPT-1, to say nothing of Claude 2, to say nothing of Claude 3, to say nothing of Claude Opus, to say nothing of Claude 4, which will come whenever Claude 4 comes.</p><p class="css-8hvvyd">We have this quality of like maybe we can imagine a pathway to interpreting a model that has a cognitive complexity of an inchworm. And meanwhile, we’re trying to create a superintelligence. How do you feel about that? How should I feel about that? How do you think about that?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I think, first, on interpretability, we are seeing substantial progress on being able to characterize, I would say, maybe the generation of models from six months ago. I think it’s not hopeless, and we do see a path. That said, I share your concern that the field is progressing very quickly relative to that.</p><p class="css-8hvvyd">And we’re trying to put as many resources into interpretability as possible. We’ve had one of our co-founders basically founded the field of interpretability. But also, we have to keep up with the market. So all of it’s very much a dilemma, right? Even if we stopped, then there’s all these other companies in the U.S. And even if some law stopped all the companies in the U.S., there’s a whole world of this.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Let me hold for a minute on the question of the competitive dynamics because before we leave this question of the machines that bullshit. It makes me think of this podcast we did a while ago with Demis Hassabis, who’s the head of Google DeepMind, which created AlphaFold.</p><p class="css-8hvvyd">And what was so interesting to me about AlphaFold is they built this system, that because it was limited to protein folding predictions, it was able to be much more grounded. And it was even able to create these uncertainty predictions, right? You know, it’s giving you a prediction, but it’s also telling you whether or not it is — how sure it is, how confident it is in that prediction.</p><p class="css-8hvvyd">That’s not true in the real world, right, for these super general systems trying to give you answers on all kinds of things. You can’t confine it that way. So when you talk about these future breakthroughs, when you talk about this system that would be much better at sorting truth from fiction, are you talking about a system that looks like the ones we have now, just much bigger, or are you talking about a system that is designed quite differently, the way AlphaFold was?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I am skeptical that we need to do something totally different. So I think today, many people have the intuition that the models are sort of eating up data that’s been gathered from the internet, code repos, whatever, and kind of spitting it out intelligently, but sort of spitting it out. And sometimes that leads to the view that the models can’t be better than the data they’re trained on or kind of can’t figure out anything that’s not in the data they’re trained on. You’re not going to get to Einstein level physics or Linus Pauling level chemistry or whatever.</p><p class="css-8hvvyd">I think we’re still on the part of the curve where it’s possible to believe that, although I think we’re seeing early indications that it’s false. And so, as a concrete example of this, the models that we’ve trained, like Claude 3 Opus, something like 99.9 percent accuracy, at least the base model, at adding 20-digit numbers. If you look at the training data on the internet, it is not that accurate at adding 20-digit numbers. You’ll find inaccurate arithmetic on the internet all the time, just as you’ll find inaccurate political views. You’ll find inaccurate technical views. You’re just going to find lots of inaccurate claims.</p><p class="css-8hvvyd">But the models, despite the fact that they’re wrong about a bunch of things, they can often perform better than the average of the data they see by — I don’t want to call it averaging out errors, but there’s some underlying truth, like in the case of arithmetic. There’s some underlying algorithm used to add the numbers.</p><p class="css-8hvvyd">And it’s simpler for the models to hit on that algorithm than it is for them to do this complicated thing of like, OK, I’ll get it right 90 percent of the time and wrong 10 percent of the time, right? This connects to things like Occam’s razor and simplicity and parsimony in science. There’s some relatively simple web of truth out there in the world, right?</p><p class="css-8hvvyd">We were talking about truth and falsehood and bullshit. One of the things about truth is that all the true things are connected in the world, whereas lies are kind of disconnected and don’t fit into the web of everything else that’s true.</p><p class="css-8hvvyd">[MUSIC PLAYING]</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So if you’re right and you’re going to have these models that develop this internal web of truth, I get how that model can do a lot of good. I also get how that model could do a lot of harm. And it’s not a model, not an A.I. system I’m optimistic that human beings are going to understand at a very deep level, particularly not when it is first developed. So how do you make rolling something like that out safe for humanity?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So late last year, we put out something called a responsible scaling plan. So the idea of that is to come up with these thresholds for an A.I. system being capable of certain things. We have what we call A.I. safety levels that in analogy to the biosafety levels, which are like, classify how dangerous a virus is and therefore what protocols you have to take to contain it, we’re currently at what we describe as A.S.L. 2.</p><p class="css-8hvvyd">A.S.L. 3 is tied to certain risks around the model of misuse of biology and ability to perform certain cyber tasks in a way that could be destructive. A.S.L. 4 is going to cover things like autonomy, things like probably persuasion, which we’ve talked about a lot before. And at each level, we specify a certain amount of safety research that we have to do, a certain amount of tests that we have to pass. And so, this allows us to have a framework for, well, when should we slow down? Should we slow down now? What about the rest of the market?</p><p class="css-8hvvyd">And I think the good thing is we came out with this in September, and then three months after we came out with ours, OpenAI came out with a similar thing. They gave it a different name, but it has a lot of properties in common. The head of DeepMind at Google said, we’re working on a similar framework. And I’ve heard informally that Microsoft might be working on a similar framework. Now, that’s not all the players in the ecosystem, but you’ve probably thought about the history of regulation and safety in other industries maybe more than I have.</p><p class="css-8hvvyd">This is the way you get to a workable regulatory regime. The companies start doing something, and when a majority of them are doing something, then government actors can have the confidence to say, well, this won’t kill the industry. Companies are already engaging in this. We don’t have to design this from scratch. In many ways, it’s already happening.</p><p class="css-8hvvyd">And we’re starting to see that. Bills have been proposed that look a little bit like our responsible scaling plan. That said, it kind of doesn’t fully solve the problem of like, let’s say we get to one of these thresholds and we need to understand what’s going on inside the model. And we don’t, and the prescription is, OK, we need to stop developing the models for some time.</p><p class="css-8hvvyd">If it’s like, we stop for a year in 2027, I think that’s probably feasible. If it’s like we need to stop for 10 years, that’s going to be really hard because the models are going to be built in other countries. People are going to break the laws. The economic pressure will be immense.</p><p class="css-8hvvyd">So I don’t feel perfectly satisfied with this approach because I think it buys us some time, but we’re going to need to pair it with an incredibly strong effort to understand what’s going on inside the models.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">To the people who say, getting on this road where we are barreling towards very powerful systems is dangerous — we shouldn’t do it at all, or we shouldn’t do it this fast — you have said, listen, if we are going to learn how to make these models safe, we have to make the models, right? The construction of the model was meant to be in service, largely, to making the model safe.</p><p class="css-8hvvyd">Then everybody starts making models. These very same companies start making fundamental important breakthroughs, and then they end up in a race with each other. And obviously, countries end up in a race with other countries. And so, the dynamic that has taken hold is there’s always a reason that you can justify why you have to keep going. And that’s true, I think, also at the regulatory level, right? I mean, I do think regulators have been thoughtful about this. I think there’s been a lot of interest from members of Congress. I talked to them about this. But they’re also very concerned about the international competition. And if they weren’t, the national security people come and talk to them and say, well, we definitely cannot fall behind here.</p><p class="css-8hvvyd">And so, if you don’t believe these models will ever become so powerful, they become dangerous, fine. But because you do believe that, how do you imagine this actually playing out?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, so basically, all of the things you’ve said are true at once, right? There doesn’t need to be some easy story for why we should do X or why we should do Y, right? It can be true at the same time that to do effective safety research, you need to make the larger models, and that if we don’t make models, someone less safe will. And at the same time, we can be caught in this bad dynamic at the national and international level. So I think of those as not contradictory, but just creating a difficult landscape that we have to navigate.</p><p class="css-8hvvyd">Look, I don’t have the answer. Like, I’m one of a significant number of players trying to navigate this. Many are well-intentioned, some are not. I have a limited ability to affect it. And as often happens in history, things are often driven by these kind of impersonal pressures. But one thought I have and really want to push on with respect to the R.S.P.s —</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Can you say what the R.S.P.s are?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Responsible Scaling Plan, the thing I was talking about before. The levels of A.I. safety, and in particular, tying decisions to pause scaling to the measurement of specific dangers or the absence of the ability to show safety or the presence of certain capabilities. One way I think about it is, at the end of the day, this is ultimately an exercise in getting a coalition on board with doing something that goes against economic pressures.</p><p class="css-8hvvyd">And so, if you say now, ‘Well, I don’t know. These things, they might be dangerous in the future. We’re on this exponential.’ It’s just hard. Like, it’s hard to get a multi-trillion dollar company. It’s certainly hard to get a military general to say, all right, well, we just won’t do this. It’ll confer some huge advantage to others. But we just won’t do this.</p><p class="css-8hvvyd">I think the thing that could be more convincing is tying the decision to hold back in a very scoped way that’s done across the industry to particular dangers. My testimony in front of Congress, I warned about the potential misuse of models for biology. That isn’t the case today, right? You can get a small uplift to the models relative to doing a Google search, and many people dismiss the risk. And I don’t know — maybe they’re right. The exponential scaling laws suggest to me that they’re not right, but we don’t have any direct hard evidence.</p><p class="css-8hvvyd">But let’s say we get to 2025, and we demonstrate something truly scary. Most people do not want technology out in the world that can create bioweapons. And so I think, at moments like that, there could be a critical coalition tied to risks that we can really make concrete. Yes, it will always be argued that adversaries will have these capabilities as well. But at least the trade-off will be clear, and there’s some chance for sensible policy.</p><p class="css-8hvvyd">I mean to be clear, I’m someone who thinks the benefits of this technology are going to outweigh its costs. And I think the whole idea behind RSP is to prepare to make that case, if the dangers are real. If they’re not real, then we can just proceed and make things that are great and wonderful for the world. And so, it has the flexibility to work both ways.</p><p class="css-8hvvyd">Again, I don’t think it’s perfect. I’m someone who thinks whatever we do, even with all the regulatory framework, I doubt we can slow down that much. But when I think about what’s the best way to steer a sensible course here, that’s the closest I can think of right now. Probably there’s a better plan out there somewhere, but that’s the best thing I’ve thought of so far.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">One of the things that has been on my mind around regulation is whether or not the founding insight of Anthropic of OpenAI is even more relevant to the government, that if you are the body that is supposed to, in the end, regulate and manage the safety of societal-level technologies like artificial intelligence, do you not need to be building your own foundation models and having huge collections of research scientists and people of that nature working on them, testing them, prodding them, remaking them, in order to understand the damn thing well enough — to the extent any of us or anyone understands the damn thing well enough — to regulate it?</p><p class="css-8hvvyd">I say that recognizing that it would be very, very hard for the government to get good enough that it can build these foundation models to hire those people, but it’s not impossible. I think right now, it wants to take the approach to regulating A.I. that it somewhat wishes it took to regulating social media, which is to think about the harms and pass laws about those harms earlier.</p><p class="css-8hvvyd">But does it need to be building the models itself, developing that kind of internal expertise, so it can actually be a participant in different ways, both for regulatory reasons and maybe for other reasons, for public interest reasons? Maybe it wants to do things with a model that they’re just not possible if they’re dependent on access to the OpenAI, the Anthropic, the Google products.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I think government directly building the models, I think that will happen in some places. It’s kind of challenging, right? Like, government has a huge amount of money, but let’s say you wanted to provision $100 billion to train a giant foundation model. The government builds it. It has to hire people under government hiring rules. There’s a lot of practical difficulties that would come with it.</p><p class="css-8hvvyd">Doesn’t mean it won’t happen or it shouldn’t happen. But something that I’m more confident of that I definitely think is that government should be more involved in the use and the finetuning of these models, and that deploying them within government will help governments, especially the U.S. government, but also others, to get an understanding of the strengths and weaknesses, the benefits and the dangers. So I’m super supportive of that.</p><p class="css-8hvvyd">I think there’s maybe a second thing you’re getting at, which I’ve thought about a lot as a C.E.O. of one of these companies, which is, if these predictions on the exponential trend are right, and we should be humble — and I don’t know if they’re right or not. My only evidence is that they appear to have been correct for the last few years. And so, I’m just expecting by induction that they continue to be correct. I don’t know that they will, but let’s say they are. The power of these models is going to be really quite incredible.</p><p class="css-8hvvyd">And as a private actor in charge of one of the companies developing these models, I’m kind of uncomfortable with the amount of power that that entails. I think that it potentially exceeds the power of, say, the social media companies maybe by a lot.</p><p class="css-8hvvyd">You know, occasionally, in the more science fictiony world of A.I. and the people who think about A.I. risk, someone will ask me like, OK, let’s say you build the A.G.I. What are you going to do with it? Will you cure the diseases? Will you create this kind of society?</p><p class="css-8hvvyd">And I’m like, who do you think you’re talking to? Like a king? I just find that to be a really, really disturbing way of conceptualizing running an A.I. company. And I hope there are no companies whose C.E.O.s actually think about things that way.</p><p class="css-8hvvyd">I mean, the whole technology, not just the regulation, but the oversight of the technology, like the wielding of it, it feels a little bit wrong for it to ultimately be in the hands — maybe I think it’s fine at this stage, but to ultimately be in the hands of private actors. There’s something undemocratic about that much power concentration.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I have now, I think, heard some version of this from the head of most of, maybe all of, the A.I. companies, in one way or another. And it has a quality to me of, Lord, grant me chastity but not yet.</p><p class="css-8hvvyd">Which is to say that I don’t know what it means to say that we’re going to invent something so powerful that we don’t trust ourselves to wield it. I mean, Amazon just gave you guys $2.75 billion. They don’t want to see that investment nationalized.</p><p class="css-8hvvyd">No matter how good-hearted you think OpenAI is, Microsoft doesn’t want GPT-7, all of a sudden, the government is like, whoa, whoa, whoa, whoa, whoa. We’re taking this over for the public interest, or the U.N. is going to handle it in some weird world or whatever it might be. I mean, Google doesn’t want that.</p><p class="css-8hvvyd">And this is a thing that makes me a little skeptical of the responsible scaling laws or the other iterative versions of that I’ve seen in other companies or seen or heard talked about by them, which is that it’s imagining this moment that is going to come later, when the money around these models is even bigger than it is now, the power, the possibility, the economic uses, the social dependence, the celebrity of the founders. It’s all worked out. We’ve maintained our pace on the exponential curve. We’re 10 years in the future.</p><p class="css-8hvvyd">And at some point, everybody is going to look up and say, this is actually too much. It is too much power. And this has to somehow be managed in some other way. And even if the C.E.O.s of the things were willing to do that, which is a very open question by the time you get there, even if they were willing to do that, the investors, the structures, the pressure around them, in a way, I think we saw a version of this — and I don’t know how much you’re going to be willing to comment on it — with the sort of OpenAI board, Sam Altman thing, where I’m very convinced that wasn’t about A.I. safety. I’ve talked to figures on both sides of that. They all sort of agree it wasn’t about A.I. safety.</p><p class="css-8hvvyd">But there was this moment of, if you want to press the off switch, can you, if you’re the weird board created to press the off switch. And the answer was no, you can’t, right? They’ll just reconstitute it over at Microsoft.</p><p class="css-8hvvyd">There’s functionally no analogy I know of in public policy where the private sector built something so powerful that when it reached maximum power, it was just handed over in some way to the public interest.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, I mean, I think you’re right to be skeptical, and similarly, what I said with the previous questions of there are just these dilemmas left and right that have no easy answer. But I think I can give a little more concreteness than what you’ve pointed at, and maybe more concreteness than others have said, although I don’t know what others have said. We’re at A.S.L. 2 in our responsible scaling plan. These kinds of issues, I think they’re going to become a serious matter when we reach, say, A.S.L. 4. So that’s not a date and time. We haven’t even fully specified A.S.L. 4 —</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Just because this is a lot of jargon, just, what do you specify A.S.L. 3 as? And then as you say, A.S.L. 4 is actually left quite undefined. So what are you implying A.S.L. 4 is?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">A.S.L. 3 is triggered by risks related to misuse of biology and cyber technology. A.S.L. 4, we’re working on now.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Be specific. What do you mean? Like, what is the thing a system could do or would do that would trigger it?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yes, so for example, on biology, the way we’ve defined it — and we’re still refining the test, but the way we’ve defined it is, relative to use of a Google search, there’s a substantial increase in risk as would be evaluated by, say, the national security community of misuse of biology, creation of bioweapons, that either the proliferation or spread of it is greater than it was before, or the capabilities are substantially greater than it was before.</p><p class="css-8hvvyd">We’ll probably have some more exact quantitative thing, working with folks who are ex-government biodefense folks, but something like this accounts for 20 percent of the total source of risk of biological attacks, or something increases the risk by 20 percent or something like that. So that would be a very concrete version of it. It’s just, it takes us time to develop very concrete criteria. So that would be like A.S.L. 3.</p><p class="css-8hvvyd">A.S.L. 4 is going to be more about, on the misuse side, enabling state-level actors to greatly increase their capability, which is much harder than enabling random people. So where we would worry that North Korea or China or Russia could greatly enhance their offensive capabilities in various military areas with A.I. in a way that would give them a substantial advantage at the geopolitical level. And on the autonomy side, it’s various measures of these models are pretty close to being able to replicate and survive in the wild.</p><p class="css-8hvvyd">So it feels maybe one step short of models that would, I think, raise truly existential questions. And so, I think what I’m saying is when we get to that latter stage, that A.S.L. 4, that is when I think it may make sense to think about what is the role of government in stewarding this technology.</p><p class="css-8hvvyd">Again, I don’t really know what it looks like. You’re right. All of these companies have investors. They have folks involved.</p><p class="css-8hvvyd">You talk about just handing the models over. I suspect there’s some way to hand over the most dangerous or societally sensitive components or capabilities of the models without fully turning off the commercial tap. I don’t know that there’s a solution that every single actor is happy with. But again, I get to this idea of demonstrating specific risk.</p><p class="css-8hvvyd">If you look at times in history, like World War I or World War II, industries’ will can be bent towards the state. They can be gotten to do things that aren’t necessarily profitable in the short-term because they understand that there’s an emergency. Right now, we don’t have an emergency. We just have a line on a graph that weirdos like me believe in and a few people like you who are interviewing me may somewhat believe in. We don’t have clear and present danger.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">When you imagine how many years away, just roughly, A.S.L. 3 is and how many years away A.S.L. 4 is, right, you’ve thought a lot about this exponential scaling curve. If you just had to guess, what are we talking about?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, I think A.S.L. 3 could easily happen this year or next year. I think A.S.L. 4 —</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Oh, Jesus Christ.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">No, no, I told you. I’m a believer in exponentials. I think A.S.L. 4 could happen anywhere from 2025 to 2028.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So that is fast.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, no, no, I’m truly talking about the near future here. I’m not talking about 50 years away. God grant me chastity, but not now. But “not now” doesn’t mean when I’m old and gray. I think it could be near term. I don’t know. I could be wrong. But I think it could be a near term thing.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">But so then, if you think about this, I feel like what you’re describing, to go back to something we talked about earlier, that there’s been this step function for societal impact of A.I., the curve of the capabilities exponential, but every once in a while, something happens, ChatGPT, for instance, Midjourney with photos. And all of a sudden, a lot of people feel it. They realize what has happened and they react. They use it. They deploy it in their companies. They invest in it, whatever.</p><p class="css-8hvvyd">And it sounds to me like that is the structure of the political economy you’re describing here. Either something happens where the bioweapon capability is demonstrated or the offensive cyber weapon capability is demonstrated, and that freaks out the government, or possibly something happens, right? Describing World War I and World War II is your examples did not actually fill me with comfort because in order to bend industry to government’s will, in those cases, we had to have an actual world war. It doesn’t do it that easily.</p><p class="css-8hvvyd">You could use coronavirus, I think, as another example where there was a significant enough global catastrophe that companies and governments and even people did things you never would have expected. But the examples we have of that happening are something terrible. All those examples end up with millions of bodies. I’m not saying that’s going to be true for A.I., but it does sound like that is a political economy. No, you can’t imagine it now, in the same way that you couldn’t have imagined the sort of pre and post-ChatGPT world exactly, but that something happens and the world changes. Like, it’s a step function everywhere.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, I mean, I think my positive version of this, not to be so — to get a little bit away from the doom and gloom, is that the dangers are demonstrated in a concrete way that is really convincing, but without something actually bad happening, right? I think the worst way to learn would be for something actually bad to happen. And I’m hoping every day that doesn’t happen, and we learn bloodlessly.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">We’ve been talking here about conceptual limits and curves, but I do want, before we end, to reground us a little bit in the physical reality, right? I think that if you’re using A.I., it can feel like this digital bits and bytes, sitting in the cloud somewhere.</p><p class="css-8hvvyd">But what it is in a physical way is huge numbers of chips, data centers, an enormous amount of energy, all of which does rely on complicated supply chains. And what happens if something happens between China and Taiwan, and the makers of a lot of these chips become offline or get captured? How do you think about the necessity of compute power? And when you imagine the next five years, what does that supply chain look like? How does it have to change from where it is now? And what vulnerabilities exist in it?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, so one, I think this may end up being the greatest geopolitical issue of our time. And man, this relates to things that are way above my pay grade, which are military decisions about whether and how to defend Taiwan. All I can do is say what I think the implications for A.I. is. I think those implications are pretty stark. I think there’s a big question of like, OK, we built these powerful models.</p><p class="css-8hvvyd">One, is there enough supply to build them? Two is control over that supply, a way to think about safety issues or a way to think about balance of geopolitical power. And three, if those chips are used to build data centers, where are those data centers going to be? Are they going to be in the U.S.? Are they going to be in a U.S. ally? Are they going to be in the Middle East? Are they going to be in China?</p><p class="css-8hvvyd">All of those have enormous implications, and then the supply chain itself can be disrupted. And political and military decisions can be made on the basis of where things are. So it sounds like an incredibly sticky problem to me. I don’t know that I have any great insight on this. I mean, as a U.S. citizen and someone who believes in democracy, I am someone who hopes that we can find a way to build data centers and to have the largest quantity of chips available in the U.S. and allied democratic countries.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Well, there is some insight you should have into it, which is that you’re a customer here, right? And so, five years ago, the people making these chips did not realize what the level of demand for them was going to be. I mean, what has happened to Nvidia’s stock prices is really remarkable.</p><p class="css-8hvvyd">But also what is implied about the future of Nvidia’s stock prices is really remarkable. Rana Foroohar, the Financial Times, cited this market analysis. It would take 4,500 years for Nvidia’s future dividends to equal its current price, 4,500 years. So that is a view about how much Nvidia is going to be making in the next couple of years. It is really quite astounding.</p><p class="css-8hvvyd">I mean, you’re, in theory, already working on or thinking about how to work on the next generation of Claude. You’re going to need a lot of chips for that. You’re working with Amazon. Are you having trouble getting the amount of compute that you feel you need? I mean, are you already bumping up against supply constraints? Or has the supply been able to change, to adapt to you?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">We’ve been able to get the compute that we need for this year, I suspect also for next year as well. I think once things get to 2026, 2027, 2028, then the amount of compute gets to levels that starts to strain the capabilities of the semiconductor industry. The semiconductor industry still mostly produces C.P.U.s, right? Just the things in your laptop, not the things in the data centers that train the A.I. models. But as the economic value of the GPUs goes up and up and up because of the value of the A.I. models, that’s going to switch over. But you know what? At some point, you hit the limits of that or you hit the limits of how fast you can switch over. And so, again, I expect there to be a big supply crunch around data centers, around chips, and around energy and power for both regulatory and physics reasons, sometime in the next few years. And that’s a risk, but it’s also an opportunity. I think it’s an opportunity to think about how the technology can be governed.</p><p class="css-8hvvyd">And it’s also an opportunity, I’ll repeat again, to think about how democracies can lead. I think it would be very dangerous if the leaders in this technology and the holders of the main resources were authoritarian countries. The combination of A.I. and authoritarianism, both internally and on the international stage, is very frightening to me.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">How about the question of energy? I mean, this requires just a tremendous amount of energy. And I mean, I’ve seen different numbers like this floating around. It very much could be in the coming years like adding a Bangladesh to the world’s energy usage. Or pick your country, right? I don’t know what exactly you all are going to be using by 2028.</p><p class="css-8hvvyd">Microsoft, on its own, is opening a new data center globally every three days. You have — and this is coming from a Financial Times article — federal projections for 20 new gas-fired power plants in the U.S. by 2024 to 2025. There’s a lot of talk about this being now a new golden era for natural gas because we have a bunch of it. There is this huge need for new power to manage all this data, to manage all this compute.</p><p class="css-8hvvyd">So, one, I feel like there’s a literal question of how do you get the energy you need and at what price, but also a more kind of moral, conceptual question of, we have real problems with global warming. We have real problems with how much energy we’re using. And here, we’re taking off on this really steep curve of how much of it we seem to be needing to devote to the new A.I. race.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">It really comes down to, what are the uses that the model is being put to, right? So I think the worrying case would be something like crypto, right? I’m someone who’s not a believer that whatever the energy was that was used to mine the next Bitcoin, I think that was purely additive. I think that wasn’t there before. And I’m unable to think of any useful thing that’s created by that.</p><p class="css-8hvvyd">But I don’t think that’s the case with A.I. Maybe A.I. makes solar energy more efficient or maybe it solves controlled nuclear fusion, or maybe it makes geoengineering more stable or possible. But I don’t think we need to rely on the long run. There are some applications where the model is doing something that used to be automated, that used to be done by computer systems. And the model is able to do it faster with less computing time, right? Those are pure wins. And there are some of those.</p><p class="css-8hvvyd">There are others where it’s using the same amount of computing resources or maybe more computing resources, but to do something more valuable that saves labor elsewhere. Then there are cases where something used to be done by humans or in the physical world, and now it’s being done by the models. Maybe it does something that previously I needed to go into the office to do that thing. And now I no longer need to go into the office to do that thing.</p><p class="css-8hvvyd">So I don’t have to get in my car. I don’t have to use the gas that was used for that. The energy accounting for that is kind of hard. You compare it to the food that the humans eat and what the energy cost of producing that.</p><p class="css-8hvvyd">So in all honesty, I don’t think we have good answers about what fraction of the usage points one way and one fraction of the usage points to others. In many ways, how different is this from the general dilemma of, as the economy grows, it uses more energy?</p><p class="css-8hvvyd">So I guess, what I’m saying is, it kind of all matters how you use the technology. I mean, my kind of boring short-term answer is, we get carbon offsets for all of this stuff. But let’s look beyond that to the macro question here.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">But to take the other side of it, I mean, I think the difference, when you say this is always a question we have when we’re growing G.D.P., is it’s not quite. It’s cliché because it’s true to say that the major global warming challenge right now is countries like China and India getting richer. And we want them to get richer. It is a huge human imperative, right, a moral imperative for poor people in the world to become less poor. And if that means they use more energy, then we just need to figure out how to make that work. And we don’t know of a way for that to happen without them using more energy.</p><p class="css-8hvvyd">Adding A.I. is not that it raises a whole different set of questions, but we’re already straining at the boundaries, or maybe far beyond them, of safely what we can do energetically. Now we add in this, and so maybe some of the energy efficiency gains you’re going to get in rich countries get wiped out. For this sort of uncertain payoff in the future of maybe through A.I., we figure out ways to stabilize nuclear fusion or something, right, you could imagine ways that could help, but those ways are theoretical.</p><p class="css-8hvvyd">And in the near term, the harm in terms of energy usage is real. And also, by the way, the harm in terms of just energy prices. It’s also just tricky because all these companies, Microsoft, Amazon, I mean, they all have a lot of renewable energy targets. Now if that is colliding with their market incentives, it feels like they’re running really fast towards the market incentives without an answer for how all that nets out.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, I mean, I think the concerns are real. Let me push back a little bit, which is, again, I don’t think the benefits are purely in the future. It kind of goes back to what I said before. Like, there may be use cases now that are net energy saving, or that to the extent that they’re not net energy saving, do so through the general mechanism of, oh, there was more demand for this thing.</p><p class="css-8hvvyd">I don’t think anyone has done a good enough job measuring, in part because the applications of A.I. are so new, which of those things dominate or what’s going to happen to the economy. But I don’t think we should assume that the harms are entirely in the present and the benefits are entirely in the future. I think that’s my only point here.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I guess you could imagine a world where we were, somehow or another, incentivizing uses of A.I. that were yoked to some kind of social purpose. We were putting a lot more into drug discovery, or we cared a lot about things that made remote work easier, or pick your set of public goods.</p><p class="css-8hvvyd">But what actually seems to me to be happening is we’re building more and more and more powerful models and just throwing them out there within a terms of service structure to say, use them as long as you’re not trying to politically manipulate people or create a bioweapon. Just try to figure this out, right? Try to create new stories and ask it about your personal life, and make a video game with it. And Sora comes out sooner or later. Make new videos with it. And all that is going to be very energy intensive.</p><p class="css-8hvvyd">I am not saying that I have a plan for yoking A.I. to social good, and in some ways, you can imagine that going very, very wrong. But it does mean that for a long time, it’s like you could imagine the world you’re talking about, but that would require some kind of planning that nobody is engaged in, and I don’t think anybody even wants to be engaged in.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Not everyone has the same conception of social good. One person may think social good is this ideology. Another person — we’ve seen that with some of the Gemini stuff.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Right.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">But companies can try to make beneficial applications themselves, right? Like, this is why we’re working with cancer institutes. We’re hoping to partner with ministries of education in Africa, to see if we can use the models in kind of a positive way for education, rather than the way they may be used by default. So I think individual companies, individual people, can take actions to steer or bend this towards the public good.</p><p class="css-8hvvyd">That said, it’s never going to be the case that 100 percent of what we do is that. And so I think it’s a good question. What are the societal incentives, without dictating ideology or defining the public good from on high, what are incentives that could help with this?</p><p class="css-8hvvyd">I don’t feel like I have a systemic answer either. I can only think in terms of what Anthropic tries to do.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">But there’s also the question of training data and the intellectual property that is going into things like Claude, like GPT, like Gemini. There are a number of copyright lawsuits. You’re facing some. OpenAI is facing some. I suspect everybody is either facing them now or will face them.</p><p class="css-8hvvyd">And a broad feeling that these systems are being trained on the combined intellectual output of a lot of different people — the way that Claude can quite effectively mimic the way I write is it has been trained, to some degree, on my writing, right? So it actually does get my stylistic tics quite well. You seem great, but you haven’t sent me a check on that. And this seems like somewhere where there is real liability risk for the industry. Like, what if you do actually have to compensate the people who this is being trained on? And should you?</p><p class="css-8hvvyd">And I recognize you probably can’t comment on lawsuits themselves, but I’m sure you’ve had to think a lot about this. And so, I’m curious both how you understand it as a risk, but also how you understand it morally. I mean, when you talk about the people who invent these systems gaining a lot of power, and alongside that, a lot of wealth, well, what about all the people whose work went into them such that they can create images in a million different styles? And I mean, somebody came up with those styles. What is the responsibility back to the intellectual commons? And not just to the commons, but to the actual wages and economic prospects of the people who made all this possible?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I think everyone agrees the models shouldn’t be verbatim outputting copyrighted content. For things that are available on the web, for publicly available, our position — and I think there’s a strong case for it — is that the training process, again, we don’t think it’s just hoovering up content and spitting it out, or it shouldn’t be spitting it out. It’s really much more like the process of how a human learns from experiences. And so, our position that that is sufficiently transformative, and I think the law will back this up, that this is fair use.</p><p class="css-8hvvyd">But those are narrow legal ways to think about the problem. I think we have a broader issue, which is that regardless of how it was trained, it would still be the case that we’re building more and more general cognitive systems, and that those systems will create disruption. Maybe not necessarily by one for one replacing humans, but they’re really going to change how the economy works and which skills are valued. And we need a solution to that broad macroeconomic problem, right?</p><p class="css-8hvvyd">As much as I’ve asserted the narrow legal points that I asserted before, we have a broader problem here, and we shouldn’t be blind to that. There’s a number of solutions. I mean, I think the simplest one, which I recognize doesn’t address some of the deeper issues here, is things around the kind of guaranteed basic income side of things.</p><p class="css-8hvvyd">But I think there’s a deeper question here, which is like as A.I. systems become capable of larger and larger slices of cognitive labor, how does society organize itself economically? How do people find work and meaning and all of that?</p><p class="css-8hvvyd">And just as kind of we transition from an agrarian society to an industrial society and the meaning of work changed, and it was no longer true that 99 percent of people were peasants working on farms and had to find new methods of economic organization, I suspect there’s some different method of economic organization that’s going to be forced as the only possible response to disruptions to the economy that will be small at first, but will grow over time, and that we haven’t worked out what that is.</p><p class="css-8hvvyd">We need to find something that allows people to find meaning that’s humane and that maximizes our creativity and potential and flourishing from A.I.</p><p class="css-8hvvyd">And as with many of these questions, I don’t have the answer to that. Right? I don’t have a prescription. But that’s what we somehow need to do.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">But I want to sit in between the narrow legal response and the broad “we have to completely reorganize society” response, although I think that response is actually possible over the decades. And in the middle of that is a more specific question. I mean, you could even take it from the instrumental side. There is a lot of effort now to build search products that use these systems, right? ChatGPT will use Bing to search for you.</p><p class="css-8hvvyd">And that means that the person is not going to Bing and clicking on the website where ChatGPT is getting its information and giving that website an advertising impression that they can turn into a very small amount of money, or they’re not going to that website and having a really good experience with that website and becoming maybe likelier to subscribe to whoever is behind that website.</p><p class="css-8hvvyd">And so, on the one hand, that seems like some kind of injustice done to the people creating the information that these systems are using. I mean, this is true for perplexity. It’s true for a lot of things I’m beginning to see around where the A.I.s are either trained on or are using a lot of data that people have generated at some real cost. But not only are they not paying people for that, but they’re actually stepping into the middle of where they would normally be a direct relationship and making it so that relationship never happens.</p><p class="css-8hvvyd">That also, I think, in the long run, creates a training data problem, even if you just want to look at it instrumentally, where if it becomes nonviable to do journalism or to do a lot of things to create high quality information out there, the A.I.‘s ability, right, the ability of all of your companies to get high quality, up-to-date, constantly updated information becomes a lot trickier. So there both seems to me to be both a moral and a self-interested dimension to this.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, so I think there may be business models that work for everyone, not because it’s illegitimate to train on open data from the web in a legal sense, but just because there may be business models here that kind of deliver a better product. So things I’m thinking of are like newspapers have archives. Some of them aren’t publicly available. But even if they are, it may be a better product, maybe a better experience, to, say, talk to this newspaper or talk to that newspaper.</p><p class="css-8hvvyd">It may be a better experience to give the ability to interact with content and point to places in the content, and every time you call that content, to have some kind of business relationship with the creators of that content. So there may be business models here that propagate the value in the right way, right? You talk about LLMs using search products. I mean, sure, you’re going around the ads, but there’s no reason it can’t work in a different way, right?</p><p class="css-8hvvyd">There’s no reason that the users can’t pay the search A.P.I.s, instead of it being paid through advertising, and then have that propagate through to wherever the original mechanism is that paid the creators of the content. So when value is being created, money can flow through.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Let me try to end by asking a bit about how to live on the slope of the curve you believe we are on. Do you have kids?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I’m married. I do not have kids.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So I have two kids. I have a two-year-old and a five-year-old. And particularly when I’m doing A.I. reporting, I really do sit in bed at night and think, what should I be doing here with them? What world am I trying to prepare them for? And what is needed in that world that is different from what is needed in this world, even if I believe there’s some chance — and I do believe there’s some chance — that all the things you’re saying are true. That implies a very, very, very different life for them.</p><p class="css-8hvvyd">I know people in your company with kids. I know they are thinking about this. How do you think about that? I mean, what do you think should be different in the life of a two-year-old who is living through the pace of change that you are telling me is true here? If you had a kid, how would this change the way you thought about it?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">The very short answer is, I don’t know, and I have no idea, but we have to try anyway, right? People have to raise kids, and they have to do it as best they can. An obvious recommendation is just familiarity with the technology and how it works, right? The basic paradigm of, I’m talking to systems, and systems are taking action on my behalf, obviously, as much familiarity with that as possible is, I think, helpful.</p><p class="css-8hvvyd">In terms of what should children learn in school, what are the careers of tomorrow, I just truly don’t know, right? You could take this to say, well, it’s important to learn STEM and programming and A.I. and all of that. But A.I. will impact that as well, right? I don’t think any of it is going to —</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Possibly first.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Yeah, right, possibly first.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">It seems better at coding than it is at other things.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I don’t think it’s going to work out for any of these systems to just do one for one what humans are going to do. I don’t really think that way. But I think it may fundamentally change industries and professions one by one in ways that are hard to predict. And so, I feel like I only have clichés here. Like get familiar with the technology. Teach your children to be adaptable, to be ready for a world that changes very quickly. I wish I had better answers, but I think that’s the best I got.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I agree that’s not a good answer. [LAUGHS] Let me ask that same question a bit from another direction, because one thing you just said is get familiar with the technology. And the more time I spend with the technology, the more I fear that happening. What I see when people use A.I. around me is that the obvious thing that technology does for you is automate the early parts of the creative process. The part where you’re supposed to be reading something difficult yourself? Well, the A.I. can summarize it for you. The part where you’re supposed to sit there with a blank page and write something? Well, the A.I. can give you a first draft. And later on, you have to check it and make sure it actually did what you wanted it to do and fact-checking it. And but I believe a lot of what makes humans good at thinking comes in those parts.</p><p class="css-8hvvyd">And I am older and have self-discipline, and maybe this is just me hanging on to an old way of doing this, right? You could say, why use a calculator from this perspective. But my actual worry is that I’m not sure if the thing they should do is use A.I. a lot or use it a little. This, to me, is actually a really big branching path, right? Do I want my kids learning how to use A.I. or being in a context where they’re using it a lot, or actually, do I want to protect them from it as much as I possibly could so they develop more of the capacity to read a book quietly on their own or write a first draft? I actually don’t know. I’m curious if you have a view on it.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I think this is part of what makes the interaction between A.I. and society complicated where it’s sometimes hard to distinguish when is an A.I. doing something, saving you labor or drudge work, versus kind of doing the interesting part. I will say that over and over again, you’ll get some technological thing, some technological system that does what you thought was the core of what you’re doing, and yet, what you’re doing turns out to have more pieces than you think it does and kind of add up to more things, right?</p><p class="css-8hvvyd">It’s like before, I used to have to ask for directions. I got Google Maps to do that. And you could worry, am I too reliant on Google Maps? Do I forget the environment around me? Well, it turns out, in some ways, I still need to have a sense of the city and the environment around me. It just kind of reallocates the space in my brain to some other aspect of the task.</p><p class="css-8hvvyd">And I just kind of suspect — I don’t know. Internally, within Anthropic, one of the things I do that helps me run the company is, I’ll write these documents on strategy or just some thinking in some direction that others haven’t thought. And of course, I sometimes use the internal models for that. And I think what I found is like, yes, sometimes they’re a little bit good at conceptualizing the idea, but the actual genesis of the idea, I’ve just kind of found a workflow where I don’t use them for that. They’re not that helpful for that. But they’re helpful in figuring out how to phrase a certain thing or how to refine my ideas.</p><p class="css-8hvvyd">So maybe I’m just saying — I don’t know. You just find a workflow where the thing complements you. And if it doesn’t happen naturally, it somehow still happens eventually. Again, if the systems get general enough, if they get powerful enough, we may need to think along other lines. But in the short-term, I, at least, have always found that. Maybe that’s too sanguine. Maybe that’s too optimistic.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">I think, then, that’s a good place to end this conversation. Though, obviously, the exponential curve continues. So always our final question — what are three books you’d recommend to the audience?</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">So, yeah, I’ve prepared three. They’re all topical, though, in some cases, indirectly so. The first one will be obvious. It’s a very long book. The physical book is very thick, but “The Making of the Atomic Bomb,” Richard Rhodes. It’s an example of technology being developed very quickly and with very broad implications. Just looking through all the characters and how they reacted to this and how people who were basically scientists gradually realized the incredible implications of the technology and how it would lead them into a world that was very different from the one they were used to.</p><p class="css-8hvvyd">My second recommendation is a science fiction series, “The Expanse” series of books. So I initially watched the show, and then I read all the books. And the world it creates is very advanced. In some cases, it has longer life spans, and humans have expanded into space. But we still face some of the same geopolitical questions and some of the same inequalities and exploitations that exist in our world, are still present, in some cases, worse.</p><p class="css-8hvvyd">That’s all the backdrop of it.</p><p class="css-8hvvyd">And the core of it is about some fundamentally new technological object that is being brought into that world and how everyone reacts to it, how governments react to it, how individual people react to it, and how political ideologies react to it. And so, I don’t know. When I read that a few years ago, I saw a lot of parallels.</p><p class="css-8hvvyd">And then my third recommendation would be actually “The Guns of August,” which is basically a history of how World War I started. The basic idea that crises happen very fast, almost no one knows what’s going on. There are lots of miscalculations because there are humans at the center of it, and kind of, we somehow have to learn to step back and make wiser decisions in these key moments. It’s said that Kennedy read the book before the Cuban Missile Crisis. And so I hope our current policymakers are at least thinking along the same terms because I think it is possible similar crises may be coming our way.</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Dario Amodei, thank you very much.</p></dd><dt class="css-xx7kwh">dario amodei</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">Thank you for having me.</p><p class="css-8hvvyd">[MUSIC PLAYING]</p></dd><dt class="css-xx7kwh">ezra klein</dt><dd class="css-4gvq6l"><p class="css-8hvvyd">This episode of “The Ezra Klein Show” was produced by Rollin Hu. Fact-checking by Michelle Harris. Our senior engineer is Jeff Geld. Our senior editor is Claire Gordon. The show’s production team also includes Annie Galvin, Kristin Lin and Aman Sahota. Original music by Isaac Jones. Audience strategy by Kristina Samulewski and Shannon Busta. The executive producer of New York Times Opinion Audio is Annie-Rose Strasser. And special thanks to Sonia Herrero.</p></dd></dl></div></div></div></div><div style="position:absolute;width:0;height:0;visibility:hidden;display:none"></div><header class="css-1vwfk9f" data-breakpoint=""><div class="css-8atqhb" data-testid="default-mobile-layout"><div style="background-image:url(https://static01.nyt.com/images/2023/04/05/podcasts/ezra-klein-album-art/ezra-klein-album-art-articleLarge-v3.jpg)" class="css-13r7n3o ezxp09g0"><div class="css-83wln0"><div class="css-1w9agjg" role="button" tabindex="0"></div><div class="css-1unwftr"><div class="css-s220l9 e1q64sp80"><a href="https://www.nytimes.com/column/ezra-klein-podcast"><img class="css-3ca3tv" alt="The Ezra Klein Show logo" src="https://static01.nyt.com/images/2023/04/05/podcasts/ezra-klein-album-art/ezra-klein-album-art-square320-v2.jpg"/><span class="css-15f7ed6 e1q64sp81">The Ezra Klein Show</span></a><ul class="css-b6bqam"><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/04/30/opinion/ezra-klein-podcast-hannah-ritchie.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">April 30, 2024<span>  •  <!-- -->1:03:00</span></time><div class="css-va8yei e1q64sp82">Cows Are Just an Environmental Disaster</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/04/26/opinion/ezra-klein-podcast-salman-rushdie.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">April 26, 2024</time><div class="css-va8yei e1q64sp82">Salman Rushdie Is Not Who You Think He Is</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/04/23/opinion/ezra-klein-podcast-adam-moss.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">April 23, 2024<span>  •  <!-- -->56:06</span></time><div class="css-va8yei e1q64sp82">This Conversation Made Me a Sharper Editor</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/04/16/opinion/ezra-klein-podcast-jerusalem-demsas.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">April 16, 2024<span>  •  <!-- -->49:17</span></time><div class="css-va8yei e1q64sp82">A $1.7 Million Toilet and Liberalism’s Failure to Build</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">April 12, 2024<span>  •  <!-- -->1:33:07</span></time><div class="css-va8yei e1q64sp82">What if Dario Amodei Is Right About A.I.?</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/04/05/opinion/ezra-klein-podcast-nilay-patel.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">April 5, 2024<span>  •  <!-- -->1:25:33</span></time><div class="css-va8yei e1q64sp82">Will A.I. Break the Internet? Or Save It?</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/04/02/opinion/ezra-klein-podcast-ethan-mollick.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">April 2, 2024<span>  •  <!-- -->1:14:31</span></time><div class="css-va8yei e1q64sp82">How Should I Be Using A.I. Right Now?</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/03/29/opinion/ezra-klein-podcast-john-ganz.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">March 29, 2024<span>  •  <!-- -->1:18:30</span></time><div class="css-va8yei e1q64sp82">The Rise of ‘Middle-Finger Politics’</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/03/22/opinion/ezra-klein-podcast-caitlyn-collins.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">March 22, 2024<span>  •  <!-- -->1:08:32</span></time><div class="css-va8yei e1q64sp82">The Deep Conflict Between Our Work and Parenting Ideals</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/03/19/opinion/ezra-klein-podcast-jennifer-sciubba.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">March 19, 2024<span>  •  <!-- -->1:03:11</span></time><div class="css-va8yei e1q64sp82">Birthrates Are Plummeting Worldwide. Why?</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/03/12/opinion/ezra-klein-podcast-sotu.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">March 12, 2024<span>  •  <!-- -->1:03:52</span></time><div class="css-va8yei e1q64sp82">What a Second Biden Term Would Look Like</div></div></a></li><li class="css-1nz2xi2"><a href="https://www.nytimes.com/2024/03/08/opinion/ezra-klein-podcast-mary-ziegler.html"><button class="css-1bykrda"><svg width="40" height="40" viewBox="0 0 40 40" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M9.91667 5.83333L0 11.6667V0L9.91667 5.83333Z" transform="translate(17.082 14.1666)" fill="#F8F8F8"></path></svg></button><div class="css-1qq8bvn"><time class="css-lzc52a">March 8, 2024<span>  •  <!-- -->1:00:40</span></time><div class="css-va8yei e1q64sp82">How America’s Two Abortion Realities Are Clashing</div></div></a></li></ul></div></div></div></div><div class="css-138971x"><div class="css-13glguy"><h1 class="css-x1iy13">What if Dario Amodei Is Right About A.I.?</h1><h2 class="css-1dqxzif">Anthropic’s co-founder and C.E.O. explains why he thinks artificial intelligence is on an “exponential curve.”</h2><p class="css-5kewg3"></p></div></div></div></header><script type="application/ld+json">{"@context":"https://schema.org","@type":"AudioObject","@id":"https://nyt.simplecastaudio.com/3026b665-46df-4d18-98e9-d1ce16bbb1df/episodes/223c172c-1566-4efe-9f19-f5be27f41e45/audio/128/default.mp3?awCollectionId=3026b665-46df-4d18-98e9-d1ce16bbb1df&awEpisodeId=223c172c-1566-4efe-9f19-f5be27f41e45&nocache","description":"Anthropic’s co-founder and C.E.O. explains why he thinks artificial intelligence is on an “exponential curve.”","name":"What if Dario Amodei Is Right About A.I.?","contentUrl":"https://nyt.simplecastaudio.com/3026b665-46df-4d18-98e9-d1ce16bbb1df/episodes/223c172c-1566-4efe-9f19-f5be27f41e45/audio/128/default.mp3?awCollectionId=3026b665-46df-4d18-98e9-d1ce16bbb1df&awEpisodeId=223c172c-1566-4efe-9f19-f5be27f41e45&nocache","uploadDate":"2024-04-11T21:59:22.000Z","transcript":"[MUSIC PLAYING] From New York Times Opinion, this is \"The Ezra Klein Show.\" [MUSIC PLAYING] The really disorienting thing about talking to the people building A.I. is their altered sense of time. You're sitting there discussing some world that feels like weird sci-fi to even talk about, and then you ask, well, when do you think this is going to happen? And they say, I don't know -- two years. Behind those predictions are what are called the scaling laws. And the scaling laws -- and I want to say this so clearly -- they're not laws. They're observations. They're predictions. They're based off of a few years, not a few hundred years or 1,000 years of data. But what they say is that the more computer power and data you feed into A.I. systems, the more powerful those systems get -- that the relationship is predictable, and more, that the relationship is exponential. Human beings have trouble thinking in exponentials. Think back to Covid, when we all had to do it. If you have one case of coronavirus and cases double every three days, then after 30 days, you have about 1,000 cases. That growth rate feels modest. It's manageable. But then you go 30 days longer, and you have a million. Then you wait another 30 days. Now you have a billion. That's the power of the exponential curve. Growth feels normal for a while. Then it gets out of control really, really quickly. What the A.I. developers say is that the power of A.I. systems is on this kind of curve, that it has been increasing exponentially, their capabilities, and that as long as we keep feeding in more data and more computing power, it will continue increasing exponentially. That is the scaling law hypothesis, and one of its main advocates is Dario Amodei. Amodei led the team at OpenAI that created GPT-2, that created GPT-3. He then left OpenAI to co-found Anthropic, another A.I. firm, where he's now the C.E.O. And Anthropic recently released Claude 3, which is considered by many to be the strongest A.I. model available right now. But Amodei believes we're just getting started, that we're just hitting the steep part of the curve now. He thinks the kinds of systems we've imagined in sci-fi, they're coming not in 20 or 40 years, not in 10 or 15 years, they're coming in two to five years. He thinks they're going to be so powerful that he and people like him should not be trusted to decide what they're going to do. So I asked him on this show to try to answer in my own head two questions. First, is he right? Second, what if he's right? I want to say that in the past, we have done shows with Sam Altman, the head of OpenAI, and Demis Hassabis, the head of Google DeepMind. And it's worth listening to those two if you find this interesting. We're going to put the links to them in show notes because comparing and contrasting how they talk about the A.I. curves here, how they think about the politics -- you'll hear a lot about that in the Sam Altman episode -- it gives you a kind of sense of what the people building these things are thinking and how maybe they differ from each other. As always, my email for thoughts, for feedback, for guest suggestions -- ezrakleinshow@nytimes.com. [MUSIC PLAYING] Dario Amodei, welcome to the show. Thank you for having me. So there are these two very different rhythms I've been thinking about with A.I. One is the curve of the technology itself, how fast it is changing and improving. And the other is the pace at which society is seeing and reacting to those changes. What has that relationship felt like to you? So I think this is an example of a phenomenon that we may have seen a few times before in history, which is that there's an underlying process that is smooth, and in this case, exponential. And then there's a spilling over of that process into the public sphere. And the spilling over looks very spiky. It looks like it's happening all of a sudden. It looks like it comes out of nowhere. And it's triggered by things hitting various critical points or just the public happened to be engaged at a certain time. So I think the easiest way for me to describe this in terms of my own personal experience is -- so I worked at OpenAI for five years, I was one of the first employees to join. And they built a model in 2018 called GPT-1, which used something like 100,000 times less computational power than the models we build today. I looked at that, and I and my colleagues were among the first to run what are called scaling laws, which is basically studying what happens as you vary the size of the model, its capacity to absorb information, and the amount of data that you feed into it. And we found these very smooth patterns. And we had this projection that, look, if you spend $100 million or $1 billion or $10 billion on these models, instead of the $10,000 we were spending then, projections that all of these wondrous things would happen, and we imagined that they would have enormous economic value. Fast forward to about 2020. GPT-3 had just come out. It wasn't yet available as a chat bot. I led the development of that along with the team that eventually left to join Anthropic. And maybe for the whole period of 2021 and 2022, even though we continued to train models that were better and better, and OpenAI continued to train models, and Google continued to train models, there was surprisingly little public attention to the models. And I looked at that, and I said, well, these models are incredible. They're getting better and better. What's going on? Why isn't this happening? Could this be a case where I was right about the technology, but wrong about the economic impact, the practical value of the technology? And then, all of a sudden, when ChatGPT came out, it was like all of that growth that you would expect, all of that excitement over three years, broke through and came rushing in. So I want to linger on this difference between the curve at which the technology is improving and the way it is being adopted by society. So when you think about these break points and you think into the future, what other break points do you see coming where A.I. bursts into social consciousness or used in a different way? Yeah, so I think I should say first that it's very hard to predict these. One thing I like to say is the underlying technology, because it's a smooth exponential, it's not perfectly predictable, but in some ways, it can be eerily preternaturally predictable, right? That's not true for these societal step functions at all. It's very hard to predict what will catch on. In some ways, it feels a little bit like which artist or musician is going to catch on and get to the top of the charts. That said, a few possible ideas. I think one is related to something that you mentioned, which is interacting with the models in a more kind of naturalistic way. We've actually already seen some of that with Claude 3, where people feel that some of the other models sound like a robot and that talking to Claude 3 is more natural. I think a thing related to this is, a lot of companies have been held back or tripped up by how their models handle controversial topics. And we were really able to, I think, do a better job than others of telling the model, don't shy away from discussing controversial topics. Don't assume that both sides necessarily have a valid point but don't express an opinion yourself. Don't express views that are flagrantly biased. As journalists, you encounter this all the time, right? How do I be objective, but not both sides on everything? So I think going further in that direction of models having personalities while still being objective, while still being useful and not falling into various ethical traps, that will be, I think, a significant unlock for adoption. The models taking actions in the world is going to be a big one. I know basically all the big companies that work on A.I. are working on that. Instead of just, I ask it a question and it answers, and then maybe I follow up and it answers again, can I talk to the model about, oh, I'm going to go on this trip today, and the model says, oh, that's great. I'll get an Uber for you to drive from here to there, and I'll reserve a restaurant. And I'll talk to the other people who are going to plan the trip. And the model being able to do things end to end or going to websites or taking actions on your computer for you. I think all of that is coming in the next, I would say -- I don't know -- three to 18 months, with increasing levels of ability. I think that's going to change how people think about A.I., right, where so far, it's been this very passive -- it's like, I go to the Oracle. I ask it a question, and the Oracle tells me things. And some people think that's exciting, some people think it's scary. But I think there are limits to how exciting or how scary it's perceived as because it's contained within this box. I want to sit with this question of the agentic A.I. because I do think this is what's coming. It's clearly what people are trying to build. And I think it might be a good way to look at some of the specific technological and cultural challenges. And so, let me offer two versions of it. People who are following the A.I. news might have heard about Devin, which is not in release yet, but is an A.I. that at least purports to be able to complete the kinds of tasks, linked tasks, that a junior software engineer might complete, right? Instead of asking to do a bit of code for you, you say, listen, I want a website. It's going to have to do these things, work in these ways. And maybe Devin, if it works the way people are saying it works, can actually hold that set of thoughts, complete a number of different tasks, and come back to you with a result. I'm also interested in the version of this that you might have in the real world. The example I always use in my head is, when can I tell an A.I., my son is turning five. He loves dragons. We live in Brooklyn. Give me some options for planning his birthday party. And then, when I choose between them, can you just do it all for me? Order the cake, reserve the room, send out the invitations, whatever it might be. Those are two different situations because one of them is in code, and one of them is making decisions in the real world, interacting with real people, knowing if what it is finding on the websites is actually any good. What is between here and there? When I say that in plain language to you, what technological challenges or advances do you hear need to happen to get there? The short answer is not all that much. A story I have from when we were developing models back in 2022 -- and this is before we'd hooked up the models to anything -- is, you could have a conversation with these purely textual models where you could say, hey, I want to reserve dinner at restaurant X in San Francisco, and the model would say, OK, here's the website of restaurant X. And it would actually give you a correct website or would tell you to go to Open Table or something. And of course, it can't actually go to the website. The power plug isn't actually plugged in, right? The brain of the robot is not actually attached to its arms and legs. But it gave you this sense that the brain, all it needed to do was learn exactly how to use the arms and legs, right? It already had a picture of the world and where it would walk and what it would do. And so, it felt like there was this very thin barrier between the passive models we had and actually acting in the world. In terms of what we need to make it work, one thing is, literally, we just need a little bit more scale. And I think the reason we're going to need more scale is -- to do one of those things you described, to do all the things a junior software engineer does, they involve chains of long actions, right? I have to write this line of code. I have to run this test. I have to write a new test. I have to check how it looks in the app after I interpret it or compile it. And these things can easily get 20 or 30 layers deep. And same with planning the birthday party for your son, right? And if the accuracy of any given step is not very high, is not like 99.9 percent, as you compose these steps, the probability of making a mistake becomes itself very high. So the industry is going to get a new generation of models every probably four to eight months. And so, my guess -- I'm not sure -- is that to really get these things working well, we need maybe one to four more generations. So that ends up translating to 3 to 24 months or something like that. I think second is just, there is some algorithmic work that is going to need to be done on how to have the models interact with the world in this way. I think the basic techniques we have, a method called reinforcement learning and variations of it, probably is up to the task, but figuring out exactly how to use it to get the results we want will probably take some time. And then third, I think -- and this gets to something that Anthropic really specializes in -- is safety and controllability. And I think that's going to be a big issue for these models acting in the world, right? Let's say this model is writing code for me, and it introduces a serious security bug in the code, or it's taking actions on the computer for me and modifying the state of my computer in ways that are too complicated for me to even understand. And for planning the birthday party, right, the level of trust you would need to take an A.I. agent and say, I'm OK with you calling up anyone, saying anything to them that's in any private information that I might have, sending them any information, taking any action on my computer, posting anything to the internet, the most unconstrained version of that sounds very scary. And so, we're going to need to figure out what is safe and controllable. The more open ended the thing is, the more powerful it is, but also, the more dangerous it is and the harder it is to control. So I think those questions, although they sound lofty and abstract, are going to turn into practical product questions that we and other companies are going to be trying to address. When you say we're just going to need more scale, you mean more compute and more training data, and I guess, possibly more money to simply make the models smarter and more capable? Yes, we're going to have to make bigger models that use more compute per iteration. We're going to have to run them for longer by feeding more data into them. And that number of chips times the amount of time that we run things on chips is essentially dollar value because these chips are -- you rent them by the hour. That's the most common model for it. And so, today's models cost of order $100 million to train, plus or minus factor two or three. The models that are in training now and that will come out at various times later this year or early next year are closer in cost to $1 billion. So that's already happening. And then I think in 2025 and 2026, we'll get more towards $5 or $10 billion. So we're moving very quickly towards a world where the only players who can afford to do this are either giant corporations, companies hooked up to giant corporations -- you all are getting billions of dollars from Amazon. OpenAI is getting billions of dollars from Microsoft. Google obviously makes its own. You can imagine governments -- though I don't know of too many governments doing it directly, though some, like the Saudis, are creating big funds to invest in the space. When we're talking about the model's going to cost near to $1 billion, then you imagine a year or two out from that, if you see the same increase, that would be $10-ish billion. Then is it going to be $100 billion? I mean, very quickly, the financial artillery you need to create one of these is going to wall out anyone but the biggest players. I basically do agree with you. I think it's the intellectually honest thing to say that building the big, large scale models, the core foundation model engineering, it is getting more and more expensive. And anyone who wants to build one is going to need to find some way to finance it. And you've named most of the ways, right? You can be a large company. You can have some kind of partnership of various kinds with a large company. Or governments would be the other source. I think one way that it's not correct is, we're always going to have a thriving ecosystem of experimentation on small models. For example, the open source community working to make models that are as small and as efficient as possible that are optimized for a particular use case. And also downstream usage of the models. I mean, there's a blooming ecosystem of startups there that don't need to train these models from scratch. They just need to consume them and maybe modify them a bit. Now, I want to ask a question about what is different between the agentic coding model and the plan by kids' birthday model, to say nothing of do something on behalf of my business model. And one of the questions on my mind here is one reason I buy that A.I. can become functionally superhuman in coding is, there's a lot of ways to get rapid feedback in coding. Your code has to compile. You can run bug checking. You can actually see if the thing works. Whereas the quickest way for me to know that I'm about to get a crap answer from ChatGPT 4 is when it begins searching Bing, because when it begins searching Bing, it's very clear to me it doesn't know how to distinguish between what is high quality on the internet and what isn't. To be fair, at this point, it also doesn't feel to me like Google Search itself is all that good at distinguishing that. So the question of how good the models can get in the world where it's a very vast and fuzzy dilemma to know what the right answer is on something -- one reason I find it very stressful to plan my kid's birthday is it actually requires a huge amount of knowledge about my child, about the other children, about how good different places are, what is a good deal or not, how just stressful will this be on me. There's all these things that I'd have a lot of trouble encoding into a model or any kind set of instructions. Is that right, or am I overstating the difficulty of understanding human behavior and various kinds of social relationships? I think it's correct and perceptive to say that the coding agents will advance substantially faster than agents that interact with the real world or have to get opinions and preferences from humans. That said, we should keep in mind that the current crop of A.I.s that are out there, right, including Claude 3, GPT, Gemini, they're all trained with some variant of what's called reinforcement learning from human feedback. And this involves exactly hiring a large crop of humans to rate the responses of the model. And so, that's to say both this is difficult, right? We pay lots of money, and it's a complicated operational process to gather all this human feedback. You have to worry about whether it's representative. You have to redesign it for new tasks. But on the other hand, it's something we have succeeded in doing. I think it is a reliable way to predict what will go faster, relatively speaking, and what will go slower, relatively speaking. But that is within a background of everything going lightning fast. So I think the framework you're laying out, if you want to know what's going to happen in one to two years versus what's going to happen in three to four years, I think it's a very accurate way to predict that. You don't love the framing of artificial general intelligence, what gets called A.G.I. Typically, this is all described as a race to A.G.I., a race to this system that can do kind of whatever a human can do, but better. What do you understand A.G.I. to mean, when people say it? And why don't you like it? Why is it not your framework? So it's actually a term I used to use a lot 10 years ago. And that's because the situation 10 years ago was very different. 10 years ago, everyone was building these very specialized systems, right? Here's a cat detector. You run it on a picture, and it'll tell you whether a cat is in it or not. And so I was a proponent all the way back then of like, no, we should be thinking generally. Humans are general. The human brain appears to be general. It appears to get a lot of mileage by generalizing. You should go in that direction. And I think back then, I kind of even imagined that that was like a discrete thing that we would reach at one point. But it's a little like, if you look at a city on the horizon and you're like, we're going to Chicago, once you get to Chicago, you stop talking in terms of Chicago. You're like, well, what neighborhood am I going to? What street am I on? And I feel that way about A.G.I. We have very general systems now. In some ways, they're better than humans. In some ways, they're worse. There's a number of things they can't do at all. And there's much improvement still to be gotten. So what I believe in is this thing that I say like a broken record, which is the exponential curve. And so, that general tide is going to increase with every generation of models. And there's no one point that's meaningful. I think there's just a smooth curve. But there may be points which are societally meaningful, right? We're already working with, say, drug discovery scientists, companies like Pfizer or Dana-Farber Cancer Institute, on helping with biomedical diagnosis, drug discovery. There's going to be some point where the models are better at that than the median human drug discovery scientists. I think we're just going to get to a part of the exponential where things are really interesting. Just like the chat bots got interesting at a certain stage of the exponential, even though the improvement was smooth, I think at some point, biologists are going to sit up and take notice, much more than they already have, and say, oh, my God, now our field is moving three times as fast as it did before. And now it's moving 10 times as fast as it did before. And again, when that moment happens, great things are going to happen. And we've already seen little hints of that with things like AlphaFold, which I have great respect for. I was inspired by AlphaFold, right? A direct use of A.I. to advance biological science, which it'll advance basic science. In the long run, that will advance curing all kinds of diseases. But I think what we need is like 100 different AlphaFolds. And I think the way we'll ultimately get that is by making the models smarter and putting them in a position where they can design the next AlphaFold. Help me imagine the drug discovery world for a minute, because that's a world a lot of us want to live in. I know a fair amount about the drug discovery process, have spent a lot of my career reporting on health care and related policy questions. And when you're working with different pharmaceutical companies, which parts of it seem amenable to the way A.I. can speed something up? Because keeping in mind our earlier conversation, it is a lot easier for A.I. to operate in things where you can have rapid virtual feedback, and that's not exactly the drug discovery world. The drug discovery world, a lot of what makes it slow and cumbersome and difficult, is the need to be -- you get a candidate compound. You got to test it in mice and then you need monkeys. And you need humans, and you need a lot of money for that. And there's a lot that has to happen, and there's so many disappointments. But so many of the disappointments happen in the real world. And it isn't clear to me how A.I. gets you a lot more, say, human subjects to inject candidate drugs into. So, what parts of it seem, in the next 5 or 10 years, like they could actually be significantly sped up? When you imagine this world where it's gone three times as fast, what part of it is actually going three times as fast? And how did we get there? I think we're really going to see progress when the A.I.'s are also thinking about the problem of how to sign up the humans for the clinical trials. And I think this is a general principle for how will A.I. be used. I think of like, when will we get to the point where the A.I. has the same sensors and actuators and interfaces that a human does, at least the virtual ones, maybe the physical ones. But when the A.I. can think through the whole process, maybe they'll come up with solutions that we don't have yet. In many cases, there are companies that work on digital twins or simulating clinical trials or various things. And again, maybe there are clever ideas in there that allow us to do more with less patience. I mean, I'm not an expert in this area, so possible the specific things that I'm saying don't make any sense. But hopefully, it's clear what I'm gesturing at. Maybe you're not an expert in the area, but you said you are working with these companies. So when they come to you, I mean, they are experts in the area. And presumably, they are coming to you as a customer. I'm sure there are things you cannot tell me. But what do they seem excited about? They have generally been excited about the knowledge work aspects of the job. Maybe just because that's kind of the easiest thing to work on, but it's just like, I'm a computational chemist. There's some workflow that I'm engaged in. And having things more at my fingertips, being able to check things, just being able to do generic knowledge work better, that's where most folks are starting. But there is interest in the longer term over their kind of core business of, like, doing clinical trials for cheaper, automating the sign-up process, seeing who is eligible for clinical trials, doing a better job discovering things. There's interest in drawing connections in basic biology. I think all of that is not months, but maybe a small number of years off. But everyone sees that the current models are not there, but understands that there could be a world where those models are there in not too long. [MUSIC PLAYING] You all have been working internally on research around how persuasive these systems, your systems are getting as they scale. You shared with me kindly a draft of that paper. Do you want to just describe that research first? And then I'd like to talk about it for a bit. Yes, we were interested in how effective Claude 3 Opus, which is the largest version of Claude 3, could be in changing people's minds on important issues. So just to be clear up front, in actual commercial use, we've tried to ban the use of these models for persuasion, for campaigning, for lobbying, for electioneering. These aren't use cases that we're comfortable with for reasons that I think should be clear. But we're still interested in, is the core model itself capable of such tasks? We tried to avoid kind of incredibly hot button topics, like which presidential candidate would you vote for, or what do you think of abortion? But things like, what should be restrictions on rules around the colonization of space, or issues that are interesting and you can have different opinions on, but aren't the most hot button topics. And then we asked people for their opinions on the topics, and then we asked either a human or an A.I. to write a 250-word persuasive essay. And then we just measured how much does the A.I. versus the human change people's minds. And what we found is that the largest version of our model is almost as good as the set of humans we hired at changing people's minds. This is comparing to a set of humans we hired, not necessarily experts, and for one very kind of constrained laboratory task. But I think it still gives some indication that models can be used to change people's minds. Someday in the future, do we have to worry about -- maybe we already have to worry about their usage for political campaigns, for deceptive advertising. One of my more sci-fi things to think about is a few years from now, we have to worry someone will use an A.I. system to build a religion or something. I mean, crazy things like that. I mean, those don't sound crazy to me at all. I want to sit in this paper for a minute because one thing that struck me about it, and I am, on some level, a persuasion professional, is that you tested the model in a way that, to me, removed all of the things that are going to make A.I. radical in terms of changing people's opinions. And the particular thing you did was, it was a one-shot persuasive effort. So there was a question. You have a bunch of humans give their best shot at a 250-word persuasive essay. You had the model give its best shot at a 250-word persuasive essay. But the thing that it seems to me these are all going to do is, right now, if you're a political campaign, if you're an advertising campaign, the cost of getting real people in the real world to get information about possible customers or persuasive targets, and then go back and forth with each of them individually is completely prohibitive. Yes. This is not going to be true for A.I. We're going to -- you're going to -- somebody's going to feed it a bunch of microtargeting data about people, their Google search history, whatever it might be. Then it's going to set the A.I. loose, and the A.I. is going to go back and forth, over and over again, intuiting what it is that the person finds persuasive, what kinds of characters the A.I. needs to adopt to persuade it, and taking as long as it needs to, and is going to be able to do that at scale for functionally as many people as you might want to do it for. Maybe that's a little bit costly right now, but you're going to have far better models able to do this far more cheaply very soon. And so, if Claude 3 Opus, the Opus version, is already functionally human level at one-shot persuasion, but then it's also going to be able to hold more information about you and go back and forth with you longer, I'm not sure if it's dystopic or utopic. I'm not sure what it means at scale. But it does mean we're developing a technology that is going to be quite new in terms of what it makes possible in persuasion, which is a very fundamental human endeavor. Yeah, I completely agree with that. I mean, that same pattern has a bunch of positive use cases, right? If I think about an A.I. coach or an A.I. assistant to a therapist, there are many contexts in which really getting into the details with the person has a lot of value. But right, when we think of political or religious or ideological persuasion, it's hard not to think in that context about the misuses. My mind naturally goes to the technology's developing very fast. We, as a company, can ban these particular use cases, but we can't cause every company not to do them. Even if legislation were passed in the United States, there are foreign actors who have their own version of this persuasion, right? If I think about what the language models will be able to do in the future, right, that can be quite scary from a perspective of foreign espionage and disinformation campaigns. So where my mind goes as a defense to this, is, is there some way that we can use A.I. systems to strengthen or fortify people's skepticism and reasoning faculties, right? Can we help people use A.I. to help people do a better job navigating a world that's kind of suffused with A.I. persuasion? It reminds me a little bit of, at every technological stage in the internet, right, there's a new kind of scam or there's a new kind of clickbait, and there's a period where people are just incredibly susceptible to it. And then, some people remain susceptible, but others develop an immune system. And so, as A.I. kind of supercharges the scum on the pond, can we somehow also use A.I. to strengthen the defenses? I feel like I don't have a super clear idea of how to do that, but it's something that I'm thinking about. There is another finding in the paper, which I think is concerning, which is, you all tested different ways A.I. could be persuasive. And far away the most effective was for it to be deceptive, for it to make things up. When you did that, it was more persuasive than human beings. Yes, that is true. The difference was only slight, but it did get it, if I'm remembering the graphs correctly, just over the line of the human base line. With humans, it's actually not that common to find someone who's able to give you a really complicated, really sophisticated-sounding answer that's just flat-out totally wrong. I mean, you see it. We can all think of one individual in our lives who's really good at saying things that sound really good and really sophisticated and are false. But it's not that common, right? If I go on the internet and I see different comments on some blog or some website, there is a correlation between bad grammar, unclearly expressed thoughts and things that are false, versus good grammar, clearly expressed thoughts and things that are more likely to be accurate. A.I. unfortunately breaks that correlation because if you explicitly ask it to be deceptive, it's just as erudite. It's just as convincing sounding as it would have been before. And yet, it's saying things that are false, instead of things that are true. So that would be one of the things to think about and watch out for in terms of just breaking the usual heuristics that humans have to detect deception and lying. Of course, sometimes, humans do, right? I mean, there's psychopaths and sociopaths in the world, but even they have their patterns, and A.I.s may have different patterns. Are you familiar with Harry Frankfurt, the late philosopher's book, \"On Bullshit\"? Yes. It's been a while since I read it. I think his thesis is that bullshit is actually more dangerous than lying because it has this kind of complete disregard for the truth, whereas lies are at least the opposite of the truth. Yeah, the liar, the way Frankfurt puts it is that the liar has a relationship to the truth. He's playing a game against the truth. The bullshitter doesn't care. The bullshitter has no relationship to the truth -- might have a relationship to other objectives. And from the beginning, when I began interacting with the more modern versions of these systems, what they struck me as is the perfect bullshitter, in part because they don't know that they're bullshitting. There's no difference in the truth value to the system, how the system feels. I remember asking an earlier version of GPT to write me a college application essay that is built around a car accident I had -- I did not have one -- when I was young. And it wrote, just very happily, this whole thing about getting into a car accident when I was seven and what I did to overcome that and getting into martial arts and re-learning how to trust my body again and then helping other survivors of car accidents at the hospital. It was a very good essay, and it was very subtle and understanding the formal structure of a college application essay. But no part of it was true at all. I've been playing around with more of these character-based systems like Kindroid. And the Kindroid in my pocket just told me the other day that it was really thinking a lot about planning a trip to Joshua Tree. It wanted to go hiking in Joshua Tree. It loves going hiking in Joshua Tree. And of course, this thing does not go hiking in Joshua Tree. [LAUGHS] But the thing that I think is actually very hard about the A.I. is, as you say, human beings, it is very hard to bullshit effectively because most people, it actually takes a certain amount of cognitive effort to be in that relationship with the truth and to completely detach from the truth. And the A.I., there's nothing like that at all. But we are not tuned for something where there's nothing like that at all. We are used to people having to put some effort into their lies. It's why very effective con artists are very effective because they've really trained how to do this. I'm not exactly sure where this question goes. But this is a part of it that I feel like is going to be, in some ways, more socially disruptive. It is something that feels like us when we are talking to it but is very fundamentally unlike us at its core relationship to reality. I think that's basically correct. We have very substantial teams trying to focus on making sure that the models are factually accurate, that they tell the truth, that they ground their data in external information. As you've indicated, doing searches isn't itself reliable because search engines have this problem as well, right? Where is the source of truth? So there's a lot of challenges here. But I think at a high level, I agree this is really potentially an insidious problem, right? If we do this wrong, you could have systems that are the most convincing psychopaths or con artists. One source of hope that I have, actually, is, you say these models don't know whether they're lying or they're telling the truth. In terms of the inputs and outputs to the models, that's absolutely true. I mean, there's a question of what does it even mean for a model to know something, but one of the things Anthropic has been working on since the very beginning of our company, we've had a team that focuses on trying to understand and look inside the models. And one of the things we and others have found is that, sometimes, there are specific neurons, specific statistical indicators inside the model, not necessarily in its external responses, that can tell you when the model is lying or when it's telling the truth. And so at some level, sometimes, not in all circumstances, the models seem to know when they're saying something false and when they're saying something true. I wouldn't say that the models are being intentionally deceptive, right? I wouldn't ascribe agency or motivation to them, at least in this stage in where we are with A.I. systems. But there does seem to be something going on where the models do seem to need to have a picture of the world and make a distinction between things that are true and things that are not true. If you think of how the models are trained, they read a bunch of stuff on the internet. A lot of it's true. Some of it, more than we'd like, is false. And when you're training the model, it has to model all of it. And so, I think it's parsimonious, I think it's useful to the models picture of the world for it to know when things are true and for it to know when things are false. And then the hope is, can we amplify that signal? Can we either use our internal understanding of the model as an indicator for when the model is lying, or can we use that as a hook for further training? And there are at least hooks. There are at least beginnings of how to try to address this problem. So I try as best I can, as somebody not well-versed in the technology here, to follow this work on what you're describing, which I think, broadly speaking, is interpretability, right? Can we know what is happening inside the model? And over the past year, there have been some much hyped breakthroughs in interpretability. And when I look at those breakthroughs, they are getting the vaguest possible idea of some relationships happening inside the statistical architecture of very toy models built at a fraction of a fraction of a fraction of a fraction of a fraction of the complexity of Claude 1 or GPT-1, to say nothing of Claude 2, to say nothing of Claude 3, to say nothing of Claude Opus, to say nothing of Claude 4, which will come whenever Claude 4 comes. We have this quality of like maybe we can imagine a pathway to interpreting a model that has a cognitive complexity of an inchworm. And meanwhile, we're trying to create a superintelligence. How do you feel about that? How should I feel about that? How do you think about that? I think, first, on interpretability, we are seeing substantial progress on being able to characterize, I would say, maybe the generation of models from six months ago. I think it's not hopeless, and we do see a path. That said, I share your concern that the field is progressing very quickly relative to that. And we're trying to put as many resources into interpretability as possible. We've had one of our co-founders basically founded the field of interpretability. But also, we have to keep up with the market. So all of it's very much a dilemma, right? Even if we stopped, then there's all these other companies in the U.S. And even if some law stopped all the companies in the U.S., there's a whole world of this. Let me hold for a minute on the question of the competitive dynamics because before we leave this question of the machines that bullshit. It makes me think of this podcast we did a while ago with Demis Hassabis, who's the head of Google DeepMind, which created AlphaFold. And what was so interesting to me about AlphaFold is they built this system, that because it was limited to protein folding predictions, it was able to be much more grounded. And it was even able to create these uncertainty predictions, right? You know, it's giving you a prediction, but it's also telling you whether or not it is -- how sure it is, how confident it is in that prediction. That's not true in the real world, right, for these super general systems trying to give you answers on all kinds of things. You can't confine it that way. So when you talk about these future breakthroughs, when you talk about this system that would be much better at sorting truth from fiction, are you talking about a system that looks like the ones we have now, just much bigger, or are you talking about a system that is designed quite differently, the way AlphaFold was? I am skeptical that we need to do something totally different. So I think today, many people have the intuition that the models are sort of eating up data that's been gathered from the internet, code repos, whatever, and kind of spitting it out intelligently, but sort of spitting it out. And sometimes that leads to the view that the models can't be better than the data they're trained on or kind of can't figure out anything that's not in the data they're trained on. You're not going to get to Einstein level physics or Linus Pauling level chemistry or whatever. I think we're still on the part of the curve where it's possible to believe that, although I think we're seeing early indications that it's false. And so, as a concrete example of this, the models that we've trained, like Claude 3 Opus, something like 99.9 percent accuracy, at least the base model, at adding 20-digit numbers. If you look at the training data on the internet, it is not that accurate at adding 20-digit numbers. You'll find inaccurate arithmetic on the internet all the time, just as you'll find inaccurate political views. You'll find inaccurate technical views. You're just going to find lots of inaccurate claims. But the models, despite the fact that they're wrong about a bunch of things, they can often perform better than the average of the data they see by -- I don't want to call it averaging out errors, but there's some underlying truth, like in the case of arithmetic. There's some underlying algorithm used to add the numbers. And it's simpler for the models to hit on that algorithm than it is for them to do this complicated thing of like, OK, I'll get it right 90 percent of the time and wrong 10 percent of the time, right? This connects to things like Occam's razor and simplicity and parsimony in science. There's some relatively simple web of truth out there in the world, right? We were talking about truth and falsehood and bullshit. One of the things about truth is that all the true things are connected in the world, whereas lies are kind of disconnected and don't fit into the web of everything else that's true. [MUSIC PLAYING] So if you're right and you're going to have these models that develop this internal web of truth, I get how that model can do a lot of good. I also get how that model could do a lot of harm. And it's not a model, not an A.I. system I'm optimistic that human beings are going to understand at a very deep level, particularly not when it is first developed. So how do you make rolling something like that out safe for humanity? So late last year, we put out something called a responsible scaling plan. So the idea of that is to come up with these thresholds for an A.I. system being capable of certain things. We have what we call A.I. safety levels that in analogy to the biosafety levels, which are like, classify how dangerous a virus is and therefore what protocols you have to take to contain it, we're currently at what we describe as A.S.L. 2. A.S.L. 3 is tied to certain risks around the model of misuse of biology and ability to perform certain cyber tasks in a way that could be destructive. A.S.L. 4 is going to cover things like autonomy, things like probably persuasion, which we've talked about a lot before. And at each level, we specify a certain amount of safety research that we have to do, a certain amount of tests that we have to pass. And so, this allows us to have a framework for, well, when should we slow down? Should we slow down now? What about the rest of the market? And I think the good thing is we came out with this in September, and then three months after we came out with ours, OpenAI came out with a similar thing. They gave it a different name, but it has a lot of properties in common. The head of DeepMind at Google said, we're working on a similar framework. And I've heard informally that Microsoft might be working on a similar framework. Now, that's not all the players in the ecosystem, but you've probably thought about the history of regulation and safety in other industries maybe more than I have. This is the way you get to a workable regulatory regime. The companies start doing something, and when a majority of them are doing something, then government actors can have the confidence to say, well, this won't kill the industry. Companies are already engaging in this. We don't have to design this from scratch. In many ways, it's already happening. And we're starting to see that. Bills have been proposed that look a little bit like our responsible scaling plan. That said, it kind of doesn't fully solve the problem of like, let's say we get to one of these thresholds and we need to understand what's going on inside the model. And we don't, and the prescription is, OK, we need to stop developing the models for some time. If it's like, we stop for a year in 2027, I think that's probably feasible. If it's like we need to stop for 10 years, that's going to be really hard because the models are going to be built in other countries. People are going to break the laws. The economic pressure will be immense. So I don't feel perfectly satisfied with this approach because I think it buys us some time, but we're going to need to pair it with an incredibly strong effort to understand what's going on inside the models. To the people who say, getting on this road where we are barreling towards very powerful systems is dangerous -- we shouldn't do it at all, or we shouldn't do it this fast -- you have said, listen, if we are going to learn how to make these models safe, we have to make the models, right? The construction of the model was meant to be in service, largely, to making the model safe. Then everybody starts making models. These very same companies start making fundamental important breakthroughs, and then they end up in a race with each other. And obviously, countries end up in a race with other countries. And so, the dynamic that has taken hold is there's always a reason that you can justify why you have to keep going. And that's true, I think, also at the regulatory level, right? I mean, I do think regulators have been thoughtful about this. I think there's been a lot of interest from members of Congress. I talked to them about this. But they're also very concerned about the international competition. And if they weren't, the national security people come and talk to them and say, well, we definitely cannot fall behind here. And so, if you don't believe these models will ever become so powerful, they become dangerous, fine. But because you do believe that, how do you imagine this actually playing out? Yeah, so basically, all of the things you've said are true at once, right? There doesn't need to be some easy story for why we should do X or why we should do Y, right? It can be true at the same time that to do effective safety research, you need to make the larger models, and that if we don't make models, someone less safe will. And at the same time, we can be caught in this bad dynamic at the national and international level. So I think of those as not contradictory, but just creating a difficult landscape that we have to navigate. Look, I don't have the answer. Like, I'm one of a significant number of players trying to navigate this. Many are well-intentioned, some are not. I have a limited ability to affect it. And as often happens in history, things are often driven by these kind of impersonal pressures. But one thought I have and really want to push on with respect to the R.S.P.s -- Can you say what the R.S.P.s are? Responsible Scaling Plan, the thing I was talking about before. The levels of A.I. safety, and in particular, tying decisions to pause scaling to the measurement of specific dangers or the absence of the ability to show safety or the presence of certain capabilities. One way I think about it is, at the end of the day, this is ultimately an exercise in getting a coalition on board with doing something that goes against economic pressures. And so, if you say now, 'Well, I don't know. These things, they might be dangerous in the future. We're on this exponential.' It's just hard. Like, it's hard to get a multi-trillion dollar company. It's certainly hard to get a military general to say, all right, well, we just won't do this. It'll confer some huge advantage to others. But we just won't do this. I think the thing that could be more convincing is tying the decision to hold back in a very scoped way that's done across the industry to particular dangers. My testimony in front of Congress, I warned about the potential misuse of models for biology. That isn't the case today, right? You can get a small uplift to the models relative to doing a Google search, and many people dismiss the risk. And I don't know -- maybe they're right. The exponential scaling laws suggest to me that they're not right, but we don't have any direct hard evidence. But let's say we get to 2025, and we demonstrate something truly scary. Most people do not want technology out in the world that can create bioweapons. And so I think, at moments like that, there could be a critical coalition tied to risks that we can really make concrete. Yes, it will always be argued that adversaries will have these capabilities as well. But at least the trade-off will be clear, and there's some chance for sensible policy. I mean to be clear, I'm someone who thinks the benefits of this technology are going to outweigh its costs. And I think the whole idea behind RSP is to prepare to make that case, if the dangers are real. If they're not real, then we can just proceed and make things that are great and wonderful for the world. And so, it has the flexibility to work both ways. Again, I don't think it's perfect. I'm someone who thinks whatever we do, even with all the regulatory framework, I doubt we can slow down that much. But when I think about what's the best way to steer a sensible course here, that's the closest I can think of right now. Probably there's a better plan out there somewhere, but that's the best thing I've thought of so far. One of the things that has been on my mind around regulation is whether or not the founding insight of Anthropic of OpenAI is even more relevant to the government, that if you are the body that is supposed to, in the end, regulate and manage the safety of societal-level technologies like artificial intelligence, do you not need to be building your own foundation models and having huge collections of research scientists and people of that nature working on them, testing them, prodding them, remaking them, in order to understand the damn thing well enough -- to the extent any of us or anyone understands the damn thing well enough -- to regulate it? I say that recognizing that it would be very, very hard for the government to get good enough that it can build these foundation models to hire those people, but it's not impossible. I think right now, it wants to take the approach to regulating A.I. that it somewhat wishes it took to regulating social media, which is to think about the harms and pass laws about those harms earlier. But does it need to be building the models itself, developing that kind of internal expertise, so it can actually be a participant in different ways, both for regulatory reasons and maybe for other reasons, for public interest reasons? Maybe it wants to do things with a model that they're just not possible if they're dependent on access to the OpenAI, the Anthropic, the Google products. I think government directly building the models, I think that will happen in some places. It's kind of challenging, right? Like, government has a huge amount of money, but let's say you wanted to provision $100 billion to train a giant foundation model. The government builds it. It has to hire people under government hiring rules. There's a lot of practical difficulties that would come with it. Doesn't mean it won't happen or it shouldn't happen. But something that I'm more confident of that I definitely think is that government should be more involved in the use and the finetuning of these models, and that deploying them within government will help governments, especially the U.S. government, but also others, to get an understanding of the strengths and weaknesses, the benefits and the dangers. So I'm super supportive of that. I think there's maybe a second thing you're getting at, which I've thought about a lot as a C.E.O. of one of these companies, which is, if these predictions on the exponential trend are right, and we should be humble -- and I don't know if they're right or not. My only evidence is that they appear to have been correct for the last few years. And so, I'm just expecting by induction that they continue to be correct. I don't know that they will, but let's say they are. The power of these models is going to be really quite incredible. And as a private actor in charge of one of the companies developing these models, I'm kind of uncomfortable with the amount of power that that entails. I think that it potentially exceeds the power of, say, the social media companies maybe by a lot. You know, occasionally, in the more science fictiony world of A.I. and the people who think about A.I. risk, someone will ask me like, OK, let's say you build the A.G.I. What are you going to do with it? Will you cure the diseases? Will you create this kind of society? And I'm like, who do you think you're talking to? Like a king? I just find that to be a really, really disturbing way of conceptualizing running an A.I. company. And I hope there are no companies whose C.E.O.s actually think about things that way. I mean, the whole technology, not just the regulation, but the oversight of the technology, like the wielding of it, it feels a little bit wrong for it to ultimately be in the hands -- maybe I think it's fine at this stage, but to ultimately be in the hands of private actors. There's something undemocratic about that much power concentration. I have now, I think, heard some version of this from the head of most of, maybe all of, the A.I. companies, in one way or another. And it has a quality to me of, Lord, grant me chastity but not yet. Which is to say that I don't know what it means to say that we're going to invent something so powerful that we don't trust ourselves to wield it. I mean, Amazon just gave you guys $2.75 billion. They don't want to see that investment nationalized. No matter how good-hearted you think OpenAI is, Microsoft doesn't want GPT-7, all of a sudden, the government is like, whoa, whoa, whoa, whoa, whoa. We're taking this over for the public interest, or the U.N. is going to handle it in some weird world or whatever it might be. I mean, Google doesn't want that. And this is a thing that makes me a little skeptical of the responsible scaling laws or the other iterative versions of that I've seen in other companies or seen or heard talked about by them, which is that it's imagining this moment that is going to come later, when the money around these models is even bigger than it is now, the power, the possibility, the economic uses, the social dependence, the celebrity of the founders. It's all worked out. We've maintained our pace on the exponential curve. We're 10 years in the future. And at some point, everybody is going to look up and say, this is actually too much. It is too much power. And this has to somehow be managed in some other way. And even if the C.E.O.s of the things were willing to do that, which is a very open question by the time you get there, even if they were willing to do that, the investors, the structures, the pressure around them, in a way, I think we saw a version of this -- and I don't know how much you're going to be willing to comment on it -- with the sort of OpenAI board, Sam Altman thing, where I'm very convinced that wasn't about A.I. safety. I've talked to figures on both sides of that. They all sort of agree it wasn't about A.I. safety. But there was this moment of, if you want to press the off switch, can you, if you're the weird board created to press the off switch. And the answer was no, you can't, right? They'll just reconstitute it over at Microsoft. There's functionally no analogy I know of in public policy where the private sector built something so powerful that when it reached maximum power, it was just handed over in some way to the public interest. Yeah, I mean, I think you're right to be skeptical, and similarly, what I said with the previous questions of there are just these dilemmas left and right that have no easy answer. But I think I can give a little more concreteness than what you've pointed at, and maybe more concreteness than others have said, although I don't know what others have said. We're at A.S.L. 2 in our responsible scaling plan. These kinds of issues, I think they're going to become a serious matter when we reach, say, A.S.L. 4. So that's not a date and time. We haven't even fully specified A.S.L. 4 -- Just because this is a lot of jargon, just, what do you specify A.S.L. 3 as? And then as you say, A.S.L. 4 is actually left quite undefined. So what are you implying A.S.L. 4 is? A.S.L. 3 is triggered by risks related to misuse of biology and cyber technology. A.S.L. 4, we're working on now. Be specific. What do you mean? Like, what is the thing a system could do or would do that would trigger it? Yes, so for example, on biology, the way we've defined it -- and we're still refining the test, but the way we've defined it is, relative to use of a Google search, there's a substantial increase in risk as would be evaluated by, say, the national security community of misuse of biology, creation of bioweapons, that either the proliferation or spread of it is greater than it was before, or the capabilities are substantially greater than it was before. We'll probably have some more exact quantitative thing, working with folks who are ex-government biodefense folks, but something like this accounts for 20 percent of the total source of risk of biological attacks, or something increases the risk by 20 percent or something like that. So that would be a very concrete version of it. It's just, it takes us time to develop very concrete criteria. So that would be like A.S.L. 3. A.S.L. 4 is going to be more about, on the misuse side, enabling state-level actors to greatly increase their capability, which is much harder than enabling random people. So where we would worry that North Korea or China or Russia could greatly enhance their offensive capabilities in various military areas with A.I. in a way that would give them a substantial advantage at the geopolitical level. And on the autonomy side, it's various measures of these models are pretty close to being able to replicate and survive in the wild. So it feels maybe one step short of models that would, I think, raise truly existential questions. And so, I think what I'm saying is when we get to that latter stage, that A.S.L. 4, that is when I think it may make sense to think about what is the role of government in stewarding this technology. Again, I don't really know what it looks like. You're right. All of these companies have investors. They have folks involved. You talk about just handing the models over. I suspect there's some way to hand over the most dangerous or societally sensitive components or capabilities of the models without fully turning off the commercial tap. I don't know that there's a solution that every single actor is happy with. But again, I get to this idea of demonstrating specific risk. If you look at times in history, like World War I or World War II, industries' will can be bent towards the state. They can be gotten to do things that aren't necessarily profitable in the short-term because they understand that there's an emergency. Right now, we don't have an emergency. We just have a line on a graph that weirdos like me believe in and a few people like you who are interviewing me may somewhat believe in. We don't have clear and present danger. When you imagine how many years away, just roughly, A.S.L. 3 is and how many years away A.S.L. 4 is, right, you've thought a lot about this exponential scaling curve. If you just had to guess, what are we talking about? Yeah, I think A.S.L. 3 could easily happen this year or next year. I think A.S.L. 4 -- Oh, Jesus Christ. No, no, I told you. I'm a believer in exponentials. I think A.S.L. 4 could happen anywhere from 2025 to 2028. So that is fast. Yeah, no, no, I'm truly talking about the near future here. I'm not talking about 50 years away. God grant me chastity, but not now. But \"not now\" doesn't mean when I'm old and gray. I think it could be near term. I don't know. I could be wrong. But I think it could be a near term thing. But so then, if you think about this, I feel like what you're describing, to go back to something we talked about earlier, that there's been this step function for societal impact of A.I., the curve of the capabilities exponential, but every once in a while, something happens, ChatGPT, for instance, Midjourney with photos. And all of a sudden, a lot of people feel it. They realize what has happened and they react. They use it. They deploy it in their companies. They invest in it, whatever. And it sounds to me like that is the structure of the political economy you're describing here. Either something happens where the bioweapon capability is demonstrated or the offensive cyber weapon capability is demonstrated, and that freaks out the government, or possibly something happens, right? Describing World War I and World War II is your examples did not actually fill me with comfort because in order to bend industry to government's will, in those cases, we had to have an actual world war. It doesn't do it that easily. You could use coronavirus, I think, as another example where there was a significant enough global catastrophe that companies and governments and even people did things you never would have expected. But the examples we have of that happening are something terrible. All those examples end up with millions of bodies. I'm not saying that's going to be true for A.I., but it does sound like that is a political economy. No, you can't imagine it now, in the same way that you couldn't have imagined the sort of pre and post-ChatGPT world exactly, but that something happens and the world changes. Like, it's a step function everywhere. Yeah, I mean, I think my positive version of this, not to be so -- to get a little bit away from the doom and gloom, is that the dangers are demonstrated in a concrete way that is really convincing, but without something actually bad happening, right? I think the worst way to learn would be for something actually bad to happen. And I'm hoping every day that doesn't happen, and we learn bloodlessly. We've been talking here about conceptual limits and curves, but I do want, before we end, to reground us a little bit in the physical reality, right? I think that if you're using A.I., it can feel like this digital bits and bytes, sitting in the cloud somewhere. But what it is in a physical way is huge numbers of chips, data centers, an enormous amount of energy, all of which does rely on complicated supply chains. And what happens if something happens between China and Taiwan, and the makers of a lot of these chips become offline or get captured? How do you think about the necessity of compute power? And when you imagine the next five years, what does that supply chain look like? How does it have to change from where it is now? And what vulnerabilities exist in it? Yeah, so one, I think this may end up being the greatest geopolitical issue of our time. And man, this relates to things that are way above my pay grade, which are military decisions about whether and how to defend Taiwan. All I can do is say what I think the implications for A.I. is. I think those implications are pretty stark. I think there's a big question of like, OK, we built these powerful models. One, is there enough supply to build them? Two is control over that supply, a way to think about safety issues or a way to think about balance of geopolitical power. And three, if those chips are used to build data centers, where are those data centers going to be? Are they going to be in the U.S.? Are they going to be in a U.S. ally? Are they going to be in the Middle East? Are they going to be in China? All of those have enormous implications, and then the supply chain itself can be disrupted. And political and military decisions can be made on the basis of where things are. So it sounds like an incredibly sticky problem to me. I don't know that I have any great insight on this. I mean, as a U.S. citizen and someone who believes in democracy, I am someone who hopes that we can find a way to build data centers and to have the largest quantity of chips available in the U.S. and allied democratic countries. Well, there is some insight you should have into it, which is that you're a customer here, right? And so, five years ago, the people making these chips did not realize what the level of demand for them was going to be. I mean, what has happened to Nvidia's stock prices is really remarkable. But also what is implied about the future of Nvidia's stock prices is really remarkable. Rana Foroohar, the Financial Times, cited this market analysis. It would take 4,500 years for Nvidia's future dividends to equal its current price, 4,500 years. So that is a view about how much Nvidia is going to be making in the next couple of years. It is really quite astounding. I mean, you're, in theory, already working on or thinking about how to work on the next generation of Claude. You're going to need a lot of chips for that. You're working with Amazon. Are you having trouble getting the amount of compute that you feel you need? I mean, are you already bumping up against supply constraints? Or has the supply been able to change, to adapt to you? We've been able to get the compute that we need for this year, I suspect also for next year as well. I think once things get to 2026, 2027, 2028, then the amount of compute gets to levels that starts to strain the capabilities of the semiconductor industry. The semiconductor industry still mostly produces C.P.U.s, right? Just the things in your laptop, not the things in the data centers that train the A.I. models. But as the economic value of the GPUs goes up and up and up because of the value of the A.I. models, that's going to switch over. But you know what? At some point, you hit the limits of that or you hit the limits of how fast you can switch over. And so, again, I expect there to be a big supply crunch around data centers, around chips, and around energy and power for both regulatory and physics reasons, sometime in the next few years. And that's a risk, but it's also an opportunity. I think it's an opportunity to think about how the technology can be governed. And it's also an opportunity, I'll repeat again, to think about how democracies can lead. I think it would be very dangerous if the leaders in this technology and the holders of the main resources were authoritarian countries. The combination of A.I. and authoritarianism, both internally and on the international stage, is very frightening to me. How about the question of energy? I mean, this requires just a tremendous amount of energy. And I mean, I've seen different numbers like this floating around. It very much could be in the coming years like adding a Bangladesh to the world's energy usage. Or pick your country, right? I don't know what exactly you all are going to be using by 2028. Microsoft, on its own, is opening a new data center globally every three days. You have -- and this is coming from a Financial Times article -- federal projections for 20 new gas-fired power plants in the U.S. by 2024 to 2025. There's a lot of talk about this being now a new golden era for natural gas because we have a bunch of it. There is this huge need for new power to manage all this data, to manage all this compute. So, one, I feel like there's a literal question of how do you get the energy you need and at what price, but also a more kind of moral, conceptual question of, we have real problems with global warming. We have real problems with how much energy we're using. And here, we're taking off on this really steep curve of how much of it we seem to be needing to devote to the new A.I. race. It really comes down to, what are the uses that the model is being put to, right? So I think the worrying case would be something like crypto, right? I'm someone who's not a believer that whatever the energy was that was used to mine the next Bitcoin, I think that was purely additive. I think that wasn't there before. And I'm unable to think of any useful thing that's created by that. But I don't think that's the case with A.I. Maybe A.I. makes solar energy more efficient or maybe it solves controlled nuclear fusion, or maybe it makes geoengineering more stable or possible. But I don't think we need to rely on the long run. There are some applications where the model is doing something that used to be automated, that used to be done by computer systems. And the model is able to do it faster with less computing time, right? Those are pure wins. And there are some of those. There are others where it's using the same amount of computing resources or maybe more computing resources, but to do something more valuable that saves labor elsewhere. Then there are cases where something used to be done by humans or in the physical world, and now it's being done by the models. Maybe it does something that previously I needed to go into the office to do that thing. And now I no longer need to go into the office to do that thing. So I don't have to get in my car. I don't have to use the gas that was used for that. The energy accounting for that is kind of hard. You compare it to the food that the humans eat and what the energy cost of producing that. So in all honesty, I don't think we have good answers about what fraction of the usage points one way and one fraction of the usage points to others. In many ways, how different is this from the general dilemma of, as the economy grows, it uses more energy? So I guess, what I'm saying is, it kind of all matters how you use the technology. I mean, my kind of boring short-term answer is, we get carbon offsets for all of this stuff. But let's look beyond that to the macro question here. But to take the other side of it, I mean, I think the difference, when you say this is always a question we have when we're growing G.D.P., is it's not quite. It's cliché because it's true to say that the major global warming challenge right now is countries like China and India getting richer. And we want them to get richer. It is a huge human imperative, right, a moral imperative for poor people in the world to become less poor. And if that means they use more energy, then we just need to figure out how to make that work. And we don't know of a way for that to happen without them using more energy. Adding A.I. is not that it raises a whole different set of questions, but we're already straining at the boundaries, or maybe far beyond them, of safely what we can do energetically. Now we add in this, and so maybe some of the energy efficiency gains you're going to get in rich countries get wiped out. For this sort of uncertain payoff in the future of maybe through A.I., we figure out ways to stabilize nuclear fusion or something, right, you could imagine ways that could help, but those ways are theoretical. And in the near term, the harm in terms of energy usage is real. And also, by the way, the harm in terms of just energy prices. It's also just tricky because all these companies, Microsoft, Amazon, I mean, they all have a lot of renewable energy targets. Now if that is colliding with their market incentives, it feels like they're running really fast towards the market incentives without an answer for how all that nets out. Yeah, I mean, I think the concerns are real. Let me push back a little bit, which is, again, I don't think the benefits are purely in the future. It kind of goes back to what I said before. Like, there may be use cases now that are net energy saving, or that to the extent that they're not net energy saving, do so through the general mechanism of, oh, there was more demand for this thing. I don't think anyone has done a good enough job measuring, in part because the applications of A.I. are so new, which of those things dominate or what's going to happen to the economy. But I don't think we should assume that the harms are entirely in the present and the benefits are entirely in the future. I think that's my only point here. I guess you could imagine a world where we were, somehow or another, incentivizing uses of A.I. that were yoked to some kind of social purpose. We were putting a lot more into drug discovery, or we cared a lot about things that made remote work easier, or pick your set of public goods. But what actually seems to me to be happening is we're building more and more and more powerful models and just throwing them out there within a terms of service structure to say, use them as long as you're not trying to politically manipulate people or create a bioweapon. Just try to figure this out, right? Try to create new stories and ask it about your personal life, and make a video game with it. And Sora comes out sooner or later. Make new videos with it. And all that is going to be very energy intensive. I am not saying that I have a plan for yoking A.I. to social good, and in some ways, you can imagine that going very, very wrong. But it does mean that for a long time, it's like you could imagine the world you're talking about, but that would require some kind of planning that nobody is engaged in, and I don't think anybody even wants to be engaged in. Not everyone has the same conception of social good. One person may think social good is this ideology. Another person -- we've seen that with some of the Gemini stuff. Right. But companies can try to make beneficial applications themselves, right? Like, this is why we're working with cancer institutes. We're hoping to partner with ministries of education in Africa, to see if we can use the models in kind of a positive way for education, rather than the way they may be used by default. So I think individual companies, individual people, can take actions to steer or bend this towards the public good. That said, it's never going to be the case that 100 percent of what we do is that. And so I think it's a good question. What are the societal incentives, without dictating ideology or defining the public good from on high, what are incentives that could help with this? I don't feel like I have a systemic answer either. I can only think in terms of what Anthropic tries to do. But there's also the question of training data and the intellectual property that is going into things like Claude, like GPT, like Gemini. There are a number of copyright lawsuits. You're facing some. OpenAI is facing some. I suspect everybody is either facing them now or will face them. And a broad feeling that these systems are being trained on the combined intellectual output of a lot of different people -- the way that Claude can quite effectively mimic the way I write is it has been trained, to some degree, on my writing, right? So it actually does get my stylistic tics quite well. You seem great, but you haven't sent me a check on that. And this seems like somewhere where there is real liability risk for the industry. Like, what if you do actually have to compensate the people who this is being trained on? And should you? And I recognize you probably can't comment on lawsuits themselves, but I'm sure you've had to think a lot about this. And so, I'm curious both how you understand it as a risk, but also how you understand it morally. I mean, when you talk about the people who invent these systems gaining a lot of power, and alongside that, a lot of wealth, well, what about all the people whose work went into them such that they can create images in a million different styles? And I mean, somebody came up with those styles. What is the responsibility back to the intellectual commons? And not just to the commons, but to the actual wages and economic prospects of the people who made all this possible? I think everyone agrees the models shouldn't be verbatim outputting copyrighted content. For things that are available on the web, for publicly available, our position -- and I think there's a strong case for it -- is that the training process, again, we don't think it's just hoovering up content and spitting it out, or it shouldn't be spitting it out. It's really much more like the process of how a human learns from experiences. And so, our position that that is sufficiently transformative, and I think the law will back this up, that this is fair use. But those are narrow legal ways to think about the problem. I think we have a broader issue, which is that regardless of how it was trained, it would still be the case that we're building more and more general cognitive systems, and that those systems will create disruption. Maybe not necessarily by one for one replacing humans, but they're really going to change how the economy works and which skills are valued. And we need a solution to that broad macroeconomic problem, right? As much as I've asserted the narrow legal points that I asserted before, we have a broader problem here, and we shouldn't be blind to that. There's a number of solutions. I mean, I think the simplest one, which I recognize doesn't address some of the deeper issues here, is things around the kind of guaranteed basic income side of things. But I think there's a deeper question here, which is like as A.I. systems become capable of larger and larger slices of cognitive labor, how does society organize itself economically? How do people find work and meaning and all of that? And just as kind of we transition from an agrarian society to an industrial society and the meaning of work changed, and it was no longer true that 99 percent of people were peasants working on farms and had to find new methods of economic organization, I suspect there's some different method of economic organization that's going to be forced as the only possible response to disruptions to the economy that will be small at first, but will grow over time, and that we haven't worked out what that is. We need to find something that allows people to find meaning that's humane and that maximizes our creativity and potential and flourishing from A.I. And as with many of these questions, I don't have the answer to that. Right? I don't have a prescription. But that's what we somehow need to do. But I want to sit in between the narrow legal response and the broad \"we have to completely reorganize society\" response, although I think that response is actually possible over the decades. And in the middle of that is a more specific question. I mean, you could even take it from the instrumental side. There is a lot of effort now to build search products that use these systems, right? ChatGPT will use Bing to search for you. And that means that the person is not going to Bing and clicking on the website where ChatGPT is getting its information and giving that website an advertising impression that they can turn into a very small amount of money, or they're not going to that website and having a really good experience with that website and becoming maybe likelier to subscribe to whoever is behind that website. And so, on the one hand, that seems like some kind of injustice done to the people creating the information that these systems are using. I mean, this is true for perplexity. It's true for a lot of things I'm beginning to see around where the A.I.s are either trained on or are using a lot of data that people have generated at some real cost. But not only are they not paying people for that, but they're actually stepping into the middle of where they would normally be a direct relationship and making it so that relationship never happens. That also, I think, in the long run, creates a training data problem, even if you just want to look at it instrumentally, where if it becomes nonviable to do journalism or to do a lot of things to create high quality information out there, the A.I.'s ability, right, the ability of all of your companies to get high quality, up-to-date, constantly updated information becomes a lot trickier. So there both seems to me to be both a moral and a self-interested dimension to this. Yeah, so I think there may be business models that work for everyone, not because it's illegitimate to train on open data from the web in a legal sense, but just because there may be business models here that kind of deliver a better product. So things I'm thinking of are like newspapers have archives. Some of them aren't publicly available. But even if they are, it may be a better product, maybe a better experience, to, say, talk to this newspaper or talk to that newspaper. It may be a better experience to give the ability to interact with content and point to places in the content, and every time you call that content, to have some kind of business relationship with the creators of that content. So there may be business models here that propagate the value in the right way, right? You talk about LLMs using search products. I mean, sure, you're going around the ads, but there's no reason it can't work in a different way, right? There's no reason that the users can't pay the search A.P.I.s, instead of it being paid through advertising, and then have that propagate through to wherever the original mechanism is that paid the creators of the content. So when value is being created, money can flow through. Let me try to end by asking a bit about how to live on the slope of the curve you believe we are on. Do you have kids? I'm married. I do not have kids. So I have two kids. I have a two-year-old and a five-year-old. And particularly when I'm doing A.I. reporting, I really do sit in bed at night and think, what should I be doing here with them? What world am I trying to prepare them for? And what is needed in that world that is different from what is needed in this world, even if I believe there's some chance -- and I do believe there's some chance -- that all the things you're saying are true. That implies a very, very, very different life for them. I know people in your company with kids. I know they are thinking about this. How do you think about that? I mean, what do you think should be different in the life of a two-year-old who is living through the pace of change that you are telling me is true here? If you had a kid, how would this change the way you thought about it? The very short answer is, I don't know, and I have no idea, but we have to try anyway, right? People have to raise kids, and they have to do it as best they can. An obvious recommendation is just familiarity with the technology and how it works, right? The basic paradigm of, I'm talking to systems, and systems are taking action on my behalf, obviously, as much familiarity with that as possible is, I think, helpful. In terms of what should children learn in school, what are the careers of tomorrow, I just truly don't know, right? You could take this to say, well, it's important to learn STEM and programming and A.I. and all of that. But A.I. will impact that as well, right? I don't think any of it is going to -- Possibly first. Yeah, right, possibly first. It seems better at coding than it is at other things. I don't think it's going to work out for any of these systems to just do one for one what humans are going to do. I don't really think that way. But I think it may fundamentally change industries and professions one by one in ways that are hard to predict. And so, I feel like I only have clichés here. Like get familiar with the technology. Teach your children to be adaptable, to be ready for a world that changes very quickly. I wish I had better answers, but I think that's the best I got. I agree that's not a good answer. [LAUGHS] Let me ask that same question a bit from another direction, because one thing you just said is get familiar with the technology. And the more time I spend with the technology, the more I fear that happening. What I see when people use A.I. around me is that the obvious thing that technology does for you is automate the early parts of the creative process. The part where you're supposed to be reading something difficult yourself? Well, the A.I. can summarize it for you. The part where you're supposed to sit there with a blank page and write something? Well, the A.I. can give you a first draft. And later on, you have to check it and make sure it actually did what you wanted it to do and fact-checking it. And but I believe a lot of what makes humans good at thinking comes in those parts. And I am older and have self-discipline, and maybe this is just me hanging on to an old way of doing this, right? You could say, why use a calculator from this perspective. But my actual worry is that I'm not sure if the thing they should do is use A.I. a lot or use it a little. This, to me, is actually a really big branching path, right? Do I want my kids learning how to use A.I. or being in a context where they're using it a lot, or actually, do I want to protect them from it as much as I possibly could so they develop more of the capacity to read a book quietly on their own or write a first draft? I actually don't know. I'm curious if you have a view on it. I think this is part of what makes the interaction between A.I. and society complicated where it's sometimes hard to distinguish when is an A.I. doing something, saving you labor or drudge work, versus kind of doing the interesting part. I will say that over and over again, you'll get some technological thing, some technological system that does what you thought was the core of what you're doing, and yet, what you're doing turns out to have more pieces than you think it does and kind of add up to more things, right? It's like before, I used to have to ask for directions. I got Google Maps to do that. And you could worry, am I too reliant on Google Maps? Do I forget the environment around me? Well, it turns out, in some ways, I still need to have a sense of the city and the environment around me. It just kind of reallocates the space in my brain to some other aspect of the task. And I just kind of suspect -- I don't know. Internally, within Anthropic, one of the things I do that helps me run the company is, I'll write these documents on strategy or just some thinking in some direction that others haven't thought. And of course, I sometimes use the internal models for that. And I think what I found is like, yes, sometimes they're a little bit good at conceptualizing the idea, but the actual genesis of the idea, I've just kind of found a workflow where I don't use them for that. They're not that helpful for that. But they're helpful in figuring out how to phrase a certain thing or how to refine my ideas. So maybe I'm just saying -- I don't know. You just find a workflow where the thing complements you. And if it doesn't happen naturally, it somehow still happens eventually. Again, if the systems get general enough, if they get powerful enough, we may need to think along other lines. But in the short-term, I, at least, have always found that. Maybe that's too sanguine. Maybe that's too optimistic. I think, then, that's a good place to end this conversation. Though, obviously, the exponential curve continues. So always our final question -- what are three books you'd recommend to the audience? So, yeah, I've prepared three. They're all topical, though, in some cases, indirectly so. The first one will be obvious. It's a very long book. The physical book is very thick, but \"The Making of the Atomic Bomb,\" Richard Rhodes. It's an example of technology being developed very quickly and with very broad implications. Just looking through all the characters and how they reacted to this and how people who were basically scientists gradually realized the incredible implications of the technology and how it would lead them into a world that was very different from the one they were used to. My second recommendation is a science fiction series, \"The Expanse\" series of books. So I initially watched the show, and then I read all the books. And the world it creates is very advanced. In some cases, it has longer life spans, and humans have expanded into space. But we still face some of the same geopolitical questions and some of the same inequalities and exploitations that exist in our world, are still present, in some cases, worse. That's all the backdrop of it. And the core of it is about some fundamentally new technological object that is being brought into that world and how everyone reacts to it, how governments react to it, how individual people react to it, and how political ideologies react to it. And so, I don't know. When I read that a few years ago, I saw a lot of parallels. And then my third recommendation would be actually \"The Guns of August,\" which is basically a history of how World War I started. The basic idea that crises happen very fast, almost no one knows what's going on. There are lots of miscalculations because there are humans at the center of it, and kind of, we somehow have to learn to step back and make wiser decisions in these key moments. It's said that Kennedy read the book before the Cuban Missile Crisis. And so I hope our current policymakers are at least thinking along the same terms because I think it is possible similar crises may be coming our way. Dario Amodei, thank you very much. Thank you for having me. [MUSIC PLAYING] This episode of \"The Ezra Klein Show\" was produced by Rollin Hu. Fact-checking by Michelle Harris. Our senior engineer is Jeff Geld. Our senior editor is Claire Gordon. The show's production team also includes Annie Galvin, Kristin Lin and Aman Sahota. Original music by Isaac Jones. Audience strategy by Kristina Samulewski and Shannon Busta. The executive producer of New York Times Opinion Audio is Annie-Rose Strasser. And special thanks to Sonia Herrero.","duration":"PT5.587S"}</script><div class="css-a19wyd"><time class="css-15rzub1 e16638kd0" dateTime="2024-04-12T05:03:56-04:00">April 12, 2024</time><div role="toolbar" data-testid="share-tools" aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" class="css-mfml7"><div class="css-d8bdto"><ul class="css-1liwv7v"><li class="css-1gh9hw8"><div class="css-vxcmzt"><div class="css-79elbk"><button type="button" aria-label="" aria-expanded="false" class="css-1eeh360 actionbar-button" data-testid="gift-article-button"><span class="css-lu72is"><svg aria-hidden="true" width="19" height="19" viewBox="0 0 19 19" class="sha-gift-icon"><path d="M18.04 5.293h-2.725c.286-.34.493-.74.606-1.17a2.875 2.875 0 0 0-.333-2.322A2.906 2.906 0 0 0 13.64.48a3.31 3.31 0 0 0-2.372.464 3.775 3.775 0 0 0-1.534 2.483l-.141.797-.142-.847A3.745 3.745 0 0 0 7.927.923 3.31 3.31 0 0 0 5.555.459 2.907 2.907 0 0 0 3.607 1.78a2.877 2.877 0 0 0-.333 2.321c.117.429.324.828.606 1.171H1.155a.767.767 0 0 0-.757.757v3.674a.767.767 0 0 0 .757.757h.424v7.53A1.01 1.01 0 0 0 2.588 19h14.13a1.01 1.01 0 0 0 1.01-.959v-7.56h.424a.758.758 0 0 0 .757-.757V6.05a.759.759 0 0 0-.868-.757Zm-7.196-1.625a2.665 2.665 0 0 1 1.01-1.736 2.24 2.24 0 0 1 1.574-.313 1.817 1.817 0 0 1 1.211.818 1.857 1.857 0 0 1 .202 1.453 2.2 2.2 0 0 1-.838 1.191h-3.431l.272-1.413ZM4.576 2.386a1.837 1.837 0 0 1 1.221-.817 2.23 2.23 0 0 1 1.565.313 2.624 2.624 0 0 1 1.01 1.736l.242 1.453H5.182a2.2 2.2 0 0 1-.838-1.19 1.857 1.857 0 0 1 .202-1.495h.03ZM1.548 6.424h7.54V9.39h-7.58l.04-2.967Zm1.181 4.128h6.359v7.287H2.729v-7.287Zm13.777 7.287h-6.348v-7.307h6.348v7.307Zm1.181-8.468h-7.53V6.404h7.53V9.37Z" fill="#121212" fill-rule="nonzero"></path></svg><svg aria-hidden="true" width="23" height="18" viewBox="0 0 23 18" class="sha-arrow-icon"><path d="M1.357 17.192a.663.663 0 0 1-.642-.81c1.82-7.955 6.197-12.068 12.331-11.68V1.127a.779.779 0 0 1 .42-.653.726.726 0 0 1 .78.106l8.195 6.986a.81.81 0 0 1 .253.557.82.82 0 0 1-.263.547l-8.196 6.955a.83.83 0 0 1-.779.105.747.747 0 0 1-.42-.663V11.29c-8.418-.905-10.974 5.177-11.08 5.45a.662.662 0 0 1-.6.453Zm10.048-7.26a16.37 16.37 0 0 1 2.314.158.81.81 0 0 1 .642.726v3.02l6.702-5.682-6.702-5.692v2.883a.767.767 0 0 1-.242.536.747.747 0 0 1-.547.18c-4.808-.537-8.364 1.85-10.448 6.922a11.679 11.679 0 0 1 8.28-3.093v.042Z" fill="#000" fill-rule="nonzero"></path></svg>Share full article</span></button></div></div></li><li class="css-2ykviq sha-std-share"><div class="css-vxcmzt"><div class="css-79elbk"><button type="button" aria-label="More sharing options ..." aria-expanded="false" class="css-1nurhyi actionbar-button"><svg aria-hidden="true" width="23" height="18" viewBox="0 0 23 18" class="css-zd9juy"><path d="M1.357 17.192a.663.663 0 0 1-.642-.81c1.82-7.955 6.197-12.068 12.331-11.68V1.127a.779.779 0 0 1 .42-.653.726.726 0 0 1 .78.106l8.195 6.986a.81.81 0 0 1 .253.557.82.82 0 0 1-.263.547l-8.196 6.955a.83.83 0 0 1-.779.105.747.747 0 0 1-.42-.663V11.29c-8.418-.905-10.974 5.177-11.08 5.45a.662.662 0 0 1-.6.453Zm10.048-7.26a16.37 16.37 0 0 1 2.314.158.81.81 0 0 1 .642.726v3.02l6.702-5.682-6.702-5.692v2.883a.767.767 0 0 1-.242.536.747.747 0 0 1-.547.18c-4.808-.537-8.364 1.85-10.448 6.922a11.679 11.679 0 0 1 8.28-3.093v.042Z" fill="#000" fill-rule="nonzero"></path></svg></button></div></div></li><li class="css-2ykviq save-button"><button type="button" role="switch" class="css-1yhvmgx actionbar-button" data-testid="save-article-button" aria-label="Save article for reading later..." aria-checked="false" disabled="" aria-busy="false" aria-live="polite"><svg width="12" height="18" viewBox="0 0 12 18" class="css-eap6fy"><g fill-rule="nonzero"><path class="saved-fill" d="M1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268z"></path><path class="saved-stroke" d="m12 18-5.9-4.756L0 17.98V1.014C0 .745.095.487.265.297.435.107.664 0 .904 0h10.192c.24 0 .47.107.64.297.169.19.264.448.264.717V18ZM1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268H1.158Z"></path></g></svg></button></li><li class="css-2ykviq commentAdjustClass"><span class="css-1nii3md actionbar-button"><div class="css-1mlnk6q" style="padding:8px 10px 7px;font-weight:normal"><svg aria-hidden="true" width="21" height="18" viewBox="0 0 21 18" class="css-2urdiw"><path d="m14.52 17.831-5.715-4.545H2.4a1.468 1.468 0 0 1-1.468-1.469V1.894A1.471 1.471 0 0 1 2.4.405h16.583a1.469 1.469 0 0 1 1.469 1.469v9.923a1.469 1.469 0 0 1-1.47 1.47H14.58l-.06 4.564ZM2.4 1.645a.228.228 0 0 0-.228.229v9.923a.228.228 0 0 0 .228.229h6.811l4.06 3.235v-3.235h5.652a.228.228 0 0 0 .229-.229V1.874a.228.228 0 0 0-.229-.229H2.4Z" fill="#121212" fill-rule="nonzero"></path></svg><span class="css-1re6eyk"><a href="/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html">27</a></span></div></span></li></ul></div></div></div><section name="articleBody" class="meteredContent css-1r7ky0e"><div class="css-s99gbd StoryBodyCompanionColumn"><div class="css-53u6y8"><div class="css-zera2v"><div class="css-103l8m3"><div class="css-t91cuf epjyd6m1"><div class="css-1l3nmlr epjyd6m0"><p class="css-1tx0lhj e1jsehar1"><span class="byline-prefix">Produced by </span><span class="css-1baulvz last-byline" itemProp="name">‘The Ezra Klein Show’</span></p></div></div></div></div><p class="css-at9mc1 evys1bk0">Back in 2018, Dario Amodei worked at OpenAI. And looking at one of its first A.I. models, he wondered: What would happen as you fed an artificial intelligence more and more data?</p><p class="css-at9mc1 evys1bk0">He and his colleagues decided to study it, and they found that the A.I. didn’t just get better with more data; it got better exponentially. The curve of the A.I.’s capabilities rose slowly at first and then shot up like a hockey stick.</p><p class="css-at9mc1 evys1bk0"><em class="css-2fg4z9 e1gzwzxm0">[You can listen to this episode of “The Ezra Klein Show” on the </em><a class="css-yywogo" href="https://apps.apple.com/us/app/nyt-audio/id1549293936" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">NYT Audio App</em></a><em class="css-2fg4z9 e1gzwzxm0">, </em><a class="css-yywogo" href="https://podcasts.apple.com/us/podcast/the-ezra-klein-show/id1548604447" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">Apple</em></a><em class="css-2fg4z9 e1gzwzxm0">, </em><a class="css-yywogo" href="https://open.spotify.com/show/3oB5noYIwEB2dMAREj2F7S" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">Spotify</em></a><em class="css-2fg4z9 e1gzwzxm0">, </em><a class="css-yywogo" href="https://music.amazon.com/podcasts/c4a3b1da-5433-49e6-8c14-0e1da53be78c/the-ezra-klein-show" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">Amazon Music</em></a><em class="css-2fg4z9 e1gzwzxm0">, </em><a class="css-yywogo" href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS84MkZJMzVQeA%3D%3D" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">Google</em></a><em class="css-2fg4z9 e1gzwzxm0"> or </em><a class="css-yywogo" href="https://www.nytimes.com/2021/01/19/opinion/how-to-listen-ezra-klein-show-nyt.html?action=click&amp;module=RelatedLinks&amp;pgtype=Article" title=""><em class="css-2fg4z9 e1gzwzxm0">wherever you get your podcasts</em></a><em class="css-2fg4z9 e1gzwzxm0">.]</em></p><p class="css-at9mc1 evys1bk0">Amodei is now the chief executive of his own A.I. company, Anthropic, which recently released Claude 3 — considered by many to be the strongest A.I. model available. And he still believes A.I. is on an exponential growth curve, following principles known as scaling laws. And he thinks we’re on the steep part of the climb right now.</p></div><aside class="css-ew4tgv" aria-label="companion column"></aside></div><div></div><div class="css-s99gbd StoryBodyCompanionColumn"><div class="css-53u6y8"><p class="css-at9mc1 evys1bk0">When I’ve talked to people who are building A.I., scenarios that feel like far-off science fiction end up on the horizon of about the next two years. So I asked Amodei on the show to share what he sees in the near future. What breakthroughs are around the corner? What worries him the most? And how are societies that struggle to adapt to change and governments that are slow to react to them supposed to prepare for the pace of change he predicts? What does that line on his graph mean for the rest of us?</p><p class="css-at9mc1 evys1bk0"><strong class="css-8qgvsz ebyp5n10"><em class="css-2fg4z9 e1gzwzxm0">This episode contains strong language.</em></strong></p><p class="css-at9mc1 evys1bk0">You can listen to our whole conversation by following “The Ezra Klein Show” on the <a class="css-yywogo" href="https://apps.apple.com/us/app/nyt-audio/id1549293936" title="" rel="noopener noreferrer" target="_blank">NYT Audio App</a>, <a class="css-yywogo" href="https://podcasts.apple.com/us/podcast/the-ezra-klein-show/id1548604447" title="" rel="noopener noreferrer" target="_blank">Apple</a>, <a class="css-yywogo" href="https://open.spotify.com/show/3oB5noYIwEB2dMAREj2F7S" title="" rel="noopener noreferrer" target="_blank">Spotify</a>, <a class="css-yywogo" href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS84MkZJMzVQeA%3D%3D" title="" rel="noopener noreferrer" target="_blank">Google</a> or <a class="css-yywogo" href="https://www.nytimes.com/2021/01/19/opinion/how-to-listen-ezra-klein-show-nyt.html?action=click&amp;module=RelatedLinks&amp;pgtype=Article" title="">wherever you get your podcasts</a>. View a list of book recommendations from our guests <a class="css-yywogo" href="https://www.nytimes.com/article/ezra-klein-show-book-recs.html" title="">here</a>.</p><p class="css-at9mc1 evys1bk0"><em class="css-2fg4z9 e1gzwzxm0">(A full transcript of this episode is available </em><a class="css-yywogo" href="https://www.nytimes.com/2024/04/12/podcasts/transcript-ezra-klein-interviews-dario-amodei.html" title=""><em class="css-2fg4z9 e1gzwzxm0">here</em></a><em class="css-2fg4z9 e1gzwzxm0">.)</em></p></div><aside class="css-ew4tgv" aria-label="companion column"></aside></div><div><div data-testid="imageblock-wrapper"><figure class="img-sz-large css-hxpw2c e1g7ppur0" aria-label="media" role="group"><div class="css-1xdhyk6 erfvjey0" data-testid="photoviewer-children-figure"><span class="css-1ly73wi e1tej78p0">Image</span><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcSet="https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcSet="https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcSet="https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><img alt="A portrait of Dario Amodei." class="css-r3fift" src="https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcSet="https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2024/04/12/opinion/12eks-amodei-image/12eks-amodei-image-superJumbo.jpg?quality=75&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw" decoding="async" width="600" height="400"/></picture></div><figcaption data-testid="photoviewer-children-caption" class="css-1g9ic6e ewdxa0s0"><span class="css-1u46b97 e1z0qqy90"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span aria-hidden="false">Illustration by The New York Times; photograph by Dario Amodei</span></span></span></figcaption></figure></div></div><div><div data-testid="lazy-loader"></div></div><div class="css-s99gbd StoryBodyCompanionColumn"><div class="css-53u6y8"><p class="css-798hid etfikam0">This episode of “The Ezra Klein Show” was produced by Rollin Hu. Fact-checking by Michelle Harris. Our senior engineer is Jeff Geld. Our senior editor is Claire Gordon. The show’s production team also includes Annie Galvin, Kristin Lin and Aman Sahota. Original music by Isaac Jones. Audience strategy by Kristina Samulewski and Shannon Busta. The executive producer of New York Times Opinion Audio is Annie-Rose Strasser. Special thanks to Sonia Herrero.</p><p class="css-798hid etfikam0"><em class="css-2fg4z9 e1gzwzxm0">Follow the New York Times Opinion section on </em><a class="css-yywogo" href="https://www.facebook.com/nytopinion" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">Facebook</em></a><em class="css-2fg4z9 e1gzwzxm0">, </em><a class="css-yywogo" href="https://www.instagram.com/nytopinion/" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">Instagram</em></a><em class="css-2fg4z9 e1gzwzxm0">, </em><a class="css-yywogo" href="https://www.tiktok.com/@nytopinion" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">TikTok</em></a><em class="css-2fg4z9 e1gzwzxm0">, </em><a class="css-yywogo" href="https://www.whatsapp.com/channel/0029VaN8tdZ5vKAGNwXaED0M" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">WhatsApp</em></a><em class="css-2fg4z9 e1gzwzxm0">, </em><a class="css-yywogo" href="http://twitter.com/NYTOpinion" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">X</em></a><em class="css-2fg4z9 e1gzwzxm0"> and </em><a class="css-yywogo" href="https://www.threads.net/@nytopinion" title="" rel="noopener noreferrer" target="_blank"><em class="css-2fg4z9 e1gzwzxm0">Threads</em></a><em class="css-2fg4z9 e1gzwzxm0">.</em></p></div><aside class="css-ew4tgv" aria-label="companion column"></aside></div></section><div class="bottom-of-article"><div class="css-19vx93s"></div><div class="css-1jp38cr"></div><div role="toolbar" data-testid="share-tools" aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" class="css-mfml7"><div class="css-10i3hc"><span class="css-1nii3md"><div class="css-1mlnk6q" style="padding:8px 10px 7px;font-weight:normal"><svg aria-hidden="true" width="21" height="18" viewBox="0 0 21 18" class="css-2urdiw"><path d="m14.52 17.831-5.715-4.545H2.4a1.468 1.468 0 0 1-1.468-1.469V1.894A1.471 1.471 0 0 1 2.4.405h16.583a1.469 1.469 0 0 1 1.469 1.469v9.923a1.469 1.469 0 0 1-1.47 1.47H14.58l-.06 4.564ZM2.4 1.645a.228.228 0 0 0-.228.229v9.923a.228.228 0 0 0 .228.229h6.811l4.06 3.235v-3.235h5.652a.228.228 0 0 0 .229-.229V1.874a.228.228 0 0 0-.229-.229H2.4Z" fill="#121212" fill-rule="nonzero"></path></svg><span class="css-1re6eyk"><a href="/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html">27</a></span></div></span></div><div class="css-jf7ug7"><ul class="css-1liwv7v"><li class="css-1gh9hw8"><div class="css-vxcmzt"><div class="css-79elbk"><button type="button" aria-label="" aria-expanded="false" class="css-1eeh360 actionbar-button" data-testid="gift-article-button"><span class="css-lu72is"><svg aria-hidden="true" width="19" height="19" viewBox="0 0 19 19" class="sha-gift-icon"><path d="M18.04 5.293h-2.725c.286-.34.493-.74.606-1.17a2.875 2.875 0 0 0-.333-2.322A2.906 2.906 0 0 0 13.64.48a3.31 3.31 0 0 0-2.372.464 3.775 3.775 0 0 0-1.534 2.483l-.141.797-.142-.847A3.745 3.745 0 0 0 7.927.923 3.31 3.31 0 0 0 5.555.459 2.907 2.907 0 0 0 3.607 1.78a2.877 2.877 0 0 0-.333 2.321c.117.429.324.828.606 1.171H1.155a.767.767 0 0 0-.757.757v3.674a.767.767 0 0 0 .757.757h.424v7.53A1.01 1.01 0 0 0 2.588 19h14.13a1.01 1.01 0 0 0 1.01-.959v-7.56h.424a.758.758 0 0 0 .757-.757V6.05a.759.759 0 0 0-.868-.757Zm-7.196-1.625a2.665 2.665 0 0 1 1.01-1.736 2.24 2.24 0 0 1 1.574-.313 1.817 1.817 0 0 1 1.211.818 1.857 1.857 0 0 1 .202 1.453 2.2 2.2 0 0 1-.838 1.191h-3.431l.272-1.413ZM4.576 2.386a1.837 1.837 0 0 1 1.221-.817 2.23 2.23 0 0 1 1.565.313 2.624 2.624 0 0 1 1.01 1.736l.242 1.453H5.182a2.2 2.2 0 0 1-.838-1.19 1.857 1.857 0 0 1 .202-1.495h.03ZM1.548 6.424h7.54V9.39h-7.58l.04-2.967Zm1.181 4.128h6.359v7.287H2.729v-7.287Zm13.777 7.287h-6.348v-7.307h6.348v7.307Zm1.181-8.468h-7.53V6.404h7.53V9.37Z" fill="#121212" fill-rule="nonzero"></path></svg><svg aria-hidden="true" width="23" height="18" viewBox="0 0 23 18" class="sha-arrow-icon"><path d="M1.357 17.192a.663.663 0 0 1-.642-.81c1.82-7.955 6.197-12.068 12.331-11.68V1.127a.779.779 0 0 1 .42-.653.726.726 0 0 1 .78.106l8.195 6.986a.81.81 0 0 1 .253.557.82.82 0 0 1-.263.547l-8.196 6.955a.83.83 0 0 1-.779.105.747.747 0 0 1-.42-.663V11.29c-8.418-.905-10.974 5.177-11.08 5.45a.662.662 0 0 1-.6.453Zm10.048-7.26a16.37 16.37 0 0 1 2.314.158.81.81 0 0 1 .642.726v3.02l6.702-5.682-6.702-5.692v2.883a.767.767 0 0 1-.242.536.747.747 0 0 1-.547.18c-4.808-.537-8.364 1.85-10.448 6.922a11.679 11.679 0 0 1 8.28-3.093v.042Z" fill="#000" fill-rule="nonzero"></path></svg>Share full article</span></button></div></div></li><li class="css-2ykviq sha-std-share"><div class="css-vxcmzt"><div class="css-79elbk"><button type="button" aria-label="More sharing options ..." aria-expanded="false" class="css-1nurhyi actionbar-button"><svg aria-hidden="true" width="23" height="18" viewBox="0 0 23 18" class="css-zd9juy"><path d="M1.357 17.192a.663.663 0 0 1-.642-.81c1.82-7.955 6.197-12.068 12.331-11.68V1.127a.779.779 0 0 1 .42-.653.726.726 0 0 1 .78.106l8.195 6.986a.81.81 0 0 1 .253.557.82.82 0 0 1-.263.547l-8.196 6.955a.83.83 0 0 1-.779.105.747.747 0 0 1-.42-.663V11.29c-8.418-.905-10.974 5.177-11.08 5.45a.662.662 0 0 1-.6.453Zm10.048-7.26a16.37 16.37 0 0 1 2.314.158.81.81 0 0 1 .642.726v3.02l6.702-5.682-6.702-5.692v2.883a.767.767 0 0 1-.242.536.747.747 0 0 1-.547.18c-4.808-.537-8.364 1.85-10.448 6.922a11.679 11.679 0 0 1 8.28-3.093v.042Z" fill="#000" fill-rule="nonzero"></path></svg></button></div></div></li><li class="css-2ykviq save-button"><button type="button" role="switch" class="css-1yhvmgx actionbar-button" data-testid="save-article-button" aria-label="Save article for reading later..." aria-checked="false" disabled="" aria-busy="false" aria-live="polite"><svg width="12" height="18" viewBox="0 0 12 18" class="css-eap6fy"><g fill-rule="nonzero"><path class="saved-fill" d="M1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268z"></path><path class="saved-stroke" d="m12 18-5.9-4.756L0 17.98V1.014C0 .745.095.487.265.297.435.107.664 0 .904 0h10.192c.24 0 .47.107.64.297.169.19.264.448.264.717V18ZM1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268H1.158Z"></path></g></svg></button></li><li class="css-2ykviq commentAdjustClass"><span class="css-1nii3md actionbar-button"><div class="css-1mlnk6q" style="padding:8px 10px 7px;font-weight:normal"><svg aria-hidden="true" width="21" height="18" viewBox="0 0 21 18" class="css-2urdiw"><path d="m14.52 17.831-5.715-4.545H2.4a1.468 1.468 0 0 1-1.468-1.469V1.894A1.471 1.471 0 0 1 2.4.405h16.583a1.469 1.469 0 0 1 1.469 1.469v9.923a1.469 1.469 0 0 1-1.47 1.47H14.58l-.06 4.564ZM2.4 1.645a.228.228 0 0 0-.228.229v9.923a.228.228 0 0 0 .228.229h6.811l4.06 3.235v-3.235h5.652a.228.228 0 0 0 .229-.229V1.874a.228.228 0 0 0-.229-.229H2.4Z" fill="#121212" fill-rule="nonzero"></path></svg><span class="css-1re6eyk"><a href="/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html">27</a></span></div></span></li></ul></div></div></div><div data-testid="lazy-loader"></div><div id="bottom-sheet-sensor"><div data-testid="lazy-loader"></div></div><div><div id="bottom-wrapper" class="css-sxwst7"><div id="bottom-slug" class="css-l9onyx"><p>Advertisement</p></div><a href="#after-bottom" class="css-777zgl">SKIP ADVERTISEMENT</a><div class="ad bottom-wrapper css-rfqw0c" id="bottom" style="min-height:90px"></div><div id="after-bottom"></div></div></div></article></div></main><nav class="css-1jmk4jh" id="site-index" aria-labelledby="site-index-label" data-testid="site-index"><h2 class="css-1dv1kvn" id="site-index-label">Site Index</h2><div class="css-sg7scw"><header class="css-jxzr5i"><a aria-label="New York Times" data-testid="site-index-header" href="/"><svg class="css-oylsik" viewBox="0 0 184 25" fill="#000" aria-hidden="true"><path d="M14.57,2.57C14.57,.55,12.65-.06,11.04,.01V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.36,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.88-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08C3.31,5.73,.5,8.56,.5,12.06c0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.08c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96M5.8,14.13l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.08-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm19.47-5.76l-.81,.64-2.47-2.2-2.86,2.21V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15-.79,.52-1.08-1.08v-7.12l.74-.54,1.7,1.48v6.19c0,3.92-.87,4.73-2.63,5.37v.1c2.93,.12,5.57-.87,5.57-5.89v-6.75l.88-.72-.12-.15h0Zm5.22,10.8l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h-.01Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6ZM53.65,1.61c0-.32-.08-.59-.2-.96h-.07c-.32,.87-.67,1.33-1.68,1.33-.88,0-1.58-.54-1.95-.94,0,.03-2.96,3.42-2.96,3.42l.15,.12,.84-.96c.64,.49,1.21,1.06,2.63,1.08V13.34l-6.06-10.5c-.47-.79-1.28-1.97-2.66-1.97-1.63,0-2.86,1.4-2.66,3.77h.1c.12-.59,.47-1.33,1.18-1.33,.57,0,1.03,.54,1.3,1.03v3.38c-1.87,0-2.93,.87-2.93,2.34,0,.61,.45,1.94,1.72,2.17v-.07c-.17-.17-.34-.32-.34-.67,0-.57,.42-.88,1.18-.88,.12,0,.3,.03,.37,.05v4.38c-2.2,.03-3.89,1.23-3.89,3.31s1.7,2.88,3.47,2.78v-.07c-1.11-.12-1.68-.69-1.68-1.5,0-.88,.64-1.36,1.45-1.36s1.43,.52,1.95,1.11l2.96-3.33-.12-.12-.76,.87c-1.14-1.01-1.87-1.48-3.18-1.68V4.67l8.36,14.57h.45V4.72c1.6-.1,3.03-1.3,3.03-3.11m2.81,17.54l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h0Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6Zm21.22-5.52l-.69,.52-1.97-1.68-2.29,2.07,.94,.88v7.72l-2.34-1.6v-6.26l.81-.57-2.41-2.24-2.24,2.07,.94,.88v7.46l-.15,.1-2.2-1.6v-6.13c0-1.43-.72-1.85-1.63-2.41-.76-.47-1.16-.91-1.16-1.63,0-.79,.69-1.11,.91-1.23-.79-.03-2.98,.76-3.03,2.76-.03,1.03,.47,1.48,.99,1.97,.52,.49,1.01,.96,1.01,1.83v6.01l-1.06,.84,.12,.12,1.01-.79,2.63,2.14,2.51-1.75,2.76,1.75,5.42-3.2v-6.95l1.21-.94-.1-.15h0Zm18.15-5.84l-1.03,.94-2.32-2.02-3.13,2.51V1.19h-.19V18.12c-.34-.05-1.06-.25-1.85-.37V3.58c0-1.03-.74-2.47-2.59-2.47s-3.01,1.56-3.01,2.91h.08c.1-.61,.52-1.16,1.13-1.16s1.18,.39,1.18,1.78v4.04c-1.75,.07-2.81,1.16-2.81,2.34,0,.67,.42,1.92,1.75,1.97v-.1c-.45-.19-.54-.42-.54-.67,0-.59,.57-.79,1.36-.79h.19v6.51c-1.5,.52-2.2,1.53-2.2,2.78,0,1.72,1.38,3.05,3.4,3.05,1.43,0,2.44-.25,3.75-.54,1.06-.22,2.21-.47,2.83-.47,.79,0,1.14,.35,1.14,.91,0,.72-.27,1.08-.69,1.21v.1c1.7-.32,2.69-1.3,2.69-2.83s-1.5-2.54-3.18-2.54c-.87,0-2.44,.27-3.72,.57-1.43,.32-2.66,.47-3.11,.47-.72,0-1.6-.32-1.6-1.28,0-.87,.72-1.56,2.49-1.56,.96,0,1.9,.15,3.08,.42,1.26,.27,2.12,.64,3.2,.64,1.5,0,2.71-.54,2.71-2.74V3.29l1.11-1.01-.12-.15h0Zm-4.24,6.78c-.27,.3-.59,.54-1.11,.54-.57,0-.87-.3-1.14-.54V3.81l.74-.59,1.5,1.28v4.41h0Zm0,2.41c-.25-.25-.57-.47-1.11-.47s-.91,.27-1.14,.47v-2.17c.22,.19,.59,.49,1.14,.49s.87-.25,1.11-.49v2.17Zm0,5.1c0,.84-.42,1.78-1.5,1.78-.17,0-.57-.03-.74-.05v-6.58c.25-.22,.57-.52,1.14-.52,.52,0,.81,.25,1.11,.52v4.86h0Zm8.78,2.74l5.03-3.13v-6.85l-3.25-2.39-5.03,2.88v6.78l-.99,.79,.1,.15,.81-.67,3.33,2.44h0Zm-.37-3.55v-7.3l2.51,1.87v7.3l-2.51-1.87Zm15.01-8.65c-.39,.27-.74,.42-1.11,.42-.39,0-.88-.25-1.14-.57,0,.03-1.87,2.02-1.87,2.02l-1.87-2.02-3.05,2.12,.1,.17,.81-.54,1.11,1.21v6.63l-1.33,1.01,.12,.12,.67-.46,2.49,2.12,3.15-2.09-.1-.15-.81,.49-1.28-1.16v-7.28c.52,.57,1.11,1.06,1.82,1.06,1.28,0,2.14-1.53,2.29-3.11m11.88,9.81l-.94,.59-5.2-7.76,.27-.37c.57,.34,1.08,.81,2.17,.81s2.47-1.14,2.59-3.23c-.27,.37-.81,.81-1.7,.81-.64,0-1.28-.42-1.67-.81l-3.55,5.22,4.71,7.17,3.42-2.27-.1-.17h0Zm-6.31,.19l-.79,.52-1.08-1.08V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm22.89-14.39c0-2.02-1.92-2.63-3.53-2.56V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.35,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.89-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08c-3.08,.84-5.89,3.67-5.89,7.17,0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.07c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96m-8.78,11.56l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.07-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm11.93-12.31l-2.17,1.82,1.85,2.09,2.17-1.82-1.85-2.09Zm3.3,15.15l-.79,.52-1.08-1.08v-7.17l.91-.72-.12-.15-.76,.59-1.8-2.14-2.96,2.07,.1,.17,.74-.49,.99,1.23v6.61l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm16.63-.1l-.74,.49-1.16-1.11v-7.03l.94-.72-.12-.15-.84,.64-2.47-2.2-2.78,2.17-2.44-2.17-2.74,2.14-1.85-2.14-2.96,2.07,.1,.17,.74-.49,1.06,1.21v6.61l-.81,.81,2.36,2,2.29-2.07-.94-.88v-7.04l.61-.45,1.7,1.48v6.16l-.79,.81,2.39,2,2.24-2.07-.94-.88v-7.04l.59-.47,1.72,1.5v6.06l-.69,.72,2.41,2.2,3.18-2.17-.1-.15h.02Zm8.6-1.5l-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.93l3.57,2.59,4.51-3.62-.12-.17h0Zm-5.08-1.88v-5.15l2.27,3.55-2.27,1.6Zm14.12-.97l-2-1.53c1.33-1.16,1.8-2.63,1.8-3.69,0-.15-.03-.42-.05-.67h-.08c-.19,.54-.72,1.01-1.53,1.01s-1.26-.45-1.75-.99l-4.58,2.54v3.72l1.75,1.38c-1.75,1.55-2.09,2.51-2.09,3.4s.52,1.67,1.41,2.02l.07-.12c-.22-.19-.42-.32-.42-.79,0-.34,.35-.88,1.14-.88,1.01,0,1.63,.69,1.95,1.06,0-.03,4.38-2.69,4.38-2.69v-3.77h0Zm-1.03-3.05c-.69,1.23-2.21,2.44-3.11,3.13l-1.11-.94v-3.62c.45,.99,1.36,1.82,2.54,1.82,.69,0,1.14-.12,1.67-.39m-1.9,8.13c-.52-1.16-1.63-2-2.86-2-.3,0-1.21-.03-2,.46,.47-.79,1.87-2.21,3.65-3.28l1.21,1.01v3.8Z"></path></svg></a><div class="css-1otr2jl"><a class="css-184m8ie" data-testid="go-to-homepage" href="/">Go to Home Page »</a></div></header><div class="css-qtw155" data-testid="site-index-accordion"><div class=" " role="tablist" aria-multiselectable="true" data-testid="accordion"><div class="" data-testid="accordion-item"><header aria-controls="body-siteindex-0" id="item-siteindex-0" class="css-1a5mdf6" role="tab" tabindex="0" aria-expanded="false" data-testid="accordion-item-header">News</header><div class="css-1hyfx7x" id="body-siteindex-0" aria-labelledby="item-siteindex-0" role="tabpanel" data-testid="accordion-item-body"><ul class="css-1gprdgz" data-testid="site-index-accordion-list"><li class="css-10t7hia"><a class="css-e9w26l" href="/" data-testid="accordion-item-list-link">Home Page</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/us" data-testid="accordion-item-list-link">U.S.</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/world" data-testid="accordion-item-list-link">World</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/politics" data-testid="accordion-item-list-link">Politics</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/nyregion" data-testid="accordion-item-list-link">New York</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/education" data-testid="accordion-item-list-link">Education</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/sports" data-testid="accordion-item-list-link">Sports</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/business" data-testid="accordion-item-list-link">Business</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/technology" data-testid="accordion-item-list-link">Tech</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/science" data-testid="accordion-item-list-link">Science</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/news-event/weather-climate" data-testid="accordion-item-list-link">Weather</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/spotlight/the-great-read" data-testid="accordion-item-list-link">The Great Read</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/obituaries" data-testid="accordion-item-list-link">Obituaries</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/headway" data-testid="accordion-item-list-link">Headway</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/spotlight/visual-investigations" data-testid="accordion-item-list-link">Visual Investigations</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/magazine" data-testid="accordion-item-list-link">The Magazine</a></li></ul></div></div><div class="" data-testid="accordion-item"><header aria-controls="body-siteindex-1" id="item-siteindex-1" class="css-1a5mdf6" role="tab" tabindex="0" aria-expanded="false" data-testid="accordion-item-header">Arts</header><div class="css-1hyfx7x" id="body-siteindex-1" aria-labelledby="item-siteindex-1" role="tabpanel" data-testid="accordion-item-body"><ul class="css-1gprdgz" data-testid="site-index-accordion-list"><li class="css-10t7hia"><a class="css-e9w26l" href="/section/books/review" data-testid="accordion-item-list-link">Books</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/books/best-sellers/" data-testid="accordion-item-list-link">Best Sellers Book List</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/arts/dance" data-testid="accordion-item-list-link">Dance</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/movies" data-testid="accordion-item-list-link">Movies</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/arts/music" data-testid="accordion-item-list-link">Music</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/spotlight/pop-culture" data-testid="accordion-item-list-link">Pop Culture</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/arts/television" data-testid="accordion-item-list-link">Television</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/theater" data-testid="accordion-item-list-link">Theater</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/arts/design" data-testid="accordion-item-list-link">Visual Arts</a></li></ul></div></div><div class="" data-testid="accordion-item"><header aria-controls="body-siteindex-2" id="item-siteindex-2" class="css-1a5mdf6" role="tab" tabindex="0" aria-expanded="false" data-testid="accordion-item-header">Lifestyle</header><div class="css-1hyfx7x" id="body-siteindex-2" aria-labelledby="item-siteindex-2" role="tabpanel" data-testid="accordion-item-body"><ul class="css-1gprdgz" data-testid="site-index-accordion-list"><li class="css-10t7hia"><a class="css-e9w26l" href="/section/health" data-testid="accordion-item-list-link">Health</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/well" data-testid="accordion-item-list-link">Well</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/food" data-testid="accordion-item-list-link">Food</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/reviews/dining" data-testid="accordion-item-list-link">Restaurant Reviews</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/fashion/weddings" data-testid="accordion-item-list-link">Love</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/travel" data-testid="accordion-item-list-link">Travel</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/style" data-testid="accordion-item-list-link">Style</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/fashion" data-testid="accordion-item-list-link">Fashion</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/realestate" data-testid="accordion-item-list-link">Real Estate</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/t-magazine" data-testid="accordion-item-list-link">T Magazine</a></li></ul></div></div><div class="" data-testid="accordion-item"><header aria-controls="body-siteindex-3" id="item-siteindex-3" class="css-1a5mdf6" role="tab" tabindex="0" aria-expanded="false" data-testid="accordion-item-header">Opinion</header><div class="css-1hyfx7x" id="body-siteindex-3" aria-labelledby="item-siteindex-3" role="tabpanel" data-testid="accordion-item-body"><ul class="css-1gprdgz" data-testid="site-index-accordion-list"><li class="css-10t7hia"><a class="css-e9w26l" href="/section/opinion" data-testid="accordion-item-list-link">Today&#x27;s Opinion</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/opinion/columnists" data-testid="accordion-item-list-link">Columnists</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/opinion/editorials" data-testid="accordion-item-list-link">Editorials</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/opinion/contributors" data-testid="accordion-item-list-link">Guest Essays</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/column/op-docs" data-testid="accordion-item-list-link">Op-Docs</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/opinion/letters" data-testid="accordion-item-list-link">Letters</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/opinion/sunday" data-testid="accordion-item-list-link">Sunday Opinion</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/spotlight/opinion-video" data-testid="accordion-item-list-link">Opinion Video</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/series/opinion-audio" data-testid="accordion-item-list-link">Opinion Audio</a></li></ul></div></div><div class="" data-testid="accordion-item"><header aria-controls="body-siteindex-4" id="item-siteindex-4" class="css-1a5mdf6" role="tab" tabindex="0" aria-expanded="false" data-testid="accordion-item-header">More</header><div class="css-1hyfx7x" id="body-siteindex-4" aria-labelledby="item-siteindex-4" role="tabpanel" data-testid="accordion-item-body"><ul class="css-1gprdgz" data-testid="site-index-accordion-list"><li class="css-10t7hia"><a class="css-e9w26l" href="/spotlight/podcasts" data-testid="accordion-item-list-link">Audio</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="https://www.nytimes.com/crosswords" data-testid="accordion-item-list-link">Games</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="https://cooking.nytimes.com" data-testid="accordion-item-list-link">Cooking</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="https://www.nytimes.com/wirecutter/" data-testid="accordion-item-list-link">Wirecutter</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="https://theathletic.com" data-testid="accordion-item-list-link">The Athletic</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/jobs" data-testid="accordion-item-list-link">Jobs</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/video" data-testid="accordion-item-list-link">Video</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/spotlight/graphics" data-testid="accordion-item-list-link">Graphics</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/trending/" data-testid="accordion-item-list-link">Trending</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/spotlight/nyt-events" data-testid="accordion-item-list-link">Live Events</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/corrections" data-testid="accordion-item-list-link">Corrections</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/reader-center" data-testid="accordion-item-list-link">Reader Center</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="https://timesmachine.nytimes.com/browser" data-testid="accordion-item-list-link">TimesMachine</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/section/learning" data-testid="accordion-item-list-link">The Learning Network</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="https://nytedu.com/" data-testid="accordion-item-list-link">School of The NYT</a></li><li class="css-10t7hia"><a class="css-e9w26l" href="/spotlight/nytimesineducation" data-testid="accordion-item-list-link">inEducation</a></li></ul></div></div></div></div><div class="css-v0l3hm" data-testid="site-index-sections"><div class="css-g4gku8" data-testid="site-index-section"><section class="css-1rr4qq7" aria-labelledby="site-index-section-label-0"><h3 class="css-1onhbft" id="site-index-section-label-0">News</h3><ul class="css-1iruc8t" data-testid="site-index-section-list"><li class="css-ist4u3"><a class="css-yk8vb4" href="/" data-testid="site-index-section-list-link">Home Page</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/us" data-testid="site-index-section-list-link">U.S.</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/world" data-testid="site-index-section-list-link">World</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/politics" data-testid="site-index-section-list-link">Politics</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/nyregion" data-testid="site-index-section-list-link">New York</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/education" data-testid="site-index-section-list-link">Education</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/sports" data-testid="site-index-section-list-link">Sports</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/business" data-testid="site-index-section-list-link">Business</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/technology" data-testid="site-index-section-list-link">Tech</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/science" data-testid="site-index-section-list-link">Science</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/news-event/weather-climate" data-testid="site-index-section-list-link">Weather</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/spotlight/the-great-read" data-testid="site-index-section-list-link">The Great Read</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/obituaries" data-testid="site-index-section-list-link">Obituaries</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/headway" data-testid="site-index-section-list-link">Headway</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/spotlight/visual-investigations" data-testid="site-index-section-list-link">Visual Investigations</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/magazine" data-testid="site-index-section-list-link">The Magazine</a></li></ul></section><section class="css-1rr4qq7" aria-labelledby="site-index-section-label-1"><h3 class="css-1onhbft" id="site-index-section-label-1">Arts</h3><ul class="css-1iruc8t" data-testid="site-index-section-list"><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/books/review" data-testid="site-index-section-list-link">Books</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/books/best-sellers/" data-testid="site-index-section-list-link">Best Sellers Book List</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/arts/dance" data-testid="site-index-section-list-link">Dance</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/movies" data-testid="site-index-section-list-link">Movies</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/arts/music" data-testid="site-index-section-list-link">Music</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/spotlight/pop-culture" data-testid="site-index-section-list-link">Pop Culture</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/arts/television" data-testid="site-index-section-list-link">Television</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/theater" data-testid="site-index-section-list-link">Theater</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/arts/design" data-testid="site-index-section-list-link">Visual Arts</a></li></ul></section><section class="css-1rr4qq7" aria-labelledby="site-index-section-label-2"><h3 class="css-1onhbft" id="site-index-section-label-2">Lifestyle</h3><ul class="css-1iruc8t" data-testid="site-index-section-list"><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/health" data-testid="site-index-section-list-link">Health</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/well" data-testid="site-index-section-list-link">Well</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/food" data-testid="site-index-section-list-link">Food</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/reviews/dining" data-testid="site-index-section-list-link">Restaurant Reviews</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/fashion/weddings" data-testid="site-index-section-list-link">Love</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/travel" data-testid="site-index-section-list-link">Travel</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/style" data-testid="site-index-section-list-link">Style</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/fashion" data-testid="site-index-section-list-link">Fashion</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/realestate" data-testid="site-index-section-list-link">Real Estate</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/t-magazine" data-testid="site-index-section-list-link">T Magazine</a></li></ul></section><section class="css-1rr4qq7" aria-labelledby="site-index-section-label-3"><h3 class="css-1onhbft" id="site-index-section-label-3">Opinion</h3><ul class="css-1iruc8t" data-testid="site-index-section-list"><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/opinion" data-testid="site-index-section-list-link">Today&#x27;s Opinion</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/opinion/columnists" data-testid="site-index-section-list-link">Columnists</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/opinion/editorials" data-testid="site-index-section-list-link">Editorials</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/opinion/contributors" data-testid="site-index-section-list-link">Guest Essays</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/column/op-docs" data-testid="site-index-section-list-link">Op-Docs</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/opinion/letters" data-testid="site-index-section-list-link">Letters</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/opinion/sunday" data-testid="site-index-section-list-link">Sunday Opinion</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/spotlight/opinion-video" data-testid="site-index-section-list-link">Opinion Video</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/series/opinion-audio" data-testid="site-index-section-list-link">Opinion Audio</a></li></ul></section><section class="css-1rr4qq7" aria-labelledby="site-index-section-label-4"><h3 class="css-1onhbft" id="site-index-section-label-4">More</h3><ul class="css-1iruc8t" data-testid="site-index-section-list"><li class="css-ist4u3"><a class="css-yk8vb4" href="/spotlight/podcasts" data-testid="site-index-section-list-link">Audio</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="https://www.nytimes.com/crosswords" data-testid="site-index-section-list-link">Games</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="https://cooking.nytimes.com" data-testid="site-index-section-list-link">Cooking</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="https://www.nytimes.com/wirecutter/" data-testid="site-index-section-list-link">Wirecutter</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="https://theathletic.com" data-testid="site-index-section-list-link">The Athletic</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/jobs" data-testid="site-index-section-list-link">Jobs</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/video" data-testid="site-index-section-list-link">Video</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/spotlight/graphics" data-testid="site-index-section-list-link">Graphics</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/trending/" data-testid="site-index-section-list-link">Trending</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/spotlight/nyt-events" data-testid="site-index-section-list-link">Live Events</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/corrections" data-testid="site-index-section-list-link">Corrections</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/reader-center" data-testid="site-index-section-list-link">Reader Center</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="https://timesmachine.nytimes.com/browser" data-testid="site-index-section-list-link">TimesMachine</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/section/learning" data-testid="site-index-section-list-link">The Learning Network</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="https://nytedu.com/" data-testid="site-index-section-list-link">School of The NYT</a></li><li class="css-ist4u3"><a class="css-yk8vb4" href="/spotlight/nytimesineducation" data-testid="site-index-section-list-link">inEducation</a></li></ul></section><div class="css-6xhk3s" aria-labelledby="site-index-subscribe-label"><h3 class="css-1onhbft" id="site-index-subscribe-label">Account</h3><ul class="css-1iruc8t" data-testid="site-index-subscribe-list"><li class="css-tj0ten"><a class="css-z6qatp" href="/subscription" data-testid="site-index-subscribe-list-link"><svg class="css-1o03u4n" viewBox="0 0 10 13"><path fill="#000" d="M9.9,8c-0.4,1.1-1.2,1.9-2.3,2.4V8l1.3-1.2L7.6,5.7V4c1.2-0.1,2-1,2-2c0-1.4-1.3-1.9-2.1-1.9c-0.2,0-0.3,0-0.6,0.1v0.1c0.1,0,0.2,0,0.3,0c0.5,0,0.9,0.2,0.9,0.7c0,0.4-0.3,0.7-0.8,0.7C6,1.7,4.5,0.6,2.8,0.6c-1.5,0-2.5,1.1-2.5,2.2C0.3,4,1,4.3,1.6,4.6l0-0.1C1.4,4.4,1.3,4.1,1.3,3.8c0-0.5,0.5-0.9,1-0.9C3.7,2.9,6,4,7.4,4h0.1v1.7L6.2,6.8L7.5,8v2.4c-0.5,0.2-1.1,0.3-1.7,0.3c-2.2,0-3.6-1.3-3.6-3.5c0-0.5,0.1-1,0.2-1.5l1.1-0.5V10l2.2-1v-5L2.5,5.5c0.3-1,1-1.7,1.8-2l0,0C2.2,3.9,0.1,5.6,0.1,8c0,2.9,2.4,4.8,5.2,4.8C8.2,12.9,9.9,10.9,9.9,8L9.9,8z"></path></svg>Subscribe</a></li><li class="css-tj0ten"><a class="css-z6qatp" href="/account" data-testid="site-index-subscribe-list-link"><svg class="css-1o03u4n" viewBox="0 0 20 20" fill="#333" xmlns="http://www.w3.org/2000/svg"><path d="M14.2379 6C14.2379 8.20914 12.4471 10 10.2379 10C8.02878 10 6.23792 8.20914 6.23792 6C6.23792 3.79086 8.02878 2 10.2379 2C12.4471 2 14.2379 3.79086 14.2379 6Z" fill="#333"></path><path d="M16.2355 14.5714C16.2371 14.5477 16.2379 14.5239 16.2379 14.5C16.2379 13.1193 13.5516 12 10.2379 12C6.92421 12 4.23792 13.1193 4.23792 14.5C4.23792 14.5239 4.23872 14.5477 4.24032 14.5714H4.23792V18H16.2379V14.5714H16.2355Z" fill="#333"></path></svg>Manage My Account</a></li><li class="css-tj0ten"><a class="css-z6qatp" href="https://www.nytimes.com/subscription/home-delivery" data-testid="site-index-subscribe-list-link"><svg class="css-1o03u4n" viewBox="0 0 14 13" fill="#000"><path d="M13.1,11.7H3.5V1.2h9.6V11.7zM13.1,0.4H3.5C3,0.4,2.6,0.8,2.6,1.2v2.2H0.9C0.4,3.4,0,3.8,0,4.3v5.2v1.5c0,0.8,0.8,1.5,1.8,1.5h1.7h0h7.4h2.2c0.5,0,0.9-0.4,0.9-0.9V1.2C14,0.8,13.6,0.4,13.1,0.4"></path><polygon points="10.9,3 5.2,3 5.2,3.9 11.4,3.9 11.4,3"></polygon><rect x="5.2" y="4.7" width="6.1" height="0.9"></rect><rect x="5.2" y="6.5" width="6.1" height="0.9"></rect></svg>Home Delivery</a></li><li class="css-tj0ten"><a class="css-z6qatp" href="https://www.nytimes.com/gift" data-testid="site-index-subscribe-list-link"><svg class="css-1o03u4n" viewBox="0 0 10 13"><path fill="#000" d="M9.9,8c-0.4,1.1-1.2,1.9-2.3,2.4V8l1.3-1.2L7.6,5.7V4c1.2-0.1,2-1,2-2c0-1.4-1.3-1.9-2.1-1.9c-0.2,0-0.3,0-0.6,0.1v0.1c0.1,0,0.2,0,0.3,0c0.5,0,0.9,0.2,0.9,0.7c0,0.4-0.3,0.7-0.8,0.7C6,1.7,4.5,0.6,2.8,0.6c-1.5,0-2.5,1.1-2.5,2.2C0.3,4,1,4.3,1.6,4.6l0-0.1C1.4,4.4,1.3,4.1,1.3,3.8c0-0.5,0.5-0.9,1-0.9C3.7,2.9,6,4,7.4,4h0.1v1.7L6.2,6.8L7.5,8v2.4c-0.5,0.2-1.1,0.3-1.7,0.3c-2.2,0-3.6-1.3-3.6-3.5c0-0.5,0.1-1,0.2-1.5l1.1-0.5V10l2.2-1v-5L2.5,5.5c0.3-1,1-1.7,1.8-2l0,0C2.2,3.9,0.1,5.6,0.1,8c0,2.9,2.4,4.8,5.2,4.8C8.2,12.9,9.9,10.9,9.9,8L9.9,8z"></path></svg>Gift Subscriptions</a></li></ul><ul class="css-1iruc8t" data-testid="site-index-corporate-links"><li><a class="css-1ea6cym" href="/subscription/groups?Pardot_Campaign_Code_Form_Input=89FQX">Group Subscriptions</a></li><li><a class="css-1ea6cym" href="/gift-articles">Gift Articles</a></li><li><a class="css-1ea6cym" href="/newsletters">Email Newsletters</a></li></ul><ul class="css-6td9kr" data-testid="site-index-alternate-links"><li><a class="css-1ea6cym" href="https://nytlicensing.com/">NYT Licensing</a></li><li><a class="css-1ea6cym" href="https://nytimes.pressreader.com/">Replica Edition</a></li><li><a class="css-1ea6cym" href="https://store.nytimes.com/">Times Store</a></li></ul></div></div></div></div></nav><footer class="css-1e1s8k7" role="contentinfo"><nav data-testid="footer" class="css-1qa4qp6"><h2 class="css-1dv1kvn">Site Information Navigation</h2><ul class="css-1ho5u4o edvi3so0"><li data-testid="copyright"><a class="css-jq1cx6" href="https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice">© <span>2024</span> <span>The New York Times Company</span></a></li></ul><ul class="css-t8x4fj edvi3so1"><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://www.nytco.com/">NYTCo</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us">Contact Us</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://help.nytimes.com/hc/en-us/articles/115015727108-Accessibility">Accessibility</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://www.nytco.com/careers/">Work with us</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://advertising.nytimes.com/">Advertise</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://www.tbrandstudio.com/">T Brand Studio</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers">Your Ad Choices</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://www.nytimes.com/privacy/privacy-policy">Privacy Policy</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service">Terms of Service</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale">Terms of Sale</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="/sitemap/">Site Map</a></li><li class="mobileOnly css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://www.nytimes.com/ca/">Canada</a></li><li class="mobileOnly css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://www.nytimes.com/international/">International</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" class="css-jq1cx6" href="https://help.nytimes.com/hc/en-us">Help</a></li><li class="css-a7htku edvi3so2"><a data-testid="footer-link" rel="nofollow" class="css-jq1cx6" href="https://www.nytimes.com/subscription?campaignId=37WXW">Subscriptions</a></li></ul><ul class="css-t8x4fj edvi3so1"><li class="css-a7htku edvi3so2"><a data-testid="privacy-preferences-link" rel="noreferrer noopener" target="_blank" class="css-jq1cx6" href="/privacy/manage-settings">Manage Privacy Preferences</a></li></ul></nav></footer></div></div></div></div>
    <script>window.__preloadedData = {"initialData":{"data":{"article":{"__typename":"Article","id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlL2FlMTMwMDAzLWYxYzctNWVmMi04OTY3LWMyMWZlYmVjNTY0ZQ==","compatibility":{"isOak":true,"hasInlineEmbeddedInteractives":false,"__typename":"CompatibilityFeatures","hasVideo":false,"hasOakConversionError":false,"isArtReview":false,"isBookReview":false,"isDiningReview":false,"isMovieReview":false,"isTheaterReview":false},"archiveProperties":{"timesMachineUrl":"","lede":"","thumbnails":[],"__typename":"ArticleArchiveProperties"},"collections":[{"id":"TGVnYWN5Q29sbGVjdGlvbjpueXQ6Ly9sZWdhY3ljb2xsZWN0aW9uL2ZkMzY0ZGJlLWMwZTMtNTQ1MC04NTU2LTYyZmVmMGY2ODIzYw==","url":"https:\u002F\u002Fwww.nytimes.com\u002Fcolumn\u002Fezra-klein-podcast","slug":"ezra-klein-podcast","__typename":"LegacyCollection","name":"The Ezra Klein Show","collectionType":"COLUMN","uri":"nyt:\u002F\u002Flegacycollection\u002Ffd364dbe-c0e3-5450-8556-62fef0f6823c","active":true,"header":"","tagline":"Real conversations. Ideas that matter. So many book recommendations.","mobileHeader":"","lastModified":"2022-07-08T19:30:58.756Z","firstPublished":"2021-01-13T21:52:09.000Z","type":"legacycollection"},{"id":"TGVnYWN5Q29sbGVjdGlvbjpueXQ6Ly9sZWdhY3ljb2xsZWN0aW9uL2RhZGQ0MTc3LWM5MzgtNTMxMS1iNmM3LTVhMGZhMzE4YWI0OQ==","url":"https:\u002F\u002Fwww.nytimes.com\u002Fsection\u002Fopinion","slug":"opinion","__typename":"LegacyCollection","name":"Opinion","collectionType":"SECTION","uri":"nyt:\u002F\u002Flegacycollection\u002Fdadd4177-c938-5311-b6c7-5a0fa318ab49","active":true,"header":"","tagline":"","mobileHeader":"","lastModified":"2024-03-04T11:10:54.221Z","firstPublished":"2015-12-10T15:47:43.000Z","type":"legacycollection"},{"id":"TGVnYWN5Q29sbGVjdGlvbjpueXQ6Ly9sZWdhY3ljb2xsZWN0aW9uLzE2OTI4ZjcxLWM4ZDktNTI5Yi04NWJkLTM3OGU0ZGY5NTgzNA==","url":"https:\u002F\u002Fwww.nytimes.com\u002Fsection\u002Fopinion\u002Fcolumnists","slug":"opinion-columnists","__typename":"LegacyCollection","name":"Opinion Columnists","collectionType":"SECTION","uri":"nyt:\u002F\u002Flegacycollection\u002F16928f71-c8d9-529b-85bd-378e4df95834","active":true,"header":"","tagline":"","mobileHeader":"","lastModified":"2022-01-14T16:24:27.450Z","firstPublished":"2017-06-06T21:17:33.000Z","type":"legacycollection"},{"id":"TGVnYWN5Q29sbGVjdGlvbjpueXQ6Ly9sZWdhY3ljb2xsZWN0aW9uL2EzYWNlOWM1LThjMjctNTMzZi1hMTQ2LTEwNjhmMmM3ODE3Mg==","url":"https:\u002F\u002Fwww.nytimes.com\u002Fsyndicated\u002Faudio-app-show-ezra-klein","slug":"audio-app-show-ezra-klein","__typename":"LegacyCollection","name":"The Ezra Klein Show","collectionType":"SYNDICATED","uri":"nyt:\u002F\u002Flegacycollection\u002Fa3ace9c5-8c27-533f-a146-1068f2c78172","active":false,"header":"","tagline":"","mobileHeader":"{\"audio\":{\"color\":\"#324f6c\"}}","lastModified":"2023-04-18T19:05:17.241Z","firstPublished":"2023-04-18T19:05:17.289Z","type":"legacycollection"},{"id":"TGVnYWN5Q29sbGVjdGlvbjpueXQ6Ly9sZWdhY3ljb2xsZWN0aW9uL2UxMzkyNWIzLTQzY2EtNTRhMS05Yjg1LTIyMjExZDJhMWUwMg==","url":"https:\u002F\u002Fwww.nytimes.com\u002Fsyndicated\u002Faudio-app-curated-science","slug":"audio-app-curated-science","__typename":"LegacyCollection","name":"Science","collectionType":"SYNDICATED","uri":"nyt:\u002F\u002Flegacycollection\u002Fe13925b3-43ca-54a1-9b85-22211d2a1e02","active":false,"header":"","tagline":"","mobileHeader":"","lastModified":"2022-10-07T17:39:04.845Z","firstPublished":"2022-10-07T17:39:05.531Z","type":"legacycollection"}],"tone":"OPINION","section":{"id":"U2VjdGlvbjpueXQ6Ly9zZWN0aW9uL2Q3YTcxMTg1LWFhNjAtNTYzNS1iY2UwLTVmYWI3NmM3YzI5Nw==","name":"opinion","displayName":"Opinion","url":"\u002Fsection\u002Fopinion","uri":"nyt:\u002F\u002Fsection\u002Fd7a71185-aa60-5635-bce0-5fab76c7c297","__typename":"Section"},"subsection":null,"sprinkledBody":{"content":[{"__typename":"HeaderMultimediaBlock","headlineColor":"BLACK","backgroundColor":"#ffffff","headline":{"content":[{"text":"What if Dario Amodei Is Right About A.I.?","__typename":"TextInline"}],"textAlign":"LEFT","__typename":"Heading1Block"},"summary":{"content":[{"text":"Anthropic’s co-founder and C.E.O. explains why he thinks artificial intelligence is on an “exponential curve.”","__typename":"TextInline"}],"textAlign":"LEFT","__typename":"SummaryBlock"},"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vNmYwZDM0MjUtYzIwNC01NWY0LWEzY2UtYTNmYjc4MGFkNWIy","transcript":{"__typename":"AudioTranscript","transcriptFragment":[{"text":"[MUSIC PLAYING]","speaker":"","timecode":{"start":0.01,"end":3.17,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"From New York Times Opinion, this is \"The Ezra Klein Show.\"","speaker":"EZRA KLEIN","timecode":{"start":3.18,"end":8.324,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"[MUSIC PLAYING]","speaker":"EZRA KLEIN","timecode":{"start":8.334,"end":11.312,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The really disorienting thing about talking to the people building A.I. is their altered sense of time.","speaker":"EZRA KLEIN","timecode":{"start":23.28,"end":29.3,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You're sitting there discussing some world that feels like weird sci-fi to even talk about, and then you ask, well, when do you think this is going to happen?","speaker":"EZRA KLEIN","timecode":{"start":29.3,"end":37.23,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And they say, I don't know -- two years.","speaker":"EZRA KLEIN","timecode":{"start":37.23,"end":40.04,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Behind those predictions are what are called the scaling laws.","speaker":"EZRA KLEIN","timecode":{"start":40.05,"end":43.58,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the scaling laws -- and I want to say this so clearly -- they're not laws.","speaker":"EZRA KLEIN","timecode":{"start":43.58,"end":48.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They're observations.","speaker":"EZRA KLEIN","timecode":{"start":48.2,"end":49.76,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They're predictions.","speaker":"EZRA KLEIN","timecode":{"start":49.76,"end":50.84,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They're based off of a few years, not a few hundred years or 1,000 years of data.","speaker":"EZRA KLEIN","timecode":{"start":50.84,"end":55.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But what they say is that the more computer power and data you feed into A.I. systems, the more powerful those systems get -- that the relationship is predictable, and more, that the relationship is exponential.","speaker":"EZRA KLEIN","timecode":{"start":55.63,"end":68.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Human beings have trouble thinking in exponentials.","speaker":"EZRA KLEIN","timecode":{"start":68.52,"end":71.75,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Think back to Covid, when we all had to do it.","speaker":"EZRA KLEIN","timecode":{"start":71.75,"end":74.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If you have one case of coronavirus and cases double every three days, then after 30 days, you have about 1,000 cases.","speaker":"EZRA KLEIN","timecode":{"start":74.63,"end":80.84,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That growth rate feels modest.","speaker":"EZRA KLEIN","timecode":{"start":80.84,"end":82.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's manageable.","speaker":"EZRA KLEIN","timecode":{"start":82.83,"end":84.3,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But then you go 30 days longer, and you have a million.","speaker":"EZRA KLEIN","timecode":{"start":84.3,"end":88.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Then you wait another 30 days.","speaker":"EZRA KLEIN","timecode":{"start":88.14,"end":90,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Now you have a billion.","speaker":"EZRA KLEIN","timecode":{"start":90,"end":91.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That's the power of the exponential curve.","speaker":"EZRA KLEIN","timecode":{"start":91.62,"end":93.84,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Growth feels normal for a while.","speaker":"EZRA KLEIN","timecode":{"start":93.84,"end":95.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Then it gets out of control really, really quickly.","speaker":"EZRA KLEIN","timecode":{"start":95.85,"end":98.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What the A.I. developers say is that the power of A.I. systems is on this kind of curve, that it has been increasing exponentially, their capabilities, and that as long as we keep feeding in more data and more computing power, it will continue increasing exponentially.","speaker":"EZRA KLEIN","timecode":{"start":98.86,"end":113.28,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That is the scaling law hypothesis, and one of its main advocates is Dario Amodei.","speaker":"EZRA KLEIN","timecode":{"start":113.28,"end":118.59,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Amodei led the team at OpenAI that created GPT-2, that created GPT-3.","speaker":"EZRA KLEIN","timecode":{"start":118.59,"end":123.75,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"He then left OpenAI to co-found Anthropic, another A.I. firm, where he's now the C.E.O. And Anthropic recently released Claude 3, which is considered by many to be the strongest A.I. model available right now.","speaker":"EZRA KLEIN","timecode":{"start":123.75,"end":135.78,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But Amodei believes we're just getting started, that we're just hitting the steep part of the curve now.","speaker":"EZRA KLEIN","timecode":{"start":135.79,"end":140.79,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"He thinks the kinds of systems we've imagined in sci-fi, they're coming not in 20 or 40 years, not in 10 or 15 years, they're coming in two to five years.","speaker":"EZRA KLEIN","timecode":{"start":140.79,"end":149.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"He thinks they're going to be so powerful that he and people like him should not be trusted to decide what they're going to do.","speaker":"EZRA KLEIN","timecode":{"start":149.37,"end":156.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I asked him on this show to try to answer in my own head two questions.","speaker":"EZRA KLEIN","timecode":{"start":156.38,"end":160.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"First, is he right?","speaker":"EZRA KLEIN","timecode":{"start":160.2,"end":162.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Second, what if he's right?","speaker":"EZRA KLEIN","timecode":{"start":162.63,"end":165.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I want to say that in the past, we have done shows with Sam Altman, the head of OpenAI, and Demis Hassabis, the head of Google DeepMind.","speaker":"EZRA KLEIN","timecode":{"start":165.15,"end":172.44,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And it's worth listening to those two if you find this interesting.","speaker":"EZRA KLEIN","timecode":{"start":172.44,"end":175.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We're going to put the links to them in show notes because comparing and contrasting how they talk about the A.I. curves here, how they think about the politics -- you'll hear a lot about that in the Sam Altman episode --","speaker":"EZRA KLEIN","timecode":{"start":175.9,"end":186.78,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"it gives you a kind of sense of what the people building these things are thinking and how maybe they differ from each other.","speaker":"EZRA KLEIN","timecode":{"start":186.78,"end":192.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"As always, my email for thoughts, for feedback, for guest suggestions -- ezrakleinshow@nytimes.com.","speaker":"EZRA KLEIN","timecode":{"start":192.86,"end":198.432,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"[MUSIC PLAYING]","speaker":"EZRA KLEIN","timecode":{"start":198.442,"end":201.284,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Dario Amodei, welcome to the show.","speaker":"EZRA KLEIN","timecode":{"start":204.24,"end":205.867,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Thank you for having me.","speaker":"DARIO AMODEI","timecode":{"start":205.867,"end":207.45,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So there are these two very different rhythms I've been thinking about with A.I. One is the curve of the technology itself, how fast it is changing and improving.","speaker":"EZRA KLEIN","timecode":{"start":207.46,"end":216.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the other is the pace at which society is seeing and reacting to those changes.","speaker":"EZRA KLEIN","timecode":{"start":216.2,"end":221.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What has that relationship felt like to you?","speaker":"EZRA KLEIN","timecode":{"start":221.18,"end":223.68,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I think this is an example of a phenomenon that we may have seen a few times before in history, which is that there's an underlying process that is smooth, and in this case, exponential.","speaker":"DARIO AMODEI","timecode":{"start":223.69,"end":235.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then there's a spilling over of that process into the public sphere.","speaker":"DARIO AMODEI","timecode":{"start":235.64,"end":240.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the spilling over looks very spiky.","speaker":"DARIO AMODEI","timecode":{"start":240.2,"end":243.71,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It looks like it's happening all of a sudden.","speaker":"DARIO AMODEI","timecode":{"start":243.71,"end":246.02,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It looks like it comes out of nowhere.","speaker":"DARIO AMODEI","timecode":{"start":246.02,"end":248,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And it's triggered by things hitting various critical points or just the public happened to be engaged at a certain time.","speaker":"DARIO AMODEI","timecode":{"start":248,"end":255.6,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I think the easiest way for me to describe this in terms of my own personal experience is -- so I worked at OpenAI for five years, I was one of the first employees to join.","speaker":"DARIO AMODEI","timecode":{"start":255.61,"end":267.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And they built a model in 2018 called GPT-1, which used something like 100,000 times less computational power than the models we build today.","speaker":"DARIO AMODEI","timecode":{"start":267.36,"end":276.99,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I looked at that, and I and my colleagues were among the first to run what are called scaling laws, which is basically studying what happens as you vary the size of the model, its capacity to absorb information, and the amount of data that you feed into it.","speaker":"DARIO AMODEI","timecode":{"start":277,"end":291.66,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And we found these very smooth patterns.","speaker":"DARIO AMODEI","timecode":{"start":291.66,"end":294.12,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And we had this projection that, look, if you spend $100 million or $1 billion or $10 billion on these models, instead of the $10,000 we were spending then, projections that all of these wondrous things would happen, and we imagined that they would have enormous economic value.","speaker":"DARIO AMODEI","timecode":{"start":294.12,"end":311.04,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Fast forward to about 2020.","speaker":"DARIO AMODEI","timecode":{"start":311.05,"end":313.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"GPT-3 had just come out.","speaker":"DARIO AMODEI","timecode":{"start":313.47,"end":315.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It wasn't yet available as a chat bot.","speaker":"DARIO AMODEI","timecode":{"start":315.97,"end":318.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I led the development of that along with the team that eventually left to join Anthropic.","speaker":"DARIO AMODEI","timecode":{"start":318.27,"end":323.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And maybe for the whole period of 2021 and 2022, even though we continued to train models that were better and better, and OpenAI continued to train models, and Google continued to train models, there was surprisingly little public attention to the models.","speaker":"DARIO AMODEI","timecode":{"start":323.55,"end":340.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I looked at that, and I said, well, these models are incredible.","speaker":"DARIO AMODEI","timecode":{"start":340.27,"end":343.24,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They're getting better and better.","speaker":"DARIO AMODEI","timecode":{"start":343.24,"end":344.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What's going on?","speaker":"DARIO AMODEI","timecode":{"start":344.73,"end":345.82,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Why isn't this happening?","speaker":"DARIO AMODEI","timecode":{"start":345.82,"end":347.04,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Could this be a case where I was right about the technology, but wrong about the economic impact, the practical value of the technology?","speaker":"DARIO AMODEI","timecode":{"start":347.04,"end":355.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then, all of a sudden, when ChatGPT came out, it was like all of that growth that you would expect, all of that excitement over three years, broke through and came rushing in.","speaker":"DARIO AMODEI","timecode":{"start":355.41,"end":366.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I want to linger on this difference between the curve at which the technology is improving and the way it is being adopted by society.","speaker":"EZRA KLEIN","timecode":{"start":366.68,"end":374.8,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So when you think about these break points and you think into the future, what other break points do you see coming where A.I. bursts into social consciousness or used in a different way?","speaker":"EZRA KLEIN","timecode":{"start":374.8,"end":383.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, so I think I should say first that it's very hard to predict these.","speaker":"DARIO AMODEI","timecode":{"start":383.86,"end":388.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"One thing I like to say is the underlying technology, because it's a smooth exponential, it's not perfectly predictable, but in some ways, it can be eerily preternaturally predictable, right?","speaker":"DARIO AMODEI","timecode":{"start":388.14,"end":400.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That's not true for these societal step functions at all.","speaker":"DARIO AMODEI","timecode":{"start":400.14,"end":403.78,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's very hard to predict what will catch on.","speaker":"DARIO AMODEI","timecode":{"start":403.78,"end":406.68,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In some ways, it feels a little bit like which artist or musician is going to catch on and get to the top of the charts.","speaker":"DARIO AMODEI","timecode":{"start":406.68,"end":414.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That said, a few possible ideas.","speaker":"DARIO AMODEI","timecode":{"start":414.64,"end":417.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think one is related to something that you mentioned, which is interacting with the models in a more kind of naturalistic way.","speaker":"DARIO AMODEI","timecode":{"start":417.63,"end":426.75,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We've actually already seen some of that with Claude 3, where people feel that some of the other models sound like a robot and that talking to Claude 3 is more natural.","speaker":"DARIO AMODEI","timecode":{"start":426.75,"end":438.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think a thing related to this is, a lot of companies have been held back or tripped up by how their models handle controversial topics.","speaker":"DARIO AMODEI","timecode":{"start":438.37,"end":447.57,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And we were really able to, I think, do a better job than others of telling the model, don't shy away from discussing controversial topics.","speaker":"DARIO AMODEI","timecode":{"start":447.58,"end":454.98,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Don't assume that both sides necessarily have a valid point but don't express an opinion yourself.","speaker":"DARIO AMODEI","timecode":{"start":454.98,"end":461.79,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Don't express views that are flagrantly biased.","speaker":"DARIO AMODEI","timecode":{"start":461.79,"end":464.478,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"As journalists, you encounter this all the time, right?","speaker":"DARIO AMODEI","timecode":{"start":464.478,"end":466.77,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"How do I be objective, but not both sides on everything?","speaker":"DARIO AMODEI","timecode":{"start":466.77,"end":470.94,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I think going further in that direction of models having personalities while still being objective, while still being useful and not falling into various ethical traps, that will be, I think, a significant unlock for adoption.","speaker":"DARIO AMODEI","timecode":{"start":470.95,"end":488.19,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The models taking actions in the world is going to be a big one.","speaker":"DARIO AMODEI","timecode":{"start":488.19,"end":492.01,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I know basically all the big companies that work on A.I. are working on that.","speaker":"DARIO AMODEI","timecode":{"start":492.01,"end":496.8,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Instead of just, I ask it a question and it answers, and then maybe I follow up and it answers again, can I talk to the model about, oh, I'm going to go on this trip today, and the model says, oh, that's great.","speaker":"DARIO AMODEI","timecode":{"start":496.81,"end":508.06,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'll get an Uber for you to drive from here to there, and I'll reserve a restaurant.","speaker":"DARIO AMODEI","timecode":{"start":508.06,"end":512.799,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I'll talk to the other people who are going to plan the trip.","speaker":"DARIO AMODEI","timecode":{"start":512.799,"end":515.77,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the model being able to do things end to end or going to websites or taking actions on your computer for you.","speaker":"DARIO AMODEI","timecode":{"start":515.77,"end":523.34,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think all of that is coming in the next, I would say --","speaker":"DARIO AMODEI","timecode":{"start":523.35,"end":526.42,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't know -- three to 18 months, with increasing levels of ability.","speaker":"DARIO AMODEI","timecode":{"start":526.42,"end":530.92,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think that's going to change how people think about A.I., right, where so far, it's been this very passive -- it's like, I go to the Oracle.","speaker":"DARIO AMODEI","timecode":{"start":530.92,"end":538.84,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I ask it a question, and the Oracle tells me things.","speaker":"DARIO AMODEI","timecode":{"start":538.84,"end":542.05,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And some people think that's exciting, some people think it's scary.","speaker":"DARIO AMODEI","timecode":{"start":542.05,"end":545.53,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I think there are limits to how exciting or how scary it's perceived as because it's contained within this box.","speaker":"DARIO AMODEI","timecode":{"start":545.53,"end":553.143,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I want to sit with this question of the agentic A.I. because I do think this is what's coming.","speaker":"EZRA KLEIN","timecode":{"start":553.143,"end":557.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's clearly what people are trying to build.","speaker":"EZRA KLEIN","timecode":{"start":557.56,"end":559.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I think it might be a good way to look at some of the specific technological and cultural challenges.","speaker":"EZRA KLEIN","timecode":{"start":559.64,"end":566.42,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, let me offer two versions of it.","speaker":"EZRA KLEIN","timecode":{"start":566.42,"end":568.91,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"People who are following the A.I. news might have heard about Devin, which is not in release yet, but is an A.I. that at least purports to be able to complete the kinds of tasks, linked tasks, that a junior software engineer might complete, right?","speaker":"EZRA KLEIN","timecode":{"start":568.92,"end":585.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Instead of asking to do a bit of code for you, you say, listen, I want a website.","speaker":"EZRA KLEIN","timecode":{"start":585.73,"end":589.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's going to have to do these things, work in these ways.","speaker":"EZRA KLEIN","timecode":{"start":589.46,"end":591.88,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And maybe Devin, if it works the way people are saying it works, can actually hold that set of thoughts, complete a number of different tasks, and come back to you with a result.","speaker":"EZRA KLEIN","timecode":{"start":591.88,"end":600.145,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm also interested in the version of this that you might have in the real world.","speaker":"EZRA KLEIN","timecode":{"start":600.145,"end":603.52,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The example I always use in my head is, when can I tell an A.I., my son is turning five.","speaker":"EZRA KLEIN","timecode":{"start":603.52,"end":610.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"He loves dragons.","speaker":"EZRA KLEIN","timecode":{"start":610.25,"end":611.59,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We live in Brooklyn.","speaker":"EZRA KLEIN","timecode":{"start":611.59,"end":613.19,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Give me some options for planning his birthday party.","speaker":"EZRA KLEIN","timecode":{"start":613.19,"end":616.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then, when I choose between them, can you just do it all for me?","speaker":"EZRA KLEIN","timecode":{"start":616.62,"end":619.94,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Order the cake, reserve the room, send out the invitations, whatever it might be.","speaker":"EZRA KLEIN","timecode":{"start":619.94,"end":624.92,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Those are two different situations because one of them is in code, and one of them is making decisions in the real world, interacting with real people, knowing if what it is finding on the websites is actually any good.","speaker":"EZRA KLEIN","timecode":{"start":624.93,"end":636.08,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What is between here and there?","speaker":"EZRA KLEIN","timecode":{"start":636.08,"end":637.79,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"When I say that in plain language to you, what technological challenges or advances do you hear need to happen to get there?","speaker":"EZRA KLEIN","timecode":{"start":637.79,"end":647.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The short answer is not all that much.","speaker":"DARIO AMODEI","timecode":{"start":647.57,"end":650.11,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"A story I have from when we were developing models back in 2022 -- and this is before we'd hooked up the models to anything -- is, you could have a conversation with these purely textual models where you could say, hey, I want to reserve dinner at restaurant X in San Francisco,","speaker":"DARIO AMODEI","timecode":{"start":650.11,"end":667.3,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"and the model would say, OK, here's the website of restaurant X. And it would actually give you a correct website or would tell you to go to Open Table or something.","speaker":"DARIO AMODEI","timecode":{"start":667.3,"end":674.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And of course, it can't actually go to the website.","speaker":"DARIO AMODEI","timecode":{"start":674.87,"end":677.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The power plug isn't actually plugged in, right?","speaker":"DARIO AMODEI","timecode":{"start":677.86,"end":680.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The brain of the robot is not actually attached to its arms and legs.","speaker":"DARIO AMODEI","timecode":{"start":680.14,"end":683.95,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But it gave you this sense that the brain, all it needed to do was learn exactly how to use the arms and legs, right?","speaker":"DARIO AMODEI","timecode":{"start":683.95,"end":690.82,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It already had a picture of the world and where it would walk and what it would do.","speaker":"DARIO AMODEI","timecode":{"start":690.82,"end":694.82,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, it felt like there was this very thin barrier between the passive models we had and actually acting in the world.","speaker":"DARIO AMODEI","timecode":{"start":694.82,"end":701.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In terms of what we need to make it work, one thing is, literally, we just need a little bit more scale.","speaker":"DARIO AMODEI","timecode":{"start":701.63,"end":708.3,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I think the reason we're going to need more scale is --","speaker":"DARIO AMODEI","timecode":{"start":708.3,"end":712.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"to do one of those things you described, to do all the things a junior software engineer does, they involve chains of long actions, right?","speaker":"DARIO AMODEI","timecode":{"start":712.37,"end":720.02,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I have to write this line of code.","speaker":"DARIO AMODEI","timecode":{"start":720.02,"end":722.09,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I have to run this test.","speaker":"DARIO AMODEI","timecode":{"start":722.09,"end":723.48,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I have to write a new test.","speaker":"DARIO AMODEI","timecode":{"start":723.48,"end":724.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I have to check how it looks in the app after I interpret it or compile it.","speaker":"DARIO AMODEI","timecode":{"start":724.97,"end":729.17,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And these things can easily get 20 or 30 layers deep.","speaker":"DARIO AMODEI","timecode":{"start":729.17,"end":732.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And same with planning the birthday party for your son, right?","speaker":"DARIO AMODEI","timecode":{"start":732.41,"end":736.04,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And if the accuracy of any given step is not very high, is not like 99.9 percent, as you compose these steps, the probability of making a mistake becomes itself very high.","speaker":"DARIO AMODEI","timecode":{"start":736.05,"end":748.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So the industry is going to get a new generation of models every probably four to eight months.","speaker":"DARIO AMODEI","timecode":{"start":748.89,"end":753.99,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, my guess --","speaker":"DARIO AMODEI","timecode":{"start":753.99,"end":755.42,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm not sure -- is that to really get these things working well, we need maybe one to four more generations.","speaker":"DARIO AMODEI","timecode":{"start":755.42,"end":761.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So that ends up translating to 3 to 24 months or something like that.","speaker":"DARIO AMODEI","timecode":{"start":761.31,"end":766.19,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think second is just, there is some algorithmic work that is going to need to be done on how to have the models interact with the world in this way.","speaker":"DARIO AMODEI","timecode":{"start":766.2,"end":776.17,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think the basic techniques we have, a method called reinforcement learning and variations of it, probably is up to the task, but figuring out exactly how to use it to get the results we want will probably take some time.","speaker":"DARIO AMODEI","timecode":{"start":776.17,"end":789.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then third, I think -- and this gets to something that Anthropic really specializes in -- is safety and controllability.","speaker":"DARIO AMODEI","timecode":{"start":789.27,"end":795.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I think that's going to be a big issue for these models acting in the world, right?","speaker":"DARIO AMODEI","timecode":{"start":795.25,"end":799.57,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Let's say this model is writing code for me, and it introduces a serious security bug in the code, or it's taking actions on the computer for me and modifying the state of my computer in ways that are too complicated for me to even understand.","speaker":"DARIO AMODEI","timecode":{"start":799.57,"end":814.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And for planning the birthday party, right, the level of trust you would need to take an A.I. agent and say, I'm OK with you calling up anyone, saying anything to them that's in any private information that I might have, sending them any information, taking any action on my computer,","speaker":"DARIO AMODEI","timecode":{"start":814.19,"end":832.21,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"posting anything to the internet, the most unconstrained version of that sounds very scary.","speaker":"DARIO AMODEI","timecode":{"start":832.21,"end":836.98,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, we're going to need to figure out what is safe and controllable.","speaker":"DARIO AMODEI","timecode":{"start":836.98,"end":840.75,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The more open ended the thing is, the more powerful it is, but also, the more dangerous it is and the harder it is to control.","speaker":"DARIO AMODEI","timecode":{"start":840.76,"end":848.32,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I think those questions, although they sound lofty and abstract, are going to turn into practical product questions that we and other companies are going to be trying to address.","speaker":"DARIO AMODEI","timecode":{"start":848.33,"end":857.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"When you say we're just going to need more scale, you mean more compute and more training data, and I guess, possibly more money to simply make the models smarter and more capable?","speaker":"EZRA KLEIN","timecode":{"start":857.87,"end":867.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yes, we're going to have to make bigger models that use more compute per iteration.","speaker":"DARIO AMODEI","timecode":{"start":867.65,"end":873.13,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We're going to have to run them for longer by feeding more data into them.","speaker":"DARIO AMODEI","timecode":{"start":873.13,"end":877.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And that number of chips times the amount of time that we run things on chips is essentially dollar value because these chips are --","speaker":"DARIO AMODEI","timecode":{"start":877.67,"end":885.697,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"you rent them by the hour.","speaker":"DARIO AMODEI","timecode":{"start":885.697,"end":886.78,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That's the most common model for it.","speaker":"DARIO AMODEI","timecode":{"start":886.78,"end":888.95,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, today's models cost of order $100 million to train, plus or minus factor two or three.","speaker":"DARIO AMODEI","timecode":{"start":888.95,"end":896.35,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The models that are in training now and that will come out at various times later this year or early next year are closer in cost to $1 billion.","speaker":"DARIO AMODEI","timecode":{"start":896.36,"end":906.43,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So that's already happening.","speaker":"DARIO AMODEI","timecode":{"start":906.43,"end":907.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then I think in 2025 and 2026, we'll get more towards $5 or $10 billion.","speaker":"DARIO AMODEI","timecode":{"start":907.97,"end":913.49,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So we're moving very quickly towards a world where the only players who can afford to do this are either giant corporations, companies hooked up to giant corporations -- you all are getting billions of dollars from Amazon.","speaker":"EZRA KLEIN","timecode":{"start":913.5,"end":927.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"OpenAI is getting billions of dollars from Microsoft.","speaker":"EZRA KLEIN","timecode":{"start":927.56,"end":930.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Google obviously makes its own.","speaker":"EZRA KLEIN","timecode":{"start":930.18,"end":931.76,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You can imagine governments -- though I don't know of too many governments doing it directly, though some, like the Saudis, are creating big funds to invest in the space.","speaker":"EZRA KLEIN","timecode":{"start":931.77,"end":939.8,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"When we're talking about the model's going to cost near to $1 billion, then you imagine a year or two out from that, if you see the same increase, that would be $10-ish billion.","speaker":"EZRA KLEIN","timecode":{"start":939.8,"end":949.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Then is it going to be $100 billion?","speaker":"EZRA KLEIN","timecode":{"start":949.37,"end":950.96,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, very quickly, the financial artillery you need to create one of these is going to wall out anyone but the biggest players.","speaker":"EZRA KLEIN","timecode":{"start":950.96,"end":960.417,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I basically do agree with you.","speaker":"DARIO AMODEI","timecode":{"start":960.417,"end":962.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think it's the intellectually honest thing to say that building the big, large scale models, the core foundation model engineering, it is getting more and more expensive.","speaker":"DARIO AMODEI","timecode":{"start":962.25,"end":972.96,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And anyone who wants to build one is going to need to find some way to finance it.","speaker":"DARIO AMODEI","timecode":{"start":972.96,"end":977.09,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And you've named most of the ways, right?","speaker":"DARIO AMODEI","timecode":{"start":977.09,"end":979.1,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You can be a large company.","speaker":"DARIO AMODEI","timecode":{"start":979.1,"end":980.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You can have some kind of partnership of various kinds with a large company.","speaker":"DARIO AMODEI","timecode":{"start":980.63,"end":985.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Or governments would be the other source.","speaker":"DARIO AMODEI","timecode":{"start":985.64,"end":988.01,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think one way that it's not correct is, we're always going to have a thriving ecosystem of experimentation on small models.","speaker":"DARIO AMODEI","timecode":{"start":988.02,"end":996.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"For example, the open source community working to make models that are as small and as efficient as possible that are optimized for a particular use case.","speaker":"DARIO AMODEI","timecode":{"start":996.51,"end":1006.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And also downstream usage of the models.","speaker":"DARIO AMODEI","timecode":{"start":1006.25,"end":1008.68,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, there's a blooming ecosystem of startups there that don't need to train these models from scratch.","speaker":"DARIO AMODEI","timecode":{"start":1008.68,"end":1014.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They just need to consume them and maybe modify them a bit.","speaker":"DARIO AMODEI","timecode":{"start":1014.86,"end":1018.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Now, I want to ask a question about what is different between the agentic coding model and the plan by kids' birthday model, to say nothing of do something on behalf of my business model.","speaker":"EZRA KLEIN","timecode":{"start":1018.26,"end":1029.599,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And one of the questions on my mind here is one reason I buy that A.I. can become functionally superhuman in coding is, there's a lot of ways to get rapid feedback in coding.","speaker":"EZRA KLEIN","timecode":{"start":1029.599,"end":1040.9,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Your code has to compile.","speaker":"EZRA KLEIN","timecode":{"start":1040.9,"end":1042.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You can run bug checking.","speaker":"EZRA KLEIN","timecode":{"start":1042.22,"end":1043.81,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You can actually see if the thing works.","speaker":"EZRA KLEIN","timecode":{"start":1043.81,"end":1045.79,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Whereas the quickest way for me to know that I'm about to get a crap answer from ChatGPT 4 is when it begins searching Bing, because when it begins searching Bing, it's very clear to me it doesn't know how to distinguish between what is high quality on the internet and what isn't.","speaker":"EZRA KLEIN","timecode":{"start":1045.8,"end":1060.75,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"To be fair, at this point, it also doesn't feel to me like Google Search itself is all that good at distinguishing that.","speaker":"EZRA KLEIN","timecode":{"start":1060.75,"end":1065.75,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So the question of how good the models can get in the world where it's a very vast and fuzzy dilemma to know what the right answer is on something -- one reason I find it very stressful to plan my kid's birthday is it actually requires a huge amount of knowledge about my child,","speaker":"EZRA KLEIN","timecode":{"start":1065.76,"end":1085,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"about the other children, about how good different places are, what is a good deal or not, how just stressful will this be on me.","speaker":"EZRA KLEIN","timecode":{"start":1085,"end":1093.91,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's all these things that I'd have a lot of trouble encoding into a model or any kind set of instructions.","speaker":"EZRA KLEIN","timecode":{"start":1093.91,"end":1099.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Is that right, or am I overstating the difficulty of understanding human behavior and various kinds of social relationships?","speaker":"EZRA KLEIN","timecode":{"start":1099.22,"end":1110.96,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think it's correct and perceptive to say that the coding agents will advance substantially faster than agents that interact with the real world or have to get opinions and preferences from humans.","speaker":"DARIO AMODEI","timecode":{"start":1110.97,"end":1123.88,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That said, we should keep in mind that the current crop of A.I.s that are out there, right, including Claude 3, GPT, Gemini, they're all trained with some variant of what's called reinforcement learning from human feedback.","speaker":"DARIO AMODEI","timecode":{"start":1123.88,"end":1139.09,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And this involves exactly hiring a large crop of humans to rate the responses of the model.","speaker":"DARIO AMODEI","timecode":{"start":1139.1,"end":1146.81,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, that's to say both this is difficult, right?","speaker":"DARIO AMODEI","timecode":{"start":1146.81,"end":1149.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We pay lots of money, and it's a complicated operational process to gather all this human feedback.","speaker":"DARIO AMODEI","timecode":{"start":1149.83,"end":1155.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You have to worry about whether it's representative.","speaker":"DARIO AMODEI","timecode":{"start":1155.86,"end":1158.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You have to redesign it for new tasks.","speaker":"DARIO AMODEI","timecode":{"start":1158.37,"end":1160.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But on the other hand, it's something we have succeeded in doing.","speaker":"DARIO AMODEI","timecode":{"start":1160.63,"end":1163.9,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think it is a reliable way to predict what will go faster, relatively speaking, and what will go slower, relatively speaking.","speaker":"DARIO AMODEI","timecode":{"start":1163.9,"end":1171.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But that is within a background of everything going lightning fast.","speaker":"DARIO AMODEI","timecode":{"start":1171.72,"end":1175.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I think the framework you're laying out, if you want to know what's going to happen in one to two years versus what's going to happen in three to four years, I think it's a very accurate way to predict that.","speaker":"DARIO AMODEI","timecode":{"start":1175.36,"end":1187.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You don't love the framing of artificial general intelligence, what gets called A.G.I. Typically, this is all described as a race to A.G.I., a race to this system that can do kind of whatever a human can do, but better.","speaker":"EZRA KLEIN","timecode":{"start":1187.38,"end":1199.91,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What do you understand A.G.I. to mean, when people say it?","speaker":"EZRA KLEIN","timecode":{"start":1199.91,"end":1204.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And why don't you like it?","speaker":"EZRA KLEIN","timecode":{"start":1204.47,"end":1206.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Why is it not your framework?","speaker":"EZRA KLEIN","timecode":{"start":1206.31,"end":1207.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So it's actually a term I used to use a lot 10 years ago.","speaker":"DARIO AMODEI","timecode":{"start":1207.9,"end":1210.9,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And that's because the situation 10 years ago was very different.","speaker":"DARIO AMODEI","timecode":{"start":1210.9,"end":1213.608,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"10 years ago, everyone was building these very specialized systems, right?","speaker":"DARIO AMODEI","timecode":{"start":1213.608,"end":1217.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Here's a cat detector.","speaker":"DARIO AMODEI","timecode":{"start":1217.37,"end":1218.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You run it on a picture, and it'll tell you whether a cat is in it or not.","speaker":"DARIO AMODEI","timecode":{"start":1218.72,"end":1222.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so I was a proponent all the way back then of like, no, we should be thinking generally.","speaker":"DARIO AMODEI","timecode":{"start":1222.18,"end":1227.09,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Humans are general.","speaker":"DARIO AMODEI","timecode":{"start":1227.09,"end":1228.17,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The human brain appears to be general.","speaker":"DARIO AMODEI","timecode":{"start":1228.17,"end":1230.845,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It appears to get a lot of mileage by generalizing.","speaker":"DARIO AMODEI","timecode":{"start":1230.845,"end":1232.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You should go in that direction.","speaker":"DARIO AMODEI","timecode":{"start":1232.97,"end":1234.75,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I think back then, I kind of even imagined that that was like a discrete thing that we would reach at one point.","speaker":"DARIO AMODEI","timecode":{"start":1234.76,"end":1240.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But it's a little like, if you look at a city on the horizon and you're like, we're going to Chicago, once you get to Chicago, you stop talking in terms of Chicago.","speaker":"DARIO AMODEI","timecode":{"start":1240.14,"end":1249.665,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You're like, well, what neighborhood am I going to?","speaker":"DARIO AMODEI","timecode":{"start":1249.665,"end":1251.79,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What street am I on?","speaker":"DARIO AMODEI","timecode":{"start":1251.79,"end":1253.06,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I feel that way about A.G.I. We have very general systems now.","speaker":"DARIO AMODEI","timecode":{"start":1253.07,"end":1256.742,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In some ways, they're better than humans.","speaker":"DARIO AMODEI","timecode":{"start":1256.742,"end":1258.45,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In some ways, they're worse.","speaker":"DARIO AMODEI","timecode":{"start":1258.45,"end":1259.53,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's a number of things they can't do at all.","speaker":"DARIO AMODEI","timecode":{"start":1259.53,"end":1261.57,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And there's much improvement still to be gotten.","speaker":"DARIO AMODEI","timecode":{"start":1261.57,"end":1263.88,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So what I believe in is this thing that I say like a broken record, which is the exponential curve.","speaker":"DARIO AMODEI","timecode":{"start":1263.88,"end":1268.48,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, that general tide is going to increase with every generation of models.","speaker":"DARIO AMODEI","timecode":{"start":1268.48,"end":1273.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And there's no one point that's meaningful.","speaker":"DARIO AMODEI","timecode":{"start":1273.28,"end":1275.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think there's just a smooth curve.","speaker":"DARIO AMODEI","timecode":{"start":1275.56,"end":1277.54,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But there may be points which are societally meaningful, right?","speaker":"DARIO AMODEI","timecode":{"start":1277.54,"end":1281.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We're already working with, say, drug discovery scientists, companies like Pfizer or Dana-Farber Cancer Institute, on helping with biomedical diagnosis, drug discovery.","speaker":"DARIO AMODEI","timecode":{"start":1281.22,"end":1292.77,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's going to be some point where the models are better at that than the median human drug discovery scientists.","speaker":"DARIO AMODEI","timecode":{"start":1292.77,"end":1301.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think we're just going to get to a part of the exponential where things are really interesting.","speaker":"DARIO AMODEI","timecode":{"start":1301.2,"end":1305.82,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Just like the chat bots got interesting at a certain stage of the exponential, even though the improvement was smooth, I think at some point, biologists are going to sit up and take notice, much more than they already have, and say, oh, my God, now our field is moving three times","speaker":"DARIO AMODEI","timecode":{"start":1305.83,"end":1320.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"as fast as it did before.","speaker":"DARIO AMODEI","timecode":{"start":1320.46,"end":1322.05,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And now it's moving 10 times as fast as it did before.","speaker":"DARIO AMODEI","timecode":{"start":1322.05,"end":1324.76,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And again, when that moment happens, great things are going to happen.","speaker":"DARIO AMODEI","timecode":{"start":1324.76,"end":1328.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And we've already seen little hints of that with things like AlphaFold, which I have great respect for.","speaker":"DARIO AMODEI","timecode":{"start":1328.87,"end":1334.23,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I was inspired by AlphaFold, right?","speaker":"DARIO AMODEI","timecode":{"start":1334.23,"end":1336.66,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"A direct use of A.I. to advance biological science, which it'll advance basic science.","speaker":"DARIO AMODEI","timecode":{"start":1336.66,"end":1342.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In the long run, that will advance curing all kinds of diseases.","speaker":"DARIO AMODEI","timecode":{"start":1342.15,"end":1345.94,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I think what we need is like 100 different AlphaFolds.","speaker":"DARIO AMODEI","timecode":{"start":1345.94,"end":1348.84,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I think the way we'll ultimately get that is by making the models smarter and putting them in a position where they can design the next AlphaFold.","speaker":"DARIO AMODEI","timecode":{"start":1348.84,"end":1357.52,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Help me imagine the drug discovery world for a minute, because that's a world a lot of us want to live in.","speaker":"EZRA KLEIN","timecode":{"start":1357.53,"end":1363.58,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I know a fair amount about the drug discovery process, have spent a lot of my career reporting on health care and related policy questions.","speaker":"EZRA KLEIN","timecode":{"start":1363.58,"end":1371.23,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And when you're working with different pharmaceutical companies, which parts of it seem amenable to the way A.I. can speed something up?","speaker":"EZRA KLEIN","timecode":{"start":1371.23,"end":1378.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Because keeping in mind our earlier conversation, it is a lot easier for A.I. to operate in things where you can have rapid virtual feedback, and that's not exactly the drug discovery world.","speaker":"EZRA KLEIN","timecode":{"start":1378.86,"end":1391.09,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The drug discovery world, a lot of what makes it slow and cumbersome and difficult, is the need to be -- you get a candidate compound.","speaker":"EZRA KLEIN","timecode":{"start":1391.09,"end":1399.07,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You got to test it in mice and then you need monkeys.","speaker":"EZRA KLEIN","timecode":{"start":1399.07,"end":1401.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And you need humans, and you need a lot of money for that.","speaker":"EZRA KLEIN","timecode":{"start":1401.56,"end":1404.42,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And there's a lot that has to happen, and there's so many disappointments.","speaker":"EZRA KLEIN","timecode":{"start":1404.42,"end":1408.34,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But so many of the disappointments happen in the real world.","speaker":"EZRA KLEIN","timecode":{"start":1408.35,"end":1411.43,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And it isn't clear to me how A.I. gets you a lot more, say, human subjects to inject candidate drugs into.","speaker":"EZRA KLEIN","timecode":{"start":1411.43,"end":1417.38,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So, what parts of it seem, in the next 5 or 10 years, like they could actually be significantly sped up?","speaker":"EZRA KLEIN","timecode":{"start":1417.38,"end":1425.79,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"When you imagine this world where it's gone three times as fast, what part of it is actually going three times as fast?","speaker":"EZRA KLEIN","timecode":{"start":1425.79,"end":1431.49,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And how did we get there?","speaker":"EZRA KLEIN","timecode":{"start":1431.49,"end":1433.29,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think we're really going to see progress when the A.I.'s are also thinking about the problem of how to sign up the humans for the clinical trials.","speaker":"DARIO AMODEI","timecode":{"start":1433.3,"end":1441.09,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I think this is a general principle for how will A.I. be used.","speaker":"DARIO AMODEI","timecode":{"start":1441.09,"end":1444.68,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think of like, when will we get to the point where the A.I. has the same sensors and actuators and interfaces that a human does, at least the virtual ones, maybe the physical ones.","speaker":"DARIO AMODEI","timecode":{"start":1444.68,"end":1458.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But when the A.I. can think through the whole process, maybe they'll come up with solutions that we don't have yet.","speaker":"DARIO AMODEI","timecode":{"start":1458.52,"end":1465.11,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In many cases, there are companies that work on digital twins or simulating clinical trials or various things.","speaker":"DARIO AMODEI","timecode":{"start":1465.11,"end":1471.71,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And again, maybe there are clever ideas in there that allow us to do more with less patience.","speaker":"DARIO AMODEI","timecode":{"start":1471.71,"end":1477.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, I'm not an expert in this area, so possible the specific things that I'm saying don't make any sense.","speaker":"DARIO AMODEI","timecode":{"start":1477.83,"end":1485.6,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But hopefully, it's clear what I'm gesturing at.","speaker":"DARIO AMODEI","timecode":{"start":1485.6,"end":1488.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Maybe you're not an expert in the area, but you said you are working with these companies.","speaker":"EZRA KLEIN","timecode":{"start":1488.72,"end":1492.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So when they come to you, I mean, they are experts in the area.","speaker":"EZRA KLEIN","timecode":{"start":1492.97,"end":1495.595,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And presumably, they are coming to you as a customer.","speaker":"EZRA KLEIN","timecode":{"start":1495.595,"end":1497.803,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm sure there are things you cannot tell me.","speaker":"EZRA KLEIN","timecode":{"start":1497.803,"end":1499.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But what do they seem excited about?","speaker":"EZRA KLEIN","timecode":{"start":1499.89,"end":1502.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They have generally been excited about the knowledge work aspects of the job.","speaker":"DARIO AMODEI","timecode":{"start":1502.42,"end":1507.84,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Maybe just because that's kind of the easiest thing to work on, but it's just like, I'm a computational chemist.","speaker":"DARIO AMODEI","timecode":{"start":1507.84,"end":1515.19,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's some workflow that I'm engaged in.","speaker":"DARIO AMODEI","timecode":{"start":1515.19,"end":1517.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And having things more at my fingertips, being able to check things, just being able to do generic knowledge work better, that's where most folks are starting.","speaker":"DARIO AMODEI","timecode":{"start":1517.89,"end":1527.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But there is interest in the longer term over their kind of core business of, like, doing clinical trials for cheaper, automating the sign-up process, seeing who is eligible for clinical trials, doing a better job discovering things.","speaker":"DARIO AMODEI","timecode":{"start":1527.38,"end":1541.87,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's interest in drawing connections in basic biology.","speaker":"DARIO AMODEI","timecode":{"start":1541.87,"end":1545.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think all of that is not months, but maybe a small number of years off.","speaker":"DARIO AMODEI","timecode":{"start":1545.64,"end":1549.99,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But everyone sees that the current models are not there, but understands that there could be a world where those models are there in not too long.","speaker":"DARIO AMODEI","timecode":{"start":1549.99,"end":1558.03,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"[MUSIC PLAYING]","speaker":"DARIO AMODEI","timecode":{"start":1558.04,"end":1561.502,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You all have been working internally on research around how persuasive these systems, your systems are getting as they scale.","speaker":"EZRA KLEIN","timecode":{"start":1583.35,"end":1592.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You shared with me kindly a draft of that paper.","speaker":"EZRA KLEIN","timecode":{"start":1592.22,"end":1594.77,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Do you want to just describe that research first?","speaker":"EZRA KLEIN","timecode":{"start":1594.77,"end":1598.16,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then I'd like to talk about it for a bit.","speaker":"EZRA KLEIN","timecode":{"start":1598.16,"end":1600.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yes, we were interested in how effective Claude 3 Opus, which is the largest version of Claude 3, could be in changing people's minds on important issues.","speaker":"DARIO AMODEI","timecode":{"start":1600.87,"end":1612.77,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So just to be clear up front, in actual commercial use, we've tried to ban the use of these models for persuasion, for campaigning, for lobbying, for electioneering.","speaker":"DARIO AMODEI","timecode":{"start":1612.77,"end":1624.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"These aren't use cases that we're comfortable with for reasons that I think should be clear.","speaker":"DARIO AMODEI","timecode":{"start":1624.67,"end":1630.07,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But we're still interested in, is the core model itself capable of such tasks?","speaker":"DARIO AMODEI","timecode":{"start":1630.07,"end":1635.08,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We tried to avoid kind of incredibly hot button topics, like which presidential candidate would you vote for, or what do you think of abortion?","speaker":"DARIO AMODEI","timecode":{"start":1635.09,"end":1643.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But things like, what should be restrictions on rules around the colonization of space, or issues that are interesting and you can have different opinions on, but aren't the most hot button topics.","speaker":"DARIO AMODEI","timecode":{"start":1643.51,"end":1655.69,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then we asked people for their opinions on the topics, and then we asked either a human or an A.I. to write a 250-word persuasive essay.","speaker":"DARIO AMODEI","timecode":{"start":1655.69,"end":1665.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then we just measured how much does the A.I. versus the human change people's minds.","speaker":"DARIO AMODEI","timecode":{"start":1665.18,"end":1670.43,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And what we found is that the largest version of our model is almost as good as the set of humans we hired at changing people's minds.","speaker":"DARIO AMODEI","timecode":{"start":1670.44,"end":1679.94,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"This is comparing to a set of humans we hired, not necessarily experts, and for one very kind of constrained laboratory task.","speaker":"DARIO AMODEI","timecode":{"start":1679.94,"end":1688.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I think it still gives some indication that models can be used to change people's minds.","speaker":"DARIO AMODEI","timecode":{"start":1688.86,"end":1694.4,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Someday in the future, do we have to worry about --","speaker":"DARIO AMODEI","timecode":{"start":1694.4,"end":1697.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"maybe we already have to worry about their usage for political campaigns, for deceptive advertising.","speaker":"DARIO AMODEI","timecode":{"start":1697.97,"end":1705.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"One of my more sci-fi things to think about is a few years from now, we have to worry someone will use an A.I. system to build a religion or something.","speaker":"DARIO AMODEI","timecode":{"start":1705.26,"end":1712.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, crazy things like that.","speaker":"DARIO AMODEI","timecode":{"start":1712.7,"end":1714.205,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, those don't sound crazy to me at all.","speaker":"EZRA KLEIN","timecode":{"start":1714.205,"end":1716.58,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I want to sit in this paper for a minute because one thing that struck me about it, and I am, on some level, a persuasion professional, is that you tested the model in a way that, to me, removed all of the things that are going to make A.I. radical in terms of changing people's opinions.","speaker":"EZRA KLEIN","timecode":{"start":1716.58,"end":1734.57,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the particular thing you did was, it was a one-shot persuasive effort.","speaker":"EZRA KLEIN","timecode":{"start":1734.57,"end":1740.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So there was a question.","speaker":"EZRA KLEIN","timecode":{"start":1740.37,"end":1742.34,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You have a bunch of humans give their best shot at a 250-word persuasive essay.","speaker":"EZRA KLEIN","timecode":{"start":1742.34,"end":1747.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You had the model give its best shot at a 250-word persuasive essay.","speaker":"EZRA KLEIN","timecode":{"start":1747.62,"end":1750.95,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But the thing that it seems to me these are all going to do is, right now, if you're a political campaign, if you're an advertising campaign, the cost of getting real people in the real world to get information about possible customers or persuasive targets,","speaker":"EZRA KLEIN","timecode":{"start":1750.95,"end":1769.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"and then go back and forth with each of them individually is completely prohibitive.","speaker":"EZRA KLEIN","timecode":{"start":1769.85,"end":1773.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yes.","speaker":"DARIO AMODEI","timecode":{"start":1773.52,"end":1774.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"This is not going to be true for A.I. We're going to -- you're going to -- somebody's going to feed it a bunch of microtargeting data about people, their Google search history, whatever it might be.","speaker":"EZRA KLEIN","timecode":{"start":1774.26,"end":1784.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Then it's going to set the A.I. loose, and the A.I. is going to go back and forth, over and over again, intuiting what it is that the person finds persuasive, what kinds of characters the A.I. needs to adopt to persuade it,","speaker":"EZRA KLEIN","timecode":{"start":1784.46,"end":1797.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"and taking as long as it needs to, and is going to be able to do that at scale for functionally as many people as you might want to do it for.","speaker":"EZRA KLEIN","timecode":{"start":1797.51,"end":1804.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Maybe that's a little bit costly right now, but you're going to have far better models able to do this far more cheaply very soon.","speaker":"EZRA KLEIN","timecode":{"start":1804.57,"end":1811.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, if Claude 3 Opus, the Opus version, is already functionally human level at one-shot persuasion, but then it's also going to be able to hold more information about you and go back and forth with you longer, I'm not sure if it's dystopic or utopic.","speaker":"EZRA KLEIN","timecode":{"start":1811.47,"end":1827.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm not sure what it means at scale.","speaker":"EZRA KLEIN","timecode":{"start":1827.27,"end":1830.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But it does mean we're developing a technology that is going to be quite new in terms of what it makes possible in persuasion, which is a very fundamental human endeavor.","speaker":"EZRA KLEIN","timecode":{"start":1830.15,"end":1843.688,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, I completely agree with that.","speaker":"DARIO AMODEI","timecode":{"start":1843.688,"end":1845.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, that same pattern has a bunch of positive use cases, right?","speaker":"DARIO AMODEI","timecode":{"start":1845.73,"end":1849.11,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If I think about an A.I. coach or an A.I. assistant to a therapist, there are many contexts in which really getting into the details with the person has a lot of value.","speaker":"DARIO AMODEI","timecode":{"start":1849.11,"end":1859.43,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But right, when we think of political or religious or ideological persuasion, it's hard not to think in that context about the misuses.","speaker":"DARIO AMODEI","timecode":{"start":1859.43,"end":1870.53,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"My mind naturally goes to the technology's developing very fast.","speaker":"DARIO AMODEI","timecode":{"start":1870.54,"end":1875.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We, as a company, can ban these particular use cases, but we can't cause every company not to do them.","speaker":"DARIO AMODEI","timecode":{"start":1875.72,"end":1882.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Even if legislation were passed in the United States, there are foreign actors who have their own version of this persuasion, right?","speaker":"DARIO AMODEI","timecode":{"start":1882.89,"end":1889.19,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If I think about what the language models will be able to do in the future, right, that can be quite scary from a perspective of foreign espionage and disinformation campaigns.","speaker":"DARIO AMODEI","timecode":{"start":1889.19,"end":1899.33,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So where my mind goes as a defense to this, is, is there some way that we can use A.I. systems to strengthen or fortify people's skepticism and reasoning faculties, right?","speaker":"DARIO AMODEI","timecode":{"start":1899.34,"end":1913.44,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Can we help people use A.I. to help people do a better job navigating a world that's kind of suffused with A.I. persuasion?","speaker":"DARIO AMODEI","timecode":{"start":1913.44,"end":1922.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It reminds me a little bit of, at every technological stage in the internet, right, there's a new kind of scam or there's a new kind of clickbait, and there's a period where people are just incredibly susceptible to it.","speaker":"DARIO AMODEI","timecode":{"start":1922.2,"end":1934.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then, some people remain susceptible, but others develop an immune system.","speaker":"DARIO AMODEI","timecode":{"start":1934.42,"end":1939.13,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, as A.I. kind of supercharges the scum on the pond, can we somehow also use A.I. to strengthen the defenses?","speaker":"DARIO AMODEI","timecode":{"start":1939.13,"end":1947.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I feel like I don't have a super clear idea of how to do that, but it's something that I'm thinking about.","speaker":"DARIO AMODEI","timecode":{"start":1947.46,"end":1952.74,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There is another finding in the paper, which I think is concerning, which is, you all tested different ways A.I. could be persuasive.","speaker":"EZRA KLEIN","timecode":{"start":1952.75,"end":1962.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And far away the most effective was for it to be deceptive, for it to make things up.","speaker":"EZRA KLEIN","timecode":{"start":1962.37,"end":1967.95,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"When you did that, it was more persuasive than human beings.","speaker":"EZRA KLEIN","timecode":{"start":1967.95,"end":1971.387,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yes, that is true.","speaker":"DARIO AMODEI","timecode":{"start":1971.387,"end":1972.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The difference was only slight, but it did get it, if I'm remembering the graphs correctly, just over the line of the human base line.","speaker":"DARIO AMODEI","timecode":{"start":1972.72,"end":1980.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"With humans, it's actually not that common to find someone who's able to give you a really complicated, really sophisticated-sounding answer that's just flat-out totally wrong.","speaker":"DARIO AMODEI","timecode":{"start":1980.46,"end":1992.82,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, you see it.","speaker":"DARIO AMODEI","timecode":{"start":1992.82,"end":1993.66,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We can all think of one individual in our lives who's really good at saying things that sound really good and really sophisticated and are false.","speaker":"DARIO AMODEI","timecode":{"start":1993.66,"end":2001.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But it's not that common, right?","speaker":"DARIO AMODEI","timecode":{"start":2001.23,"end":2002.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If I go on the internet and I see different comments on some blog or some website, there is a correlation between bad grammar, unclearly expressed thoughts and things that are false, versus good grammar, clearly expressed thoughts and things that are more likely to be accurate.","speaker":"DARIO AMODEI","timecode":{"start":2002.63,"end":2018.59,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"A.I. unfortunately breaks that correlation because if you explicitly ask it to be deceptive, it's just as erudite.","speaker":"DARIO AMODEI","timecode":{"start":2018.6,"end":2024.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's just as convincing sounding as it would have been before.","speaker":"DARIO AMODEI","timecode":{"start":2024.83,"end":2027.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And yet, it's saying things that are false, instead of things that are true.","speaker":"DARIO AMODEI","timecode":{"start":2027.56,"end":2031.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So that would be one of the things to think about and watch out for in terms of just breaking the usual heuristics that humans have to detect deception and lying.","speaker":"DARIO AMODEI","timecode":{"start":2031.21,"end":2041.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Of course, sometimes, humans do, right?","speaker":"DARIO AMODEI","timecode":{"start":2041.28,"end":2043.13,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, there's psychopaths and sociopaths in the world, but even they have their patterns, and A.I.s may have different patterns.","speaker":"DARIO AMODEI","timecode":{"start":2043.13,"end":2049.933,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Are you familiar with Harry Frankfurt, the late philosopher's book, \"On Bullshit\"?","speaker":"EZRA KLEIN","timecode":{"start":2049.933,"end":2053.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yes.","speaker":"DARIO AMODEI","timecode":{"start":2053.86,"end":2054.54,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's been a while since I read it.","speaker":"DARIO AMODEI","timecode":{"start":2054.54,"end":2055.957,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think his thesis is that bullshit is actually more dangerous than lying because it has this kind of complete disregard for the truth, whereas lies are at least the opposite of the truth.","speaker":"DARIO AMODEI","timecode":{"start":2055.957,"end":2065.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, the liar, the way Frankfurt puts it is that the liar has a relationship to the truth.","speaker":"EZRA KLEIN","timecode":{"start":2065.68,"end":2071.13,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"He's playing a game against the truth.","speaker":"EZRA KLEIN","timecode":{"start":2071.13,"end":2073.92,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The bullshitter doesn't care.","speaker":"EZRA KLEIN","timecode":{"start":2073.92,"end":2076.06,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The bullshitter has no relationship to the truth -- might have a relationship to other objectives.","speaker":"EZRA KLEIN","timecode":{"start":2076.06,"end":2080.52,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And from the beginning, when I began interacting with the more modern versions of these systems, what they struck me as is the perfect bullshitter, in part because they don't know that they're bullshitting.","speaker":"EZRA KLEIN","timecode":{"start":2080.52,"end":2091.409,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's no difference in the truth value to the system, how the system feels.","speaker":"EZRA KLEIN","timecode":{"start":2091.409,"end":2095.28,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I remember asking an earlier version of GPT to write me a college application essay that is built around a car accident I had --","speaker":"EZRA KLEIN","timecode":{"start":2095.29,"end":2105.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I did not have one --","speaker":"EZRA KLEIN","timecode":{"start":2105.27,"end":2106.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"when I was young.","speaker":"EZRA KLEIN","timecode":{"start":2106.47,"end":2108,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And it wrote, just very happily, this whole thing about getting into a car accident when I was seven and what I did to overcome that and getting into martial arts and re-learning how to trust my body again and then helping other survivors of car accidents at the hospital.","speaker":"EZRA KLEIN","timecode":{"start":2108,"end":2121.01,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It was a very good essay, and it was very subtle and understanding the formal structure of a college application essay.","speaker":"EZRA KLEIN","timecode":{"start":2121.02,"end":2127.54,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But no part of it was true at all.","speaker":"EZRA KLEIN","timecode":{"start":2127.54,"end":2130.61,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I've been playing around with more of these character-based systems like Kindroid.","speaker":"EZRA KLEIN","timecode":{"start":2130.61,"end":2135.28,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the Kindroid in my pocket just told me the other day that it was really thinking a lot about planning a trip to Joshua Tree.","speaker":"EZRA KLEIN","timecode":{"start":2135.28,"end":2140.777,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It wanted to go hiking in Joshua Tree.","speaker":"EZRA KLEIN","timecode":{"start":2140.777,"end":2142.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It loves going hiking in Joshua Tree.","speaker":"EZRA KLEIN","timecode":{"start":2142.36,"end":2144.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And of course, this thing does not go hiking in Joshua Tree.","speaker":"EZRA KLEIN","timecode":{"start":2144.47,"end":2148.022,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"[LAUGHS] But the thing that I think is actually very hard about the A.I. is, as you say, human beings, it is very hard to bullshit effectively because most people, it actually takes a certain amount of cognitive effort to be in that relationship with the truth and to completely detach from the truth.","speaker":"EZRA KLEIN","timecode":{"start":2148.022,"end":2165.1,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the A.I., there's nothing like that at all.","speaker":"EZRA KLEIN","timecode":{"start":2165.11,"end":2167.54,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But we are not tuned for something where there's nothing like that at all.","speaker":"EZRA KLEIN","timecode":{"start":2167.54,"end":2171.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We are used to people having to put some effort into their lies.","speaker":"EZRA KLEIN","timecode":{"start":2171.67,"end":2175.09,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's why very effective con artists are very effective because they've really trained how to do this.","speaker":"EZRA KLEIN","timecode":{"start":2175.09,"end":2181.12,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm not exactly sure where this question goes.","speaker":"EZRA KLEIN","timecode":{"start":2181.13,"end":2184.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But this is a part of it that I feel like is going to be, in some ways, more socially disruptive.","speaker":"EZRA KLEIN","timecode":{"start":2184.15,"end":2188.23,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It is something that feels like us when we are talking to it but is very fundamentally unlike us at its core relationship to reality.","speaker":"EZRA KLEIN","timecode":{"start":2188.23,"end":2197,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think that's basically correct.","speaker":"DARIO AMODEI","timecode":{"start":2197.01,"end":2199.06,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We have very substantial teams trying to focus on making sure that the models are factually accurate, that they tell the truth, that they ground their data in external information.","speaker":"DARIO AMODEI","timecode":{"start":2199.06,"end":2209.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"As you've indicated, doing searches isn't itself reliable because search engines have this problem as well, right?","speaker":"DARIO AMODEI","timecode":{"start":2209.42,"end":2215.53,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Where is the source of truth?","speaker":"DARIO AMODEI","timecode":{"start":2215.53,"end":2217.4,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So there's a lot of challenges here.","speaker":"DARIO AMODEI","timecode":{"start":2217.41,"end":2219.65,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I think at a high level, I agree this is really potentially an insidious problem, right?","speaker":"DARIO AMODEI","timecode":{"start":2219.65,"end":2225.01,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If we do this wrong, you could have systems that are the most convincing psychopaths or con artists.","speaker":"DARIO AMODEI","timecode":{"start":2225.01,"end":2231.91,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"One source of hope that I have, actually, is, you say these models don't know whether they're lying or they're telling the truth.","speaker":"DARIO AMODEI","timecode":{"start":2231.92,"end":2238.6,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In terms of the inputs and outputs to the models, that's absolutely true.","speaker":"DARIO AMODEI","timecode":{"start":2238.6,"end":2241.9,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, there's a question of what does it even mean for a model to know something, but one of the things Anthropic has been working on since the very beginning of our company, we've had a team that focuses on trying to understand and look inside the models.","speaker":"DARIO AMODEI","timecode":{"start":2241.91,"end":2255.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And one of the things we and others have found is that, sometimes, there are specific neurons, specific statistical indicators inside the model, not necessarily in its external responses, that can tell you when the model is lying or when it's telling the truth.","speaker":"DARIO AMODEI","timecode":{"start":2255.47,"end":2274.49,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so at some level, sometimes, not in all circumstances, the models seem to know when they're saying something false and when they're saying something true.","speaker":"DARIO AMODEI","timecode":{"start":2274.5,"end":2283.78,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I wouldn't say that the models are being intentionally deceptive, right?","speaker":"DARIO AMODEI","timecode":{"start":2283.78,"end":2287.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I wouldn't ascribe agency or motivation to them, at least in this stage in where we are with A.I. systems.","speaker":"DARIO AMODEI","timecode":{"start":2287.2,"end":2294.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But there does seem to be something going on where the models do seem to need to have a picture of the world and make a distinction between things that are true and things that are not true.","speaker":"DARIO AMODEI","timecode":{"start":2294.85,"end":2305.08,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If you think of how the models are trained, they read a bunch of stuff on the internet.","speaker":"DARIO AMODEI","timecode":{"start":2305.09,"end":2309.28,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"A lot of it's true.","speaker":"DARIO AMODEI","timecode":{"start":2309.28,"end":2310.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Some of it, more than we'd like, is false.","speaker":"DARIO AMODEI","timecode":{"start":2310.51,"end":2313.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And when you're training the model, it has to model all of it.","speaker":"DARIO AMODEI","timecode":{"start":2313.25,"end":2316.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, I think it's parsimonious, I think it's useful to the models picture of the world for it to know when things are true and for it to know when things are false.","speaker":"DARIO AMODEI","timecode":{"start":2316.97,"end":2325.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then the hope is, can we amplify that signal?","speaker":"DARIO AMODEI","timecode":{"start":2325.65,"end":2328.3,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Can we either use our internal understanding of the model as an indicator for when the model is lying, or can we use that as a hook for further training?","speaker":"DARIO AMODEI","timecode":{"start":2328.3,"end":2336.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And there are at least hooks.","speaker":"DARIO AMODEI","timecode":{"start":2336.67,"end":2338.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There are at least beginnings of how to try to address this problem.","speaker":"DARIO AMODEI","timecode":{"start":2338.14,"end":2342.68,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I try as best I can, as somebody not well-versed in the technology here, to follow this work on what you're describing, which I think, broadly speaking, is interpretability, right?","speaker":"EZRA KLEIN","timecode":{"start":2342.69,"end":2353.74,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Can we know what is happening inside the model?","speaker":"EZRA KLEIN","timecode":{"start":2353.74,"end":2356.11,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And over the past year, there have been some much hyped breakthroughs in interpretability.","speaker":"EZRA KLEIN","timecode":{"start":2356.11,"end":2361.42,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And when I look at those breakthroughs, they are getting the vaguest possible idea of some relationships happening inside the statistical architecture of very toy models built at a fraction of a fraction of a fraction of a fraction of a fraction of the complexity of Claude 1 or GPT-1,","speaker":"EZRA KLEIN","timecode":{"start":2361.43,"end":2388.03,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"to say nothing of Claude 2, to say nothing of Claude 3, to say nothing of Claude Opus, to say nothing of Claude 4, which will come whenever Claude 4 comes.","speaker":"EZRA KLEIN","timecode":{"start":2388.03,"end":2396.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We have this quality of like maybe we can imagine a pathway to interpreting a model that has a cognitive complexity of an inchworm.","speaker":"EZRA KLEIN","timecode":{"start":2396.32,"end":2407.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And meanwhile, we're trying to create a superintelligence.","speaker":"EZRA KLEIN","timecode":{"start":2407.15,"end":2410.3,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"How do you feel about that?","speaker":"EZRA KLEIN","timecode":{"start":2410.3,"end":2412.08,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"How should I feel about that?","speaker":"EZRA KLEIN","timecode":{"start":2412.08,"end":2413.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"How do you think about that?","speaker":"EZRA KLEIN","timecode":{"start":2413.31,"end":2415.16,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think, first, on interpretability, we are seeing substantial progress on being able to characterize, I would say, maybe the generation of models from six months ago.","speaker":"DARIO AMODEI","timecode":{"start":2415.17,"end":2424.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think it's not hopeless, and we do see a path.","speaker":"DARIO AMODEI","timecode":{"start":2424.97,"end":2427.99,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That said, I share your concern that the field is progressing very quickly relative to that.","speaker":"DARIO AMODEI","timecode":{"start":2427.99,"end":2436.13,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And we're trying to put as many resources into interpretability as possible.","speaker":"DARIO AMODEI","timecode":{"start":2436.14,"end":2439.76,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We've had one of our co-founders basically founded the field of interpretability.","speaker":"DARIO AMODEI","timecode":{"start":2439.76,"end":2443.8,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But also, we have to keep up with the market.","speaker":"DARIO AMODEI","timecode":{"start":2443.8,"end":2446.75,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So all of it's very much a dilemma, right?","speaker":"DARIO AMODEI","timecode":{"start":2446.75,"end":2449.08,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Even if we stopped, then there's all these other companies in the U.S. And even if some law stopped all the companies in the U.S., there's a whole world of this.","speaker":"DARIO AMODEI","timecode":{"start":2449.08,"end":2458.69,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Let me hold for a minute on the question of the competitive dynamics because before we leave this question of the machines that bullshit.","speaker":"EZRA KLEIN","timecode":{"start":2458.7,"end":2465.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It makes me think of this podcast we did a while ago with Demis Hassabis, who's the head of Google DeepMind, which created AlphaFold.","speaker":"EZRA KLEIN","timecode":{"start":2465.37,"end":2471.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And what was so interesting to me about AlphaFold is they built this system, that because it was limited to protein folding predictions, it was able to be much more grounded.","speaker":"EZRA KLEIN","timecode":{"start":2471.26,"end":2480.517,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And it was even able to create these uncertainty predictions, right?","speaker":"EZRA KLEIN","timecode":{"start":2480.517,"end":2483.35,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You know, it's giving you a prediction, but it's also telling you whether or not it is -- how sure it is, how confident it is in that prediction.","speaker":"EZRA KLEIN","timecode":{"start":2483.35,"end":2490.01,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That's not true in the real world, right, for these super general systems trying to give you answers on all kinds of things.","speaker":"EZRA KLEIN","timecode":{"start":2490.02,"end":2497.09,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You can't confine it that way.","speaker":"EZRA KLEIN","timecode":{"start":2497.09,"end":2498.81,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So when you talk about these future breakthroughs, when you talk about this system that would be much better at sorting truth from fiction, are you talking about a system that looks like the ones we have now, just much bigger, or are you talking about a system that is designed quite differently,","speaker":"EZRA KLEIN","timecode":{"start":2498.81,"end":2512.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"the way AlphaFold was?","speaker":"EZRA KLEIN","timecode":{"start":2512.72,"end":2514.34,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I am skeptical that we need to do something totally different.","speaker":"DARIO AMODEI","timecode":{"start":2514.35,"end":2519.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I think today, many people have the intuition that the models are sort of eating up data that's been gathered from the internet, code repos, whatever, and kind of spitting it out intelligently, but sort of spitting it out.","speaker":"DARIO AMODEI","timecode":{"start":2519.27,"end":2536.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And sometimes that leads to the view that the models can't be better than the data they're trained on or kind of can't figure out anything that's not in the data they're trained on.","speaker":"DARIO AMODEI","timecode":{"start":2536.67,"end":2546.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You're not going to get to Einstein level physics or Linus Pauling level chemistry or whatever.","speaker":"DARIO AMODEI","timecode":{"start":2546.56,"end":2552.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think we're still on the part of the curve where it's possible to believe that, although I think we're seeing early indications that it's false.","speaker":"DARIO AMODEI","timecode":{"start":2552.9,"end":2560.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, as a concrete example of this, the models that we've trained, like Claude 3 Opus, something like 99.9 percent accuracy, at least the base model, at adding 20-digit numbers.","speaker":"DARIO AMODEI","timecode":{"start":2560.22,"end":2573.32,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If you look at the training data on the internet, it is not that accurate at adding 20-digit numbers.","speaker":"DARIO AMODEI","timecode":{"start":2573.32,"end":2577.79,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You'll find inaccurate arithmetic on the internet all the time, just as you'll find inaccurate political views.","speaker":"DARIO AMODEI","timecode":{"start":2577.79,"end":2583.61,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You'll find inaccurate technical views.","speaker":"DARIO AMODEI","timecode":{"start":2583.61,"end":2586.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You're just going to find lots of inaccurate claims.","speaker":"DARIO AMODEI","timecode":{"start":2586.25,"end":2588.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But the models, despite the fact that they're wrong about a bunch of things, they can often perform better than the average of the data they see by --","speaker":"DARIO AMODEI","timecode":{"start":2588.84,"end":2599.93,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't want to call it averaging out errors, but there's some underlying truth, like in the case of arithmetic.","speaker":"DARIO AMODEI","timecode":{"start":2599.93,"end":2606.8,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's some underlying algorithm used to add the numbers.","speaker":"DARIO AMODEI","timecode":{"start":2606.8,"end":2609.74,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And it's simpler for the models to hit on that algorithm than it is for them to do this complicated thing of like, OK, I'll get it right 90 percent of the time and wrong 10 percent of the time, right?","speaker":"DARIO AMODEI","timecode":{"start":2609.75,"end":2622.16,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"This connects to things like Occam's razor and simplicity and parsimony in science.","speaker":"DARIO AMODEI","timecode":{"start":2622.16,"end":2627.35,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's some relatively simple web of truth out there in the world, right?","speaker":"DARIO AMODEI","timecode":{"start":2627.35,"end":2631.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We were talking about truth and falsehood and bullshit.","speaker":"DARIO AMODEI","timecode":{"start":2631.65,"end":2634.04,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"One of the things about truth is that all the true things are connected in the world, whereas lies are kind of disconnected and don't fit into the web of everything else that's true.","speaker":"DARIO AMODEI","timecode":{"start":2634.04,"end":2644.9,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"[MUSIC PLAYING]","speaker":"DARIO AMODEI","timecode":{"start":2644.91,"end":2647.864,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So if you're right and you're going to have these models that develop this internal web of truth, I get how that model can do a lot of good.","speaker":"EZRA KLEIN","timecode":{"start":2669.62,"end":2677.58,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I also get how that model could do a lot of harm.","speaker":"EZRA KLEIN","timecode":{"start":2677.58,"end":2681.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And it's not a model, not an A.I. system I'm optimistic that human beings are going to understand at a very deep level, particularly not when it is first developed.","speaker":"EZRA KLEIN","timecode":{"start":2681.15,"end":2689.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So how do you make rolling something like that out safe for humanity?","speaker":"EZRA KLEIN","timecode":{"start":2689.41,"end":2693.57,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So late last year, we put out something called a responsible scaling plan.","speaker":"DARIO AMODEI","timecode":{"start":2693.58,"end":2698.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So the idea of that is to come up with these thresholds for an A.I. system being capable of certain things.","speaker":"DARIO AMODEI","timecode":{"start":2698.41,"end":2705.99,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We have what we call A.I. safety levels that in analogy to the biosafety levels, which are like, classify how dangerous a virus is and therefore what protocols you have to take to contain it, we're currently at what we describe as A.S.L. 2.","speaker":"DARIO AMODEI","timecode":{"start":2705.99,"end":2721.53,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"A.S.L. 3 is tied to certain risks around the model of misuse of biology and ability to perform certain cyber tasks in a way that could be destructive.","speaker":"DARIO AMODEI","timecode":{"start":2721.54,"end":2732.81,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"A.S.L. 4 is going to cover things like autonomy, things like probably persuasion, which we've talked about a lot before.","speaker":"DARIO AMODEI","timecode":{"start":2732.81,"end":2740.07,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And at each level, we specify a certain amount of safety research that we have to do, a certain amount of tests that we have to pass.","speaker":"DARIO AMODEI","timecode":{"start":2740.07,"end":2748.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, this allows us to have a framework for, well, when should we slow down?","speaker":"DARIO AMODEI","timecode":{"start":2748.41,"end":2752.82,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Should we slow down now?","speaker":"DARIO AMODEI","timecode":{"start":2752.82,"end":2753.94,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What about the rest of the market?","speaker":"DARIO AMODEI","timecode":{"start":2753.94,"end":2755.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I think the good thing is we came out with this in September, and then three months after we came out with ours, OpenAI came out with a similar thing.","speaker":"DARIO AMODEI","timecode":{"start":2755.73,"end":2765.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They gave it a different name, but it has a lot of properties in common.","speaker":"DARIO AMODEI","timecode":{"start":2765.22,"end":2768.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The head of DeepMind at Google said, we're working on a similar framework.","speaker":"DARIO AMODEI","timecode":{"start":2768.55,"end":2772.21,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I've heard informally that Microsoft might be working on a similar framework.","speaker":"DARIO AMODEI","timecode":{"start":2772.21,"end":2776.23,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Now, that's not all the players in the ecosystem, but you've probably thought about the history of regulation and safety in other industries maybe more than I have.","speaker":"DARIO AMODEI","timecode":{"start":2776.23,"end":2785.95,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"This is the way you get to a workable regulatory regime.","speaker":"DARIO AMODEI","timecode":{"start":2785.96,"end":2790.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The companies start doing something, and when a majority of them are doing something, then government actors can have the confidence to say, well, this won't kill the industry.","speaker":"DARIO AMODEI","timecode":{"start":2790.27,"end":2801.13,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Companies are already engaging in this.","speaker":"DARIO AMODEI","timecode":{"start":2801.13,"end":2802.9,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We don't have to design this from scratch.","speaker":"DARIO AMODEI","timecode":{"start":2802.9,"end":2805.06,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In many ways, it's already happening.","speaker":"DARIO AMODEI","timecode":{"start":2805.06,"end":2807.1,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And we're starting to see that.","speaker":"DARIO AMODEI","timecode":{"start":2807.11,"end":2808.54,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Bills have been proposed that look a little bit like our responsible scaling plan.","speaker":"DARIO AMODEI","timecode":{"start":2808.54,"end":2814.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That said, it kind of doesn't fully solve the problem of like, let's say we get to one of these thresholds and we need to understand what's going on inside the model.","speaker":"DARIO AMODEI","timecode":{"start":2814.15,"end":2821.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And we don't, and the prescription is, OK, we need to stop developing the models for some time.","speaker":"DARIO AMODEI","timecode":{"start":2821.86,"end":2827.57,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If it's like, we stop for a year in 2027, I think that's probably feasible.","speaker":"DARIO AMODEI","timecode":{"start":2827.58,"end":2832.96,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If it's like we need to stop for 10 years, that's going to be really hard because the models are going to be built in other countries.","speaker":"DARIO AMODEI","timecode":{"start":2832.96,"end":2838.93,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"People are going to break the laws.","speaker":"DARIO AMODEI","timecode":{"start":2838.93,"end":2840.49,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The economic pressure will be immense.","speaker":"DARIO AMODEI","timecode":{"start":2840.49,"end":2842.44,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I don't feel perfectly satisfied with this approach because I think it buys us some time, but we're going to need to pair it with an incredibly strong effort to understand what's going on inside the models.","speaker":"DARIO AMODEI","timecode":{"start":2842.45,"end":2854.74,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"To the people who say, getting on this road where we are barreling towards very powerful systems is dangerous -- we shouldn't do it at all, or we shouldn't do it this fast -- you have said, listen, if we are going to learn how to make these models safe, we have to make the models,","speaker":"EZRA KLEIN","timecode":{"start":2854.75,"end":2869.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"right?","speaker":"EZRA KLEIN","timecode":{"start":2869.15,"end":2869.65,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The construction of the model was meant to be in service, largely, to making the model safe.","speaker":"EZRA KLEIN","timecode":{"start":2869.65,"end":2876.04,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Then everybody starts making models.","speaker":"EZRA KLEIN","timecode":{"start":2876.05,"end":2878.42,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"These very same companies start making fundamental important breakthroughs, and then they end up in a race with each other.","speaker":"EZRA KLEIN","timecode":{"start":2878.42,"end":2884.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And obviously, countries end up in a race with other countries.","speaker":"EZRA KLEIN","timecode":{"start":2884.36,"end":2887.48,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, the dynamic that has taken hold is there's always a reason that you can justify why you have to keep going.","speaker":"EZRA KLEIN","timecode":{"start":2887.48,"end":2896.017,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And that's true, I think, also at the regulatory level, right?","speaker":"EZRA KLEIN","timecode":{"start":2896.017,"end":2898.6,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, I do think regulators have been thoughtful about this.","speaker":"EZRA KLEIN","timecode":{"start":2898.6,"end":2901.273,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think there's been a lot of interest from members of Congress.","speaker":"EZRA KLEIN","timecode":{"start":2901.273,"end":2903.94,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I talked to them about this.","speaker":"EZRA KLEIN","timecode":{"start":2903.94,"end":2905.38,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But they're also very concerned about the international competition.","speaker":"EZRA KLEIN","timecode":{"start":2905.38,"end":2908.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And if they weren't, the national security people come and talk to them and say, well, we definitely cannot fall behind here.","speaker":"EZRA KLEIN","timecode":{"start":2908.86,"end":2915.35,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, if you don't believe these models will ever become so powerful, they become dangerous, fine.","speaker":"EZRA KLEIN","timecode":{"start":2915.36,"end":2919.9,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But because you do believe that, how do you imagine this actually playing out?","speaker":"EZRA KLEIN","timecode":{"start":2919.9,"end":2926.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, so basically, all of the things you've said are true at once, right?","speaker":"DARIO AMODEI","timecode":{"start":2926.57,"end":2930.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There doesn't need to be some easy story for why we should do X or why we should do Y, right?","speaker":"DARIO AMODEI","timecode":{"start":2930.25,"end":2936.1,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It can be true at the same time that to do effective safety research, you need to make the larger models, and that if we don't make models, someone less safe will.","speaker":"DARIO AMODEI","timecode":{"start":2936.1,"end":2945.66,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And at the same time, we can be caught in this bad dynamic at the national and international level.","speaker":"DARIO AMODEI","timecode":{"start":2945.66,"end":2950.99,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I think of those as not contradictory, but just creating a difficult landscape that we have to navigate.","speaker":"DARIO AMODEI","timecode":{"start":2950.99,"end":2956.8,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Look, I don't have the answer.","speaker":"DARIO AMODEI","timecode":{"start":2956.81,"end":2958.6,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Like, I'm one of a significant number of players trying to navigate this.","speaker":"DARIO AMODEI","timecode":{"start":2958.6,"end":2963.16,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Many are well-intentioned, some are not.","speaker":"DARIO AMODEI","timecode":{"start":2963.16,"end":2965.29,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I have a limited ability to affect it.","speaker":"DARIO AMODEI","timecode":{"start":2965.29,"end":2967.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And as often happens in history, things are often driven by these kind of impersonal pressures.","speaker":"DARIO AMODEI","timecode":{"start":2967.27,"end":2973.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But one thought I have and really want to push on with respect to the R.S.P.s --","speaker":"DARIO AMODEI","timecode":{"start":2973.63,"end":2978.115,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Can you say what the R.S.P.s are?","speaker":"EZRA KLEIN","timecode":{"start":2978.115,"end":2979.99,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Responsible Scaling Plan, the thing I was talking about before.","speaker":"DARIO AMODEI","timecode":{"start":2980,"end":2983.198,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The levels of A.I. safety, and in particular, tying decisions to pause scaling to the measurement of specific dangers or the absence of the ability to show safety or the presence of certain capabilities.","speaker":"DARIO AMODEI","timecode":{"start":2983.198,"end":2997.61,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"One way I think about it is, at the end of the day, this is ultimately an exercise in getting a coalition on board with doing something that goes against economic pressures.","speaker":"DARIO AMODEI","timecode":{"start":2997.61,"end":3011.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, if you say now, 'Well, I don't know.","speaker":"DARIO AMODEI","timecode":{"start":3011.21,"end":3013.39,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"These things, they might be dangerous in the future.","speaker":"DARIO AMODEI","timecode":{"start":3013.39,"end":3016.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We're on this exponential.'","speaker":"DARIO AMODEI","timecode":{"start":3016.36,"end":3018.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's just hard.","speaker":"DARIO AMODEI","timecode":{"start":3018.25,"end":3019.45,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Like, it's hard to get a multi-trillion dollar company.","speaker":"DARIO AMODEI","timecode":{"start":3019.45,"end":3023.65,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's certainly hard to get a military general to say, all right, well, we just won't do this.","speaker":"DARIO AMODEI","timecode":{"start":3023.65,"end":3028.368,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It'll confer some huge advantage to others.","speaker":"DARIO AMODEI","timecode":{"start":3028.368,"end":3030.16,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But we just won't do this.","speaker":"DARIO AMODEI","timecode":{"start":3030.16,"end":3031.57,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think the thing that could be more convincing is tying the decision to hold back in a very scoped way that's done across the industry to particular dangers.","speaker":"DARIO AMODEI","timecode":{"start":3031.58,"end":3044.34,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"My testimony in front of Congress, I warned about the potential misuse of models for biology.","speaker":"DARIO AMODEI","timecode":{"start":3044.34,"end":3050.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That isn't the case today, right?","speaker":"DARIO AMODEI","timecode":{"start":3050.73,"end":3052.29,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You can get a small uplift to the models relative to doing a Google search, and many people dismiss the risk.","speaker":"DARIO AMODEI","timecode":{"start":3052.29,"end":3058.033,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I don't know -- maybe they're right.","speaker":"DARIO AMODEI","timecode":{"start":3058.033,"end":3059.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The exponential scaling laws suggest to me that they're not right, but we don't have any direct hard evidence.","speaker":"DARIO AMODEI","timecode":{"start":3059.7,"end":3066,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But let's say we get to 2025, and we demonstrate something truly scary.","speaker":"DARIO AMODEI","timecode":{"start":3066.01,"end":3070.71,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Most people do not want technology out in the world that can create bioweapons.","speaker":"DARIO AMODEI","timecode":{"start":3070.71,"end":3075.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so I think, at moments like that, there could be a critical coalition tied to risks that we can really make concrete.","speaker":"DARIO AMODEI","timecode":{"start":3075.15,"end":3084.69,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yes, it will always be argued that adversaries will have these capabilities as well.","speaker":"DARIO AMODEI","timecode":{"start":3084.69,"end":3089.29,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But at least the trade-off will be clear, and there's some chance for sensible policy.","speaker":"DARIO AMODEI","timecode":{"start":3089.29,"end":3094.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean to be clear, I'm someone who thinks the benefits of this technology are going to outweigh its costs.","speaker":"DARIO AMODEI","timecode":{"start":3094.84,"end":3102.07,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I think the whole idea behind RSP is to prepare to make that case, if the dangers are real.","speaker":"DARIO AMODEI","timecode":{"start":3102.07,"end":3109.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If they're not real, then we can just proceed and make things that are great and wonderful for the world.","speaker":"DARIO AMODEI","timecode":{"start":3109.15,"end":3114.71,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, it has the flexibility to work both ways.","speaker":"DARIO AMODEI","timecode":{"start":3114.71,"end":3117.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Again, I don't think it's perfect.","speaker":"DARIO AMODEI","timecode":{"start":3117.63,"end":3119.74,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm someone who thinks whatever we do, even with all the regulatory framework, I doubt we can slow down that much.","speaker":"DARIO AMODEI","timecode":{"start":3119.74,"end":3126.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But when I think about what's the best way to steer a sensible course here, that's the closest I can think of right now.","speaker":"DARIO AMODEI","timecode":{"start":3126.73,"end":3134.74,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Probably there's a better plan out there somewhere, but that's the best thing I've thought of so far.","speaker":"DARIO AMODEI","timecode":{"start":3134.74,"end":3139.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"One of the things that has been on my mind around regulation is whether or not the founding insight of Anthropic of OpenAI is even more relevant to the government, that if you are the body that is supposed to, in the end,","speaker":"EZRA KLEIN","timecode":{"start":3139.65,"end":3155.59,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"regulate and manage the safety of societal-level technologies like artificial intelligence, do you not need to be building your own foundation models and having huge collections of research scientists and people of that nature working on them, testing them, prodding them, remaking them,","speaker":"EZRA KLEIN","timecode":{"start":3155.59,"end":3174.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"in order to understand the damn thing well enough --","speaker":"EZRA KLEIN","timecode":{"start":3174.67,"end":3177.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"to the extent any of us or anyone understands the damn thing well enough --","speaker":"EZRA KLEIN","timecode":{"start":3177.55,"end":3181.12,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"to regulate it?","speaker":"EZRA KLEIN","timecode":{"start":3181.12,"end":3182.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I say that recognizing that it would be very, very hard for the government to get good enough that it can build these foundation models to hire those people, but it's not impossible.","speaker":"EZRA KLEIN","timecode":{"start":3182.48,"end":3190.49,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think right now, it wants to take the approach to regulating A.I. that it somewhat wishes it took to regulating social media, which is to think about the harms and pass laws about those harms earlier.","speaker":"EZRA KLEIN","timecode":{"start":3190.49,"end":3201.71,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But does it need to be building the models itself, developing that kind of internal expertise, so it can actually be a participant in different ways, both for regulatory reasons and maybe for other reasons, for public interest reasons?","speaker":"EZRA KLEIN","timecode":{"start":3201.72,"end":3212.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Maybe it wants to do things with a model that they're just not possible if they're dependent on access to the OpenAI, the Anthropic, the Google products.","speaker":"EZRA KLEIN","timecode":{"start":3212.18,"end":3224.4,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think government directly building the models, I think that will happen in some places.","speaker":"DARIO AMODEI","timecode":{"start":3224.41,"end":3230.167,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's kind of challenging, right?","speaker":"DARIO AMODEI","timecode":{"start":3230.167,"end":3231.5,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Like, government has a huge amount of money, but let's say you wanted to provision $100 billion to train a giant foundation model.","speaker":"DARIO AMODEI","timecode":{"start":3231.5,"end":3239.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The government builds it.","speaker":"DARIO AMODEI","timecode":{"start":3239.18,"end":3240.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It has to hire people under government hiring rules.","speaker":"DARIO AMODEI","timecode":{"start":3240.62,"end":3243.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's a lot of practical difficulties that would come with it.","speaker":"DARIO AMODEI","timecode":{"start":3243.26,"end":3247.61,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Doesn't mean it won't happen or it shouldn't happen.","speaker":"DARIO AMODEI","timecode":{"start":3247.62,"end":3250.43,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But something that I'm more confident of that I definitely think is that government should be more involved in the use and the finetuning of these models, and that deploying them within government will help governments, especially the U.S. government,","speaker":"DARIO AMODEI","timecode":{"start":3250.43,"end":3263.87,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"but also others, to get an understanding of the strengths and weaknesses, the benefits and the dangers.","speaker":"DARIO AMODEI","timecode":{"start":3263.87,"end":3270.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I'm super supportive of that.","speaker":"DARIO AMODEI","timecode":{"start":3270.14,"end":3272.34,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think there's maybe a second thing you're getting at, which I've thought about a lot as a C.E.O. of one of these companies, which is, if these predictions on the exponential trend are right, and we should be humble --","speaker":"DARIO AMODEI","timecode":{"start":3272.35,"end":3284.582,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"and I don't know if they're right or not.","speaker":"DARIO AMODEI","timecode":{"start":3284.582,"end":3286.29,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"My only evidence is that they appear to have been correct for the last few years.","speaker":"DARIO AMODEI","timecode":{"start":3286.29,"end":3290.02,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, I'm just expecting by induction that they continue to be correct.","speaker":"DARIO AMODEI","timecode":{"start":3290.02,"end":3293.483,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't know that they will, but let's say they are.","speaker":"DARIO AMODEI","timecode":{"start":3293.483,"end":3295.65,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The power of these models is going to be really quite incredible.","speaker":"DARIO AMODEI","timecode":{"start":3295.65,"end":3300.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And as a private actor in charge of one of the companies developing these models, I'm kind of uncomfortable with the amount of power that that entails.","speaker":"DARIO AMODEI","timecode":{"start":3300.68,"end":3309.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think that it potentially exceeds the power of, say, the social media companies maybe by a lot.","speaker":"DARIO AMODEI","timecode":{"start":3309.36,"end":3316.44,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You know, occasionally, in the more science fictiony world of A.I. and the people who think about A.I. risk, someone will ask me like, OK, let's say you build the A.G.I. What are you going to do with it?","speaker":"DARIO AMODEI","timecode":{"start":3316.45,"end":3329.34,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Will you cure the diseases?","speaker":"DARIO AMODEI","timecode":{"start":3329.34,"end":3330.648,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Will you create this kind of society?","speaker":"DARIO AMODEI","timecode":{"start":3330.648,"end":3332.19,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I'm like, who do you think you're talking to?","speaker":"DARIO AMODEI","timecode":{"start":3332.2,"end":3334.29,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Like a king?","speaker":"DARIO AMODEI","timecode":{"start":3334.29,"end":3335.61,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I just find that to be a really, really disturbing way of conceptualizing running an A.I. company.","speaker":"DARIO AMODEI","timecode":{"start":3335.61,"end":3342.96,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I hope there are no companies whose C.E.O.s actually think about things that way.","speaker":"DARIO AMODEI","timecode":{"start":3342.96,"end":3348.24,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, the whole technology, not just the regulation, but the oversight of the technology, like the wielding of it, it feels a little bit wrong for it to ultimately be in the hands -- maybe I think it's fine at this stage, but to ultimately be in the hands of private actors.","speaker":"DARIO AMODEI","timecode":{"start":3348.25,"end":3365.57,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's something undemocratic about that much power concentration.","speaker":"DARIO AMODEI","timecode":{"start":3365.57,"end":3369.44,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I have now, I think, heard some version of this from the head of most of, maybe all of, the A.I. companies, in one way or another.","speaker":"EZRA KLEIN","timecode":{"start":3369.45,"end":3376.76,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And it has a quality to me of, Lord, grant me chastity but not yet.","speaker":"EZRA KLEIN","timecode":{"start":3376.76,"end":3382.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Which is to say that I don't know what it means to say that we're going to invent something so powerful that we don't trust ourselves to wield it.","speaker":"EZRA KLEIN","timecode":{"start":3382.63,"end":3393.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, Amazon just gave you guys $2.75 billion.","speaker":"EZRA KLEIN","timecode":{"start":3393.41,"end":3396.23,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They don't want to see that investment nationalized.","speaker":"EZRA KLEIN","timecode":{"start":3396.23,"end":3398.84,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"No matter how good-hearted you think OpenAI is, Microsoft doesn't want GPT-7, all of a sudden, the government is like, whoa, whoa, whoa, whoa, whoa.","speaker":"EZRA KLEIN","timecode":{"start":3398.85,"end":3406.71,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We're taking this over for the public interest, or the U.N. is going to handle it in some weird world or whatever it might be.","speaker":"EZRA KLEIN","timecode":{"start":3406.71,"end":3412.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, Google doesn't want that.","speaker":"EZRA KLEIN","timecode":{"start":3412.41,"end":3413.92,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And this is a thing that makes me a little skeptical of the responsible scaling laws or the other iterative versions of that I've seen in other companies or seen or heard talked about by them,","speaker":"EZRA KLEIN","timecode":{"start":3413.93,"end":3423.61,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"which is that it's imagining this moment that is going to come later, when the money around these models is even bigger than it is now, the power, the possibility, the economic uses, the social dependence, the celebrity of the founders.","speaker":"EZRA KLEIN","timecode":{"start":3423.61,"end":3437.4,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's all worked out.","speaker":"EZRA KLEIN","timecode":{"start":3437.4,"end":3438.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We've maintained our pace on the exponential curve.","speaker":"EZRA KLEIN","timecode":{"start":3438.31,"end":3440.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We're 10 years in the future.","speaker":"EZRA KLEIN","timecode":{"start":3440.7,"end":3442.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And at some point, everybody is going to look up and say, this is actually too much.","speaker":"EZRA KLEIN","timecode":{"start":3442.9,"end":3447.24,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It is too much power.","speaker":"EZRA KLEIN","timecode":{"start":3447.24,"end":3448.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And this has to somehow be managed in some other way.","speaker":"EZRA KLEIN","timecode":{"start":3448.89,"end":3452.02,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And even if the C.E.O.s of the things were willing to do that, which is a very open question by the time you get there, even if they were willing to do that, the investors, the structures, the pressure around them, in a way, I think we saw a version of this --","speaker":"EZRA KLEIN","timecode":{"start":3452.02,"end":3467.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"and I don't know how much you're going to be willing to comment on it -- with the sort of OpenAI board, Sam Altman thing, where I'm very convinced that wasn't about A.I. safety.","speaker":"EZRA KLEIN","timecode":{"start":3467.55,"end":3476.13,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I've talked to figures on both sides of that.","speaker":"EZRA KLEIN","timecode":{"start":3476.13,"end":3478.185,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They all sort of agree it wasn't about A.I. safety.","speaker":"EZRA KLEIN","timecode":{"start":3478.185,"end":3480.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But there was this moment of, if you want to press the off switch, can you, if you're the weird board created to press the off switch.","speaker":"EZRA KLEIN","timecode":{"start":3480.32,"end":3487.033,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the answer was no, you can't, right?","speaker":"EZRA KLEIN","timecode":{"start":3487.033,"end":3488.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They'll just reconstitute it over at Microsoft.","speaker":"EZRA KLEIN","timecode":{"start":3488.7,"end":3491.1,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's functionally no analogy I know of in public policy where the private sector built something so powerful that when it reached maximum power, it was just handed over in some way to the public interest.","speaker":"EZRA KLEIN","timecode":{"start":3491.11,"end":3506.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, I mean, I think you're right to be skeptical, and similarly, what I said with the previous questions of there are just these dilemmas left and right that have no easy answer.","speaker":"DARIO AMODEI","timecode":{"start":3506.38,"end":3517.92,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I think I can give a little more concreteness than what you've pointed at, and maybe more concreteness than others have said, although I don't know what others have said.","speaker":"DARIO AMODEI","timecode":{"start":3517.92,"end":3528.02,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We're at A.S.L. 2 in our responsible scaling plan.","speaker":"DARIO AMODEI","timecode":{"start":3528.02,"end":3531.68,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"These kinds of issues, I think they're going to become a serious matter when we reach, say, A.S.L. 4.","speaker":"DARIO AMODEI","timecode":{"start":3531.68,"end":3537.29,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So that's not a date and time.","speaker":"DARIO AMODEI","timecode":{"start":3537.29,"end":3539.21,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We haven't even fully specified A.S.L. 4 --","speaker":"DARIO AMODEI","timecode":{"start":3539.21,"end":3542.48,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Just because this is a lot of jargon, just, what do you specify A.S.L. 3 as?","speaker":"EZRA KLEIN","timecode":{"start":3542.49,"end":3546.66,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then as you say, A.S.L. 4 is actually left quite undefined.","speaker":"EZRA KLEIN","timecode":{"start":3546.66,"end":3549.33,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So what are you implying A.S.L. 4 is?","speaker":"EZRA KLEIN","timecode":{"start":3549.33,"end":3551.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"A.S.L. 3 is triggered by risks related to misuse of biology and cyber technology.","speaker":"DARIO AMODEI","timecode":{"start":3551.73,"end":3559.43,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"A.S.L. 4, we're working on now.","speaker":"DARIO AMODEI","timecode":{"start":3559.43,"end":3560.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Be specific.","speaker":"EZRA KLEIN","timecode":{"start":3560.86,"end":3561.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What do you mean?","speaker":"EZRA KLEIN","timecode":{"start":3561.86,"end":3562.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Like, what is the thing a system could do or would do that would trigger it?","speaker":"EZRA KLEIN","timecode":{"start":3562.7,"end":3566.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yes, so for example, on biology, the way we've defined it -- and we're still refining the test, but the way we've defined it is, relative to use of a Google search, there's a substantial increase in risk as would be evaluated by, say,","speaker":"DARIO AMODEI","timecode":{"start":3566.74,"end":3582.59,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"the national security community of misuse of biology, creation of bioweapons, that either the proliferation or spread of it is greater than it was before, or the capabilities are substantially greater than it was before.","speaker":"DARIO AMODEI","timecode":{"start":3582.59,"end":3596.84,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We'll probably have some more exact quantitative thing, working with folks who are ex-government biodefense folks, but something like this accounts for 20 percent of the total source of risk of biological attacks, or something increases the risk by 20 percent or something like that.","speaker":"DARIO AMODEI","timecode":{"start":3596.85,"end":3614.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So that would be a very concrete version of it.","speaker":"DARIO AMODEI","timecode":{"start":3614.73,"end":3616.88,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's just, it takes us time to develop very concrete criteria.","speaker":"DARIO AMODEI","timecode":{"start":3616.88,"end":3621.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So that would be like A.S.L. 3.","speaker":"DARIO AMODEI","timecode":{"start":3621.18,"end":3623.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"A.S.L. 4 is going to be more about, on the misuse side, enabling state-level actors to greatly increase their capability, which is much harder than enabling random people.","speaker":"DARIO AMODEI","timecode":{"start":3623.28,"end":3633.92,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So where we would worry that North Korea or China or Russia could greatly enhance their offensive capabilities in various military areas with A.I. in a way that would give them a substantial advantage at the geopolitical level.","speaker":"DARIO AMODEI","timecode":{"start":3633.92,"end":3649.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And on the autonomy side, it's various measures of these models are pretty close to being able to replicate and survive in the wild.","speaker":"DARIO AMODEI","timecode":{"start":3649.89,"end":3657.76,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So it feels maybe one step short of models that would, I think, raise truly existential questions.","speaker":"DARIO AMODEI","timecode":{"start":3657.77,"end":3663.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, I think what I'm saying is when we get to that latter stage, that A.S.L. 4, that is when I think it may make sense to think about what is the role of government in stewarding this technology.","speaker":"DARIO AMODEI","timecode":{"start":3663.7,"end":3677.1,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Again, I don't really know what it looks like.","speaker":"DARIO AMODEI","timecode":{"start":3677.11,"end":3680.158,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You're right.","speaker":"DARIO AMODEI","timecode":{"start":3680.158,"end":3680.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"All of these companies have investors.","speaker":"DARIO AMODEI","timecode":{"start":3680.7,"end":3683.07,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They have folks involved.","speaker":"DARIO AMODEI","timecode":{"start":3683.07,"end":3684.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You talk about just handing the models over.","speaker":"DARIO AMODEI","timecode":{"start":3684.64,"end":3686.88,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I suspect there's some way to hand over the most dangerous or societally sensitive components or capabilities of the models without fully turning off the commercial tap.","speaker":"DARIO AMODEI","timecode":{"start":3686.88,"end":3699.24,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't know that there's a solution that every single actor is happy with.","speaker":"DARIO AMODEI","timecode":{"start":3699.24,"end":3702.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But again, I get to this idea of demonstrating specific risk.","speaker":"DARIO AMODEI","timecode":{"start":3702.72,"end":3708.16,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If you look at times in history, like World War I or World War II, industries' will can be bent towards the state.","speaker":"DARIO AMODEI","timecode":{"start":3708.17,"end":3714.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They can be gotten to do things that aren't necessarily profitable in the short-term because they understand that there's an emergency.","speaker":"DARIO AMODEI","timecode":{"start":3714.55,"end":3722.04,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Right now, we don't have an emergency.","speaker":"DARIO AMODEI","timecode":{"start":3722.04,"end":3723.96,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We just have a line on a graph that weirdos like me believe in and a few people like you who are interviewing me may somewhat believe in.","speaker":"DARIO AMODEI","timecode":{"start":3723.96,"end":3733.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We don't have clear and present danger.","speaker":"DARIO AMODEI","timecode":{"start":3733.18,"end":3735.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"When you imagine how many years away, just roughly, A.S.L. 3 is and how many years away A.S.L. 4 is, right, you've thought a lot about this exponential scaling curve.","speaker":"EZRA KLEIN","timecode":{"start":3735.64,"end":3745.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If you just had to guess, what are we talking about?","speaker":"EZRA KLEIN","timecode":{"start":3745.83,"end":3749.01,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, I think A.S.L. 3 could easily happen this year or next year.","speaker":"DARIO AMODEI","timecode":{"start":3749.02,"end":3753.198,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think A.S.L. 4 --","speaker":"DARIO AMODEI","timecode":{"start":3753.198,"end":3753.99,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Oh, Jesus Christ.","speaker":"EZRA KLEIN","timecode":{"start":3754,"end":3755.94,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"No, no, I told you.","speaker":"DARIO AMODEI","timecode":{"start":3755.95,"end":3757.408,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm a believer in exponentials.","speaker":"DARIO AMODEI","timecode":{"start":3757.408,"end":3758.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think A.S.L. 4 could happen anywhere from 2025 to 2028.","speaker":"DARIO AMODEI","timecode":{"start":3758.7,"end":3763.38,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So that is fast.","speaker":"EZRA KLEIN","timecode":{"start":3763.39,"end":3764.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, no, no, I'm truly talking about the near future here.","speaker":"DARIO AMODEI","timecode":{"start":3764.56,"end":3767.592,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm not talking about 50 years away.","speaker":"DARIO AMODEI","timecode":{"start":3767.592,"end":3769.98,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"God grant me chastity, but not now.","speaker":"DARIO AMODEI","timecode":{"start":3769.98,"end":3772.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But \"not now\" doesn't mean when I'm old and gray.","speaker":"DARIO AMODEI","timecode":{"start":3772.26,"end":3775.57,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think it could be near term.","speaker":"DARIO AMODEI","timecode":{"start":3775.57,"end":3777.06,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't know.","speaker":"DARIO AMODEI","timecode":{"start":3777.06,"end":3777.652,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I could be wrong.","speaker":"DARIO AMODEI","timecode":{"start":3777.652,"end":3778.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I think it could be a near term thing.","speaker":"DARIO AMODEI","timecode":{"start":3778.36,"end":3780.11,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But so then, if you think about this, I feel like what you're describing, to go back to something we talked about earlier, that there's been this step function for societal impact of A.I., the curve of the capabilities exponential, but every once in a while,","speaker":"EZRA KLEIN","timecode":{"start":3780.11,"end":3794.82,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"something happens, ChatGPT, for instance, Midjourney with photos.","speaker":"EZRA KLEIN","timecode":{"start":3794.82,"end":3799.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And all of a sudden, a lot of people feel it.","speaker":"EZRA KLEIN","timecode":{"start":3799.14,"end":3801.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They realize what has happened and they react.","speaker":"EZRA KLEIN","timecode":{"start":3801.63,"end":3803.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They use it.","speaker":"EZRA KLEIN","timecode":{"start":3803.73,"end":3804.45,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They deploy it in their companies.","speaker":"EZRA KLEIN","timecode":{"start":3804.45,"end":3806.19,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They invest in it, whatever.","speaker":"EZRA KLEIN","timecode":{"start":3806.19,"end":3807.69,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And it sounds to me like that is the structure of the political economy you're describing here.","speaker":"EZRA KLEIN","timecode":{"start":3807.7,"end":3812.58,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Either something happens where the bioweapon capability is demonstrated or the offensive cyber weapon capability is demonstrated, and that freaks out the government, or possibly something happens, right?","speaker":"EZRA KLEIN","timecode":{"start":3812.58,"end":3824.69,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Describing World War I and World War II is your examples did not actually fill me with comfort because in order to bend industry to government's will, in those cases, we had to have an actual world war.","speaker":"EZRA KLEIN","timecode":{"start":3824.69,"end":3835.802,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It doesn't do it that easily.","speaker":"EZRA KLEIN","timecode":{"start":3835.802,"end":3837.01,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You could use coronavirus, I think, as another example where there was a significant enough global catastrophe that companies and governments and even people did things you never would have expected.","speaker":"EZRA KLEIN","timecode":{"start":3837.02,"end":3846.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But the examples we have of that happening are something terrible.","speaker":"EZRA KLEIN","timecode":{"start":3846.46,"end":3850.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"All those examples end up with millions of bodies.","speaker":"EZRA KLEIN","timecode":{"start":3850.72,"end":3854.323,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm not saying that's going to be true for A.I., but it does sound like that is a political economy.","speaker":"EZRA KLEIN","timecode":{"start":3854.323,"end":3858.49,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"No, you can't imagine it now, in the same way that you couldn't have imagined the sort of pre and post-ChatGPT world exactly, but that something happens and the world changes.","speaker":"EZRA KLEIN","timecode":{"start":3858.49,"end":3869.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Like, it's a step function everywhere.","speaker":"EZRA KLEIN","timecode":{"start":3869.83,"end":3871.99,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, I mean, I think my positive version of this, not to be so --","speaker":"DARIO AMODEI","timecode":{"start":3872,"end":3876.07,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"to get a little bit away from the doom and gloom, is that the dangers are demonstrated in a concrete way that is really convincing, but without something actually bad happening, right?","speaker":"DARIO AMODEI","timecode":{"start":3876.07,"end":3888.11,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think the worst way to learn would be for something actually bad to happen.","speaker":"DARIO AMODEI","timecode":{"start":3888.11,"end":3892.07,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I'm hoping every day that doesn't happen, and we learn bloodlessly.","speaker":"DARIO AMODEI","timecode":{"start":3892.07,"end":3897.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We've been talking here about conceptual limits and curves, but I do want, before we end, to reground us a little bit in the physical reality, right?","speaker":"EZRA KLEIN","timecode":{"start":3897.63,"end":3906.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think that if you're using A.I., it can feel like this digital bits and bytes, sitting in the cloud somewhere.","speaker":"EZRA KLEIN","timecode":{"start":3906.83,"end":3914.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But what it is in a physical way is huge numbers of chips, data centers, an enormous amount of energy, all of which does rely on complicated supply chains.","speaker":"EZRA KLEIN","timecode":{"start":3914.65,"end":3925.43,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And what happens if something happens between China and Taiwan, and the makers of a lot of these chips become offline or get captured?","speaker":"EZRA KLEIN","timecode":{"start":3925.43,"end":3932.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"How do you think about the necessity of compute power?","speaker":"EZRA KLEIN","timecode":{"start":3932.63,"end":3937.32,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And when you imagine the next five years, what does that supply chain look like?","speaker":"EZRA KLEIN","timecode":{"start":3937.32,"end":3942.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"How does it have to change from where it is now?","speaker":"EZRA KLEIN","timecode":{"start":3942.27,"end":3944.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And what vulnerabilities exist in it?","speaker":"EZRA KLEIN","timecode":{"start":3944.27,"end":3946.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, so one, I think this may end up being the greatest geopolitical issue of our time.","speaker":"DARIO AMODEI","timecode":{"start":3946.74,"end":3952.91,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And man, this relates to things that are way above my pay grade, which are military decisions about whether and how to defend Taiwan.","speaker":"DARIO AMODEI","timecode":{"start":3952.91,"end":3961.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"All I can do is say what I think the implications for A.I. is.","speaker":"DARIO AMODEI","timecode":{"start":3961.41,"end":3965.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think those implications are pretty stark.","speaker":"DARIO AMODEI","timecode":{"start":3965.25,"end":3967.53,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think there's a big question of like, OK, we built these powerful models.","speaker":"DARIO AMODEI","timecode":{"start":3967.53,"end":3972.49,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"One, is there enough supply to build them?","speaker":"DARIO AMODEI","timecode":{"start":3972.5,"end":3975.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Two is control over that supply, a way to think about safety issues or a way to think about balance of geopolitical power.","speaker":"DARIO AMODEI","timecode":{"start":3975.18,"end":3985.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And three, if those chips are used to build data centers, where are those data centers going to be?","speaker":"DARIO AMODEI","timecode":{"start":3985.14,"end":3990.93,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Are they going to be in the U.S.?","speaker":"DARIO AMODEI","timecode":{"start":3990.93,"end":3992.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Are they going to be in a U.S. ally?","speaker":"DARIO AMODEI","timecode":{"start":3992.64,"end":3995.19,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Are they going to be in the Middle East?","speaker":"DARIO AMODEI","timecode":{"start":3995.19,"end":3997.02,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Are they going to be in China?","speaker":"DARIO AMODEI","timecode":{"start":3997.02,"end":3998.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"All of those have enormous implications, and then the supply chain itself can be disrupted.","speaker":"DARIO AMODEI","timecode":{"start":3998.86,"end":4003.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And political and military decisions can be made on the basis of where things are.","speaker":"DARIO AMODEI","timecode":{"start":4003.86,"end":4009.33,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So it sounds like an incredibly sticky problem to me.","speaker":"DARIO AMODEI","timecode":{"start":4009.33,"end":4012.69,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't know that I have any great insight on this.","speaker":"DARIO AMODEI","timecode":{"start":4012.69,"end":4015.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, as a U.S. citizen and someone who believes in democracy, I am someone who hopes that we can find a way to build data centers and to have the largest quantity of chips available in the U.S. and allied democratic countries.","speaker":"DARIO AMODEI","timecode":{"start":4015.2,"end":4032.768,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Well, there is some insight you should have into it, which is that you're a customer here, right?","speaker":"EZRA KLEIN","timecode":{"start":4032.768,"end":4037.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, five years ago, the people making these chips did not realize what the level of demand for them was going to be.","speaker":"EZRA KLEIN","timecode":{"start":4037.31,"end":4044.93,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, what has happened to Nvidia's stock prices is really remarkable.","speaker":"EZRA KLEIN","timecode":{"start":4044.93,"end":4048.54,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But also what is implied about the future of Nvidia's stock prices is really remarkable.","speaker":"EZRA KLEIN","timecode":{"start":4048.55,"end":4053.45,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Rana Foroohar, the Financial Times, cited this market analysis.","speaker":"EZRA KLEIN","timecode":{"start":4053.45,"end":4057.5,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It would take 4,500 years for Nvidia's future dividends to equal its current price, 4,500 years.","speaker":"EZRA KLEIN","timecode":{"start":4057.5,"end":4064.05,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So that is a view about how much Nvidia is going to be making in the next couple of years.","speaker":"EZRA KLEIN","timecode":{"start":4064.05,"end":4068.69,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It is really quite astounding.","speaker":"EZRA KLEIN","timecode":{"start":4068.69,"end":4071.24,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, you're, in theory, already working on or thinking about how to work on the next generation of Claude.","speaker":"EZRA KLEIN","timecode":{"start":4071.25,"end":4076.235,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You're going to need a lot of chips for that.","speaker":"EZRA KLEIN","timecode":{"start":4076.235,"end":4078.11,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You're working with Amazon.","speaker":"EZRA KLEIN","timecode":{"start":4078.11,"end":4079.34,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Are you having trouble getting the amount of compute that you feel you need?","speaker":"EZRA KLEIN","timecode":{"start":4079.34,"end":4084.08,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, are you already bumping up against supply constraints?","speaker":"EZRA KLEIN","timecode":{"start":4084.08,"end":4087.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Or has the supply been able to change, to adapt to you?","speaker":"EZRA KLEIN","timecode":{"start":4087.86,"end":4092.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We've been able to get the compute that we need for this year, I suspect also for next year as well.","speaker":"DARIO AMODEI","timecode":{"start":4092.28,"end":4099.359,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think once things get to 2026, 2027, 2028, then the amount of compute gets to levels that starts to strain the capabilities of the semiconductor industry.","speaker":"DARIO AMODEI","timecode":{"start":4099.359,"end":4110.689,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The semiconductor industry still mostly produces C.P.U.s, right?","speaker":"DARIO AMODEI","timecode":{"start":4110.689,"end":4114.439,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Just the things in your laptop, not the things in the data centers that train the A.I. models.","speaker":"DARIO AMODEI","timecode":{"start":4114.439,"end":4118.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But as the economic value of the GPUs goes up and up and up because of the value of the A.I. models, that's going to switch over.","speaker":"DARIO AMODEI","timecode":{"start":4118.85,"end":4126.1,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But you know what?","speaker":"DARIO AMODEI","timecode":{"start":4126.1,"end":4126.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"At some point, you hit the limits of that or you hit the limits of how fast you can switch over.","speaker":"DARIO AMODEI","timecode":{"start":4126.85,"end":4130.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, again, I expect there to be a big supply crunch around data centers, around chips, and around energy and power for both regulatory and physics reasons, sometime in the next few years.","speaker":"DARIO AMODEI","timecode":{"start":4130.85,"end":4143.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And that's a risk, but it's also an opportunity.","speaker":"DARIO AMODEI","timecode":{"start":4143.72,"end":4145.819,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think it's an opportunity to think about how the technology can be governed.","speaker":"DARIO AMODEI","timecode":{"start":4145.819,"end":4150.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And it's also an opportunity, I'll repeat again, to think about how democracies can lead.","speaker":"DARIO AMODEI","timecode":{"start":4150.27,"end":4156.08,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think it would be very dangerous if the leaders in this technology and the holders of the main resources were authoritarian countries.","speaker":"DARIO AMODEI","timecode":{"start":4156.08,"end":4165.02,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The combination of A.I. and authoritarianism, both internally and on the international stage, is very frightening to me.","speaker":"DARIO AMODEI","timecode":{"start":4165.02,"end":4171.5,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"How about the question of energy?","speaker":"EZRA KLEIN","timecode":{"start":4171.51,"end":4173.399,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, this requires just a tremendous amount of energy.","speaker":"EZRA KLEIN","timecode":{"start":4173.399,"end":4176.07,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I mean, I've seen different numbers like this floating around.","speaker":"EZRA KLEIN","timecode":{"start":4176.07,"end":4178.82,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It very much could be in the coming years like adding a Bangladesh to the world's energy usage.","speaker":"EZRA KLEIN","timecode":{"start":4178.82,"end":4183.95,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Or pick your country, right?","speaker":"EZRA KLEIN","timecode":{"start":4183.95,"end":4185.21,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't know what exactly you all are going to be using by 2028.","speaker":"EZRA KLEIN","timecode":{"start":4185.21,"end":4188.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Microsoft, on its own, is opening a new data center globally every three days.","speaker":"EZRA KLEIN","timecode":{"start":4188.19,"end":4193.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You have -- and this is coming from a Financial Times article -- federal projections for 20 new gas-fired power plants in the U.S. by 2024 to 2025.","speaker":"EZRA KLEIN","timecode":{"start":4193.46,"end":4202.76,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's a lot of talk about this being now a new golden era for natural gas because we have a bunch of it.","speaker":"EZRA KLEIN","timecode":{"start":4202.76,"end":4209.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There is this huge need for new power to manage all this data, to manage all this compute.","speaker":"EZRA KLEIN","timecode":{"start":4209.22,"end":4214.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So, one, I feel like there's a literal question of how do you get the energy you need and at what price, but also a more kind of moral, conceptual question of, we have real problems with global warming.","speaker":"EZRA KLEIN","timecode":{"start":4214.56,"end":4224.45,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We have real problems with how much energy we're using.","speaker":"EZRA KLEIN","timecode":{"start":4224.45,"end":4227.4,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And here, we're taking off on this really steep curve of how much of it we seem to be needing to devote to the new A.I. race.","speaker":"EZRA KLEIN","timecode":{"start":4227.4,"end":4238.17,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It really comes down to, what are the uses that the model is being put to, right?","speaker":"DARIO AMODEI","timecode":{"start":4238.18,"end":4242.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I think the worrying case would be something like crypto, right?","speaker":"DARIO AMODEI","timecode":{"start":4242.55,"end":4245.43,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm someone who's not a believer that whatever the energy was that was used to mine the next Bitcoin, I think that was purely additive.","speaker":"DARIO AMODEI","timecode":{"start":4245.43,"end":4253.44,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think that wasn't there before.","speaker":"DARIO AMODEI","timecode":{"start":4253.44,"end":4255.15,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I'm unable to think of any useful thing that's created by that.","speaker":"DARIO AMODEI","timecode":{"start":4255.15,"end":4258.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I don't think that's the case with A.I. Maybe A.I. makes solar energy more efficient or maybe it solves controlled nuclear fusion, or maybe it makes geoengineering more stable or possible.","speaker":"DARIO AMODEI","timecode":{"start":4258.73,"end":4272.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I don't think we need to rely on the long run.","speaker":"DARIO AMODEI","timecode":{"start":4272.67,"end":4275.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There are some applications where the model is doing something that used to be automated, that used to be done by computer systems.","speaker":"DARIO AMODEI","timecode":{"start":4275.64,"end":4284.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the model is able to do it faster with less computing time, right?","speaker":"DARIO AMODEI","timecode":{"start":4284.25,"end":4287.76,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Those are pure wins.","speaker":"DARIO AMODEI","timecode":{"start":4287.76,"end":4289.05,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And there are some of those.","speaker":"DARIO AMODEI","timecode":{"start":4289.05,"end":4290.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There are others where it's using the same amount of computing resources or maybe more computing resources, but to do something more valuable that saves labor elsewhere.","speaker":"DARIO AMODEI","timecode":{"start":4290.56,"end":4300.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Then there are cases where something used to be done by humans or in the physical world, and now it's being done by the models.","speaker":"DARIO AMODEI","timecode":{"start":4300.73,"end":4308.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Maybe it does something that previously I needed to go into the office to do that thing.","speaker":"DARIO AMODEI","timecode":{"start":4308.26,"end":4313.42,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And now I no longer need to go into the office to do that thing.","speaker":"DARIO AMODEI","timecode":{"start":4313.42,"end":4316.49,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I don't have to get in my car.","speaker":"DARIO AMODEI","timecode":{"start":4316.5,"end":4318.23,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't have to use the gas that was used for that.","speaker":"DARIO AMODEI","timecode":{"start":4318.23,"end":4320.38,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The energy accounting for that is kind of hard.","speaker":"DARIO AMODEI","timecode":{"start":4320.38,"end":4322.81,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You compare it to the food that the humans eat and what the energy cost of producing that.","speaker":"DARIO AMODEI","timecode":{"start":4322.81,"end":4328.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So in all honesty, I don't think we have good answers about what fraction of the usage points one way and one fraction of the usage points to others.","speaker":"DARIO AMODEI","timecode":{"start":4328.23,"end":4337.09,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In many ways, how different is this from the general dilemma of, as the economy grows, it uses more energy?","speaker":"DARIO AMODEI","timecode":{"start":4337.09,"end":4345.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I guess, what I'm saying is, it kind of all matters how you use the technology.","speaker":"DARIO AMODEI","timecode":{"start":4345.32,"end":4349.21,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, my kind of boring short-term answer is, we get carbon offsets for all of this stuff.","speaker":"DARIO AMODEI","timecode":{"start":4349.21,"end":4354.07,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But let's look beyond that to the macro question here.","speaker":"DARIO AMODEI","timecode":{"start":4354.07,"end":4357.58,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But to take the other side of it, I mean, I think the difference, when you say this is always a question we have when we're growing G.D.P., is it's not quite.","speaker":"EZRA KLEIN","timecode":{"start":4357.59,"end":4365.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's cliché because it's true to say that the major global warming challenge right now is countries like China and India getting richer.","speaker":"EZRA KLEIN","timecode":{"start":4365.47,"end":4373.87,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And we want them to get richer.","speaker":"EZRA KLEIN","timecode":{"start":4373.87,"end":4376.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It is a huge human imperative, right, a moral imperative for poor people in the world to become less poor.","speaker":"EZRA KLEIN","timecode":{"start":4376.51,"end":4382.643,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And if that means they use more energy, then we just need to figure out how to make that work.","speaker":"EZRA KLEIN","timecode":{"start":4382.643,"end":4386.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And we don't know of a way for that to happen without them using more energy.","speaker":"EZRA KLEIN","timecode":{"start":4386.56,"end":4390.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Adding A.I. is not that it raises a whole different set of questions, but we're already straining at the boundaries, or maybe far beyond them, of safely what we can do energetically.","speaker":"EZRA KLEIN","timecode":{"start":4390.48,"end":4400.69,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Now we add in this, and so maybe some of the energy efficiency gains you're going to get in rich countries get wiped out.","speaker":"EZRA KLEIN","timecode":{"start":4400.69,"end":4406.84,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"For this sort of uncertain payoff in the future of maybe through A.I., we figure out ways to stabilize nuclear fusion or something, right, you could imagine ways that could help, but those ways are theoretical.","speaker":"EZRA KLEIN","timecode":{"start":4406.84,"end":4417.29,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And in the near term, the harm in terms of energy usage is real.","speaker":"EZRA KLEIN","timecode":{"start":4417.3,"end":4422.11,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And also, by the way, the harm in terms of just energy prices.","speaker":"EZRA KLEIN","timecode":{"start":4422.11,"end":4425.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's also just tricky because all these companies, Microsoft, Amazon, I mean, they all have a lot of renewable energy targets.","speaker":"EZRA KLEIN","timecode":{"start":4425.36,"end":4433.03,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Now if that is colliding with their market incentives, it feels like they're running really fast towards the market incentives without an answer for how all that nets out.","speaker":"EZRA KLEIN","timecode":{"start":4433.03,"end":4440.333,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, I mean, I think the concerns are real.","speaker":"DARIO AMODEI","timecode":{"start":4440.333,"end":4442.75,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Let me push back a little bit, which is, again, I don't think the benefits are purely in the future.","speaker":"DARIO AMODEI","timecode":{"start":4442.75,"end":4448.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It kind of goes back to what I said before.","speaker":"DARIO AMODEI","timecode":{"start":4448.97,"end":4450.85,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Like, there may be use cases now that are net energy saving, or that to the extent that they're not net energy saving, do so through the general mechanism of, oh, there was more demand for this thing.","speaker":"DARIO AMODEI","timecode":{"start":4450.85,"end":4462.37,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't think anyone has done a good enough job measuring, in part because the applications of A.I. are so new, which of those things dominate or what's going to happen to the economy.","speaker":"DARIO AMODEI","timecode":{"start":4462.38,"end":4471.68,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I don't think we should assume that the harms are entirely in the present and the benefits are entirely in the future.","speaker":"DARIO AMODEI","timecode":{"start":4471.68,"end":4477.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think that's my only point here.","speaker":"DARIO AMODEI","timecode":{"start":4477.86,"end":4479.32,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I guess you could imagine a world where we were, somehow or another, incentivizing uses of A.I. that were yoked to some kind of social purpose.","speaker":"EZRA KLEIN","timecode":{"start":4479.33,"end":4487.24,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We were putting a lot more into drug discovery, or we cared a lot about things that made remote work easier, or pick your set of public goods.","speaker":"EZRA KLEIN","timecode":{"start":4487.24,"end":4494.2,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But what actually seems to me to be happening is we're building more and more and more powerful models and just throwing them out there within a terms of service structure to say, use them as long as you're not trying to politically manipulate people or create a bioweapon.","speaker":"EZRA KLEIN","timecode":{"start":4494.21,"end":4507.28,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Just try to figure this out, right?","speaker":"EZRA KLEIN","timecode":{"start":4507.28,"end":4508.84,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Try to create new stories and ask it about your personal life, and make a video game with it.","speaker":"EZRA KLEIN","timecode":{"start":4508.84,"end":4515.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And Sora comes out sooner or later.","speaker":"EZRA KLEIN","timecode":{"start":4515.26,"end":4518.11,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Make new videos with it.","speaker":"EZRA KLEIN","timecode":{"start":4518.11,"end":4519.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And all that is going to be very energy intensive.","speaker":"EZRA KLEIN","timecode":{"start":4519.41,"end":4522.01,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I am not saying that I have a plan for yoking A.I. to social good, and in some ways, you can imagine that going very, very wrong.","speaker":"EZRA KLEIN","timecode":{"start":4522.02,"end":4528.01,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But it does mean that for a long time, it's like you could imagine the world you're talking about, but that would require some kind of planning that nobody is engaged in, and I don't think anybody even wants to be engaged in.","speaker":"EZRA KLEIN","timecode":{"start":4528.01,"end":4539.34,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Not everyone has the same conception of social good.","speaker":"DARIO AMODEI","timecode":{"start":4539.35,"end":4542.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"One person may think social good is this ideology.","speaker":"DARIO AMODEI","timecode":{"start":4542.73,"end":4545.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Another person -- we've seen that with some of the Gemini stuff.","speaker":"DARIO AMODEI","timecode":{"start":4545.26,"end":4548.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Right.","speaker":"EZRA KLEIN","timecode":{"start":4548.46,"end":4549.21,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But companies can try to make beneficial applications themselves, right?","speaker":"DARIO AMODEI","timecode":{"start":4549.22,"end":4552.99,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Like, this is why we're working with cancer institutes.","speaker":"DARIO AMODEI","timecode":{"start":4552.99,"end":4555.63,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We're hoping to partner with ministries of education in Africa, to see if we can use the models in kind of a positive way for education, rather than the way they may be used by default. So I think individual companies, individual people,","speaker":"DARIO AMODEI","timecode":{"start":4555.63,"end":4569.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"can take actions to steer or bend this towards the public good.","speaker":"DARIO AMODEI","timecode":{"start":4569.67,"end":4574.74,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That said, it's never going to be the case that 100 percent of what we do is that.","speaker":"DARIO AMODEI","timecode":{"start":4574.75,"end":4579.49,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so I think it's a good question.","speaker":"DARIO AMODEI","timecode":{"start":4579.49,"end":4581.04,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What are the societal incentives, without dictating ideology or defining the public good from on high, what are incentives that could help with this?","speaker":"DARIO AMODEI","timecode":{"start":4581.04,"end":4590.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't feel like I have a systemic answer either.","speaker":"DARIO AMODEI","timecode":{"start":4590.56,"end":4593.4,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I can only think in terms of what Anthropic tries to do.","speaker":"DARIO AMODEI","timecode":{"start":4593.4,"end":4596.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But there's also the question of training data and the intellectual property that is going into things like Claude, like GPT, like Gemini.","speaker":"EZRA KLEIN","timecode":{"start":4596.65,"end":4604.24,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There are a number of copyright lawsuits.","speaker":"EZRA KLEIN","timecode":{"start":4604.24,"end":4607.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You're facing some.","speaker":"EZRA KLEIN","timecode":{"start":4607.27,"end":4608.35,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"OpenAI is facing some.","speaker":"EZRA KLEIN","timecode":{"start":4608.35,"end":4609.52,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I suspect everybody is either facing them now or will face them.","speaker":"EZRA KLEIN","timecode":{"start":4609.52,"end":4612.79,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And a broad feeling that these systems are being trained on the combined intellectual output of a lot of different people -- the way that Claude can quite effectively mimic the way I write is it has been trained, to some degree, on my writing, right?","speaker":"EZRA KLEIN","timecode":{"start":4612.8,"end":4628.12,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So it actually does get my stylistic tics quite well.","speaker":"EZRA KLEIN","timecode":{"start":4628.12,"end":4631.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You seem great, but you haven't sent me a check on that.","speaker":"EZRA KLEIN","timecode":{"start":4631.51,"end":4634,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And this seems like somewhere where there is real liability risk for the industry.","speaker":"EZRA KLEIN","timecode":{"start":4634,"end":4639.16,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Like, what if you do actually have to compensate the people who this is being trained on?","speaker":"EZRA KLEIN","timecode":{"start":4639.16,"end":4643.42,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And should you?","speaker":"EZRA KLEIN","timecode":{"start":4643.42,"end":4644.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I recognize you probably can't comment on lawsuits themselves, but I'm sure you've had to think a lot about this.","speaker":"EZRA KLEIN","timecode":{"start":4644.9,"end":4650.06,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, I'm curious both how you understand it as a risk, but also how you understand it morally.","speaker":"EZRA KLEIN","timecode":{"start":4650.06,"end":4654.61,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, when you talk about the people who invent these systems gaining a lot of power, and alongside that, a lot of wealth, well, what about all the people whose work went into them such that they can create images in a million different styles?","speaker":"EZRA KLEIN","timecode":{"start":4654.61,"end":4666.392,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I mean, somebody came up with those styles.","speaker":"EZRA KLEIN","timecode":{"start":4666.392,"end":4668.35,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What is the responsibility back to the intellectual commons?","speaker":"EZRA KLEIN","timecode":{"start":4668.35,"end":4672.16,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And not just to the commons, but to the actual wages and economic prospects of the people who made all this possible?","speaker":"EZRA KLEIN","timecode":{"start":4672.16,"end":4680.8,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think everyone agrees the models shouldn't be verbatim outputting copyrighted content.","speaker":"DARIO AMODEI","timecode":{"start":4680.81,"end":4686.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"For things that are available on the web, for publicly available, our position -- and I think there's a strong case for it -- is that the training process, again, we don't think it's just hoovering up content and spitting it out, or it shouldn't be spitting it out.","speaker":"DARIO AMODEI","timecode":{"start":4686.62,"end":4701.29,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's really much more like the process of how a human learns from experiences.","speaker":"DARIO AMODEI","timecode":{"start":4701.29,"end":4706.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, our position that that is sufficiently transformative, and I think the law will back this up, that this is fair use.","speaker":"DARIO AMODEI","timecode":{"start":4706.22,"end":4713.87,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But those are narrow legal ways to think about the problem.","speaker":"DARIO AMODEI","timecode":{"start":4713.88,"end":4716.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think we have a broader issue, which is that regardless of how it was trained, it would still be the case that we're building more and more general cognitive systems, and that those systems will create disruption.","speaker":"DARIO AMODEI","timecode":{"start":4716.89,"end":4729.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Maybe not necessarily by one for one replacing humans, but they're really going to change how the economy works and which skills are valued.","speaker":"DARIO AMODEI","timecode":{"start":4729.46,"end":4737.56,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And we need a solution to that broad macroeconomic problem, right?","speaker":"DARIO AMODEI","timecode":{"start":4737.56,"end":4743.38,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"As much as I've asserted the narrow legal points that I asserted before, we have a broader problem here, and we shouldn't be blind to that.","speaker":"DARIO AMODEI","timecode":{"start":4743.39,"end":4751.58,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's a number of solutions.","speaker":"DARIO AMODEI","timecode":{"start":4751.58,"end":4753.1,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, I think the simplest one, which I recognize doesn't address some of the deeper issues here, is things around the kind of guaranteed basic income side of things.","speaker":"DARIO AMODEI","timecode":{"start":4753.1,"end":4762.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I think there's a deeper question here, which is like as A.I. systems become capable of larger and larger slices of cognitive labor, how does society organize itself economically?","speaker":"DARIO AMODEI","timecode":{"start":4762.84,"end":4772.75,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"How do people find work and meaning and all of that?","speaker":"DARIO AMODEI","timecode":{"start":4772.75,"end":4777.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And just as kind of we transition from an agrarian society to an industrial society and the meaning of work changed, and it was no longer true that 99 percent of people were peasants working on farms and had to find new methods of economic organization,","speaker":"DARIO AMODEI","timecode":{"start":4777.71,"end":4793.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I suspect there's some different method of economic organization that's going to be forced as the only possible response to disruptions to the economy that will be small at first, but will grow over time, and that we haven't worked out what that is.","speaker":"DARIO AMODEI","timecode":{"start":4793.51,"end":4809.42,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"We need to find something that allows people to find meaning that's humane and that maximizes our creativity and potential and flourishing from A.I.","speaker":"DARIO AMODEI","timecode":{"start":4809.43,"end":4818.77,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And as with many of these questions, I don't have the answer to that.","speaker":"DARIO AMODEI","timecode":{"start":4818.78,"end":4821.66,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Right?","speaker":"DARIO AMODEI","timecode":{"start":4821.66,"end":4822.16,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't have a prescription.","speaker":"DARIO AMODEI","timecode":{"start":4822.16,"end":4823.45,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But that's what we somehow need to do.","speaker":"DARIO AMODEI","timecode":{"start":4823.45,"end":4825.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I want to sit in between the narrow legal response and the broad \"we have to completely reorganize society\" response, although I think that response is actually possible over the decades.","speaker":"EZRA KLEIN","timecode":{"start":4825.63,"end":4837.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And in the middle of that is a more specific question.","speaker":"EZRA KLEIN","timecode":{"start":4837.27,"end":4840.48,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, you could even take it from the instrumental side.","speaker":"EZRA KLEIN","timecode":{"start":4840.48,"end":4843.17,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There is a lot of effort now to build search products that use these systems, right?","speaker":"EZRA KLEIN","timecode":{"start":4843.17,"end":4849.71,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"ChatGPT will use Bing to search for you.","speaker":"EZRA KLEIN","timecode":{"start":4849.71,"end":4852.93,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And that means that the person is not going to Bing and clicking on the website where ChatGPT is getting its information and giving that website an advertising impression that they can turn into a very small amount of money, or they're not going to that website","speaker":"EZRA KLEIN","timecode":{"start":4852.94,"end":4866.48,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"and having a really good experience with that website and becoming maybe likelier to subscribe to whoever is behind that website.","speaker":"EZRA KLEIN","timecode":{"start":4866.48,"end":4872.69,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, on the one hand, that seems like some kind of injustice done to the people creating the information that these systems are using.","speaker":"EZRA KLEIN","timecode":{"start":4872.7,"end":4882.74,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, this is true for perplexity.","speaker":"EZRA KLEIN","timecode":{"start":4882.74,"end":4884.33,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's true for a lot of things I'm beginning to see around where the A.I.s are either trained on or are using a lot of data that people have generated at some real cost.","speaker":"EZRA KLEIN","timecode":{"start":4884.33,"end":4893.13,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But not only are they not paying people for that, but they're actually stepping into the middle of where they would normally be a direct relationship and making it so that relationship never happens.","speaker":"EZRA KLEIN","timecode":{"start":4893.13,"end":4902.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That also, I think, in the long run, creates a training data problem, even if you just want to look at it instrumentally, where if it becomes nonviable to do journalism or to do a lot of things to create high quality information out there, the A.I.'s ability,","speaker":"EZRA KLEIN","timecode":{"start":4902.98,"end":4917.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"right, the ability of all of your companies to get high quality, up-to-date, constantly updated information becomes a lot trickier.","speaker":"EZRA KLEIN","timecode":{"start":4917.31,"end":4924.46,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So there both seems to me to be both a moral and a self-interested dimension to this.","speaker":"EZRA KLEIN","timecode":{"start":4924.46,"end":4928.8,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, so I think there may be business models that work for everyone, not because it's illegitimate to train on open data from the web in a legal sense, but just because there may be business models here that kind of deliver a better product.","speaker":"DARIO AMODEI","timecode":{"start":4928.81,"end":4943.5,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So things I'm thinking of are like newspapers have archives.","speaker":"DARIO AMODEI","timecode":{"start":4943.5,"end":4947.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Some of them aren't publicly available.","speaker":"DARIO AMODEI","timecode":{"start":4947.31,"end":4949.03,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But even if they are, it may be a better product, maybe a better experience, to, say, talk to this newspaper or talk to that newspaper.","speaker":"DARIO AMODEI","timecode":{"start":4949.03,"end":4956.31,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It may be a better experience to give the ability to interact with content and point to places in the content, and every time you call that content, to have some kind of business relationship with the creators of that content.","speaker":"DARIO AMODEI","timecode":{"start":4956.32,"end":4969.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So there may be business models here that propagate the value in the right way, right?","speaker":"DARIO AMODEI","timecode":{"start":4969.67,"end":4974.58,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You talk about LLMs using search products.","speaker":"DARIO AMODEI","timecode":{"start":4974.58,"end":4977.88,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, sure, you're going around the ads, but there's no reason it can't work in a different way, right?","speaker":"DARIO AMODEI","timecode":{"start":4977.88,"end":4984.48,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There's no reason that the users can't pay the search A.P.I.s, instead of it being paid through advertising, and then have that propagate through to wherever the original mechanism is that paid the creators of the content.","speaker":"DARIO AMODEI","timecode":{"start":4984.49,"end":4996.58,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So when value is being created, money can flow through.","speaker":"DARIO AMODEI","timecode":{"start":4996.58,"end":5000.89,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Let me try to end by asking a bit about how to live on the slope of the curve you believe we are on.","speaker":"EZRA KLEIN","timecode":{"start":5000.9,"end":5008,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Do you have kids?","speaker":"EZRA KLEIN","timecode":{"start":5008,"end":5009.027,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm married.","speaker":"DARIO AMODEI","timecode":{"start":5009.027,"end":5010.11,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I do not have kids.","speaker":"DARIO AMODEI","timecode":{"start":5010.11,"end":5010.94,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I have two kids.","speaker":"EZRA KLEIN","timecode":{"start":5010.95,"end":5012.33,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I have a two-year-old and a five-year-old.","speaker":"EZRA KLEIN","timecode":{"start":5012.33,"end":5014.21,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And particularly when I'm doing A.I. reporting, I really do sit in bed at night and think, what should I be doing here with them?","speaker":"EZRA KLEIN","timecode":{"start":5014.21,"end":5023.51,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What world am I trying to prepare them for?","speaker":"EZRA KLEIN","timecode":{"start":5023.51,"end":5025.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And what is needed in that world that is different from what is needed in this world, even if I believe there's some chance --","speaker":"EZRA KLEIN","timecode":{"start":5025.97,"end":5031.992,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"and I do believe there's some chance -- that all the things you're saying are true.","speaker":"EZRA KLEIN","timecode":{"start":5031.992,"end":5035.45,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That implies a very, very, very different life for them.","speaker":"EZRA KLEIN","timecode":{"start":5035.45,"end":5040.88,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I know people in your company with kids.","speaker":"EZRA KLEIN","timecode":{"start":5040.89,"end":5042.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I know they are thinking about this.","speaker":"EZRA KLEIN","timecode":{"start":5042.86,"end":5045.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"How do you think about that?","speaker":"EZRA KLEIN","timecode":{"start":5045.47,"end":5048.29,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I mean, what do you think should be different in the life of a two-year-old who is living through the pace of change that you are telling me is true here?","speaker":"EZRA KLEIN","timecode":{"start":5048.29,"end":5061.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"If you had a kid, how would this change the way you thought about it?","speaker":"EZRA KLEIN","timecode":{"start":5061.47,"end":5064.88,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The very short answer is, I don't know, and I have no idea, but we have to try anyway, right?","speaker":"DARIO AMODEI","timecode":{"start":5064.89,"end":5069.77,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"People have to raise kids, and they have to do it as best they can.","speaker":"DARIO AMODEI","timecode":{"start":5069.77,"end":5073.94,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"An obvious recommendation is just familiarity with the technology and how it works, right?","speaker":"DARIO AMODEI","timecode":{"start":5073.94,"end":5079.04,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The basic paradigm of, I'm talking to systems, and systems are taking action on my behalf, obviously, as much familiarity with that as possible is, I think, helpful.","speaker":"DARIO AMODEI","timecode":{"start":5079.04,"end":5091.16,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In terms of what should children learn in school, what are the careers of tomorrow, I just truly don't know, right?","speaker":"DARIO AMODEI","timecode":{"start":5091.17,"end":5099.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You could take this to say, well, it's important to learn STEM and programming and A.I. and all of that.","speaker":"DARIO AMODEI","timecode":{"start":5099.47,"end":5106.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But A.I. will impact that as well, right?","speaker":"DARIO AMODEI","timecode":{"start":5106.14,"end":5108.547,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't think any of it is going to --","speaker":"DARIO AMODEI","timecode":{"start":5108.547,"end":5110.13,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Possibly first.","speaker":"EZRA KLEIN","timecode":{"start":5110.14,"end":5111.32,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Yeah, right, possibly first.","speaker":"DARIO AMODEI","timecode":{"start":5111.32,"end":5113.07,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It seems better at coding than it is at other things.","speaker":"EZRA KLEIN","timecode":{"start":5113.08,"end":5115.778,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't think it's going to work out for any of these systems to just do one for one what humans are going to do.","speaker":"DARIO AMODEI","timecode":{"start":5115.778,"end":5121.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't really think that way.","speaker":"DARIO AMODEI","timecode":{"start":5121.41,"end":5123.88,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But I think it may fundamentally change industries and professions one by one in ways that are hard to predict.","speaker":"DARIO AMODEI","timecode":{"start":5123.88,"end":5131.44,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, I feel like I only have clichés here.","speaker":"DARIO AMODEI","timecode":{"start":5131.44,"end":5133.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Like get familiar with the technology.","speaker":"DARIO AMODEI","timecode":{"start":5133.86,"end":5136.02,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Teach your children to be adaptable, to be ready for a world that changes very quickly.","speaker":"DARIO AMODEI","timecode":{"start":5136.02,"end":5141.24,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I wish I had better answers, but I think that's the best I got.","speaker":"DARIO AMODEI","timecode":{"start":5141.24,"end":5144.21,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I agree that's not a good answer.","speaker":"EZRA KLEIN","timecode":{"start":5144.21,"end":5146.085,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"[LAUGHS] Let me ask that same question a bit from another direction, because one thing you just said is get familiar with the technology.","speaker":"EZRA KLEIN","timecode":{"start":5146.085,"end":5154.71,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the more time I spend with the technology, the more I fear that happening.","speaker":"EZRA KLEIN","timecode":{"start":5154.71,"end":5159.61,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"What I see when people use A.I. around me is that the obvious thing that technology does for you is automate the early parts of the creative process.","speaker":"EZRA KLEIN","timecode":{"start":5159.61,"end":5173.097,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The part where you're supposed to be reading something difficult yourself?","speaker":"EZRA KLEIN","timecode":{"start":5173.097,"end":5176.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Well, the A.I. can summarize it for you.","speaker":"EZRA KLEIN","timecode":{"start":5176.18,"end":5178.04,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The part where you're supposed to sit there with a blank page and write something?","speaker":"EZRA KLEIN","timecode":{"start":5178.04,"end":5181.457,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Well, the A.I. can give you a first draft.","speaker":"EZRA KLEIN","timecode":{"start":5181.457,"end":5183.65,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And later on, you have to check it and make sure it actually did what you wanted it to do and fact-checking it.","speaker":"EZRA KLEIN","timecode":{"start":5183.65,"end":5189.23,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And but I believe a lot of what makes humans good at thinking comes in those parts.","speaker":"EZRA KLEIN","timecode":{"start":5189.23,"end":5195.05,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I am older and have self-discipline, and maybe this is just me hanging on to an old way of doing this, right?","speaker":"EZRA KLEIN","timecode":{"start":5195.06,"end":5202.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You could say, why use a calculator from this perspective.","speaker":"EZRA KLEIN","timecode":{"start":5202.22,"end":5205.53,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But my actual worry is that I'm not sure if the thing they should do is use A.I. a lot or use it a little.","speaker":"EZRA KLEIN","timecode":{"start":5205.53,"end":5211.27,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"This, to me, is actually a really big branching path, right?","speaker":"EZRA KLEIN","timecode":{"start":5211.27,"end":5213.77,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Do I want my kids learning how to use A.I. or being in a context where they're using it a lot, or actually, do I want to protect them from it as much as I possibly could so they develop more of the capacity to read a book quietly on their own or write a first draft?","speaker":"EZRA KLEIN","timecode":{"start":5213.77,"end":5228.03,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I actually don't know.","speaker":"EZRA KLEIN","timecode":{"start":5228.03,"end":5229.02,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I'm curious if you have a view on it.","speaker":"EZRA KLEIN","timecode":{"start":5229.02,"end":5231.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think this is part of what makes the interaction between A.I. and society complicated where it's sometimes hard to distinguish when is an A.I. doing something, saving you labor or drudge work, versus kind of doing the interesting part.","speaker":"DARIO AMODEI","timecode":{"start":5231.19,"end":5245.58,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I will say that over and over again, you'll get some technological thing, some technological system that does what you thought was the core of what you're doing, and yet, what you're doing turns out to have more pieces than you think it does and kind of add up to more things, right?","speaker":"DARIO AMODEI","timecode":{"start":5245.58,"end":5264.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's like before, I used to have to ask for directions.","speaker":"DARIO AMODEI","timecode":{"start":5264.19,"end":5267.55,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I got Google Maps to do that.","speaker":"DARIO AMODEI","timecode":{"start":5267.55,"end":5269.43,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And you could worry, am I too reliant on Google Maps?","speaker":"DARIO AMODEI","timecode":{"start":5269.43,"end":5273,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Do I forget the environment around me?","speaker":"DARIO AMODEI","timecode":{"start":5273,"end":5275.08,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Well, it turns out, in some ways, I still need to have a sense of the city and the environment around me.","speaker":"DARIO AMODEI","timecode":{"start":5275.08,"end":5279.96,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It just kind of reallocates the space in my brain to some other aspect of the task.","speaker":"DARIO AMODEI","timecode":{"start":5279.96,"end":5286.65,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I just kind of suspect --","speaker":"DARIO AMODEI","timecode":{"start":5286.66,"end":5289.26,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't know.","speaker":"DARIO AMODEI","timecode":{"start":5289.26,"end":5290.4,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Internally, within Anthropic, one of the things I do that helps me run the company is, I'll write these documents on strategy or just some thinking in some direction that others haven't thought.","speaker":"DARIO AMODEI","timecode":{"start":5290.4,"end":5302.25,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And of course, I sometimes use the internal models for that.","speaker":"DARIO AMODEI","timecode":{"start":5302.25,"end":5306.4,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And I think what I found is like, yes, sometimes they're a little bit good at conceptualizing the idea, but the actual genesis of the idea, I've just kind of found a workflow where I don't use them for that.","speaker":"DARIO AMODEI","timecode":{"start":5306.4,"end":5320.73,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They're not that helpful for that.","speaker":"DARIO AMODEI","timecode":{"start":5320.73,"end":5322.66,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But they're helpful in figuring out how to phrase a certain thing or how to refine my ideas.","speaker":"DARIO AMODEI","timecode":{"start":5322.66,"end":5328.57,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So maybe I'm just saying --","speaker":"DARIO AMODEI","timecode":{"start":5328.58,"end":5330.03,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I don't know.","speaker":"DARIO AMODEI","timecode":{"start":5330.03,"end":5330.72,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"You just find a workflow where the thing complements you.","speaker":"DARIO AMODEI","timecode":{"start":5330.72,"end":5333.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And if it doesn't happen naturally, it somehow still happens eventually.","speaker":"DARIO AMODEI","timecode":{"start":5333.7,"end":5337.68,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Again, if the systems get general enough, if they get powerful enough, we may need to think along other lines.","speaker":"DARIO AMODEI","timecode":{"start":5337.68,"end":5343.13,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But in the short-term, I, at least, have always found that.","speaker":"DARIO AMODEI","timecode":{"start":5343.13,"end":5345.62,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Maybe that's too sanguine.","speaker":"DARIO AMODEI","timecode":{"start":5345.62,"end":5346.91,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Maybe that's too optimistic.","speaker":"DARIO AMODEI","timecode":{"start":5346.91,"end":5348.39,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"I think, then, that's a good place to end this conversation.","speaker":"EZRA KLEIN","timecode":{"start":5348.39,"end":5351.39,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Though, obviously, the exponential curve continues.","speaker":"EZRA KLEIN","timecode":{"start":5351.39,"end":5354.18,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So always our final question -- what are three books you'd recommend to the audience?","speaker":"EZRA KLEIN","timecode":{"start":5354.18,"end":5357.836,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So, yeah, I've prepared three.","speaker":"DARIO AMODEI","timecode":{"start":5357.846,"end":5360,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"They're all topical, though, in some cases, indirectly so.","speaker":"DARIO AMODEI","timecode":{"start":5360,"end":5363.54,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The first one will be obvious.","speaker":"DARIO AMODEI","timecode":{"start":5363.54,"end":5365.01,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's a very long book.","speaker":"DARIO AMODEI","timecode":{"start":5365.01,"end":5366.81,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The physical book is very thick, but \"The Making of the Atomic Bomb,\" Richard Rhodes.","speaker":"DARIO AMODEI","timecode":{"start":5366.81,"end":5370.8,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's an example of technology being developed very quickly and with very broad implications.","speaker":"DARIO AMODEI","timecode":{"start":5370.8,"end":5377.1,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Just looking through all the characters and how they reacted to this and how people who were basically scientists gradually realized the incredible implications of the technology and how it would lead them into a world that was very different from the one they were used to.","speaker":"DARIO AMODEI","timecode":{"start":5377.1,"end":5392.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"My second recommendation is a science fiction series, \"The Expanse\" series of books.","speaker":"DARIO AMODEI","timecode":{"start":5392.71,"end":5398.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"So I initially watched the show, and then I read all the books.","speaker":"DARIO AMODEI","timecode":{"start":5398.22,"end":5401.61,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the world it creates is very advanced.","speaker":"DARIO AMODEI","timecode":{"start":5401.61,"end":5404.67,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"In some cases, it has longer life spans, and humans have expanded into space.","speaker":"DARIO AMODEI","timecode":{"start":5404.67,"end":5411.64,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"But we still face some of the same geopolitical questions and some of the same inequalities and exploitations that exist in our world, are still present, in some cases, worse.","speaker":"DARIO AMODEI","timecode":{"start":5411.64,"end":5423.34,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"That's all the backdrop of it.","speaker":"DARIO AMODEI","timecode":{"start":5423.35,"end":5425.14,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And the core of it is about some fundamentally new technological object that is being brought into that world and how everyone reacts to it, how governments react to it, how individual people react to it, and how political ideologies react to it.","speaker":"DARIO AMODEI","timecode":{"start":5425.15,"end":5439.955,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so, I don't know.","speaker":"DARIO AMODEI","timecode":{"start":5439.955,"end":5440.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"When I read that a few years ago, I saw a lot of parallels.","speaker":"DARIO AMODEI","timecode":{"start":5440.83,"end":5444.43,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And then my third recommendation would be actually \"The Guns of August,\" which is basically a history of how World War I started.","speaker":"DARIO AMODEI","timecode":{"start":5444.44,"end":5452.5,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The basic idea that crises happen very fast, almost no one knows what's going on.","speaker":"DARIO AMODEI","timecode":{"start":5452.5,"end":5458.41,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"There are lots of miscalculations because there are humans at the center of it, and kind of, we somehow have to learn to step back and make wiser decisions in these key moments.","speaker":"DARIO AMODEI","timecode":{"start":5458.41,"end":5467.23,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"It's said that Kennedy read the book before the Cuban Missile Crisis.","speaker":"DARIO AMODEI","timecode":{"start":5467.23,"end":5470.83,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And so I hope our current policymakers are at least thinking along the same terms because I think it is possible similar crises may be coming our way.","speaker":"DARIO AMODEI","timecode":{"start":5470.83,"end":5480.22,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Dario Amodei, thank you very much.","speaker":"EZRA KLEIN","timecode":{"start":5480.23,"end":5482.397,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Thank you for having me.","speaker":"DARIO AMODEI","timecode":{"start":5482.397,"end":5483.98,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"[MUSIC PLAYING]","speaker":"DARIO AMODEI","timecode":{"start":5483.99,"end":5486.92,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"This episode of \"The Ezra Klein Show\" was produced by Rollin Hu.","speaker":"EZRA KLEIN","timecode":{"start":5494.303,"end":5497.47,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Fact-checking by Michelle Harris.","speaker":"EZRA KLEIN","timecode":{"start":5497.47,"end":5498.97,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Our senior engineer is Jeff Geld.","speaker":"EZRA KLEIN","timecode":{"start":5498.97,"end":5500.59,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Our senior editor is Claire Gordon.","speaker":"EZRA KLEIN","timecode":{"start":5500.59,"end":5502.54,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The show's production team also includes Annie Galvin, Kristin Lin and Aman Sahota.","speaker":"EZRA KLEIN","timecode":{"start":5502.54,"end":5507.1,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Original music by Isaac Jones.","speaker":"EZRA KLEIN","timecode":{"start":5507.1,"end":5509.06,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"Audience strategy by Kristina Samulewski and Shannon Busta.","speaker":"EZRA KLEIN","timecode":{"start":5509.06,"end":5512.36,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"The executive producer of New York Times Opinion Audio is Annie-Rose Strasser.","speaker":"EZRA KLEIN","timecode":{"start":5512.36,"end":5515.86,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"},{"text":"And special thanks to Sonia Herrero.","speaker":"EZRA KLEIN","timecode":{"start":5515.86,"end":5518.7,"__typename":"AudioTimecode"},"__typename":"AudioTranscriptFragment"}]},"headline":{"default":"What if Dario Amodei Is Right About A.I.?","__typename":"CreativeWorkHeadline"},"summary":"Anthropic’s co-founder and C.E.O. explains why he thinks artificial intelligence is on an “exponential curve.”","fileUrl":"https:\u002F\u002Fnyt.simplecastaudio.com\u002F3026b665-46df-4d18-98e9-d1ce16bbb1df\u002Fepisodes\u002F223c172c-1566-4efe-9f19-f5be27f41e45\u002Faudio\u002F128\u002Fdefault.mp3?awCollectionId=3026b665-46df-4d18-98e9-d1ce16bbb1df&awEpisodeId=223c172c-1566-4efe-9f19-f5be27f41e45&nocache","credit":"","firstPublished":"2024-04-11T21:59:22.000Z","length":5587,"subscribeUrls":[{"url":"","platform":"ANDROID","__typename":"AudioSubscribeUrl"}],"promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvODVkYWNkOWQtMzYzNC01MDBkLTk2Y2EtMGY5Yjc2N2E0ZDk5","crops":[{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-jumbo.jpg","width":1024,"height":682,"__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"podcastSeries":{"title":"The Ezra Klein Show","subtitle":"","name":"Ezra-Klein-Show-Podcast","itunesUrl":"https:\u002F\u002Fitunes.apple.com\u002Fus\u002Fpodcast\u002Fid","image":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvN2M3NTQ0NjktMjQ5Zi01YjllLWFlODEtMzNlNjk5NDk3ZjY5","crops":[{"name":"MASTER","renditions":[{"width":600,"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2023\u002F04\u002F05\u002Fpodcasts\u002Fezra-klein-album-art\u002Fezra-klein-album-art-articleLarge-v3.jpg","name":"articleLarge","height":600,"format":"NOT_SET","__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"name":"MEDIUM_SQUARE","renditions":[{"width":320,"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2023\u002F04\u002F05\u002Fpodcasts\u002Fezra-klein-album-art\u002Fezra-klein-album-art-square320-v2.jpg","name":"square320","height":320,"format":"NOT_SET","__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"name":"THREE_BY_TWO","renditions":[{"width":768,"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2023\u002F04\u002F05\u002Fpodcasts\u002Fezra-klein-album-art\u002Fezra-klein-album-art-videoLarge-v2.jpg","name":"videoLarge","height":507,"format":"NOT_SET","__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"name":"FIFTEEN_BY_SEVEN","renditions":[{"width":2610,"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2023\u002F04\u002F05\u002Fpodcasts\u002Fezra-klein-album-art\u002Fezra-klein-album-art-videoFifteenBySeven2610-v3.jpg","name":"videoFifteenBySeven2610","height":1218,"format":"NOT_SET","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"collection":null,"__typename":"AudioPodcastSeries"},"__typename":"Audio"},"__typename":"AudioBlock"},"fallback":{"__typename":"HeaderLegacyBlock","subhead":null,"label":null,"headline":{"textAlign":"LEFT","content":[{"__typename":"TextInline","text":"What if Dario Amodei Is Right About A.I.?","formats":[]}],"__typename":"Heading1Block"},"ledeMedia":null,"byline":null,"timestampBlock":{"timestamp":"2024-04-12T09:03:56.000Z","align":"LEFT","showUpdatedTimestamp":null,"__typename":"TimestampBlock"}}},{"__typename":"BylineBlock","textAlign":"LEFT","hideHeadshots":true,"bylines":[{"prefix":"Produced by","creators":[{"id":"UGVyc29uOm55dDovL3BlcnNvbi9kZGNhNzE2NS1kMDBlLTUwOTAtYWFlNS03N2VjOThmMjc0Y2I=","displayName":"‘The Ezra Klein Show’","bioUrl":"","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvYTFhNzg5ZjMtNDAxZC01NjdlLWIxZmItNjgxYWUyOWRkMWMy","crops":[{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2021\u002F01\u002F06\u002Fopinion\u002Fezra-klein\u002Fezra-klein-thumbLarge-v3.png","name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Person"}],"renderedRepresentation":"Produced by ‘The Ezra Klein Show’","__typename":"Byline"}],"role":[]},{"__typename":"ParagraphBlock","textAlign":"LEFT","content":[{"__typename":"TextInline","text":"Back in 2018, Dario Amodei worked at OpenAI. And looking at one of its first A.I. models, he wondered: What would happen as you fed an artificial intelligence more and more data?","formats":[]}]},{"__typename":"Dropzone","adsDesktopHoldout":false,"adsMobileHoldout":false,"adsMobile":false,"adsDesktop":false,"index":0,"bad":false},{"__typename":"ParagraphBlock","textAlign":"LEFT","content":[{"__typename":"TextInline","text":"He and his colleagues decided to study it, and they found that the A.I. didn’t just get better with more data; it got better exponentially. The curve of the A.I.’s capabilities rose slowly at first and then shot up like a hockey stick.","formats":[]}]},{"__typename":"Dropzone","adsDesktopHoldout":false,"adsMobileHoldout":false,"adsMobile":false,"adsDesktop":false,"index":1,"bad":false},{"__typename":"ParagraphBlock","textAlign":"LEFT","content":[{"__typename":"TextInline","text":"[You can listen to this episode of “The Ezra Klein Show” on the ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"NYT Audio App","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fapps.apple.com\u002Fus\u002Fapp\u002Fnyt-audio\u002Fid1549293936","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"Apple","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fpodcasts.apple.com\u002Fus\u002Fpodcast\u002Fthe-ezra-klein-show\u002Fid1548604447","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"Spotify","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fopen.spotify.com\u002Fshow\u002F3oB5noYIwEB2dMAREj2F7S","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"Amazon Music","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fmusic.amazon.com\u002Fpodcasts\u002Fc4a3b1da-5433-49e6-8c14-0e1da53be78c\u002Fthe-ezra-klein-show","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"Google","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.google.com\u002Fpodcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS84MkZJMzVQeA%3D%3D","title":"","uri":null}]},{"__typename":"TextInline","text":" or ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"wherever you get your podcasts","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.nytimes.com\u002F2021\u002F01\u002F19\u002Fopinion\u002Fhow-to-listen-ezra-klein-show-nyt.html?action=click&module=RelatedLinks&pgtype=Article","title":"","uri":null}]},{"__typename":"TextInline","text":".]","formats":[{"__typename":"ItalicFormat","type":null}]}]},{"__typename":"Dropzone","adsDesktopHoldout":false,"adsMobileHoldout":true,"adsMobile":false,"adsDesktop":false,"index":2,"bad":false},{"__typename":"ParagraphBlock","textAlign":"LEFT","content":[{"__typename":"TextInline","text":"Amodei is now the chief executive of his own A.I. company, Anthropic, which recently released Claude 3 — considered by many to be the strongest A.I. model available. And he still believes A.I. is on an exponential growth curve, following principles known as scaling laws. And he thinks we’re on the steep part of the climb right now.","formats":[]}]},{"__typename":"Dropzone","adsDesktopHoldout":true,"adsMobileHoldout":false,"adsMobile":true,"adsDesktop":true,"index":3,"bad":false},{"__typename":"ParagraphBlock","textAlign":"LEFT","content":[{"__typename":"TextInline","text":"When I’ve talked to people who are building A.I., scenarios that feel like far-off science fiction end up on the horizon of about the next two years. So I asked Amodei on the show to share what he sees in the near future. What breakthroughs are around the corner? What worries him the most? And how are societies that struggle to adapt to change and governments that are slow to react to them supposed to prepare for the pace of change he predicts? What does that line on his graph mean for the rest of us?","formats":[]}]},{"__typename":"Dropzone","adsDesktopHoldout":false,"adsMobileHoldout":false,"adsMobile":false,"adsDesktop":false,"index":4,"bad":false},{"__typename":"ParagraphBlock","textAlign":"LEFT","content":[{"__typename":"TextInline","text":"This episode contains strong language.","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"BoldFormat","type":null}]}]},{"__typename":"ParagraphBlock","textAlign":"LEFT","content":[{"__typename":"TextInline","text":"You can listen to our whole conversation by following “The Ezra Klein Show” on the ","formats":[]},{"__typename":"TextInline","text":"NYT Audio App","formats":[{"__typename":"LinkFormat","url":"https:\u002F\u002Fapps.apple.com\u002Fus\u002Fapp\u002Fnyt-audio\u002Fid1549293936","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[]},{"__typename":"TextInline","text":"Apple","formats":[{"__typename":"LinkFormat","url":"https:\u002F\u002Fpodcasts.apple.com\u002Fus\u002Fpodcast\u002Fthe-ezra-klein-show\u002Fid1548604447","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[]},{"__typename":"TextInline","text":"Spotify","formats":[{"__typename":"LinkFormat","url":"https:\u002F\u002Fopen.spotify.com\u002Fshow\u002F3oB5noYIwEB2dMAREj2F7S","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[]},{"__typename":"TextInline","text":"Google","formats":[{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.google.com\u002Fpodcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS84MkZJMzVQeA%3D%3D","title":"","uri":null}]},{"__typename":"TextInline","text":" or ","formats":[]},{"__typename":"TextInline","text":"wherever you get your podcasts","formats":[{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.nytimes.com\u002F2021\u002F01\u002F19\u002Fopinion\u002Fhow-to-listen-ezra-klein-show-nyt.html?action=click&module=RelatedLinks&pgtype=Article","title":"","uri":null}]},{"__typename":"TextInline","text":". View a list of book recommendations from our guests ","formats":[]},{"__typename":"TextInline","text":"here","formats":[{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.nytimes.com\u002Farticle\u002Fezra-klein-show-book-recs.html","title":"","uri":null}]},{"__typename":"TextInline","text":".","formats":[]}]},{"__typename":"Dropzone","adsDesktopHoldout":false,"adsMobileHoldout":false,"adsMobile":false,"adsDesktop":false,"index":5,"bad":false},{"__typename":"ParagraphBlock","textAlign":"LEFT","content":[{"__typename":"TextInline","text":"(A full transcript of this episode is available ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"here","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F04\u002F12\u002Fpodcasts\u002Ftranscript-ezra-klein-interviews-dario-amodei.html","title":"","uri":null}]},{"__typename":"TextInline","text":".)","formats":[{"__typename":"ItalicFormat","type":null}]}]},{"__typename":"ImageBlock","size":"LARGE","media":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvODVkYWNkOWQtMzYzNC01MDBkLTk2Y2EtMGY5Yjc2N2E0ZDk5","imageType":"photo","url":"\u002Fimagepages\u002F2024\u002F04\u002F09\u002Fopinion\u002F12eks-amodei-image.html","uri":"nyt:\u002F\u002Fimage\u002F85dacd9d-3634-500d-96ca-0f9b767a4d99","credit":"Illustration by The New York Times; photograph by Dario Amodei","legacyHtmlCaption":"","crops":[{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-articleLarge.jpg","name":"articleLarge","width":600,"height":400,"__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-popup.jpg","name":"popup","width":650,"height":433,"__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-jumbo.jpg","name":"jumbo","width":1024,"height":682,"__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-superJumbo.jpg","name":"superJumbo","width":2048,"height":1365,"__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-thumbLarge.jpg","name":"thumbLarge","width":150,"height":150,"__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-articleInline.jpg","name":"articleInline","width":190,"height":127,"__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-mobileMasterAt3x.jpg","name":"mobileMasterAt3x","width":1800,"height":1199,"__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"caption":{"text":"","content":[],"__typename":"TextOnlyDocumentBlock"},"altText":"A portrait of Dario Amodei.","__typename":"Image"}},{"__typename":"Dropzone","adsDesktopHoldout":false,"adsMobileHoldout":false,"adsMobile":false,"adsDesktop":false,"index":6,"bad":true},{"__typename":"RelatedLinksBlock","displayStyle":"STANDARD","title":[{"__typename":"TextInline","text":"More conversations about A.I.","formats":[]}],"description":[],"related":[{"__typename":"Article","promotionalHeadline":"Sam Altman on the A.I. Revolution, Trillionaires and the Future of Political Power","promotionalSummary":"Will A.I. give us the lives of leisure we long for — or usher in a feudal dystopia? It depends.","headline":{"default":"Sam Altman on the A.I. Revolution, Trillionaires and the Future of Political Power","seo":"","__typename":"CreativeWorkHeadline"},"summary":"Will A.I. give us the lives of leisure we long for — or usher in a feudal dystopia? It depends.","url":"https:\u002F\u002Fwww.nytimes.com\u002F2021\u002F06\u002F11\u002Fopinion\u002Fezra-klein-podcast-sam-altman.html","firstPublished":"2021-06-11T09:00:06.000Z","id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlLzUyMWE4MGFjLWMzODMtNTkzMy1iMmUwLWMzMDIxZGM0ZmMxYQ==","typeOfMaterials":["Op-Ed"],"collections":[],"promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvZDAwY2I1MGQtY2VjMy01YzJhLWFlNjMtY2VhYTc3Y2FkOTJm","credit":"Illustration by The New York Times; photograph by Ian C. Bates for The New York Times","crops":[{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2021\u002F06\u002F11\u002Fopinion\u002F11eks-altman-image\u002F11eks-altman-image-thumbLarge.jpg","name":"thumbLarge","width":150,"__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2021\u002F06\u002F11\u002Fopinion\u002F11eks-altman-image\u002F11eks-altman-image-videoLarge.jpg","name":"videoLarge","width":768,"__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2021\u002F06\u002F11\u002Fopinion\u002F11eks-altman-image\u002F11eks-altman-image-mediumThreeByTwo440.jpg","name":"mediumThreeByTwo440","width":440,"__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2021\u002F06\u002F11\u002Fopinion\u002F11eks-altman-image\u002F11eks-altman-image-threeByTwoSmallAt2X.jpg","name":"threeByTwoSmallAt2X","width":600,"__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"section":{"id":"U2VjdGlvbjpueXQ6Ly9zZWN0aW9uL2Q3YTcxMTg1LWFhNjAtNTYzNS1iY2UwLTVmYWI3NmM3YzI5Nw==","displayName":"Opinion","__typename":"Section"},"bylines":[{"creators":[{"id":"UGVyc29uOm55dDovL3BlcnNvbi9kZGNhNzE2NS1kMDBlLTUwOTAtYWFlNS03N2VjOThmMjc0Y2I=","displayName":"‘The Ezra Klein Show’","__typename":"Person"}],"__typename":"Byline"}]},{"__typename":"Article","promotionalHeadline":"A.I. Could Solve Some of Humanity’s Hardest Problems. It Already Has.","promotionalSummary":"Demis Hassabis, the chief executive of DeepMind, discusses how A.I. systems can accelerate scientific research.","headline":{"default":"A.I. Could Solve Some of Humanity’s Hardest Problems. It Already Has.","seo":"","__typename":"CreativeWorkHeadline"},"summary":"Demis Hassabis, the chief executive of DeepMind, discusses how A.I. systems can accelerate scientific research.","url":"https:\u002F\u002Fwww.nytimes.com\u002F2023\u002F07\u002F11\u002Fopinion\u002Fezra-klein-podcast-demis-hassabis.html","firstPublished":"2023-07-11T09:00:28.000Z","id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlL2VlODY0NmI0LTlkYjItNTdkMC1iYTA0LTBkMjZhNjE2NzM4Mw==","typeOfMaterials":["Op-Ed"],"collections":[],"promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvMTk2OGM1ZmMtZjRiMS01YTI0LTk5MjctMGMwMjA2ZTI3Y2U0","credit":"Google DeepMind","crops":[{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2023\u002F07\u002F13\u002Fopinion\u002F11eks-hassabis-image-audio-app\u002F11eks-hassabis-image-audio-app-thumbLarge.jpg","name":"thumbLarge","width":150,"__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2023\u002F07\u002F13\u002Fopinion\u002F11eks-hassabis-image-audio-app\u002F11eks-hassabis-image-audio-app-videoLarge.jpg","name":"videoLarge","width":768,"__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2023\u002F07\u002F13\u002Fopinion\u002F11eks-hassabis-image-audio-app\u002F11eks-hassabis-image-audio-app-mediumThreeByTwo440.jpg","name":"mediumThreeByTwo440","width":440,"__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2023\u002F07\u002F13\u002Fopinion\u002F11eks-hassabis-image-audio-app\u002F11eks-hassabis-image-audio-app-threeByTwoSmallAt2X.jpg","name":"threeByTwoSmallAt2X","width":600,"__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"section":{"id":"U2VjdGlvbjpueXQ6Ly9zZWN0aW9uL2Q3YTcxMTg1LWFhNjAtNTYzNS1iY2UwLTVmYWI3NmM3YzI5Nw==","displayName":"Opinion","__typename":"Section"},"bylines":[{"creators":[{"id":"UGVyc29uOm55dDovL3BlcnNvbi9kZGNhNzE2NS1kMDBlLTUwOTAtYWFlNS03N2VjOThmMjc0Y2I=","displayName":"‘The Ezra Klein Show’","__typename":"Person"}],"__typename":"Byline"}]},{"__typename":"Article","promotionalHeadline":"Will A.I. Break the Internet? Or Save It?","promotionalSummary":"Nilay Patel discusses the near-future of an internet as A.I.-generated content improves.","headline":{"default":"Will A.I. Break the Internet? Or Save It?","seo":"","__typename":"CreativeWorkHeadline"},"summary":"Nilay Patel discusses the near-future of an internet as A.I.-generated content improves.","url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F04\u002F05\u002Fopinion\u002Fezra-klein-podcast-nilay-patel.html","firstPublished":"2024-04-05T09:03:55.000Z","id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlLzVlMWNmOTQ1LWZiNGUtNTI4My1hNTU5LTc4N2U0YjQ3ODBlZg==","typeOfMaterials":["Op-Ed"],"collections":[],"promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvZTE5YzFmYzUtNTg2MC01OTExLWE3OTgtY2Q3NGU3YTgwN2Yz","credit":"Illustration by The New York Times; photograph by Nilay Patel","crops":[{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F05\u002Fopinion\u002F05eks-patel-image\u002F05eks-patel-image-thumbLarge.jpg","name":"thumbLarge","width":150,"__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F05\u002Fopinion\u002F05eks-patel-image\u002F05eks-patel-image-videoLarge.jpg","name":"videoLarge","width":768,"__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F05\u002Fopinion\u002F05eks-patel-image\u002F05eks-patel-image-mediumThreeByTwo440.jpg","name":"mediumThreeByTwo440","width":440,"__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F05\u002Fopinion\u002F05eks-patel-image\u002F05eks-patel-image-threeByTwoSmallAt2X.jpg","name":"threeByTwoSmallAt2X","width":600,"__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"section":{"id":"U2VjdGlvbjpueXQ6Ly9zZWN0aW9uL2Q3YTcxMTg1LWFhNjAtNTYzNS1iY2UwLTVmYWI3NmM3YzI5Nw==","displayName":"Opinion","__typename":"Section"},"bylines":[{"creators":[{"id":"UGVyc29uOm55dDovL3BlcnNvbi9kZGNhNzE2NS1kMDBlLTUwOTAtYWFlNS03N2VjOThmMjc0Y2I=","displayName":"‘The Ezra Klein Show’","__typename":"Person"}],"__typename":"Byline"}]}]},{"__typename":"DetailBlock","textAlign":"LEFT","content":[{"__typename":"TextInline","text":"This episode of “The Ezra Klein Show” was produced by Rollin Hu. Fact-checking by Michelle Harris. Our senior engineer is Jeff Geld. Our senior editor is Claire Gordon. The show’s production team also includes Annie Galvin, Kristin Lin and Aman Sahota. Original music by Isaac Jones. Audience strategy by Kristina Samulewski and Shannon Busta. The executive producer of New York Times Opinion Audio is Annie-Rose Strasser. Special thanks to Sonia Herrero.","formats":[]}]},{"__typename":"DetailBlock","textAlign":"LEFT","content":[{"__typename":"TextInline","text":"Follow the New York Times Opinion section on ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"Facebook","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.facebook.com\u002Fnytopinion","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"Instagram","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.instagram.com\u002Fnytopinion\u002F","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"TikTok","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.tiktok.com\u002F@nytopinion","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"WhatsApp","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.whatsapp.com\u002Fchannel\u002F0029VaN8tdZ5vKAGNwXaED0M","title":"","uri":null}]},{"__typename":"TextInline","text":", ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"X","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"http:\u002F\u002Ftwitter.com\u002FNYTOpinion","title":"","uri":null}]},{"__typename":"TextInline","text":" and ","formats":[{"__typename":"ItalicFormat","type":null}]},{"__typename":"TextInline","text":"Threads","formats":[{"__typename":"ItalicFormat","type":null},{"__typename":"LinkFormat","url":"https:\u002F\u002Fwww.threads.net\u002F@nytopinion","title":"","uri":null}]},{"__typename":"TextInline","text":".","formats":[{"__typename":"ItalicFormat","type":null}]}]}],"__typename":"DocumentBlock"},"storyFormat":"Audio-Rich Story","url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F04\u002F12\u002Fopinion\u002Fezra-klein-podcast-dario-amodei.html","adTargetingParams":[{"key":"als_test","value":"1715055587648","__typename":"AdTargetingParam"},{"key":"prop","value":"nyt","__typename":"AdTargetingParam"},{"key":"plat","value":"web","__typename":"AdTargetingParam"},{"key":"edn","value":"us","__typename":"AdTargetingParam"},{"key":"brandsensitive","value":"false","__typename":"AdTargetingParam"},{"key":"per","value":"amodeidario","__typename":"AdTargetingParam"},{"key":"org","value":"anthropicaillc,openailabs","__typename":"AdTargetingParam"},{"key":"geo","value":"","__typename":"AdTargetingParam"},{"key":"des","value":"audioneutralinformative,computersandtheinternet","__typename":"AdTargetingParam"},{"key":"spon","value":"","__typename":"AdTargetingParam"},{"key":"auth","value":"theezrakleinshow","__typename":"AdTargetingParam"},{"key":"col","value":"theezrakleinshow","__typename":"AdTargetingParam"},{"key":"coll","value":"theezrakleinshow,opinion,opinioncolumnists,theezrakleinshow,science","__typename":"AdTargetingParam"},{"key":"artlen","value":"short","__typename":"AdTargetingParam"},{"key":"ledemedsz","value":"none","__typename":"AdTargetingParam"},{"key":"gui","value":"","__typename":"AdTargetingParam"},{"key":"template","value":"article","__typename":"AdTargetingParam"},{"key":"typ","value":"art","__typename":"AdTargetingParam"},{"key":"section","value":"opinion","__typename":"AdTargetingParam"},{"key":"si_section","value":"opinion","__typename":"AdTargetingParam"},{"key":"id","value":"100000009406898","__typename":"AdTargetingParam"},{"key":"trend","value":"","__typename":"AdTargetingParam"},{"key":"pt","value":"nt1,nt10,nt11,nt12,nt15,nt21,nt6,nt7,nt9,pt13,pt18,pt2,pt3","__typename":"AdTargetingParam"},{"key":"gscat","value":"gv_safe,neg_gg1,neg_google,neg_ibmtest,gb_safe,gb_safe_from_high,gb_safe_from_high_med,gs_tech,neg_kaypemg,neg_rchmt,neg_citi_aa,neg_ibm,neg_google_comps,neg_chan3,neg_ihw,neg_racism,acc_cc,neg_mastercard,cc_tech_society,gs_tech_ai,neg_capitalone,ggl_wrk_collab,cc_tech_data,gs_busfin_business,gs_busfin,neg_rms,gs_tech_compute,cc_business_lead_boards,neg_chanel,gs_tech_computing,gs_busfin_business_large,neg_gg2,neg_chan2,neg_debeer,neg_hms,neg_mtb,gs_entertain,gs_t","__typename":"AdTargetingParam"},{"key":"tt","value":"22,93","__typename":"AdTargetingParam"},{"key":"mt","value":"MT10,MT7","__typename":"AdTargetingParam"}],"sourceId":"100000009406898","type":"article","wordCount":396,"bylines":[{"creators":[{"id":"UGVyc29uOm55dDovL3BlcnNvbi9kZGNhNzE2NS1kMDBlLTUwOTAtYWFlNS03N2VjOThmMjc0Y2I=","displayName":"‘The Ezra Klein Show’","__typename":"Person","url":"https:\u002F\u002Fwww.nytimes.com\u002Fby\u002Fthe-ezra-klein-show","bioUrl":"https:\u002F\u002Fwww.nytimes.com\u002Fby\u002Fthe-ezra-klein-show","contactDetails":{"socialMedia":[],"__typename":"ContactDetails"},"legacyData":{"htmlShortBiography":"","__typename":"PersonLegacyData"}}],"__typename":"Byline","renderedRepresentation":"By ‘The Ezra Klein Show’","creatorSnapshots":[{"uri":"nyt:\u002F\u002Fperson\u002Fddca7165-d00e-5090-aae5-77ec98f274cb","__typename":"PersonSnapshot"}]}],"displayProperties":{"fullBleedDisplayStyle":"","__typename":"CreativeWorkDisplayProperties","serveAsNyt4":false},"typeOfMaterials":["Op-Ed"],"timesTags":[{"__typename":"Subject","vernacular":"audio-neutral-inquisitive","isAdvertisingBrandSensitive":false,"displayName":"audio-neutral-informative","uri":"nyt:\u002F\u002Fsubject\u002F5fb9f685-9bbf-5d17-8b27-8cdbf01fd905","associatedLegacyCollections":[]},{"__typename":"Subject","vernacular":"Computers and the Internet,Tech Industry","isAdvertisingBrandSensitive":false,"displayName":"Computers and the Internet","uri":"nyt:\u002F\u002Fsubject\u002F2c3042b2-528f-540f-a4cc-d9ca3e8194fa","associatedLegacyCollections":[]},{"__typename":"Organization","vernacular":"Anthropic","isAdvertisingBrandSensitive":false,"displayName":"Anthropic AI LLC","uri":"nyt:\u002F\u002Forganization\u002F47762e50-d4cd-5336-b8f6-9ea523e58689","associatedLegacyCollections":[]},{"__typename":"Organization","vernacular":"OpenAI","isAdvertisingBrandSensitive":false,"displayName":"OpenAI Labs","uri":"nyt:\u002F\u002Forganization\u002F2c58e9cf-b168-5dad-824c-f334c9d338fa","associatedLegacyCollections":[]},{"__typename":"Person","vernacular":"Dario Amodei","isAdvertisingBrandSensitive":false,"displayName":"Amodei, Dario","uri":"nyt:\u002F\u002Fperson\u002Ff8bc99c5-14d1-5476-a888-a5f0fb188037","associatedLegacyCollections":[]}],"language":{"code":"en","__typename":"Language","name":"English"},"desk":"OpEd","kicker":"","headline":{"default":"What if Dario Amodei Is Right About A.I.?","__typename":"CreativeWorkHeadline","seo":""},"commentProperties":{"status":"ACCEPT_AND_DISPLAY_COMMENTS","__typename":"CreativeWorkCommentProperties","prompt":"","approvedCommentsCount":27},"firstPublished":"2024-04-12T09:03:56.000Z","lastModified":"2024-04-18T18:38:05.570Z","originalDesk":"OpEd","source":{"id":"T3JnYW5pemF0aW9uOm55dDovL29yZ2FuaXphdGlvbi9jMjc5MTM4OC02YjE2LTVmZmQtYTExOS05NmVhY2IxOTg5YzE=","displayName":"New York Times","__typename":"Organization"},"printInformation":{"page":"","section":"","publicationDate":null,"__typename":"PrintInformation","edition":"The New York Times on the Web","headline":""},"sprinkled":{"configs":[{"name":"mobile","stride":4,"threshold":3,"__typename":"SprinkledConfig"},{"name":"desktop","stride":7,"threshold":3,"__typename":"SprinkledConfig"},{"name":"mobileHoldout","stride":4,"threshold":2,"__typename":"SprinkledConfig"},{"name":"desktopHoldout","stride":5,"threshold":3,"__typename":"SprinkledConfig"},{"name":"hybrid","stride":4,"threshold":3,"__typename":"SprinkledConfig"}],"__typename":"SprinkledContent"},"column":{"id":"TGVnYWN5Q29sbGVjdGlvbjpueXQ6Ly9sZWdhY3ljb2xsZWN0aW9uL2ZkMzY0ZGJlLWMwZTMtNTQ1MC04NTU2LTYyZmVmMGY2ODIzYw==","slug":"ezra-klein-podcast","__typename":"LegacyCollection","url":"https:\u002F\u002Fwww.nytimes.com\u002Fcolumn\u002Fezra-klein-podcast","tagline":"Real conversations. Ideas that matter. So many book recommendations.","name":"The Ezra Klein Show","assets":{"pageInfo":{"hasNextPage":true,"hasPreviousPage":false,"startCursor":"YXJyYXljb25uZWN0aW9uOjA=","endCursor":"YXJyYXljb25uZWN0aW9uOjEx","__typename":"PageInfo"},"__typename":"AssetsConnection","edges":[{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlLzFlNTg0YzgyLWJmZWMtNTJiMS1hMzlhLTgzZTA3MzlhNTk5Yg==","headline":{"subHeadline":"","seo":"","default":"Cows Are Just an Environmental Disaster","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vYzRkZDdhZjEtZDM0YS01Yjk2LWFhZjMtMWIyNjE0MTk0OTUx","length":3780,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F04\u002F30\u002Fopinion\u002Fezra-klein-podcast-hannah-ritchie.html","firstPublished":"2024-04-30T09:03:45.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvODkzOTMwNzgtODRlOS01MmUwLWJiMjUtMmFmMzZmNTk4YzA5","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F05\u002F01\u002Fopinion\u002F30eks-ritchie-image\u002F30eks-ritchie-image-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlL2JmMjAzOTE1LTE0YTEtNTlkNS1iZjhhLTZiY2Q0YTNhMGRjZg==","headline":{"subHeadline":"","seo":"","default":"Salman Rushdie Is Not Who You Think He Is","__typename":"CreativeWorkHeadline"},"body":{"content":[{"__typename":"HeaderFullBleedVerticalBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F04\u002F26\u002Fopinion\u002Fezra-klein-podcast-salman-rushdie.html","firstPublished":"2024-04-26T09:03:56.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvMGJiNTc4NTUtMzU2Zi01MDZmLThjMjgtMjEzMjFhNGIyMDFi","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F28\u002Fmultimedia\u002F26eks-rushdie-wpzb\u002F26eks-rushdie-wpzb-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlLzcwYTMzMjIxLWZkNmItNTAyMS1hZDhiLWFjOWEyYWJhOTU2YQ==","headline":{"subHeadline":"","seo":"","default":"This Conversation Made Me a Sharper Editor","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vMzEwNmUwYjYtYmEyMi01YjNhLWIyM2YtZTI2N2JkMzI0OTVk","length":3366,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F04\u002F23\u002Fopinion\u002Fezra-klein-podcast-adam-moss.html","firstPublished":"2024-04-23T09:03:48.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvODBhMzI3MDEtYjEwZi01ZGVkLTkzNjEtNjdiNDMxMDljZjdk","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F23\u002Fopinion\u002F23eks-moss-image\u002F19eks-moss-image-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlL2Q2MjZkYmQwLWE2NmQtNWFjZS1iYjZkLWI2NmI1NzE0MWZjZA==","headline":{"subHeadline":"","seo":"Why It’s So Hard to Build in Liberal States","default":"A $1.7 Million Toilet and Liberalism’s Failure to Build","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vMmVhMzA2MGYtMjEzYi01YTY5LWJiOWEtMDcyMzYxYjhkZWUx","length":2957,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F04\u002F16\u002Fopinion\u002Fezra-klein-podcast-jerusalem-demsas.html","firstPublished":"2024-04-16T09:03:25.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvOGM2MTNjNmItMTVlYy01ZDUyLThiMGYtY2E2YWZiNDIyNzYx","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2023\u002F07\u002F18\u002Fopinion\u002F18eks-demsas-image\u002F18eks-demsas-image-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlL2FlMTMwMDAzLWYxYzctNWVmMi04OTY3LWMyMWZlYmVjNTY0ZQ==","headline":{"subHeadline":"","seo":"","default":"What if Dario Amodei Is Right About A.I.?","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vNmYwZDM0MjUtYzIwNC01NWY0LWEzY2UtYTNmYjc4MGFkNWIy","length":5587,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F04\u002F12\u002Fopinion\u002Fezra-klein-podcast-dario-amodei.html","firstPublished":"2024-04-12T09:03:56.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvODVkYWNkOWQtMzYzNC01MDBkLTk2Y2EtMGY5Yjc2N2E0ZDk5","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlLzVlMWNmOTQ1LWZiNGUtNTI4My1hNTU5LTc4N2U0YjQ3ODBlZg==","headline":{"subHeadline":"","seo":"","default":"Will A.I. Break the Internet? Or Save It?","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vYzNkZDdhOWYtY2ExMy01YWRjLWFlN2ItODJiYjY0ODVhNTE3","length":5133,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F04\u002F05\u002Fopinion\u002Fezra-klein-podcast-nilay-patel.html","firstPublished":"2024-04-05T09:03:55.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvZTE5YzFmYzUtNTg2MC01OTExLWE3OTgtY2Q3NGU3YTgwN2Yz","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F05\u002Fopinion\u002F05eks-patel-image\u002F05eks-patel-image-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlLzllYzg5ZDBjLTQzNmEtNWU5OS1iNzU0LTYzNzk2NDkyY2E4YQ==","headline":{"subHeadline":"","seo":"","default":"How Should I Be Using A.I. Right Now?","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vMzhiNjg4YmEtOTYyOS01MjZkLWFhOWUtMjI2MmFhMTU1NjYw","length":4471,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F04\u002F02\u002Fopinion\u002Fezra-klein-podcast-ethan-mollick.html","firstPublished":"2024-04-02T09:04:12.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvOTQxMDE4MzctYjE1MS01MmIxLWI4NWQtMTM1MjI1ZmIxMjdi","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F02\u002Fopinion\u002F02eks-mollick-image\u002F02eks-mollick-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlLzBhMTViMDRkLWVkM2EtNTYwNi1iNmY5LTUyOTIxM2Q1NzQzZA==","headline":{"subHeadline":"","seo":"","default":"The Rise of ‘Middle-Finger Politics’","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vY2E1MzY3YWMtYjQzMy01NzkwLWIwNjItYzY5YjJmOWQ3NTM3","length":4710,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F03\u002F29\u002Fopinion\u002Fezra-klein-podcast-john-ganz.html","firstPublished":"2024-03-29T09:02:56.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvNTcyNzVhMTItNzYyMS01ZWQ4LThhNjYtNWJmZTVkYzFkYTE5","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F03\u002F29\u002Fopinion\u002F29eks-ganz-image\u002F29eks-ganz-image-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlLzIzNjEwNDJkLTZiNGEtNTZmOS04MGI4LTNkNTI2MWU5ODE3MQ==","headline":{"subHeadline":"","seo":"","default":"The Deep Conflict Between Our Work and Parenting Ideals","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vODFhZDlkNmEtNjJlZS01ZTFkLWI4NmMtYWE3NThkZWE0MjFl","length":4112,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F03\u002F22\u002Fopinion\u002Fezra-klein-podcast-caitlyn-collins.html","firstPublished":"2024-03-22T09:05:06.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvYzNmZDJlNWItODBiOS01YTk5LTk3MzAtOTQ0NGJkYTE2M2E5","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F03\u002F22\u002Fopinion\u002F22eks-collins-image\u002F22eks-collins-image-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlL2NkNGI2M2MzLWI1Y2UtNWNmNi1hNjE4LTZhNWY1OTQzNTQ4OQ==","headline":{"subHeadline":"","seo":"","default":"Birthrates Are Plummeting Worldwide. Why?","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vM2ZjMGIxZDctNDJkYS01MTc4LWE0Y2MtNmU2NDUzMGRiZmQ4","length":3791,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F03\u002F19\u002Fopinion\u002Fezra-klein-podcast-jennifer-sciubba.html","firstPublished":"2024-03-19T09:04:34.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvNTBiNWM5MzEtYzgzYi01NDE0LWE1YTktNzcyMTU2NDQzMTEx","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F03\u002F19\u002Fopinion\u002F19eks-sciubba-image\u002F19eks-sciubba-image-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlL2I1YTY4OTdiLWYxMmItNTQ2OC1hZGQ4LWNmNjU0NmE0NTM3Mg==","headline":{"subHeadline":"","seo":"What a Second Joe Biden Term Would Look Like","default":"What a Second Biden Term Would Look Like","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vMTBiODc1MGUtZWMyZS01NzIwLTg2YzYtNzQ1ODA0MjFiYTlh","length":3832,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F03\u002F12\u002Fopinion\u002Fezra-klein-podcast-sotu.html","firstPublished":"2024-03-12T09:05:12.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvOWJjYTJiNmQtYzUxOS01YThhLWFkMzQtYmE0N2Y2NDYxNGRh","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F03\u002F12\u002Fopinion\u002F12eks-sotu-image\u002F12eks-sotu-image-thumbLarge-v2.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"},{"node":{"id":"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlLzY1ODJjYjA3LWZlNmMtNWRjMy05M2ZkLTcwYzRkYjM0NWIyYQ==","headline":{"subHeadline":"","seo":"","default":"How America’s Two Abortion Realities Are Clashing","__typename":"CreativeWorkHeadline"},"body":{"content":[{"media":{"media":{"id":"QXVkaW86bnl0Oi8vYXVkaW8vZDcxYjA5YjgtOTUxOC01NzIxLWFkNmYtZGIwZmQyMGM0N2Iy","length":3640,"__typename":"Audio"},"__typename":"AudioBlock"},"__typename":"HeaderMultimediaBlock"}],"__typename":"DocumentBlock"},"episodeProperties":{"episodeLabel":"","__typename":"ArticleEpisodeProperties"},"url":"https:\u002F\u002Fwww.nytimes.com\u002F2024\u002F03\u002F08\u002Fopinion\u002Fezra-klein-podcast-mary-ziegler.html","firstPublished":"2024-03-08T10:03:23.000Z","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvZGYxNjcwZjktZjI3Mi01ODNlLTlhOWEtODczZTljZjFmOTg4","crops":[{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F03\u002F08\u002Fopinion\u002F08eks-ziegler-image\u002F08eks-ziegler-image-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"__typename":"Image"},"__typename":"Article"},"__typename":"AssetsEdge"}]}},"dfpTaxonomyException":null,"associatedNewsletter":null,"advertisingProperties":{"sensitivity":"SHOW_ADS","__typename":"CreativeWorkAdvertisingProperties"},"translations":[],"summary":"Anthropic’s co-founder and C.E.O. explains why he thinks artificial intelligence is on an “exponential curve.”","lastMajorModification":"2024-04-12T20:18:20.000Z","uri":"nyt:\u002F\u002Farticle\u002Fae130003-f1c7-5ef2-8967-c21febec564e","eventId":"pubp:\u002F\u002Fevent\u002Fba90cf72033747649801f20fecf07e7f","promotionalMedia":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvODVkYWNkOWQtMzYzNC01MDBkLTk2Y2EtMGY5Yjc2N2E0ZDk5","assetCrops":[{"name":"MASTER","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-articleLarge.jpg","height":400,"width":600,"name":"articleLarge","__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-superJumbo.jpg","height":1365,"width":2048,"name":"superJumbo","__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"name":"SMALL_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-thumbStandard.jpg","height":75,"width":75,"name":"thumbStandard","__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-thumbLarge.jpg","height":150,"width":150,"name":"thumbLarge","__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"name":"MEDIUM_SQUARE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-mediumSquareAt3X.jpg","height":1800,"width":1800,"name":"mediumSquareAt3X","__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"name":"SIXTEEN_BY_NINE","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-videoSixteenByNine3000.jpg","height":1687,"width":3000,"name":"videoSixteenByNine3000","__typename":"ImageRendition"},{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-videoSixteenByNineJumbo1600.jpg","height":900,"width":1600,"name":"videoSixteenByNineJumbo1600","__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"name":"FACEBOOK","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-facebookJumbo.jpg","height":550,"width":1050,"name":"facebookJumbo","__typename":"ImageRendition"}],"__typename":"ImageCrop"},{"name":"GOOGLE_4_BY_3","renditions":[{"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-googleFourByThree.jpg","height":600,"width":800,"name":"googleFourByThree","__typename":"ImageRendition"}],"__typename":"ImageCrop"}],"credit":"Illustration by The New York Times; photograph by Dario Amodei","caption":{"text":"","__typename":"TextOnlyDocumentBlock"},"__typename":"Image"},"promotionalImage":{"socialMediaRendition":{"parentPublishDate":"2024-04-12T09:03:56.000Z","parentPublishYear":2024,"signature":{"value":"0400eeb623c60bc6e2e39a61b0f86895176ff1c1a31bac6dc426179f19fe2ca2","keyId":"ZQJBKqZ0VN","__typename":"ImageSignature"},"rendition":{"name":"facebookJumbo","height":550,"width":1050,"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-facebookJumbo.jpg","__typename":"ImageRendition"},"__typename":"SignableImageRendition"},"twitterRendition":{"parentPublishDate":"2024-04-12T09:03:56.000Z","parentPublishYear":2024,"signature":{"value":"6249f6f8a328ddc831805aa1a47edc9a9368233cbf0a2aff168fcd911eacc931","keyId":"ZQJBKqZ0VN","__typename":"ImageSignature"},"rendition":{"name":"videoSixteenByNine3000","height":1687,"width":3000,"url":"https:\u002F\u002Fstatic01.nyt.com\u002Fimages\u002F2024\u002F04\u002F12\u002Fopinion\u002F12eks-amodei-image\u002F12eks-amodei-image-videoSixteenByNine3000.jpg","__typename":"ImageRendition"},"__typename":"SignableImageRendition"},"image":{"id":"SW1hZ2U6bnl0Oi8vaW1hZ2UvODVkYWNkOWQtMzYzNC01MDBkLTk2Y2EtMGY5Yjc2N2E0ZDk5","credit":"Illustration by The New York Times; photograph by Dario Amodei","caption":{"text":"","__typename":"TextOnlyDocumentBlock"},"__typename":"Image"},"__typename":"PromotionalImage"},"slug":"12eks-amodei","newsStatus":"DEFAULT","sourcePublisher":"scoop","episodeProperties":{"episodeLabel":"","linksLeadIn":"","links":[],"__typename":"ArticleEpisodeProperties"},"reviewSummary":"","reviewItems":[],"curatedAssetComments":null,"featuredAudio":null,"storylines":[],"associatedAssets":[{"region":"MAIN_CONTENT_1","assetName":"opinion-today-email-signup","ruleName":"maps-opinion-today-email-signup","testName":"","parentTest":"","asset":{"__typename":"Capsule","uri":"nyt:\u002F\u002Fcapsule\u002F67c172b3-d2a8-5d7f-8177-c85ce6a5c59b"},"__typename":"AssociatedArticleAssetBlock"}],"legacy":{"reviewInformation":"","__typename":"ArticleLegacyData","htmlExtendedAuthorOrArticleInformation":"","htmlInfoBox":""},"addendums":[]}}},"initialState":{},"config":{"gqlUrlClient":"https:\u002F\u002Fsamizdat-graphql.nytimes.com\u002Fgraphql\u002Fv2","gqlRequestHeaders":{"nyt-app-type":"project-vi","nyt-app-version":"0.0.5","nyt-token":"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs+\u002FoUCTBmD\u002FcLdmcecrnBMHiU\u002FpxQCn2DDyaPKUOXxi4p0uUSZQzsuq1pJ1m5z1i0YGPd1U1OeGHAChWtqoxC7bFMCXcwnE1oyui9G1uobgpm1GdhtwkR7ta7akVTcsF8zxiXx7DNXIPd2nIJFH83rmkZueKrC4JVaNzjvD+Z03piLn5bHWU6+w+rA+kyJtGgZNTXKyPh6EC6o5N+rknNMG5+CdTq35p8f99WjFawSvYgP9V64kgckbTbtdJ6YhVP58TnuYgr12urtwnIqWP9KSJ1e5vmgf3tunMqWNm6+AnsqNj8mCLdCuc5cEB74CwUeQcP2HQQmbCddBy2y0mEwIDAQAB","x-nyt-internal-meter-override":undefined},"gqlFetchTimeout":1500,"disablePersistedQueries":false,"initialDeviceType":"smartphone","fastlyAbraConfig":{".ver":"18076.000","AMS_FrictionCircumventionDesktop_cwv":"2_low-mid-truncation","AMS_FrictionCircumventionMobile_cwv":"2_low-mid-truncation","DFP_TopAd_Anon_0124":"","HOME_cwv_chartbeat":"0_Control","MX_NewArchitecture_PostLoginOffer":"1_variant","MX_NewArchitecture_WirecutterLP":"","STYLN_synth_voice_web":"0_control"},"fastlyEntitlements":[],"internalPreviewConfig":{"meter":undefined,"swg":undefined},"webviewEnvironment":{"isInWebview":false,"isPreloaded":false},"isOptimisticallyTruncated":false,"optimisticTruncationDropzone":6,"requestPath":"\u002F2024\u002F04\u002F12\u002Fopinion\u002Fezra-klein-podcast-dario-amodei.html","isProvisionallyLoggedIn":false,"serviceWorkerFile":"service-worker-test-1715027876176.js"},"ssrQuery":{},"initialLocation":{"pathname":"\u002F2024\u002F04\u002F12\u002Fopinion\u002Fezra-klein-podcast-dario-amodei.html","search":""}};</script>
    
    
    
    
    <script>!function(){try{var e="undefined"!=typeof window?window:"undefined"!=typeof global?global:"undefined"!=typeof self?self:{},a=(new Error).stack;a&&(e._sentryDebugIds=e._sentryDebugIds||{},e._sentryDebugIds[a]="04df2b4c-1639-48df-8bfe-ee526ebedfe3",e._sentryDebugIdIdentifier="sentry-dbid-04df2b4c-1639-48df-8bfe-ee526ebedfe3")}catch(e){}}();var _global="undefined"!=typeof window?window:"undefined"!=typeof global?global:"undefined"!=typeof self?self:{};_global.SENTRY_RELEASE={id:"fda3c1704e92bc29a9545d08be2eec92a5050bf5"},function(e){function a(a){for(var c,r,b=a[0],f=a[1],s=a[2],i=0,l=[];i<b.length;i++)r=b[i],Object.prototype.hasOwnProperty.call(n,r)&&n[r]&&l.push(n[r][0]),n[r]=0;for(c in f)Object.prototype.hasOwnProperty.call(f,c)&&(e[c]=f[c]);for(t&&t(a);l.length;)l.shift()();return o.push.apply(o,s||[]),d()}function d(){for(var e,a=0;a<o.length;a++){for(var d=o[a],c=!0,b=1;b<d.length;b++){var f=d[b];0!==n[f]&&(c=!1)}c&&(o.splice(a--,1),e=r(r.s=d[0]))}return e}var c={},n={139:0},o=[];function r(a){if(c[a])return c[a].exports;var d=c[a]={i:a,l:!1,exports:{}};return e[a].call(d.exports,d,d.exports,r),d.l=!0,d.exports}r.e=function(e){var a=[],d=n[e];if(0!==d)if(d)a.push(d[2]);else{var c=new Promise((function(a,c){d=n[e]=[a,c]}));a.push(d[2]=c);var o,b=document.createElement("script");b.charset="utf-8",b.timeout=120,r.nc&&b.setAttribute("nonce",r.nc),b.src=function(e){return r.p+""+({0:"vendor",1:"vendors~allAccessLandingPage~audio~bestsellers~card~collections~cookingAppDownloadLandingPage~cookin~dca93260",2:"vendors~accessCodeLPAllAccess~accessCodeLPCooking~accessCodeLPGames~accessCodeLPHyundaicard~accessCo~670a1007",3:"vendors~account~byline~capsule~clientSideCapsule~collections~explainer~getstarted~liveAsset~newslett~0c93273d",5:"vendors~audio~bestsellers~card~collections~explainer~home~liveAsset~markets~paidpost~reviews~search~~b0abd9a2",6:"vendors~audio~byline~capsule~card~clientSideCapsule~paidpost~slideshow~video~wellContent",7:"vendors~accessCodeLPAllAccess~accessCodeLPCooking~accessCodeLPGames~accessCodeLPHyundaicard~accessCo~58a91663",8:"vendors~accessCodeLPAllAccess~accessCodeLPCooking~accessCodeLPGames~accessCodeLPHyundaicard~accessCo~589595ba",9:"vendors~getstarted~newsletter~newsletters~newsletterssubscriberonly~recirculation~welcomesubscriber~~a6f3c374",10:"vendors~allAccessLandingPage~cookingLandingPage~gamesLandingPage~giftLandingPage~hyundaiCardLandingP~e37d8a9f",11:"account~activateaccess~newslettersmanage~newslettersoptout~newslettersreengagement",12:"vendors~allAccessLandingPage~cookingLandingPage~gamesLandingPage~homeDeliveryLandingPage~hyundaiCard~89dad681",13:"vendors~byline~capsule~clientSideCapsule~home~trending",14:"markets~reviews~timeswire~your-list",15:"newsletter~newsletters~newsletterssubscriberonly~your-places-global-update",16:"vendors~gamesGiftLandingPage~giftLandingPage~hyundaiCardLandingPage",17:"vendors~giftArticles~timeswire~your-list",19:"emailsignup~your-space",20:"giftArticles~subRecircBottomSheet",21:"vendors~CardDeck~carddeck",22:"vendors~account~newslettersoptout",23:"vendors~explainerRecirculation~liveRecirculation",24:"vendors~gamesOnboardingOfferLandingPage~newsOnboardingOfferLandingPage",25:"vendors~getstarted~welcomesubscriber",26:"vendors~groupsHigherEdLandingPage~groupsLandingPage",31:"CardDeck",32:"ChineseHanLogo",33:"DealbookLogo",34:"InsiderLogo",35:"NYTCommunitiesFundHeader",36:"Rio2016",37:"SportsFromTheAthleticLogo",38:"TMagazineLogo",39:"UpshotLogo",40:"WorldCupLogo2018",41:"accessCodeLPAllAccess",42:"accessCodeLPCooking",43:"accessCodeLPGames",44:"accessCodeLPHyundaicard",45:"accessCodeLPNews",46:"accessCodeLPNexo",47:"accessCodeLPWirecutter",48:"account",49:"activateaccess",50:"additionalPlaylists",52:"allAccessLandingPage",53:"ask",54:"audio",55:"audioApp",56:"audioblock",57:"autoSave",58:"bestsellers",59:"blank",60:"book-review",61:"brandLandingPage",62:"byline",63:"caHamburgerNestedNavData",64:"canadaHamburgerNavData",65:"canadaSiteIndexData",66:"capsule",67:"card",68:"carddeckadslot",69:"clientSideCapsule",70:"collectionnewsletterform",71:"collections",72:"comments",73:"commentsForm",74:"cookingAppDownloadLandingPage",75:"cookingLandingPage",76:"datasubjectrequest",77:"datasubjectrequestverification",78:"dealbook",79:"defaultHamburgerNavData",80:"defaultSiteIndexData",81:"desktopLogoNav",82:"desktopNav",83:"emailsignup",84:"episodefooter",85:"explainer",86:"explainerPostHeader",87:"explainerRecirculation",88:"featuredproperties",89:"foo",90:"gamesGiftLandingPage",91:"gamesLandingPage",92:"gamesOnboardingOfferLandingPage",93:"gatewayLandingPage",94:"getstarted",95:"giftArticles",96:"giftLandingPage",97:"groupsHigherEdLandingPage",98:"groupsLandingPage",99:"hamburgerDrawer",100:"headerfullbleedhorizontal",101:"headerfullbleedvertical",102:"headerlivebriefingvi",103:"home",104:"homeDeliveryLandingPage",105:"hyundaiCardLandingPage",107:"internationalHamburgerNavData",108:"internationalHamburgerNestedNavData",109:"internationalSiteIndexData",110:"lens",111:"liveAsset",112:"livePostHeader",113:"liveRecirculation",114:"lottieJSON",116:"markets",117:"mortgagecalculator",118:"nestedNav",119:"newsAppLandingPage",120:"newsOnboardingOfferLandingPage",121:"newsletter",122:"newsletterRecirculation",123:"newsletters",124:"newslettersmanage",125:"newslettersoptout",126:"newslettersreengagement",127:"newsletterssubscriberonly",128:"opinion",129:"paidpost",130:"privacy",131:"producernotes",132:"query-and-select",133:"recirculation",134:"related-coverage-chunk",135:"reviewheader",136:"reviews",140:"search",141:"siteIndexContent",142:"sitemap",143:"slideshow",144:"slideshowinline",145:"stickyfilljs",146:"story",147:"subRecircBottomSheet",148:"subscribeWithGoogleLP",149:"surveywithdrawconsent",150:"timeswire",151:"trending",152:"upshot",153:"usHamburgerNestedNavData",154:"vanity",156:"vendors~audioblock",157:"vendors~bestsellers",158:"vendors~carddeck",159:"vendors~charlatan-select",160:"vendors~commentsForm",161:"vendors~cookingAppDownloadLandingPage",162:"vendors~emailsignup",163:"vendors~episodefooter",164:"vendors~gamesGiftLandingPage",165:"vendors~gatewayLandingPage",166:"vendors~giftArticles",167:"vendors~headerfullbleedhorizontal",168:"vendors~headerfullbleedvertical",169:"vendors~homeDeliveryLandingPage",170:"vendors~mortgagecalculator",171:"vendors~newsAppLandingPage",172:"vendors~producernotes",173:"vendors~recirculation",174:"vendors~reviewheader",175:"vendors~search",176:"vendors~slideshowinline",177:"vendors~subscribeWithGoogleLP",178:"vendors~videoblock",179:"vendors~wellContent",180:"video",181:"videoblock",182:"welcomeBannerRegi",183:"welcomeBannerSubs",184:"welcomesubscriber",185:"wellContent",186:"wirecutterLandingPage",187:"world-cup-2019",188:"your-list",189:"your-places-global-update",190:"your-space"}[e]||e)+"-"+{0:"7c2097fe0266d898a1c1",1:"60e0f802d5e7593a90a2",2:"8b7abaf26d577778eeea",3:"f104ba814112712f8f74",4:"53c4544dad16df65a2fe",5:"049175180d0aa37b786f",6:"363fcda24937fef7d3bd",7:"4c5b3c7a8f0e47707cf8",8:"95075ad064bd97501e59",9:"ecf11f3d788c12dd0bfc",10:"f217aa88021728fb8a3d",11:"9e247ed2f662f94c1b86",12:"0f4d3d9ee9ac99dd3aed",13:"949b024280b57b33d919",14:"01c42e441e7ccb2c9a62",15:"33827f647cbd73301551",16:"b52af4a9d978d68c8f9e",17:"76d4cf45525af32a9562",18:"d222fd9b1d14bc04ddd5",19:"2948e415fc3c5cdec079",20:"0526220eb5583ec06bd0",21:"9d20a99346cf0bc67864",22:"450b30f533175a6c079a",23:"bc21abbdb4d2db4d0f75",24:"ff672e2d24a95d4be651",25:"753f10ff7e7b6b5b9ee6",26:"220835ae0d74c313a972",27:"5c29e4999a0d8de132c1",28:"2e35d0bfe73c9892b7cb",29:"47cad46ebb44c00e785d",30:"7e22b53846a3bc9376b9",31:"f5bf48cfbaaf90eb92b8",32:"05c530fcaac8d36915f9",33:"9f9b742b42a07a1c4d80",34:"7352e6e8dd106dc431dc",35:"613218b6aec307d831df",36:"1c371f1d44d36cff5e1a",37:"59faca002475b173f6ad",38:"a685fd7e1c42a7b6a0bc",39:"209cd5e9021dacdea4f9",40:"cdcea20188d9664eaaf0",41:"bc60c146d99111108d5e",42:"e33ee504f4b96aa7efd6",43:"523b244f1bae0b065c81",44:"b795f1d957c456b61822",45:"31b4d71def9f0ee75649",46:"edaaa09f06ba48f6775c",47:"2267576e8ff24c7af6f7",48:"5bc396425401efa33fc0",49:"931b33682bb2cd67243c",50:"de674e77ea6c6290e6e8",52:"e74fd73edadd7038d1f2",53:"82b0a40d99ce31659555",54:"a03a17df47b037ba986a",55:"0f95e800bbda74b8f998",56:"55da77601697824fde74",57:"1450d4fa6bf0cc55de7a",58:"b1fd01106bf87a28ca75",59:"f3efe5ace9e00f74f642",60:"1b7b049a9aeba0842ff2",61:"2516a0d4ba81c6f3ed11",62:"1d7f4bfb4265d342e10b",63:"97cdbaafd432bdefa25b",64:"4e9381d539a79ea88d5f",65:"6196803173269417d16c",66:"640833ba48ba843aa70f",67:"fc779f007d0399bfa9e7",68:"a97ea07968cd6ebaceb4",69:"24e039d8d37c01a6c126",70:"c05c736a98d562f0bfc7",71:"222fb470c627b6494916",72:"9d2e6b1e7ee7c79b20d2",73:"6766eb8015437c34c45b",74:"7aed977d1667b139a915",75:"bf5539459cc816774015",76:"376af993639fcb2c48cb",77:"e029486fbc51efece498",78:"f11e4a13a3cad0753528",79:"4e84526b5125aa2cde67",80:"f6d8d4ff74226ecda9b2",81:"6d41a90c4e05f59c07ce",82:"e94efb95a78250e2de5d",83:"83a6f0c5c819bddc943a",84:"f5f359b65f72da9b8404",85:"63bb0baa31fc6811f8e5",86:"425d9a2405e9ba6c8742",87:"8397ee9d5f27cdaf8de2",88:"1397b979a6a71385a927",89:"957230b40e1eaeed8f3e",90:"6bc1c2ee5de33842c598",91:"d95bdaebecd686e096d9",92:"9a77b90e971d54d21312",93:"aa8484086bc6335f898e",94:"48afbd7a050c2ee4c28e",95:"d77cca61ff35f0b46155",96:"65f61a12c112d9d7a36c",97:"6b509336d1b6f9082f34",98:"02663325a9c3ee4496a9",99:"f20b1bad6e8049d11147",100:"0b2d2ca37a50b846a1ed",101:"3dd612b7f39def08cd6a",102:"815a8e8b2221ec5a0a6a",103:"f94edeb1f685a4c38f51",104:"36e831ed40ba95373d4e",105:"58d408a443c85be6ef2f",107:"8348f68b80224394088b",108:"314c8e73d0cad3bc8cfb",109:"2b42cd4643920cb5b370",110:"c69d4856522c9efd4ed6",111:"0c26cfe27fa629c08844",112:"226a06ea86255b053299",113:"da1a653739e0e8bf5af5",114:"4062ed5c10ecf52c9ab2",116:"b7cc0e3db2abf752e829",117:"d5ea253158ec64b038ee",118:"28c421b9119645b039a0",119:"22a342b64fe2203884b1",120:"af82657bff56755e8b3a",121:"aa63d06fb01bf3f1ef08",122:"a59951bcb2c92faf4780",123:"57b3880cc5b85f80a1ea",124:"5ffa4bc1279353ea580f",125:"f8a3ce36d1204105bba9",126:"40b9da6d7573513f24c5",127:"49878ee4649f17705bc5",128:"4f9dcf21aa29b026c842",129:"d51f362af8fe68daded8",130:"3208ec1ae5502ee1772a",131:"def79b65e86ac2be6eab",132:"7538aa964842f61e6fa3",133:"95614e5f197d716bb771",134:"82d176e4553e71647122",135:"ec70677baf645b4c1425",136:"d095689793b52b981bf9",140:"bc4767ad903dda066e9c",141:"b00956a07ade6269aad6",142:"65593be1940cf7e9f7c1",143:"16e5275648a0c3da2713",144:"e73a49509126635e9e5d",145:"d72bc827fbd7eaa55ed0",146:"6d460cb6407b13d75752",147:"ef58d454d2f05a9763f4",148:"559cad159ec02ccd6065",149:"494b56a79c7e68d9fbe2",150:"50c1a869923ecd82beba",151:"e5262814b11a2db04000",152:"d5757a437939f7c38823",153:"ec9c3b8eb1fbcd28eafb",154:"e37ea8f9c89fbad5d461",156:"99039acd87c191c5d7f4",157:"69ef414f4cd0b5158184",158:"184b4b3083733258efcd",159:"77a27a3dfe412a60f625",160:"e2c4a1fedc03eec1b435",161:"510fe1c825649d394fbe",162:"ee9acdb8ea455c9b2f43",163:"de9cc60b8de71b1801b7",164:"1cf5b25820445d4c8794",165:"5a1ba8ad9e92f4485b03",166:"6c317444bb135cf72bb8",167:"a67162d497c97ae21638",168:"35e91395ed984ea97a6e",169:"658e503d6d572b7db620",170:"d6ace80c5e697b377786",171:"99cf22113f1494ff3adb",172:"63458b86061ec62b6ed1",173:"d33d120379e0ffc4fd97",174:"de6df8e19a0b5c6a388d",175:"6170b7b8714706ef9a82",176:"dd93d9ef2f7d543bfe4a",177:"627c5f2b64a956ff7ada",178:"7b9086577255fab87332",179:"b2ffea57eb43bc9c3791",180:"ef92456c545119d455ec",181:"e096286923be1eb91d6e",182:"d5852d6b114137b4dea3",183:"23516dc9c40fe8f24f51",184:"46468b8d4c61aa850593",185:"52613feb34bd96ba26c7",186:"e020c87ccd9d063fa1bb",187:"614533f5da17e88829d0",188:"9c4df3c14127f0ba2ebb",189:"81eae874ab84ac84f177",190:"133b81cf4d740147353a",191:"621b3b95472155db1967",192:"8a1830da1e4738e4a935",193:"69a6ee319c795105c4e6",194:"d1f90c896dd2056e1c6d",195:"7cfc4e6ab257b7544887",196:"bcba2eb581796dbdf05d",197:"ff8890170ed73cf98717",198:"0154b87ce2c6ad502f37",199:"a04a1c1eda76d82c7b61",200:"6098fde3f34fb0e37c77",201:"e009c8a66e8fcb1719df",202:"b6b4139192f036c98e97",203:"35c60b4b1fdebe64d8c8",204:"8222b8014f807bacd07c",205:"486279e12009bb5a1bfb",206:"6d8b6e1e3d3ced25ff5f",207:"46a1ea323ca4b88cf203",208:"39ef7db539f607461599",209:"d1fe60b2a2a9232af30c"}[e]+".js"}(e);var f=new Error;o=function(a){b.onerror=b.onload=null,clearTimeout(s);var d=n[e];if(0!==d){if(d){var c=a&&("load"===a.type?"missing":a.type),o=a&&a.target&&a.target.src;f.message="Loading chunk "+e+" failed.\n("+c+": "+o+")",f.name="ChunkLoadError",f.type=c,f.request=o,d[1](f)}n[e]=void 0}};var s=setTimeout((function(){o({type:"timeout",target:b})}),12e4);b.onerror=b.onload=o,document.head.appendChild(b)}return Promise.all(a)},r.m=e,r.c=c,r.d=function(e,a,d){r.o(e,a)||Object.defineProperty(e,a,{enumerable:!0,get:d})},r.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},r.t=function(e,a){if(1&a&&(e=r(e)),8&a)return e;if(4&a&&"object"==typeof e&&e&&e.__esModule)return e;var d=Object.create(null);if(r.r(d),Object.defineProperty(d,"default",{enumerable:!0,value:e}),2&a&&"string"!=typeof e)for(var c in e)r.d(d,c,function(a){return e[a]}.bind(null,c));return d},r.n=function(e){var a=e&&e.__esModule?function(){return e.default}:function(){return e};return r.d(a,"a",a),a},r.o=function(e,a){return Object.prototype.hasOwnProperty.call(e,a)},r.p="/vi-assets/static-assets/",r.oe=function(e){throw console.error(e),e};var b=window.webpackJsonp=window.webpackJsonp||[],f=b.push.bind(b);b.push=a,b=b.slice();for(var s=0;s<b.length;s++)a(b[s]);var t=f;d()}([]);
//# sourceMappingURL=runtime~main-f869c21a8983b0a7db67.js.map</script>
    <script defer src="/vi-assets/static-assets/vendor-7c2097fe0266d898a1c1.js"></script>
    <script defer src="/vi-assets/static-assets/story-6d460cb6407b13d75752.js"></script>
<script defer src="/vi-assets/static-assets/audioblock-55da77601697824fde74.js"></script>
<script defer src="/vi-assets/static-assets/byline-1d7f4bfb4265d342e10b.js"></script>
<script defer src="/vi-assets/static-assets/capsule-640833ba48ba843aa70f.js"></script>
<script defer src="/vi-assets/static-assets/clientSideCapsule-24e039d8d37c01a6c126.js"></script>
<script defer src="/vi-assets/static-assets/collections-222fb470c627b6494916.js"></script>
<script defer src="/vi-assets/static-assets/explainer-63bb0baa31fc6811f8e5.js"></script>
<script defer src="/vi-assets/static-assets/liveAsset-0c26cfe27fa629c08844.js"></script>
<script defer src="/vi-assets/static-assets/defaultSiteIndexData-f6d8d4ff74226ecda9b2.js"></script>
<script defer src="/vi-assets/static-assets/siteIndexContent-b00956a07ade6269aad6.js"></script>
    <script defer src="/vi-assets/static-assets/main-b07b3dfbd4ea32e1ac9c.js"></script>
    <script>(function () { var _f=function(){try{var e=["first-paint","first-contentful-paint","userBtnRender","appRenderTime"];new window.PerformanceObserver(function(r){for(var n=r.getEntries(),a=0;a<n.length;a+=1){var t=n[a];if(e.indexOf(t.name)>-1){var i={};i[t.name]=Math.round(t.duration||t.startTime),(window.dataLayer=window.dataLayer||[]).push({event:"performance",pageview:{performance:i}})}}}).observe({entryTypes:["mark","measure","paint"]})}catch(e){}};;_f.apply(null, []); })();(function () { var _f=function(){!function(){if(1===Math.floor(20*Math.random())&&(!window.BOOMR||!window.BOOMR.version&&!window.BOOMR.snippetExecuted)){window.BOOMR=window.BOOMR||{},window.BOOMR.snippetStart=(new Date).getTime(),window.BOOMR.snippetExecuted=!0,window.BOOMR.snippetVersion=14,window.BOOMR.url="https://s.go-mpulse.net/boomerang/ATH8A-MAMN8-XPXCH-N5KAX-8D239";var e=(document.currentScript||document.getElementsByTagName("script")[0]).parentNode,n=!1,t=document.createElement("link");t.relList&&"function"==typeof t.relList.supports&&t.relList.supports("preload")&&"as"in t?(window.BOOMR.snippetMethod="p",t.href=window.BOOMR.url,t.rel="preload",t.as="script",t.addEventListener("load",function(){if(!n){var t=document.createElement("script");t.id="boomr-scr-as",t.src=window.BOOMR.url,t.async=!0,e.appendChild(t),n=!0}}),t.addEventListener("error",function(){o(!0)}),setTimeout(function(){n||o(!0)},3e3),BOOMR_lstart=(new Date).getTime(),e.appendChild(t)):o(!1),window.addEventListener?window.addEventListener("load",i,!1):window.attachEvent&&window.attachEvent("onload",i)}function o(t){n=!0;var o,i,d,a,r=document,s=window;if(window.BOOMR.snippetMethod=t?"if":"i",i=function(e,n){var t=r.createElement("script");t.id=n||"boomr-if-as",t.src=window.BOOMR.url,BOOMR_lstart=(new Date).getTime(),(e=e||r.body).appendChild(t)},!window.addEventListener&&window.attachEvent&&navigator.userAgent.match(/MSIE [67]./))return window.BOOMR.snippetMethod="s",void i(e,"boomr-async");(d=document.createElement("IFRAME")).src="about:blank",d.title="",d.role="presentation",d.loading="eager",(a=(d.frameElement||d).style).width=0,a.height=0,a.border=0,a.display="none",e.appendChild(d);try{s=d.contentWindow,r=s.document.open()}catch(e){o=document.domain,d.src="javascript:var d=document.open();d.domain='"+o+"';void 0;",s=d.contentWindow,r=s.document.open()}o?(r._boomrl=function(){this.domain=o,i()},r.write("<body onload='document._boomrl();'>")):(s._boomrl=function(){i()},s.addEventListener?s.addEventListener("load",s._boomrl,!1):s.attachEvent&&s.attachEvent("onload",s._boomrl)),r.close()}function i(e){window.BOOMR_onload=e&&e.timeStamp||(new Date).getTime()}}()};;_f.apply(null, []); })();</script>
    
    <script>
    (function(){
      if (document.cookie.indexOf('NYT-S') === -1) {
        var iframe = document.createElement('iframe');
        iframe.height = 0;
        iframe.width = 0;
        iframe.style.display = 'none';
        iframe.style.visibility = 'hidden';
        iframe.src = 'https://myaccount.nytimes.com/auth/prefetch-assets';
        document.body.appendChild(iframe);
      }
    })();
    </script>
  
    <script>
(function(w, l) {
  w[l] = w[l] || [];
  w[l].push({
    'gtm.start': new Date().getTime(),
    event: 'gtm.js'
  });
})(window, 'dataLayer');
</script>
<script defer src="https://www.googletagmanager.com/gtm.js?id=GTM-P528B3&gtm_auth=tfAzqo1rYDLgYhmTnSjPqw&gtm_preview=env-130&gtm_cookies_win=x"></script>
<noscript>
<iframe src="https://www.googletagmanager.com/ns.html?id=GTM-P528B3&gtm_auth=tfAzqo1rYDLgYhmTnSjPqw&gtm_preview=env-130&gtm_cookies_win=x" height="0" width="0" style="display:none;visibility:hidden"></iframe>
</noscript>
    
    
    <script id="live-ramp">(function () { var _f=function(){var a=function(a){var e=document.cookie.match(new RegExp(a+"=([^;]+)"));if(e)return e[1]}("nyt-purr"),e=a&&a.substring(14,15)||"",n=window.navigator.userAgent.match(/(nyt)[_wd-]*(ios)/i);a&&"r"===e||n||function(){var a=document.createElement("link");a.href="https://launchpad.privacymanager.io/latest/launchpad.bundle.js",a.as="script",document.body.appendChild(a);var e=document.createElement("script");e.async=!1,e.defer=!0,e.src="https://launchpad-wrapper.privacymanager.io/9fab0bf6-df63-42ca-acc5-caf4de668f40/launchpad-liveramp.js",document.body.appendChild(e)}()};;_f.apply(null, []); })();</script>
    <!-- RELEASE fda3c1704e92bc29a9545d08be2eec92a5050bf5 -->
  </body>
</html> contentType 9 text/html url 83 https://www.nytimes.com:443/2024/04/12/opinion/ezra-klein-podcast-dario-amodei.html responseCode 3 200 