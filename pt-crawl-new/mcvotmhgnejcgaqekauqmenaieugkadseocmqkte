mcvotmhgnejcgaqekauqmenaieugkadseocmqkte length 6 402692 page 402692 <!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@verge"/><meta property="fb:app_id" content="549923288395304"/><meta property="og:site_name" content="The Verge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="apple-mobile-web-app-title" content="Verge"/><meta name="google-site-verification" content="IucFf_TKtbFFH8_YeFyEteQIwYPdANM1R46_U9DpAr4"/><link rel="alternate" type="application/rss+xml" title="The Verge" href="/rss/index.xml"/><title>How to keep your art out of AI generators - The Verge</title><meta name="robots" content="index,follow,max-image-preview:large"/><meta name="description" content="Here’s how you can opt out of training some of the more popular generative AI models, or use tools like Glaze and Nightshade to protect art that’s used without permission."/><meta property="og:title" content="How to keep your art out of AI generators"/><meta property="og:description" content="Here’s what you need to know about opting out and protecting your work."/><meta property="og:url" content="https://www.theverge.com/24063327/ai-art-protect-images-copyright-generators"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2024-02-07T19:00:00.000Z"/><meta property="article:modified_time" content="2024-02-07T19:00:00.000Z"/><meta property="og:image" content="https://cdn.vox-cdn.com/thumbor/offjB8fuUVZ0qRXVsrZ1YIRhbbE=/0x0:3000x2000/1200x628/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg"/><meta property="og:image:alt" content="Vector collage showing aspects of AI art and protecting your artwork from being used to train AI."/><meta property="og:image:type" content="image/jpeg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="628"/><link rel="canonical" href="https://www.theverge.com/24063327/ai-art-protect-images-copyright-generators"/><meta property="author" content="Jess Weatherbed"/><meta name="parsely-type" content="post"/><meta name="parsely-title" content="How to keep your art out of AI generators"/><meta name="parsely-link" content="https://www.theverge.com/24063327/ai-art-protect-images-copyright-generators"/><meta name="parsely-image-url" content="https://cdn.vox-cdn.com/thumbor/offjB8fuUVZ0qRXVsrZ1YIRhbbE=/0x0:3000x2000/1200x628/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg"/><meta name="parsely-pub-date" content="2024-02-07T19:00:00.000Z"/><meta name="parsely-section" content="front-page"/><meta name="parsely-tags" content="verge,front-page,how-to,guidebook,tech,ai-artificial-intelligence,creators"/><meta name="parsely-author" content="Jess Weatherbed"/><script type="application/ld+json">{"@context":"http://schema.org/","@type":"NewsArticle","headline":"How to keep your art out of AI generators","description":"Here’s how you can opt out of training some of the more popular generative AI models, or use tools like Glaze and Nightshade to protect art that’s used without permission.","datePublished":"2024-02-07T19:00:00.000Z","dateModified":"2024-02-07T19:00:00.000Z","thumbnailUrl":"https://cdn.vox-cdn.com/thumbor/ewBKLfJJmd6VuWC4ADqvRPjwRqk=/0x0:3000x2000/1400x788/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","author":[{"@type":"Person","name":"Jess Weatherbed","url":"https://www.theverge.com/authors/jess-weatherbed"}],"publisher":{"@type":"Organization","name":"The Verge","logo":{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png","width":250,"height":50}},"image":[{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/ewBKLfJJmd6VuWC4ADqvRPjwRqk=/0x0:3000x2000/1400x788/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","width":1400,"height":788},{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/Xk9VbLJF0HrXY78H9fyaQslEMCo=/0x0:3000x2000/1400x1050/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","width":1400,"height":1050},{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/FLLHuXnc--Ih-H5nU-KalBuZM68=/0x0:3000x2000/1400x1400/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","width":1400,"height":1400}],"url":"https://www.theverge.com/24063327/ai-art-protect-images-copyright-generators","articleBody":"AI-generated imagery feels inescapable. It’s in the video games you play, in the movies you watch, and has flooded social media platforms. It’s even been used to promote the physical hardware that real, human artists use to create digital paintings and illustrations, to the immense frustration of those who already feel displaced by the technology. \n\nThe pervasive nature of it seems especially egregious to creators who are fighting to stop their works from being used, without consent or compensation, to improve the very thing that threatens to disrupt their careers and livelihoods. The data pools that go into training generative AI models often contain images that are indiscriminately scraped from the internet, and some AI image generator tools allow users to upload reference images they want to imitate. Many creative professionals need to advertise their work via social media and online portfolios, so simply taking everything offline isn’t a viable solution. And a lack of legal clarity around AI technology has created something of a Wild-West environment that’s difficult to resist. Difficult, but not impossible.\n\nWhile the tools are often complicated and time consuming, several AI companies provide creators with ways to opt their work out of training. And for visual artists who want broader protections there are tools like Glaze and Kin.Art, which make the works useless for training. Here’s how to navigate the best solutions we’ve found so far.\n\nOpting Out\n\nGenerative AI models depend on training datasets, and the companies behind them are motivated to avoid restricting those potential data pools. So while they often do allow artists to opt their work out, the process can be crude and labor intensive — especially if you have a sizable catalog of work. \n\nOpting out typically requires submitting a request to an AI provider, either via a dedicated form or directly via email, along with the copies and written descriptions of images you want to protect. Additionally, if you’ve agreed to let third parties license your images, the terms may include a license for AI training. It’s worth scanning the user agreements for any platforms hosting your work to check what rights they hold over it. But different AI tools’ policies vary — here’s how to opt out of some popular ones.\n\nOpenAI DALL-E\n\nOpenAI started allowing creators to remove their work from its training data alongside its DALL-E 3 generative AI model last September, and it’s one of the easier processes to follow. Content creators or owners just need to submit a form to OpenAI to request that the work be excluded from future training datasets, including a copy of the image, a description of it, and a ticked checkbox confirming that you have the rights for said image.\n\nUnfortunately, you’ll have to submit a separate form for every image you want excluded from OpenAI’s datasets, which could amount to thousands of works for some people; OpenAI hasn’t disclosed how many artists have undertaken this ordeal. \n\n[Image: You have to submit a single form for every artwork you want opting out of OpenAIs training, which simply isn’t realistic for creatives with vast portfolios. https://cdn.vox-cdn.com/thumbor/ZnMeuBMJ4NUwYQP5p55P5GXE2Ig=/0x0:1150x1693/1150x1693/filters:focal(575x847:576x848)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg]\n\nIf you only host your works on your own website, there might be a more efficient option. You can follow the instructions linked here to block the “GPTBot” web crawler used to scrape data from publicly available internet sources, which should protect all the content on it. A downside to this method, however, is that images posted anywhere outside of those walled protections, such as on social media, are still at risk of being scraped. Submitting a form at least ensures that your work is protected by a wider net, providing OpenAI hasn’t already obtained the images via a licensed third party.\n\nBoth these processes only offer protection against being swept into future training datasets. OpenAI claims that its AI models don’t retain any information they’ve already been trained on, so if you believe your work was already consumed by DALL-E 3 or its previous iterations, it’s too late to have it removed.\n\nDALL-E 3 is also the model used by Image Creator from Designer, the Microsoft tool previously known as Bing Image Creator. As such, the process of opting out with OpenAI directly should also prevent Image Creator from being trained on your works.\n\nAdobe Firefly\n\nOf course, for every AI company that does allow artists to remove their works from training data, many others don’t openly advertise having such a service. And if they’re training models on a platform they own, users of that platform may not be allowed to opt out at all. That’s the case with creative software giant Adobe, which uses a model called Firefly across its Creative Cloud suite, including in Photoshop’s generative fill tool.\n\nAdobe proclaims that Firefly is commercially and legally safe because it’s entirely trained on the company’s own stock image platform, Adobe Stock. But there’s no means for Adobe Stock contributors to opt out of training Adobe’s AI models, which has resulted in some existing users criticizing the company for not seeking their permission. If you don’t want your work used to improve Firefly, you can’t put it on Adobe Stock, period.\n\n[Image: It doesn’t get much clearer than this line from Adobe’s FAQs. If you don’t want to train Firefly, avoid Adobe Stock. https://cdn.vox-cdn.com/thumbor/-YUqoxNIUWrtW2JUHz36t5zMLQA=/0x0:706x135/706x135/filters:focal(353x68:354x69)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg]\n\nIn principle, Adobe’s approach should mean that non-Stock users don’t have to worry about Firefly. But the reality is that there’s plenty of pirated work uploaded to the platform. If you find that someone has fraudulently uploaded your work to Adobe Stock, you can send Adobe an IP infringement notice to get it removed from the platform. \n\nMeta \n\nCreatives who want to avoid training Meta’s AI models will have to jump through similar hoops. Meta is using “information from its products and services” to train its generative AI models, so anything personal you upload, or have historically uploaded, to platforms like Facebook, Instagram, and Threads is fair game for AI training. If you don’t have an account on any of those services then you’ve potentially avoided feeding its AI machine, but deleting existing accounts and/or not uploading future works to them is the next best thing.\n\nYou can submit a form to Meta to request the company correct or delete personal information that’s being used to train its generative AI models, but only if that information has been supplied by a third party. It won’t let you exclude, for instance, art you’ve been voluntarily showcasing on Instagram. Many artists have also found it to be a frustrating process, criticizing how often the tool is unable to process requests. Conceptual artist Bethany Berg told Wired that the removal form felt like “it was just a fake PR stunt to make it look like they were actually trying to do something.”\n\n[Image: Just remember that Meta will hold some rights over any content you upload to its platforms, so the most effective solution is to avoid them entirely. https://cdn.vox-cdn.com/thumbor/ivfJdF-MwlXfMg9DznEVCObGSrM=/0x0:979x969/979x969/filters:focal(490x485:491x486)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg]\n\nBeyond that, you can limit what personal information third parties are sharing with Meta by managing your Off-Facebook Activity. This tool will display which sites and services are giving your data to Meta and allow you to sever the connection that ties your identity with such data. This won’t clear the data that’s already been uploaded, but it should enable users to monitor if platforms they know are hosting their works are potentially feeding that information back to Meta directly.\n\nThat said, Meta also uses “information that is publicly available online” to train its generative AI models, and it doesn’t disclose its datasets. So there’s no way of knowing precisely what’s already in that massive content pool — and no surefire way of staying out.\n\nWhat about Stability AI, Midjourney, and so on?\n\nTwo of the most popular generative AI tools — Midjourney and Stability AI’s Stable Diffusion — will remove copyright-infringing materials under the Digital Millennium Copyright Act (DMCA). But this information is buried in their respective Terms of Use policies, and the processes are crude. This also isn’t strictly an opt-out tool, and neither company provides a means to opt work out of being sucked into future training data pools.\n\nFor both services, you’ll need to email the companies directly. Midjourney can be reached at takedown@midjourney.com. For Stability AI, email your requests to both mariya@stability.ai and legal@stability.ai. Stability’s user terms don’t specify what you’d need to provide, but the information required by Midjourney, and most DMCA copyright infringement notices generally, includes a description of the original works, where the image infringing on them is located, your contact information, and a copy of your signature. \n\nOther, smaller AI providers may also provide a similar approach to removing data that infringes on intellectual property rights thanks to regulations like DCMA, to varying success — if you’re unsure, try contacting the AI provider directly.\n\nHow else can I protect my work against generative AI?\n\nWith all that laid out, it’s clear that artists’ options when dealing directly with AI companies are pretty limited. Externally, however, several tools and services can grant creators better defenses — or even offenses — when fighting back. The various tools work differently, but in general, they run your visual art through processes that confuse or block effective training. That way, even if your work is scraped for an AI model, that model (ideally) won’t learn to reproduce it.\n\nGlaze\n\n[Image: When you launch Glaze, you’ll need to give it some time to download the resources it needs to protect your work. https://cdn.vox-cdn.com/thumbor/XYVMl3IPUQ5a7QupLrJj1_F8rUg=/0x0:1282x1132/1282x1132/filters:focal(641x566:642x567)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg]\n\nOne of the most notable anti-training tools is Glaze, a project launched by a team out of the University of Chicago. The free-to-use tool works as a kind of cloak, making pixel-level changes to images that confuse AI software trying to read them. Real people can’t typically see these alterations on highly-detailed images so there’s little impact on the human viewing experience, but AI image generators that are fed the same materials will recognize it as something else entirely — meaning anyone who tries to replicate its specific art style will be unable to do so.\n\nGlaze is available for Windows or macOS. There are GPU and non-GPU versions available for Windows, but running the GPU variant specifically requires an Nvidia GPU from this list with at least 3.6GB of memory. (The developers say Glaze generally uses around 5GB of system memory to run.) Using it is straightforward: at first launch, the application will automatically download a number of machine learning libraries and other resources it needs to cloud your images. When that’s complete, head to the “Select” box at the top left and choose which images on your computer you’d like to Glaze. These can be uploaded in batches, so it’s much quicker than making individual opt-out requests.\n\n[Image: https://cdn.vox-cdn.com/thumbor/HQJPufnIxBA2F7zxDPxW2-8qhac=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg]\n[Image: https://cdn.vox-cdn.com/thumbor/ZUH7k6ah3Kh_VorufnSRqVAKxb8=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg]\nYou may want to experiment with the strength of the Glaze application — on simple illustrations like this, Glazing at max intensity can distort the results.\n\nYou can then adjust the intensity of the Glaze cloaking from “very low” to “very high,” with the latter offering greater protection against AI but increasing the possibility of changes being visible to humans. Render quality, another option, determines the overall quality of the finished image — higher-quality rendering looks better and offers greater protection but will also take much longer to process. Generally, the finished result should look virtually unchanged from your original. But a close inspection will reveal tiny differences, almost like a textured wash has been applied to it.\n\nNightshade\n\n[Image: Nightshade shares a very similar UI to Glaze, which is unsurprising considering it’s being developed by the same team. https://cdn.vox-cdn.com/thumbor/oQUoPhgyk0ildslgybihtqPE3qE=/0x0:1302x1100/1302x1100/filters:focal(651x550:652x551)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg]\n\nNightshade, from the team behind Glaze, takes a similar but more extreme approach. Images passed through this cloaking tool are actually intended to “poison” generative AI models that train on them, sabotaging the outputs for text prompts. If you upload a batch of dog pictures, for instance, Nightshade is supposed to fool models into seeing some other object like cars — rather than just confusing the model like Glaze does. The idea is that if a model takes in enough confusing images, it will start building rules based on them, so any dog-related prompt might become distorted with wheels and windshields. \n\nYou can’t specify what you’d like your poisoned images to masquerade as because Nightshade is built around algorithms that can’t accommodate that kind of personalization. If you want a better insight into how it works, check out this breakdown provided by data scientist Dorian Drost.\n\nLike Glaze, Nightshade applies a filter-like film over the image that shouldn’t massively impact the human viewing experience, depending on the intensity of the protection layer and how detailed the original art is. (You can apply both Glaze and Nightshade to images without them interfering with each other.) Nightshade is also available for Windows and macOS systems, though only machines running Apple’s own silicon are supported for the latter.\n\n[Image: https://cdn.vox-cdn.com/thumbor/HQJPufnIxBA2F7zxDPxW2-8qhac=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg]\n[Image: https://cdn.vox-cdn.com/thumbor/gzaQ2O2SO_tDyzxCo5YXIUE_Qcw=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg]\nAt default intensity, Nightshade should produce similar-looking results to Glazed images. The poisoned results on the right are nearly identical to our Glaze tests.\n\nMost of the overall process is the same as Glaze: you wait for the tool to download machine learning libraries, upload your work, and set the intensity and rendering options. But there’s one extra step. Nightshade will analyze the images and fill the “current tag” field with a single-word description identifying the content, like “dog” or “girl.” For the poisoning effect to work, this needs to be accurate — so you can change it if it’s wrong. Then, when you upload the images online, make sure that single-word tag is included in the metadata or alt text. \n\nSome generative AI advocates argue Nightshade won’t be much of a hindrance. AI systems are trained on truly vast amounts of data, so you’d need a lot of poisoning to affect any given prompt. And companies can develop workarounds that detect Nightshade. But most of these workarounds only filter out images that use it, rather than removing the protections — so the end result is just having art excluded from the training data, which is still a win. The Glaze project team is also continually working to update the applications to close any loopholes that are being exploited by workarounds.\n\nMist\n\n[Image: Mist can be tricky to set up, but its another option to try if you’re unhappy with results from Glaze and Nightshade. https://cdn.vox-cdn.com/thumbor/428XwtgEkMHMNdrbsfn-yaw5xiE=/0x0:1767x831/1767x831/filters:focal(884x416:885x417)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg]\n\nMist is a “preprocessing tool” developed by Psyker Group that, like Glaze and Nightshade, also prevents generative AI applications from effectively imitating a creator’s unique style and works. Mist’s approach is more akin to watermarking images. If an AI model is trained on “misted images,” any attempt to mimic them will see the output completely covered in visual distortions that render it unfit for most purposes and generally unpleasant to look at.\n\n[Image: Here’s an example of what’s produced by AI generation tools that reference Misted images. https://cdn.vox-cdn.com/thumbor/epkM8JALgo4JWPCrDQpt3RKsEOA=/0x0:512x512/512x512/filters:focal(256x256:257x257)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg]\n\nElements of the original image can still be seen in some of these outputs, like similarities in photography or art styles, but the chaotic, noisy filter over the generated image isn’t something that can be easily corrected. Mist requires a graphics card with at least 6GB of VRAM, which isn’t a lot of computational resources, but it’s still greater than the 3.6GB Glaze requires. Mist has been open-sourced on GitHub to allow developers to build their own tools around it, and its creators have committed to offering long-term support and continuously improving its function.\n\nThere are currently two ways for non-developers to use Mist. Windows PC users running an Nvidia GPU can download Mist for free via this Google Drive package. The software doesn’t require installation and can be used almost immediately after downloading — though it’s a little finicky to set up if you lack any coding or development experience.\n\n[Image: https://cdn.vox-cdn.com/thumbor/5eU328CU5OnDFEK7ITjLgu7SWOM=/0x0:600x600/600x600/filters:focal(300x300:301x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png]\n[Image: https://cdn.vox-cdn.com/thumbor/eOisXUU_lbyl4nxNMhLi1K17QWM=/0x0:600x600/600x600/filters:focal(300x300:301x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png]\nMisting images can also produce a faint, swirling filter over the results, but like Glaze, it's harder to spot on detailed art or photography.\n\nA detailed handbook is available that will walk you through the entire process, along with a community Discord channel for troubleshooting. First, make sure you’ve installed the .NET desktop runtime. When that’s done, you just select the “ENG” file inside Google Drive and download the zipped Mist_V2 folder within it. Create a new folder called “IMG” in mist-v2 > src > data >. Drop any images that you plan on Misting into the new folder when completed. Then, go back to the main folder (which should be titled “mist-v2_gui_free_version”) and run the Mist GUI booter. Mist allows you to adjust the strength of protection applied to images and select between using your device’s GPU or CPU, which may prove useful if you’re running old or inefficient hardware.\n\nFor anyone who’s using macOS or doesn’t possess an Nvidia GPU, you can also run Mist via Colab Notebook, a cloud-based Jupyter Notebook environment that runs in your web browser. Detailed instructions for how to do this are available here, but it’s a much more complicated process to set up than its Windows equivalent. Glaze and Nightshade, generally, will be much easier to navigate for folks who aren't familiar with coding processes.\n\nKin.Art\n\nKin.Art isn’t so much an AI protection tool as it is an entire portfolio platform that artists can use to host and sell their work. It goes beyond just banning AI-generated works — though that’s appreciated, given the backlash against sites like DeviantArt and ArtStation — and actively makes AI scraping and training harder.\n\nKin.Art uses two different techniques to thwart AI companies. The first is image segmentation, which is used to break apart images and muddle them into something unrecognizable. It’s undetectable to human eyes but disrupts generative AI models from being able to read the image. This visual scrambling will also be present if anyone attempts to save or download the image, though it doesn’t block manual screenshots. The second technique involves scrambling the metadata, like title and description, so any labels the AI model reads won’t accurately reflect the content.\n\n[Image: Kin.Art’s AI protections just require users to tick a box when uploading their works to the platform. https://cdn.vox-cdn.com/thumbor/SO1ehnIJaxSF_oGgKdTgDKfq7k0=/0x0:915x410/915x410/filters:focal(458x205:459x206)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg]\n\nThese protections are automatically applied on the Kin.Art platform, so you just need to create an account and upload your works to benefit from them, and that works like practically any social media platform. There are some neat creator-focused features included, like the ability to add a commission status to advertise your availability to accept requests, and you can link out to external platforms like social media pages directly on your user profile. You can toggle the protections on or off when uploading images, and the service is currently free to use. Instead, Kin.Art will start placing a 5 percent service fee on top of commissions made through the service in March.\n\nWhat about music, writing, and other media?\n\nOur guide covers what protections are available for image-based art largely because that format has more tools available than other mediums, and the opting-out processes tend to be clearer (when they are available). That said, creatives in other fields, like writing, voice acting, and music, are also fighting to protect their work. It’s much harder to disrupt how AI models are trained on this kind of data without noticeably affecting the original content, but there are still precautions you can take to reduce the risk of it being swept into AI training datasets.\n\nAs with art, always check the user terms of the hosting platform to which you’re uploading your works. Services will generally disclose if they’re handing platform data over to third parties for AI training or using it to develop their own models — if there’s no explicit opt-out process, you may unknowingly be giving consent simply by signing up. Instead, look for platforms like Medium, which have committed to blocking attempts to use content hosted on the site to train AI models. If you’re hosting work on your own site, you can also do things like block GPTBot to avoid pages being scraped.\n\nSome rights distributors have made similar commitments, like the Society of Authors, Composers and Publishers of Music (SACEM) — a French association that announced it was exercising its right to opt out on behalf of its members last year. Another tip for writers, courtesy of the Authors Guild, is to place a short warning notice on your published works that clearly states you don’t consent to it being used to train AI. This is the example provided by the guild:\n\n> “NO AI TRAINING: Without in any way limiting the author’s [and publisher’s] exclusive rights under copyright, any use of this publication to “train” generative artificial intelligence (AI) technologies to generate text is expressly prohibited. The author reserves all rights to license uses of this work for generative AI training and development of machine learning language models.”\n\nThese warnings serve to clearly flag that the work isn’t freely available to use, which may be useful in any future lawsuits raised against companies that violate your ownership rights. If bots scraping web data are also intuitive enough to filter out results with such warnings then this could also potentially provide another layer of proactive protection, but there’s little evidence to show how many actually observe such information. Otherwise, performers and writers will need to submit copyright takedown notices to AI companies if they believe their works have been infringed.\n"}</script><link rel="preload" as="image" imageSrcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/16x11/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 16w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/32x21/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 32w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/48x32/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 48w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/64x43/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 64w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/96x64/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 96w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/128x85/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 128w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/256x171/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 256w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/376x251/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/384x256/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/415x277/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/480x320/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/540x360/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/640x427/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/750x500/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/828x552/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1080x720/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1200x800/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1440x960/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1920x1280/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2048x1365/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2400x1600/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 2400w" imageSizes="(max-width: 768px) calc(100vw - 100px), (max-width: 1180px) 700px, 600px"/><meta name="next-head-count" content="35"/><meta name="robots" content="nocache"/><link rel="me" href="https://mastodon.social/@verge"/><link rel="shortcut icon" href="/icons/favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="/icons/apple_touch_icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon_32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon_96x96.png"/><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon_16x16.png"/><link rel="mask-icon" href="/icons/safari_pinned_tab.svg" color="#5200ff"/><link rel="icon" type="image/png" href="/icons/android_chrome_192x192.png" sizes="192x192"/><link rel="icon" type="image/png" href="/icons/android_chrome_512x512.png" sizes="512x512"/><link rel="dns-prefetch" href="https://pagead2.googlesyndication.com"/><link rel="dns-prefetch" href="https://micro.rubiconproject.com/prebid/dynamic/7470.js"/><link rel="dns-prefetch" href="https://securepubads.g.doubleclick.net"/><link rel="dns-prefetch" href="https://stats.g.doubleclick.net"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://cdn.permutive.com"/><link rel="preload" href="/_next/static/media/b61d461e2e1d8573-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/af51b8e80b7e5b97-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/4c161430243654b9-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/faa4a7ab7fe4ff34-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/e0d450417c4fcdb2-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/c6806ee6b9a6284f-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/167de315d6f8820c-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/c32d4f9e62509b70-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/8314bd48671746e7-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/1acdcb23bd60cdf8-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/e334064d2786be51-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/dbe24bfb7e9bcd79-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/caa65695070c604f-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/7f8638c9585902a6-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/d2cd5f6e542bad4c-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/857aa1a339c7fe20-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/516340c748fee9da-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/afa7a955b67174eb-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/d2ddd5a6c0493c79-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/70754f98ca969379-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/60369a8d37d9d5b8-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/96fec850ad729c00-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/78c96ab956e7dd1d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/78c96ab956e7dd1d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/df212bc532bc2860.css" as="style"/><link rel="stylesheet" href="/_next/static/css/df212bc532bc2860.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="https://micro.rubiconproject.com/prebid/dynamic/7470.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://c.amazon-adsystem.com/aax2/apstag.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://www.googletagservices.com/tag/js/gpt.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://cdn.concert.io/lib/concert-ads/v2-latest/concert_ads.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://cdn.concert.io/lib/concert-concierge.2.10.1.min.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://pub.doubleverify.com/dvtag/21236410/DV464041/pub.js" async="" defer="" data-nscript="beforeInteractive"></script><script src="https://polyfill.io/v3/polyfill.min.js?features=AbortController,Array.prototype.entries,Array.prototype.keys,Array.prototype.sort,Array.prototype.values,ArrayBuffer,ArrayBuffer.isView,AudioContext,Blob,console,console.error,console.log,console.warn,CustomEvent,DataView,document,Document,DocumentFragment,DocumentFragment.prototype.append,DOMRect,DOMTokenList,DOMTokenList.prototype.forEach,DOMTokenList.prototype.replace,Element,Element.prototype.after,Element.prototype.append,Element.prototype.before,Element.prototype.classList,Element.prototype.closest,Element.prototype.matches,Element.prototype.previousElementSibling,Element.prototype.remove,Element.prototype.scroll,Element.prototype.scrollIntoView,Event,EventSource,getComputedStyle,globalThis,HTMLDocument,HTMLPictureElement,HTMLTemplateElement,IntersectionObserver,IntersectionObserverEntry,Intl,Intl.DateTimeFormat,Intl.NumberFormat,Intl.RelativeTimeFormat,JSON,location.origin,Math.clz32,Math.imul,Math.sign,modernizr:es6string,MutationObserver,Node.prototype.contains,NodeList.prototype.forEach,Object.getOwnPropertySymbols,Object.isExtensible,Object.isFrozen,Object.preventExtensions,Object.setPrototypeOf,queueMicrotask,Reflect.construct,Reflect.defineProperty,Reflect.set,RegExp.prototype.flags,requestAnimationFrame,ResizeObserver,String.prototype.link,String.prototype.normalize,String.prototype.sub,Symbol.for,Symbol.iterator,Symbol.prototype.description,Symbol.toPrimitive,Symbol.toStringTag,TextDecoder,TextEncoder,Uint8Array,Window,XMLHttpRequest,Intl.RelativeTimeFormat,Intl.RelativeTimeFormat.~locale.en" defer="" data-nscript="beforeInteractive"></script><script src="/_next/static/chunks/webpack-c376b9c42b10a4ef.js" defer=""></script><script src="/_next/static/chunks/framework-1d2b8554342c6a75.js" defer=""></script><script src="/_next/static/chunks/main-a19b11f4c6f53406.js" defer=""></script><script src="/_next/static/chunks/pages/_app-da18e97646b55740.js" defer=""></script><script src="/_next/static/chunks/7404-a1bc449f4440a25c.js" defer=""></script><script src="/_next/static/chunks/5833-5ad65b6eeff676da.js" defer=""></script><script src="/_next/static/chunks/4723-ec0bd4ab4f72e2c9.js" defer=""></script><script src="/_next/static/chunks/5271-346d91caff9b1218.js" defer=""></script><script src="/_next/static/chunks/3882-4e711a09aa4476ce.js" defer=""></script><script src="/_next/static/chunks/2156-6ec5849a2514173a.js" defer=""></script><script src="/_next/static/chunks/996-f415a23a59cde4f1.js" defer=""></script><script src="/_next/static/chunks/3494-79231dcbde5aec1f.js" defer=""></script><script src="/_next/static/chunks/5207-f1962b33fbbeca79.js" defer=""></script><script src="/_next/static/chunks/6276-ea6f3169216875c5.js" defer=""></script><script src="/_next/static/chunks/9549-99a115a465a16121.js" defer=""></script><script src="/_next/static/chunks/9546-25ba14b07b9f1957.js" defer=""></script><script src="/_next/static/chunks/5055-f42044eaed03c6a4.js" defer=""></script><script src="/_next/static/chunks/825-df4ac27514145832.js" defer=""></script><script src="/_next/static/chunks/4640-33e62f43d3f652bf.js" defer=""></script><script src="/_next/static/chunks/6901-e5ee6375c0cc7088.js" defer=""></script><script src="/_next/static/chunks/pages/entry/standard/%5Buid%5D-e520968804b4e146.js" defer=""></script><script src="/_next/static/TIjH7e7ABna7etOOsIsVO/_buildManifest.js" defer=""></script><script src="/_next/static/TIjH7e7ABna7etOOsIsVO/_ssgManifest.js" defer=""></script><style id="__jsx-2324231005">:root{--font-fkroman:'__fkRomanStandard_6bdc6d', '__fkRomanStandard_Fallback_6bdc6d', Georgia, serif;--font-manuka:'__manuka_e0d4a3', '__manuka_Fallback_e0d4a3', Impact, Helvetica, sans-serif;--font-polysans:'__polySans_c60300', '__polySans_Fallback_c60300', Helvetica, Arial, sans-serif;--font-polysans-mono:'__polySansMono_0d16dc', '__polySansMono_Fallback_0d16dc', Courier New, Courier, monospace}</style></head><body class="antialiased"><div id="__next"><style>
        *, *::before, *::after {
          transition: none!important;
        }
      </style><div class="jsx-2324231005 duet--app"><a class="text-2xl text-pink-500 border-b-pink-500 focus:outline-pink-500 sr-only z-50 block border-8 bg-white p-7 text-center opacity-0 transition-opacity focus:visible focus:static focus:h-auto focus:w-full focus:overflow-auto focus:opacity-100  focus:outline-dotted" href="#content">Skip to main content</a><div class=""><div class="duet--navigation--navigation"><div class="absolute h-[64px] w-full overflow-x-hidden md:h-[150px]"><div class="relative h-[64px] w-full max-w-container-lg md:left-1/2 md:h-[150px] md:-translate-x-1/2"><a href="/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 309 70" role="img" class="absolute left-[-16px] top-[-3px] z-0 h-[64px] w-[282px] md:h-[174px] md:w-[769px] md:left-[-200px] md:top-[-24px] fill-franklin md:fill-franklin/50" width="100%" height="100%" fill="none"><title>The Verge</title><desc>The Verge logo.</desc><path d="m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z"></path></svg></a><a class="absolute left-0 top-0 z-10 h-[60px] w-[265px] md:hidden" href="/"><span class="sr-only">The Verge homepage</span></a></div></div><div class="md:px-34 pointer-events-none relative mx-auto mb-16 flex h-[48px] w-full max-w-container-lg items-end px-20 font-polysans text-15 md:mb-80 md:h-80 md:text-19 lg:px-0"><nav class="pointer-events-auto relative ml-auto border-b pb-6 md:pb-8 text-black"><ul class="flex items-end font-light"><li class="hidden md:flex"><a href="/"><span class="sr-only">The Verge homepage</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 309 70" role="img" class="h-[28px] w-[117px] hover:opacity-60 hover:transition-all hover:ease-in-out md:translate-y-2 fill-black" width="100%" height="100%" fill="none"><title>The Verge</title><desc>The Verge logo.</desc><path d="m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z"></path></svg></a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li class="hidden md:inline"><a href="/tech" class="hover:opacity-50 hover:transition-all hover:ease-in-out">Tech</a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li class="hidden md:inline"><a href="/reviews" class="hover:opacity-50 hover:transition-all hover:ease-in-out">Reviews</a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li class="hidden md:inline"><a href="/science" class="hover:opacity-50 hover:transition-all hover:ease-in-out">Science</a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li class="hidden md:inline"><a href="/entertainment" class="hover:opacity-50 hover:transition-all hover:ease-in-out">Entertainment</a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li class="hidden md:inline"><a href="/ai-artificial-intelligence" class="hover:opacity-50 hover:transition-all hover:ease-in-out tracking-widest">AI</a><span aria-hidden="true" class="hidden px-16 md:inline">/</span></li><li><button class="flex cursor-pointer flex-nowrap items-center hover:opacity-50 hover:transition-all hover:ease-in-out"><span class="hidden md:inline">More</span><span class="md:hidden">Menu</span><svg width="100%" height="100%" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="ml-8 inline-block h-18 w-18 md:mt-2 md:h-[22px] md:w-[22px] fill-black"><title>Expand</title><path d="M28 11.76H16.24V0h-4.48v11.76H0v4.48h11.76V28h4.48V16.24H28v-4.48Z"></path></svg></button></li></ul></nav></div></div><div class="duet--navigation--sticky-nav fixed inset-x-0 top-0 z-40 w-full bg-white drop-shadow-sticky-nav transition-opacity duration-200 pointer-events-none opacity-0"><div class="mx-auto flex h-50 w-full max-w-container-lg items-center justify-between justify-self-start px-12 lg:px-0"><a class="flex" href="/" aria-label="The Verge logo. Click to visit the homepage" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 309 70" role="img" class="w-[141px] fill-black hover:opacity-60 hover:transition-all hover:ease-in-out" width="100%" height="100%" fill="none"><title>The Verge</title><desc>The Verge logo.</desc><path d="m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z"></path></svg></a><div class="group flex flex-nowrap"><button class="cursor-pointer items-center font-polysans text-15 flex"><span class="group-hover:opacity-60">Menu</span><svg width="100%" height="100%" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="ml-8 inline-block h-18 w-18 fill-black group-hover:opacity-60 md:mt-2 md:h-[22px] md:w-[22px]"><title>Expand</title><path d="M28 11.76H16.24V0h-4.48v11.76H0v4.48h11.76V28h4.48V16.24H28v-4.48Z"></path></svg></button></div></div></div></div><div class="duet--page-layout--standard-article"><div style="position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none"></div><div style="position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none"></div><main class="md:px-34 relative px-20"><div style="min-height:90px;min-width:728px;margin-top:40px;margin-bottom:40px" class="_1gsaw2w0 _1gsaw2w3" data-concert="tablet_leaderboard"></div><div style="min-height:90px;min-width:728px;margin-top:100px;margin-bottom:60px" class="_1gsaw2w0 _1gsaw2w5" data-concert="desktop_leaderboard_variable"></div><article id="content" class="mx-auto my-24 w-full max-w-container-lg md:mt-16 lg:mt-45"><div class="duet--article--lede mx-auto mb-28 w-full md:max-w-container-md lg:mb-36 lg:max-w-none"><ul class="lg:px-0 article-groups leading-100 mb-8"><li class="inline font-polysans-mono text-12 font-medium uppercase tracking-12 text-blurple"><a class="hover:shadow-underline-inherit" href="/how-to">How to</a><span class="px-6">/</span></li><li class="inline font-polysans-mono text-12 font-medium uppercase tracking-12 text-blurple"><a class="hover:shadow-underline-inherit" href="/tech">Tech</a><span class="px-6">/</span></li><li class="inline font-polysans-mono text-12 font-medium uppercase tracking-12 text-blurple"><a class="hover:shadow-underline-inherit" href="/ai-artificial-intelligence">Artificial Intelligence</a></li></ul><h1 class="mb-28 hidden max-w-[900px] font-polysans text-45 font-bold leading-100 selection:bg-franklin-20 lg:block">How to keep your art out of AI generators</h1><span class="sticky-nav-trigger"></span><div class="flex flex-col lg:flex-row-reverse lg:justify-end"><div class="flex-col lg:flex lg:ml-40"><div class="mb-24 grow"><h1 class="inline font-polysans text-22 font-bold leading-110 md:text-33 lg:hidden">How to keep your art out of AI generators</h1><span class="font-polysans text-22 font-light leading-110 md:text-30 lg:block"><span class="text-blurple"> / </span><h2 class="inline selection:bg-franklin-20">Some AI companies provide ways to opt images out of being used in training data, while tools like Glaze and Nightshade can interfere with AI models directly.</h2></span></div><div><div class="mb-16 w-[200px] border-t border-gray-bd lg:hidden"></div><div class="mb-2 text-blurple [&amp;&gt;p&gt;span:first-child]:text-gray-13 [&amp;_.duet--article-byline-and]:text-gray-13"><p class="duet--article--article-byline max-w-[550px] font-polysans text-12 leading-120"><span>By</span> <span><span class="duet--article-byline-and"></span> <span class="font-medium"><a class="hover:shadow-underline-inherit" href="/authors/jess-weatherbed">Jess Weatherbed</a></span><span class="text-gray-13">, <span class="duet--article--dangerously-set-cms-markup">a news writer focused on creative industries, computing, and internet culture. Jess started her career at TechRadar, covering news and hardware reviews.</span></span></span></p></div><div class="duet--article--date-and-comments mb-20 inline-block font-polysans text-12 text-gray-5a"><time dateTime="2024-02-07T19:00:00.000Z" class="duet--article--timestamp font-polysans text-12"> <!-- -->Feb 7, 2024, 7:00 PM UTC</time></div><div class="mb-24 flex lg:mb-0 lg:mb-0"><div class="flex"><div><h2 class="sr-only">Share this story</h2><ul class="duet--article--share-buttons flex leading-[0]"><li class="mr-8"><div class="relative flex items-center"><button aria-label="Copy link" class="rounded-full bg-transparent transition shadow-border-gray-d3 hover:bg-blurple hover:shadow-border-blurple"><svg width="30" height="30" class="transition fill-blurple hover:fill-white" viewBox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"><path d="M13.7876 20.18C12.6943 21.2733 10.9133 21.2733 9.81998 20.18C8.72669 19.0867 8.72666 17.3056 9.81998 16.2123L12.0243 14.0081C13.1176 12.9147 14.8986 12.9147 15.9919 14.0081C16.0816 14.0954 16.1326 14.2149 16.1335 14.34C16.1343 14.4651 16.085 14.5854 15.9965 14.6739C15.9081 14.7624 15.7877 14.8118 15.6627 14.8109C15.5376 14.81 15.418 14.759 15.3306 14.6693C14.5922 13.9309 13.4239 13.9309 12.6855 14.6693L10.4812 16.8736C9.74277 17.6121 9.74277 18.7803 10.4812 19.5188C11.2197 20.2572 12.3879 20.2571 13.1264 19.5188L15.2204 17.4246V17.4247C15.3077 17.335 15.4273 17.284 15.5525 17.2832C15.6776 17.2823 15.7978 17.3317 15.8863 17.4202C15.9747 17.5087 16.0241 17.6289 16.0232 17.7541C16.0224 17.8792 15.9714 17.9987 15.8817 18.086L13.7876 20.18ZM17.9757 15.9919C16.8824 17.0852 15.1014 17.0852 14.0081 15.9919V15.992C13.9184 15.9047 13.8674 15.7852 13.8665 15.6601C13.8658 15.5349 13.915 15.4147 14.0035 15.3262C14.092 15.2377 14.2123 15.1883 14.3374 15.1892C14.4626 15.19 14.582 15.241 14.6694 15.3307C15.4078 16.0692 16.5761 16.0692 17.3145 15.3307L19.5188 13.1265C20.2572 12.388 20.2572 11.2197 19.5188 10.4813C18.7803 9.74283 17.6121 9.74283 16.8736 10.4813L14.7796 12.5753C14.6923 12.665 14.5727 12.7161 14.4475 12.717C14.3224 12.7179 14.2022 12.6685 14.1137 12.58C14.0252 12.4915 13.9758 12.3712 13.9767 12.246C13.9775 12.1208 14.0285 12.0012 14.1183 11.914L16.2124 9.82001C17.3057 8.72668 19.0867 8.72668 20.18 9.82001C21.2733 10.9133 21.2733 12.6944 20.18 13.7877L17.9757 15.992L17.9757 15.9919Z"></path></svg></button></div></li><li class="mr-8"><button aria-label="Share on Facebook" class="rounded-full bg-transparent transition shadow-border-gray-d3 hover:bg-blurple hover:shadow-border-blurple"><svg width="30" height="30" class="transition fill-blurple hover:fill-white" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 30 30"><path d="M17.407 15.6999L17.7398 13.5442H15.6561V12.1455C15.6561 11.5562 15.9467 10.9806 16.8808 10.9806H17.8286V9.14574C17.8286 9.14574 16.9685 9 16.1464 9C14.4304 9 13.3083 10.0317 13.3083 11.9012V13.5442H11.4V15.6999H13.3083V20.9098C13.6908 20.9696 14.0828 21 14.4822 21C14.8816 21 15.2736 20.9685 15.6561 20.9098V15.6999H17.407Z"></path></svg></button></li><li class=""><button aria-label="Share on Twitter" class="rounded-full bg-transparent transition shadow-border-gray-d3 hover:bg-blurple hover:shadow-border-blurple"><svg width="30" height="30" class="transition fill-blurple hover:fill-white" viewBox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"><path d="M20.0896 12.4337C20.0974 12.5459 20.0974 12.6581 20.0974 12.7713C20.0974 16.2205 17.4557 20.1985 12.6254 20.1985V20.1964C11.1985 20.1985 9.80122 19.7922 8.60001 19.0262C8.80749 19.051 9.01601 19.0634 9.22506 19.0639C10.4076 19.0649 11.5563 18.6705 12.4865 17.9443C11.3628 17.9231 10.3774 17.1948 10.0331 16.1316C10.4268 16.207 10.8324 16.1915 11.2188 16.0866C9.99363 15.8406 9.11221 14.7706 9.11221 13.528C9.11221 13.5166 9.11221 13.5058 9.11221 13.4949C9.47726 13.697 9.88599 13.8092 10.3041 13.8216C9.15017 13.055 8.79449 11.5292 9.4913 10.3362C10.8246 11.967 12.7918 12.9584 14.9035 13.0633C14.6919 12.1567 14.981 11.2066 15.6633 10.5693C16.721 9.58102 18.3845 9.63167 19.3787 10.6825C19.9669 10.5672 20.5306 10.3527 21.0464 10.0488C20.8504 10.653 20.4401 11.1663 19.892 11.4925C20.4125 11.4315 20.9211 11.293 21.4 11.0815C21.0474 11.6067 20.6034 12.0642 20.0896 12.4337Z"></path></svg></button></li></ul></div><span class="duet--article--lede-share-tools-separator mx-16 mt-4 h-[20px] border-l border-gray-d3"></span><div class=""><button title="Go to comments" class="duet--article--comments-link text-0 inline-block text-16 md:inline"><span class="inline-block h-18 align-text-bottom font-polysans text-12 font-medium leading-[18px] text-blurple"><span class="coral-count" data-coral-id="1c995675-e913-450a-abef-091ac7bb185a" data-coral-url="https://www.theverge.com/24063327/ai-art-protect-images-copyright-generators"></span></span></button></div></div></div><div style="margin:0" class="_1gsaw2w0 _1gsaw2w1" data-concert="article_sponsorship"></div></div></div><div class="w-full shrink-0 lg:basis-[600px]"><div class="md:pl-0"><figure class="duet--article--lede-image w-full"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:66.63636363636364%"></span><img alt="Vector collage showing aspects of AI art and protecting your artwork from being used to train AI." sizes="(max-width: 768px) calc(100vw - 100px), (max-width: 1180px) 700px, 600px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/16x11/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 16w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/32x21/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 32w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/48x32/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 48w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/64x43/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 64w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/96x64/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 96w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/128x85/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 128w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/256x171/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 256w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/376x251/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/384x256/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/415x277/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/480x320/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/540x360/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/640x427/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/750x500/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/828x552/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1080x720/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1200x800/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1440x960/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1920x1280/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2048x1365/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2400x1600/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2400x1600/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/></span><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>Here’s how to opt-out where you can, and fight back where you can’t.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Samar Haddad / The Verge</cite></div></figure></div></div></div></div><div class="relative md:mx-auto md:flex md:max-w-container-md lg:max-w-none"><div class="duet--article--article-body-component-container clearfix sm:ml-auto md:ml-100 md:max-w-article-body lg:mx-100"><div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">AI-generated imagery feels inescapable. It’s in the <a href="/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney">video games you play</a>, in the <a href="/2023/6/27/23770133/secret-invasion-ai-credits-marvel">movies you watch</a>, and has flooded social media platforms. It’s even been used to <a href="/2024/1/9/24031468/wacom-wizards-of-the-coast-mtg-artists-against-generative-ai">promote the physical hardware</a> that real, human artists use to create digital paintings and illustrations, to the immense frustration of those who already feel displaced by the technology. </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">The pervasive nature of it seems especially egregious to creators who are fighting to stop their works from being used, without consent or compensation, to improve the very thing that threatens to disrupt their careers and livelihoods. The data pools that go into training generative AI models often contain images that are indiscriminately scraped from the internet, and some AI image generator tools allow users to upload reference images they want to imitate. Many creative professionals need to advertise their work via social media and online portfolios, so simply taking everything offline isn’t a viable solution. <a href="/2023/11/4/23946353/generative-ai-copyright-training-data-openai-microsoft-google-meta-stabilityai">And a lack of legal clarity around AI technology</a> has created something of a Wild-West environment that’s difficult to resist. Difficult, but not impossible.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">While the tools are often <a href="https://www.theatlantic.com/technology/archive/2023/10/openai-dall-e-3-artists-work/675519/">complicated and time consuming</a>, several AI companies provide creators with ways to opt their work out of training. And for visual artists who want broader protections there are tools like Glaze and Kin.Art, which make the works useless for training. Here’s how to navigate the best solutions we’ve found so far.</p></div><div class="duet--article--article-body-component"><h3 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading mb-20 mt-40 font-polysans text-26 font-medium leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-30 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>Opting Out</strong></h3></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Generative AI models depend on training datasets, and the companies behind them are motivated to avoid restricting those potential data pools. So while they often do allow artists to opt their work out, the process can be crude and labor intensive — especially if you have a sizable catalog of work. </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Opting out typically requires submitting a request to an AI provider, either via a dedicated form or directly via email, along with the copies and written descriptions of images you want to protect. Additionally, if you’ve agreed to let third parties license your images, the terms may include a license for AI training. It’s worth scanning the user agreements for any platforms hosting your work to check what rights they hold over it. But different AI tools’ policies vary — here’s how to opt out of some popular ones.</p></div><div class="duet--article--article-body-component"><h4 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading my-20 font-polysans text-24 font-light leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-26 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>OpenAI DALL-E</strong></h4></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">OpenAI started allowing creators to remove their work from its training data alongside its DALL-E 3 generative AI model last September, and it’s one of the easier processes to follow. Content creators or owners just need to <a href="https://share.hsforms.com/1_OuT5tfFSpic89PqN6r1CQ4sk30">submit a form to OpenAI</a> to request that the work be excluded from future training datasets, including a copy of the image, a description of it, and a ticked checkbox confirming that you have the rights for said image.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Unfortunately, you’ll have to submit a separate form for <em>every</em> image you want excluded from OpenAI’s datasets, which could amount to thousands of works for some people; <a href="/2023/11/3/23944971/openai-wont-say-how-many-artists-have-opted-out-of-training-ai">OpenAI hasn’t disclosed how many artists have undertaken this ordeal</a>. </p></div><div class="duet--article--article-body-component clear-both block"><div class="my-9"><div class="transition-all duration-300 ease-in-out"><div class="fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0" role="button" aria-label="Close" tabindex="0"></div><div role="button" aria-label="Zoom" tabindex="0" class="visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:147.21739130434784%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot taken of the OpenAI form needed to opt works out of being used to train AI models." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot taken of the OpenAI form needed to opt works out of being used to train AI models." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/376x554/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/384x565/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/415x611/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/480x707/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/540x795/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/640x942/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/750x1104/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/828x1219/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/1080x1590/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/1200x1767/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/1440x2120/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/1920x2827/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/2048x3015/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/2400x3533/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/2400x3533/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg"/></noscript></span></div></div></figure></div><div class="z-1 w-full hidden"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:147.21739130434784%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot taken of the OpenAI form needed to opt works out of being used to train AI models." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot taken of the OpenAI form needed to opt works out of being used to train AI models." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/376x554/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/384x565/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/415x611/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/480x707/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/540x795/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/640x942/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/750x1104/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/828x1219/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/1080x1590/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/1200x1767/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/1440x2120/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/1920x2827/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/2048x3015/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/2400x3533/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1150x1693/2400x3533/filters:focal(575x847:576x848):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg"/></noscript></span></div></div></figure></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>You have to submit a single form for every artwork you want opting out of OpenAIs training, which simply isn’t realistic for creatives with vast portfolios.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: OpenAI</cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">If you only host your works on your own website, there might be a more efficient option. You can <a href="https://platform.openai.com/docs/gptbot">follow the instructions linked here</a> to block the “GPTBot” web crawler used to scrape data from publicly available internet sources, which should protect all the content on it. A downside to this method, however, is that images posted anywhere outside of those walled protections, such as on social media, are still at risk of being scraped. Submitting a form at least ensures that your work is protected by a wider net, providing OpenAI hasn’t already obtained the images via a licensed third party.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Both these processes only offer protection against being swept into future training datasets. OpenAI claims that its AI models don’t retain any information they’ve already been trained on, so if you believe your work was already consumed by DALL-E 3 or its previous iterations, it’s too late to have it removed.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">DALL-E 3 is also the model used by Image Creator from Designer, the Microsoft tool previously known as <a href="/2023/10/3/23901963/bing-chat-dall-e-3-openai-image-generator">Bing Image Creator</a>. As such, the process of opting out with OpenAI directly should also prevent Image Creator from being trained on your works.</p></div><div class="duet--article--article-body-component"><h4 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading my-20 font-polysans text-24 font-light leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-26 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>Adobe Firefly</strong></h4></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Of course, for every AI company that <em>does</em> allow artists to remove their works from training data, many others don’t openly advertise having such a service. And if they’re training models on a platform they own, users of that platform may not be allowed to opt out at all. That’s the case with creative software giant Adobe, which uses a model called Firefly across its Creative Cloud suite, including in Photoshop’s generative fill tool.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Adobe proclaims that Firefly is commercially and legally safe because it’s entirely trained on the company’s own stock image platform, Adobe Stock. But there’s no means for Adobe Stock contributors to opt out of training Adobe’s AI models, which has resulted in some <a href="https://venturebeat.com/ai/adobe-stock-creators-arent-happy-with-firefly-the-companys-commercially-safe-gen-ai-tool/">existing users criticizing the company</a> for not seeking their permission. If you don’t want your work used to improve Firefly, you can’t put it on Adobe Stock, period.</p></div><div class="duet--article--article-body-component clear-both block"><div class="my-9"><div class="transition-all duration-300 ease-in-out"><div class="fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0" role="button" aria-label="Close" tabindex="0"></div><div role="button" aria-label="Zoom" tabindex="0" class="visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:19.121813031161473%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot taken from Adobe Stock’s FAQ for contributors" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot taken from Adobe Stock’s FAQ for contributors" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/376x72/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/384x73/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/415x79/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/480x92/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/540x103/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/640x122/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/750x143/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/828x158/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/1080x207/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/1200x229/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/1440x275/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/1920x367/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/2048x392/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/2400x459/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/2400x459/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg"/></noscript></span></div></div></figure></div><div class="z-1 w-full hidden"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:19.121813031161473%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot taken from Adobe Stock’s FAQ for contributors" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot taken from Adobe Stock’s FAQ for contributors" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/376x72/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/384x73/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/415x79/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/480x92/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/540x103/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/640x122/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/750x143/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/828x158/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/1080x207/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/1200x229/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/1440x275/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/1920x367/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/2048x392/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/2400x459/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:706x135/2400x459/filters:focal(353x68:354x69):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg"/></noscript></span></div></div></figure></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>It doesn’t get much clearer than this line from Adobe’s FAQs. If you don’t want to train Firefly, avoid Adobe Stock.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: Adobe</cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">In principle, Adobe’s approach <em>should </em>mean that non-Stock users don’t have to worry about Firefly. But the reality is that there’s plenty of pirated work uploaded to the platform. If you find that someone has fraudulently uploaded your work to Adobe Stock, you can send Adobe <a href="https://helpx.adobe.com/stock/contributor/help/how-to-report-suspected-misuse-of-your-intellectual-property.html#:~:text=If%20you%20believe%20that%20any,%2Dstock%40adobe.com%20.">an IP infringement notice</a> to get it removed from the platform. </p></div><div class="duet--article--article-body-component"><h4 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading my-20 font-polysans text-24 font-light leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-26 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>Meta </strong></h4></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Creatives who want to avoid training Meta’s AI models will have to jump through similar hoops. Meta is using “<a href="https://www.facebook.com/privacy/genai">information from its products and services</a>” to train its generative AI models, so anything personal you upload, or have historically uploaded, to platforms like Facebook, Instagram, and Threads is fair game for AI training. If you don’t have an account on any of those services then you’ve potentially avoided feeding its AI machine, but deleting existing accounts and/or not uploading future works to them is the next best thing.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">You can <a href="https://www.facebook.com/help/contact/510058597920541">submit a form to Meta</a> to request the company correct or delete personal information that’s being used to train its generative AI models, but only if that information has been supplied by a third party. It won’t let you exclude, for instance, art you’ve been voluntarily showcasing on Instagram. Many artists have also found it to be a frustrating process, criticizing how often the tool is unable to process requests. Conceptual artist <a href="https://www.wired.com/story/meta-artificial-intelligence-data-deletion/#:~:text=Mihaela%20Voicu%2C%20a%20Romanian%20digital%20artist%20and%20photographer%20who%20has%20tried%20to%20request%20data%20deletion%20twice%20using%20Meta%E2%80%99s%20form%2C%20says%20the%20process%20feels%20like%20%E2%80%9Ca%20bad%20joke.%E2%80%9D%20She%E2%80%99s%20received%20the%20%E2%80%9Cunable%20to%20process%20request%E2%80%9D%20boilerplate%20language%2C%20too.%20%E2%80%9CIt%E2%80%99s%20not%20actually%20intended%20to%20help%20people%2C%E2%80%9D%20she%20believes.">Bethany Berg told <em>Wired</em></a> that the removal form felt like “it was just a fake PR stunt to make it look like they were actually trying to do something.”</p></div><div class="duet--article--article-body-component clear-both block"><div class="my-9"><div class="transition-all duration-300 ease-in-out"><div class="fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0" role="button" aria-label="Close" tabindex="0"></div><div role="button" aria-label="Zoom" tabindex="0" class="visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:98.97854954034729%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot taken of Meta’s form for opting data out of training AI models." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot taken of Meta’s form for opting data out of training AI models." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/376x372/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/384x380/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/415x411/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/480x475/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/540x534/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/640x633/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/750x742/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/828x820/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/1080x1069/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/1200x1188/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/1440x1425/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/1920x1900/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/2048x2027/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/2400x2375/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/2400x2375/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg"/></noscript></span></div></div></figure></div><div class="z-1 w-full hidden"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:98.97854954034729%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot taken of Meta’s form for opting data out of training AI models." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot taken of Meta’s form for opting data out of training AI models." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/376x372/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/384x380/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/415x411/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/480x475/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/540x534/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/640x633/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/750x742/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/828x820/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/1080x1069/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/1200x1188/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/1440x1425/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/1920x1900/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/2048x2027/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/2400x2375/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:979x969/2400x2375/filters:focal(490x485:491x486):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg"/></noscript></span></div></div></figure></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>Just remember that Meta will hold some rights over any content you upload to its platforms, so the most effective solution is to avoid them entirely.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: Meta</cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Beyond that, you can limit what personal information third parties are sharing with Meta by managing your <a href="https://accountscenter.facebook.com/info_and_permissions/off_facebook_activity/">Off-Facebook Activity</a>. This tool will display which sites and services are giving your data to Meta and allow you to sever the connection that ties your identity with such data. This won’t clear the data that’s already been uploaded, but it should enable users to monitor if platforms they know are hosting their works are potentially feeding that information back to Meta directly.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">That said, Meta also uses “information that is publicly available online” to train its generative AI models, and it doesn’t disclose its datasets. So there’s no way of knowing precisely what’s already in that massive content pool — and no surefire way of staying out.</p></div><div class="duet--article--article-body-component"><h3 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading mb-20 mt-40 font-polysans text-26 font-medium leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-30 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>What about Stability AI, Midjourney, and so on?</strong></h3></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Two of the most popular generative AI tools — Midjourney and Stability AI’s Stable Diffusion — will remove copyright-infringing materials under the Digital Millennium Copyright Act (DMCA). But this information is buried in their respective Terms of Use policies, and the processes are crude. This also isn’t strictly an opt-out tool, and neither company provides a means to opt work out of being sucked into future training data pools.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">For both services, you’ll need to email the companies directly. Midjourney can be reached at <a href="mailto:takedown@midjourney.com">takedown@midjourney.com</a>. For Stability AI, email your requests to both <a href="mailto:mariya@stability.ai">mariya@stability.ai</a> and <a href="mailto:legal@stability.ai">legal@stability.ai</a>. <a href="https://stability.ai/terms-of-use#:~:text=DMCA%20Copyright%20Infringement,stability.ai)">Stability</a>’s user terms don’t specify what you’d need to provide, but the information required by <a href="https://www.amd.com/en/legal/notices/dmca.html#:~:text=The%20Digital%20Millennium%20Copyright%20Act,by%20the%20Copyright%20owner%20or">Midjourney</a>, and most DMCA copyright infringement notices generally, includes a description of the original works, where the image infringing on them is located, your contact information, and a copy of your signature. </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Other, smaller AI providers may also provide a similar approach to removing data that infringes on intellectual property rights thanks to regulations like DCMA, to varying success — if you’re unsure, try contacting the AI provider directly.</p></div><div class="duet--article--article-body-component"><h3 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading mb-20 mt-40 font-polysans text-26 font-medium leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-30 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>How else can I protect my work against generative AI?</strong></h3></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">With all that laid out, it’s clear that artists’ options when dealing directly with AI companies are pretty limited. Externally, however, several tools and services can grant creators better defenses — or even <em>offenses</em> — when fighting back. The various tools work differently, but in general, they run your visual art through processes that confuse or block effective training. That way, even if your work is scraped for an AI model, that model (ideally) won’t learn to reproduce it.</p></div><div class="duet--article--article-body-component"><h4 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading my-20 font-polysans text-24 font-light leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-26 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>Glaze</strong></h4></div><div class="duet--article--article-body-component clear-both block"><div class="my-9"><div class="transition-all duration-300 ease-in-out"><div class="fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0" role="button" aria-label="Close" tabindex="0"></div><div role="button" aria-label="Zoom" tabindex="0" class="visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:88.29953198127926%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screengrab of the Glaze launcher." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screengrab of the Glaze launcher." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/376x332/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/384x339/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/415x366/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/480x424/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/540x477/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/640x565/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/750x662/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/828x731/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/1080x954/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/1200x1060/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/1440x1272/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/1920x1695/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/2048x1808/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/2400x2119/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/2400x2119/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg"/></noscript></span></div></div></figure></div><div class="z-1 w-full hidden"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:88.29953198127926%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screengrab of the Glaze launcher." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screengrab of the Glaze launcher." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/376x332/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/384x339/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/415x366/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/480x424/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/540x477/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/640x565/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/750x662/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/828x731/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/1080x954/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/1200x1060/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/1440x1272/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/1920x1695/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/2048x1808/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/2400x2119/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1282x1132/2400x2119/filters:focal(641x566:642x567):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg"/></noscript></span></div></div></figure></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>When you launch Glaze, you’ll need to give it some time to download the resources it needs to protect your work.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: Sand Lab, University of Chicago</cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">One of the most notable anti-training tools is <a href="https://glaze.cs.uchicago.edu/what-is-glaze.html">Glaze</a>, a project launched by a team out of the University of Chicago. The free-to-use tool works as a kind of cloak, making pixel-level changes to images that confuse AI software trying to read them. Real people can’t typically see these alterations on highly-detailed images so there’s little impact on the human viewing experience, but AI image generators that are fed the same materials will recognize it as something else entirely — meaning anyone who tries to replicate its specific art style will be unable to do so.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Glaze is available for <a href="https://glaze.cs.uchicago.edu/download.html">Windows or macOS</a>. There are GPU and non-GPU versions available for Windows, but running the GPU variant specifically requires <a href="https://developer.nvidia.com/cuda-gpus">an Nvidia GPU from this list</a> with at least 3.6GB of memory. (The developers say Glaze generally uses around 5GB of system memory to run.) Using it is straightforward: at first launch, the application will automatically download a number of machine learning libraries and other resources it needs to cloud your images. When that’s complete, head to the “Select” box at the top left and choose which images on your computer you’d like to Glaze. These can be uploaded in batches, so it’s much quicker than making individual opt-out requests.</p></div><div class="duet--article--article-body-component clear-both block"><div class="duet--article--image-comparison relative my-40"><div class="relative inline-block overflow-hidden"><div class="absolute top-2/4 z-20  h-[50px] w-[9px] cursor-move rounded-lg bg-white" style="left:calc(50% - 6px)"></div><div class="absolute inset-0 z-10 cursor-move overflow-hidden border-r-2 border-white" style="width:50%"><div class="relative h-full w-[calc(100vw-2rem)] max-w-none md:w-article-body"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A green and purple illustration of an ominous floating figure" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" class="object-left" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A green and purple illustration of an ominous floating figure" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="object-left" sizes="(max-width: 1023px) 100vw, 600px" srcSet="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 376w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 384w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 415w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 480w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 540w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 640w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 750w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 828w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 1080w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 1200w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 1440w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 1920w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 2048w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 2400w" src="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg"/></noscript></span></div></div><div class="relative w-[calc(100vw-2rem)] md:w-article-body" style="padding-bottom:87.5%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="An image that’s had Glaze AI protection applied at max intensity." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="An image that’s had Glaze AI protection applied at max intensity." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 376w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 384w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 415w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 480w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 540w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 640w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 750w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 828w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 1080w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 1200w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 1440w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 1920w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 2048w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg 2400w" src="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg"/></noscript></span></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>You may want to experiment with the strength of the Glaze application — on simple illustrations like this, Glazing at max intensity can distort the results.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: Jess Weatherbed / The Verge and Image: Jess Weatherbed / The Verge</cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">You can then adjust the intensity of the Glaze cloaking from “very low” to “very high,” with the latter offering greater protection against AI but increasing the possibility of changes being visible to humans. Render quality, another option, determines the overall quality of the finished image — higher-quality rendering looks better and offers greater protection but will also take much longer to process. Generally, the finished result should look virtually unchanged from your original. But a close inspection will reveal tiny differences, almost like a textured wash has been applied to it.</p></div><div class="duet--article--article-body-component"><h4 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading my-20 font-polysans text-24 font-light leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-26 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>Nightshade</strong></h4></div><div class="duet--article--article-body-component clear-both block"><div class="my-9"><div class="transition-all duration-300 ease-in-out"><div class="fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0" role="button" aria-label="Close" tabindex="0"></div><div role="button" aria-label="Zoom" tabindex="0" class="visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:84.48540706605223%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot of the Nightshade launcher." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot of the Nightshade launcher." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/376x318/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/384x324/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/415x351/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/480x406/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/540x456/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/640x541/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/750x634/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/828x700/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/1080x912/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/1200x1014/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/1440x1217/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/1920x1622/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/2048x1730/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/2400x2028/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/2400x2028/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg"/></noscript></span></div></div></figure></div><div class="z-1 w-full hidden"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:84.48540706605223%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot of the Nightshade launcher." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot of the Nightshade launcher." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/376x318/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/384x324/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/415x351/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/480x406/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/540x456/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/640x541/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/750x634/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/828x700/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/1080x912/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/1200x1014/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/1440x1217/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/1920x1622/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/2048x1730/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/2400x2028/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1302x1100/2400x2028/filters:focal(651x550:652x551):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg"/></noscript></span></div></div></figure></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>Nightshade shares a very similar UI to Glaze, which is unsurprising considering it’s being developed by the same team.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: Sand Lab, University of Chicago</cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><a href="https://nightshade.cs.uchicago.edu/downloads.html">Nightshade</a>, from the team behind Glaze, takes a similar but more extreme approach. Images passed through this cloaking tool are actually intended to “poison” generative AI models that train on them, sabotaging the outputs for text prompts. If you upload a batch of dog pictures, for instance, Nightshade is supposed to fool models into seeing some other object like cars — rather than just confusing the model like Glaze does. The idea is that if a model takes in enough confusing images, it will start building rules based on them, so any dog-related prompt might become distorted with wheels and windshields. </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">You can’t specify what you’d like your poisoned images to masquerade as because Nightshade is built around algorithms that can’t accommodate that kind of personalization. If you want a better insight into how it works, check out this <a href="https://towardsdatascience.com/how-nightshade-works-b1ae14ae76c3">breakdown provided by data scientist Dorian Drost</a>.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Like Glaze, Nightshade applies a filter-like film over the image that shouldn’t massively impact the human viewing experience, depending on the intensity of the protection layer and how detailed the original art is. (You can apply both Glaze and Nightshade to images without them interfering with each other.) Nightshade is also available for Windows and macOS systems, though only machines running Apple’s own silicon are supported for the latter.</p></div><div class="duet--article--article-body-component clear-both block"><div class="duet--article--image-comparison relative my-40"><div class="relative inline-block overflow-hidden"><div class="absolute top-2/4 z-20  h-[50px] w-[9px] cursor-move rounded-lg bg-white" style="left:calc(50% - 6px)"></div><div class="absolute inset-0 z-10 cursor-move overflow-hidden border-r-2 border-white" style="width:50%"><div class="relative h-full w-[calc(100vw-2rem)] max-w-none md:w-article-body"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A green and purple illustration of an ominous floating figure" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" class="object-left" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A green and purple illustration of an ominous floating figure" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="object-left" sizes="(max-width: 1023px) 100vw, 600px" srcSet="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 376w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 384w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 415w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 480w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 540w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 640w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 750w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 828w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 1080w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 1200w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 1440w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 1920w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 2048w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg 2400w" src="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg"/></noscript></span></div></div><div class="relative w-[calc(100vw-2rem)] md:w-article-body" style="padding-bottom:87.5%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="An ominous floating figure in a destroyed city." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="An ominous floating figure in a destroyed city." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 376w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 384w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 415w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 480w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 540w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 640w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 750w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 828w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 1080w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 1200w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 1440w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 1920w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 2048w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg 2400w" src="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg"/></noscript></span></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>At default intensity, Nightshade should produce similar-looking results to Glazed images. The poisoned results on the right are nearly identical to our Glaze tests.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: Jess Weatherbed / The Verge and Image: Jess Weatherbed / The Verge</cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Most of the overall process is the same as Glaze: you wait for the tool to download machine learning libraries, upload your work, and set the intensity and rendering options. But there’s one extra step. Nightshade will analyze the images and fill the “current tag” field with a single-word description identifying the content, like “dog” or “girl.” For the poisoning effect to work, this needs to be accurate — so you can change it if it’s wrong. Then, when you upload the images online, make sure that single-word tag is included in the metadata or alt text. </p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Some generative AI advocates argue Nightshade won’t be much of a hindrance. AI systems are trained on <em>truly </em>vast amounts of data, so you’d need a lot of poisoning to affect any given prompt. And companies can develop workarounds that detect Nightshade. But most of these workarounds only filter out images that use it, rather than removing the protections — so the end result is just having art excluded from the training data, which is still a win. The Glaze project team is also continually working to update the applications to close any loopholes that are being exploited by workarounds.</p></div><div class="duet--article--article-body-component"><h4 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading my-20 font-polysans text-24 font-light leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-26 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>Mist</strong></h4></div><div class="duet--article--article-body-component clear-both block"><div class="my-9"><div class="transition-all duration-300 ease-in-out"><div class="fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0" role="button" aria-label="Close" tabindex="0"></div><div role="button" aria-label="Zoom" tabindex="0" class="visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:47.02886247877759%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot of the Mist launcher." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot of the Mist launcher." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/376x177/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/384x181/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/415x195/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/480x226/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/540x254/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/640x301/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/750x353/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/828x389/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/1080x508/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/1200x564/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/1440x677/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/1920x903/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/2048x963/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/2400x1129/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/2400x1129/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg"/></noscript></span></div></div></figure></div><div class="z-1 w-full hidden"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:47.02886247877759%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot of the Mist launcher." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot of the Mist launcher." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/376x177/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/384x181/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/415x195/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/480x226/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/540x254/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/640x301/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/750x353/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/828x389/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/1080x508/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/1200x564/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/1440x677/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/1920x903/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/2048x963/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/2400x1129/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1767x831/2400x1129/filters:focal(884x416:885x417):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg"/></noscript></span></div></div></figure></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>Mist can be tricky to set up, but its another option to try if you’re unhappy with results from Glaze and Nightshade.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: Mist</cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><a href="https://github.com/mist-project">Mist</a> is a “preprocessing tool” developed by Psyker Group that, like Glaze and Nightshade, also prevents generative AI applications from effectively imitating a creator’s unique style and works. Mist’s approach is more akin to watermarking images. If an AI model is trained on “misted images,” any attempt to mimic them will see the output completely covered in visual distortions that render it unfit for most purposes and generally unpleasant to look at.</p></div><div class="duet--article--article-body-component clear-both block"><div class="my-9"><div class="transition-all duration-300 ease-in-out"><div class="fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0" role="button" aria-label="Close" tabindex="0"></div><div role="button" aria-label="Zoom" tabindex="0" class="visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:100%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="An AI-generated image covered in visual distortions." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="An AI-generated image covered in visual distortions." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/376x376/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/384x384/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/415x415/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/480x480/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/540x540/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/640x640/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/750x750/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/828x828/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/1080x1080/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/1200x1200/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/1440x1440/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/1920x1920/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/2048x2048/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/2400x2400/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/2400x2400/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg"/></noscript></span></div></div></figure></div><div class="z-1 w-full hidden"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:100%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="An AI-generated image covered in visual distortions." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="An AI-generated image covered in visual distortions." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/376x376/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/384x384/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/415x415/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/480x480/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/540x540/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/640x640/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/750x750/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/828x828/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/1080x1080/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/1200x1200/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/1440x1440/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/1920x1920/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/2048x2048/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/2400x2400/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:512x512/2400x2400/filters:focal(256x256:257x257):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg"/></noscript></span></div></div></figure></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>Here’s an example of what’s produced by AI generation tools that reference Misted images.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: Mist / <a href="https://www.artstation.com/ase?continueFlag=726f268c053ad33ebabc8eafed6efef4">Sang Delan</a></cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Elements of the original image can still be seen in some of these outputs, like similarities in photography or art styles, but the chaotic, noisy filter over the generated image isn’t something that can be easily corrected. Mist requires a graphics card with at least 6GB of VRAM, which isn’t a lot of computational resources, but it’s still greater than the 3.6GB Glaze requires. Mist has been open-sourced on GitHub to allow developers to build their own tools around it, and its creators have committed to offering long-term support and continuously improving its function.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">There are currently two ways for non-developers to use Mist. Windows PC users running an Nvidia GPU can download Mist for free via <a href="https://drive.google.com/drive/folders/1vg8oK2BUOla5adaJcFYx5QMq0-MoP8kk?usp=drive_link">this Google Drive package</a>. The software doesn’t require installation and can be used almost immediately after downloading — though it’s a little finicky to set up if you lack any coding or development experience.</p></div><div class="duet--article--article-body-component clear-both block"><div class="duet--article--image-comparison relative my-40"><div class="relative inline-block overflow-hidden"><div class="absolute top-2/4 z-20  h-[50px] w-[9px] cursor-move rounded-lg bg-white" style="left:calc(50% - 6px)"></div><div class="absolute inset-0 z-10 cursor-move overflow-hidden border-r-2 border-white" style="width:50%"><div class="relative h-full w-[calc(100vw-2rem)] max-w-none md:w-article-body"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" class="object-left" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" class="object-left" sizes="(max-width: 1023px) 100vw, 600px" srcSet="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 376w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 384w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 415w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 480w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 540w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 640w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 750w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 828w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 1080w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 1200w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 1440w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 1920w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 2048w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png 2400w" src="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png"/></noscript></span></div></div><div class="relative w-[calc(100vw-2rem)] md:w-article-body" style="padding-bottom:100%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 376w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 384w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 415w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 480w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 540w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 640w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 750w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 828w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 1080w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 1200w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 1440w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 1920w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 2048w, https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png 2400w" src="https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png"/></noscript></span></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>Misting images can also produce a faint, swirling filter over the results, but like Glaze, it&#39;s harder to spot on detailed art or photography.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: Mist / <a href="https://www.artstation.com/ase?continueFlag=726f268c053ad33ebabc8eafed6efef4">Sang Delan</a> and Image: Mist / <a href="https://www.artstation.com/ase?continueFlag=726f268c053ad33ebabc8eafed6efef4">Sang Delan</a></cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><a href="https://github.com/mist-project/mist-v2/blob/main/docs/Handbook-Free-version.md">A detailed handbook</a> is available that will walk you through the entire process, along with a community Discord channel for troubleshooting. First, make sure you’ve installed the <a href="https://dotnet.microsoft.com/en-us/download/dotnet/thank-you/runtime-desktop-7.0.13-windows-x64-installer">.NET desktop runtime</a>. When that’s done, you just select the “ENG” file inside Google Drive and download the zipped Mist_V2 folder within it. Create a new folder called “IMG” in mist-v2 &gt; src &gt; data &gt;. Drop any images that you plan on Misting into the new folder when completed. Then, go back to the main folder (which should be titled “mist-v2_gui_free_version”) and run the Mist GUI booter. Mist allows you to adjust the strength of protection applied to images and select between using your device’s GPU or CPU, which may prove useful if you’re running old or inefficient hardware.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">For anyone who’s using macOS or doesn’t possess an Nvidia GPU, you can also run Mist via <a href="https://colab.google/">Colab Notebook</a>, a cloud-based Jupyter Notebook environment that runs in your web browser. Detailed instructions for how to do this <a href="https://colab.research.google.com/drive/1k5tLNsWTTAkOlkl5d9llf93bJ6csvMuZ?usp=sharing">are available here</a>, but it’s a much more complicated process to set up than its Windows equivalent. Glaze and Nightshade, generally, will be much easier to navigate for folks who aren&#39;t familiar with coding processes.</p></div><div class="duet--article--article-body-component"><h4 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading my-20 font-polysans text-24 font-light leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-26 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>Kin.Art</strong></h4></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><a href="https://kin.art/">Kin.Art</a> isn’t so much an AI protection tool as it is an <em>entire</em> portfolio platform that artists can use to host and sell their work. It goes beyond just banning AI-generated works — though that’s appreciated, given the backlash against sites like <a href="/2022/11/15/23449036/deviantart-ai-art-dreamup-training-data-controversy">DeviantArt</a> and <a href="/2022/12/23/23523864/artstation-removing-anti-ai-protest-artwork-censorship">ArtStation</a> — and actively makes AI scraping and training harder.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white"><a href="https://kin.art/press/ai-protection">Kin.Art uses two different techniques</a> to thwart AI companies. The first is image segmentation, which is used to break apart images and muddle them into something unrecognizable. It’s undetectable to human eyes but disrupts generative AI models from being able to read the image. This visual scrambling will also be present if anyone attempts to save or download the image, though it doesn’t block manual screenshots. The second technique involves scrambling the metadata, like title and description, so any labels the AI model reads won’t accurately reflect the content.</p></div><div class="duet--article--article-body-component clear-both block"><div class="my-9"><div class="transition-all duration-300 ease-in-out"><div class="fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0" role="button" aria-label="Close" tabindex="0"></div><div role="button" aria-label="Zoom" tabindex="0" class="visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:44.80874316939891%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot of the image uploader on Kin.Art." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot of the image uploader on Kin.Art." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/376x168/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/384x172/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/415x186/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/480x215/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/540x242/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/640x287/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/750x336/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/828x371/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/1080x484/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/1200x538/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/1440x645/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/1920x860/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/2048x918/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/2400x1075/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/2400x1075/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg"/></noscript></span></div></div></figure></div><div class="z-1 w-full hidden"><figure class="transition-all duration-300 ease-in-out lg:mx-0"><div><div class="duet--media--content-warning relative" style="padding-top:44.80874316939891%"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="A screenshot of the image uploader on Kin.Art." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="A screenshot of the image uploader on Kin.Art." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="(max-width: 1023px) 100vw, 744px" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/376x168/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/384x172/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/415x186/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/480x215/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/540x242/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/640x287/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/750x336/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/828x371/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/1080x484/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/1200x538/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/1440x645/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/1920x860/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/2048x918/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/2400x1075/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:915x410/2400x1075/filters:focal(458x205:459x206):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg"/></noscript></span></div></div></figure></div></div><div class="duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1"><figcaption class="duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63"><em>Kin.Art’s AI protections just require users to tick a box when uploading their works to the platform.</em></figcaption> <cite class="duet--article--dangerously-set-cms-markup inline not-italic text-gray-63 dark:text-gray-bd [&amp;&gt;a:hover]:text-gray-63 [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-bd dark:[&amp;&gt;a:hover]:shadow-underline-gray [&amp;&gt;a]:shadow-underline-gray-63 dark:[&amp;&gt;a]:text-gray-bd dark:[&amp;&gt;a]:shadow-underline-gray">Image: Kin.Art</cite></div></div></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">These protections are automatically applied on the Kin.Art platform, so you just need to create an account and upload your works to benefit from them, and that works like practically any social media platform. There are some neat creator-focused features included, like the ability to add a commission status to advertise your availability to accept requests, and you can link out to external platforms like social media pages directly on your user profile. You can toggle the protections on or off when uploading images, and the service is currently free to use. Instead, Kin.Art will start placing a 5 percent service fee on top of commissions made through the service in March.</p></div><div class="duet--article--article-body-component"><h3 class="duet--article--dangerously-set-cms-markup duet--article--standard-heading mb-20 mt-40 font-polysans text-26 font-medium leading-110 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple md:text-30 [&amp;&gt;a:hover]:shadow-highlight-franklin dark:[&amp;&gt;a:hover]:shadow-highlight-franklin [&amp;&gt;a]:shadow-underline-black dark:[&amp;&gt;a]:shadow-underline-white"><strong>What about music, writing, and other media?</strong></h3></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Our guide covers what protections are available for image-based art largely because that format has more tools available than other mediums, and the opting-out processes tend to be clearer (when they are available). That said, creatives in other fields, like writing, voice acting, and music, are also fighting to protect their work. It’s much harder to disrupt how AI models are trained on this kind of data without noticeably affecting the original content, but there are still precautions you can take to reduce the risk of it being swept into AI training datasets.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">As with art, always check the user terms of the hosting platform to which you’re uploading your works. Services will generally disclose if they’re handing platform data over to third parties for AI training or using it to develop their own models — if there’s no explicit opt-out process, you may unknowingly be giving consent simply by signing up. Instead, look for platforms like <a href="https://blog.medium.com/default-no-to-ai-training-on-your-stories-abb5b4589c8">Medium</a>, which have committed to blocking attempts to use content hosted on the site to train AI models. If you’re hosting work on your own site, you can also do things like block GPTBot to avoid pages being scraped.</p></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">Some rights distributors have made similar commitments, like the <a href="https://societe.sacem.fr/en/news/our-society/sacem-favour-virtuous-transparent-and-fair-ai-exercises-its-right-opt-out">Society of Authors, Composers and Publishers of Music</a> (SACEM) — a French association that announced it was exercising its right to opt out on behalf of its members last year. Another tip for writers, courtesy of the Authors Guild, is to place a short warning notice on your published works that clearly states you don’t consent to it being used to train AI. This is the example provided by the guild:</p></div><div class="duet--article--article-body-component"><blockquote class="duet--article--blockquote jzbdts2"><p class="duet--article--dangerously-set-cms-markup jzbdtsa jzbdts0">“NO AI TRAINING: Without in any way limiting the author’s [and publisher’s] exclusive rights under copyright, any use of this publication to “train” generative artificial intelligence (AI) technologies to generate text is expressly prohibited. The author reserves all rights to license uses of this work for generative AI training and development of machine learning language models.”</p></blockquote></div><div class="duet--article--article-body-component"><p class="duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white">These warnings serve to clearly flag that the work isn’t freely available to use, which may be useful in any future lawsuits raised against companies that violate your ownership rights. If bots scraping web data are also intuitive enough to filter out results with such warnings then this could also <em>potentially</em> provide another layer of proactive protection, but there’s little evidence to show how many actually observe such information. Otherwise, performers and writers will need to submit copyright takedown notices to AI companies if they believe their works have been infringed.</p></div></div><div class="mb-40 mt-30"><button class="duet--article--comments-button group inline-flex h-40 w-full items-center justify-center rounded-[2px] border-[1px] border-solid border-blurple font-polysans-mono text-11 font-light uppercase tracking-12 text-blurple hover:bg-blurple hover:text-white md:w-auto md:px-30"><svg class="mr-10 inline pt-2" width="12" height="14" fill="none" viewBox="0 0 12 12" stroke-width="1px" xmlns="http://www.w3.org/2000/svg"><title>Comments</title><path d="M2.4 9.1h-.207l-.147.146L.5 10.793V1.2c0-.384.316-.7.7-.7h9.6c.384 0 .7.316.7.7v7.2c0 .384-.316.7-.7.7H2.4Z" stroke="currentColor"></path></svg><span class="coral-count" data-coral-id="1c995675-e913-450a-abef-091ac7bb185a" data-coral-url="https://www.theverge.com/24063327/ai-art-protect-images-copyright-generators"></span></button></div></div><div class="duet--layout--rail max-h-[8000px] max-w-[300px] hidden z-0 text-white lg:flex lg:flex-1 lg:flex-col"><div class="flex-auto"><div style="min-height:250px;min-width:300px;position:sticky;top:90px;margin-bottom:40px" class="_1gsaw2w0 _1gsaw2w5" data-concert="medium_rectangle_variable"></div></div><div class="flex-auto"><div class="duet--recirculation--list-breaker-standard sticky m-auto my-50 rounded-[4px] lg:mb-40 lg:mt-0 bg-white top-90 w-mobile-breaker p-20"><div class="absolute right-[-25px] top-0 h-full rotate-180 whitespace-nowrap text-center font-manuka text-[168px] font-ultra leading-100 text-franklin opacity-50" style="writing-mode:vertical-rl;text-orientation:sideways">Most Popular</div><div class="relative z-10 mb-20 flex justify-between font-polysans text-11 font-medium uppercase tracking-15 text-blurple">Most Popular</div><ol class="styled-counter styled-counter-standard md:w-full w-full"><li class="leading-120 text-blurple"><a class="text-black hover:text-blurple" href="/2024/5/6/24150274/tesla-layoffs-employee-fourth-week-elon-musk-ev-demand"><h2 class="mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1">More Tesla employees laid off as bloodbath enters its fourth week</h2></a><hr class="-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple"/></li><li class="leading-120 text-blurple"><a class="text-black hover:text-blurple" href="/2024/5/6/24150573/sonos-ace-headphones-reveal-leak-wireless"><h2 class="mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1">These are the upcoming Sonos Ace wireless headphones</h2></a><hr class="-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple"/></li><li class="leading-120 text-blurple"><a class="text-black hover:text-blurple" href="/2024/5/5/24148223/arc-browser-windows-claude-sofa-bose-beats-hacks-coffee-installer"><h2 class="mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1">The best new browser for Windows</h2></a><hr class="-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple"/></li><li class="leading-120 text-blurple"><a class="text-black hover:text-blurple" href="/2024/5/5/24147995/apple-siri-ai-research-chatbot-creativity"><h2 class="mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1">Better Siri is coming: what Apple’s research says about its AI plans</h2></a><hr class="-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple"/></li><li class="leading-120 text-blurple"><a class="text-black hover:text-blurple" href="/2024/5/6/24150198/apple-pencil-pro-japan-website-code-leak"><h2 class="mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1">‘Apple Pencil Pro’ spotted in code on Apple’s Japanese site</h2></a><hr class="-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple"/></li></ol></div></div><div class="flex-auto"><div class="sticky top-90"><div style="min-height:250px;min-width:300px;margin-bottom:40px" class="_1gsaw2w0 _1gsaw2w5" data-concert="medium_rectangle_gamestop"></div><div style="min-height:100px;min-width:300px;padding-bottom:40px" class="_1gsaw2w0 _1gsaw2w5" data-concert="connatix_right_rail"></div></div></div><div class="flex-auto"><aside class="sticky top-90 pb-40 duet--article--rail"><div class="mb-8 hidden md:block"><div><form class=""><div class="duet--cta--newsletter flex w-full flex-col border-t px-12 pt-16 font-polysans-mono text-14 font-light leading-130 -tracking-2 md:text-15 text-blurple border-blurple"><div class="mb-10"><h2 class="inline font-medium">Verge Deals</h2><p class="inline"> / <span class="duet--article--dangerously-set-cms-markup">Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.</span></p></div><div><fieldset><div class="mb-4 flex"><label class="sr-only" for="email">Email (required)</label><input id="email" type="email" name="email" placeholder="Enter your email" class="mr-8 rounded-sm border px-10 font-polysans text-15 font-light focus:outline-none w-full placeholder:text-blurple bg-white"/><button type="submit" class="whitespace-nowrap rounded-sm border px-18 py-12 text-12 font-medium uppercase tracking-12 no-underline border-blurple hover:bg-blurple hover:text-white">Sign up</button></div></fieldset><div class="mt-2 font-polysans text-11 leading-110">By submitting your email, you agree to our<!-- --> <a href="https://www.voxmedia.com/legal/terms-of-use" class="underline">Terms</a> and <a href="https://www.voxmedia.com/legal/privacy-notice" class="underline">Privacy Notice</a>. <!-- -->This site is protected by reCAPTCHA and the Google<!-- --> <a href="https://policies.google.com/privacy" class="underline">Privacy Policy</a> <!-- -->and<!-- --> <a href="https://policies.google.com/terms" class="underline">Terms of Service</a> <!-- -->apply.</div></div></div></form></div></div></aside></div><div class="duet--ad--native-ad-rail hidden flex-auto" data-native-ad-id="container"><div class="sticky top-90 mb-40"><div class="hidden"><div class="dynamic-native-ad-native_ad_latest"></div></div><div class="flex items-center text-black"><div class="w-[210px]"><div class="mb-6"><span class="border-b border-b-blurple pb-6 font-polysans text-10 font-medium uppercase leading-140 tracking-15 text-gray-5a">From our sponsor</span></div><h3 class="font-polysans text-20 leading-110 tracking-1"><a data-native-ad-id="title" href="http://theverge.com" class="hover:shadow-underline-black"></a></h3><a href="http://theverge.com"><div class="mb-4 flex items-center text-gray-31"><span data-native-ad-id="preamble" class="font-polysans text-10 font-medium uppercase leading-140 tracking-15">Advertiser Content From</span><img data-native-ad-id="sponsored_logo" class="max-h-[24px] max-w-[120px] pl-8" alt="Sponsor logo" src="/icons/native-ad-placeholder.png"/></div></a></div><div><img data-native-ad-id="thumbnail" class="max-w-[75px] pl-8" alt="Sponsor thumbnail" src="/icons/native-ad-placeholder.png"/></div></div></div></div><div class="flex-auto"><div style="min-height:250px;min-width:300px;position:sticky;top:90px;margin-bottom:40px" class="_1gsaw2w0 _1gsaw2w5" data-concert="btf_medium_rectangle_variable_article"></div></div></div><div style="position:absolute;top:8200px;right:10px;bottom:40px" class="_1gsaw2w0 _1gsaw2w5" data-concert="btf_medium_rectangle_variable_feature_extended_sticky"></div></div></article></main><div style="min-height:250px;min-width:300px;margin-bottom:40px" class="_1gsaw2w0 _1gsaw2w4" data-concert="medium_rectangle_gamestop"></div><section class="duet--article--more-stories bg-franklin px-20 pb-16 pt-30 lg:pb-36 lg:pt-50"><div class="md:mx-auto md:max-w-container-md lg:max-w-container-lg"><h2 class="mb-16 font-polysans-mono text-16 font-light leading-120 tracking-2 text-gray-13">More from<!-- --> <a class="border-b font-medium hover:border-blurple hover:text-blurple" href="/tech">Tech</a></h2><ul class="divide-y"><li class="flex items-start border-black/30 py-16 lg:items-center"><div class="relative ml-10 mr-20 aspect-square h-[60px] w-[60px] [&amp;&gt;span]:rounded-[2px]"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="Stock image illustration featuring the Nintendo logo stamped in black on a background of tan, blue, and black color blocking." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="Stock image illustration featuring the Nintendo logo stamped in black on a background of tan, blue, and black color blocking." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="100vw" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/376x376/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/415x415/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/480x480/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/540x540/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/640x640/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/750x750/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/828x828/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1080x1080/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1200x1200/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1440x1440/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1920x1920/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2048x2048/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2400x2400/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2400x2400/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg"/></noscript></span></div><h3 class="font-polysans text-22 font-medium leading-100 -tracking-1 lg:text-34"><a class="hover:shadow-underline-black" href="/2024/2/16/24075174/switch-2-launch-date-rumor-q1-2025">The Nintendo Switch 2 will now reportedly arrive in 2025 instead of 2024</a></h3></li><li class="flex items-start border-black/30 py-16 lg:items-center"><div class="relative ml-10 mr-20 aspect-square h-[60px] w-[60px] [&amp;&gt;span]:rounded-[2px]"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="Apple AirPods Pro" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="Apple AirPods Pro" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="100vw" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/376x376/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/415x415/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/480x480/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/540x540/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/640x640/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/750x750/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/828x828/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1080x1080/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1200x1200/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1440x1440/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1920x1920/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2048x2048/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2400x2400/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2400x2400/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg"/></noscript></span></div><h3 class="font-polysans text-22 font-medium leading-100 -tracking-1 lg:text-34"><a class="hover:shadow-underline-black" href="/24072881/best-presidents-day-sales-deals-2024-apple-tvs-gaming-headphones-smartwatches">The best Presidents Day deals you can already get</a></h3></li><li class="flex items-start border-black/30 py-16 lg:items-center"><div class="relative ml-10 mr-20 aspect-square h-[60px] w-[60px] [&amp;&gt;span]:rounded-[2px]"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="Figma CEO Dylan Field." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="Figma CEO Dylan Field." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="100vw" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/376x376/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/415x415/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/480x480/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/540x540/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/640x640/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/750x750/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/828x828/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1080x1080/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1200x1200/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1440x1440/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1920x1920/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2048x2048/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2400x2400/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2400x2400/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg"/></noscript></span></div><h3 class="font-polysans text-22 font-medium leading-100 -tracking-1 lg:text-34"><a class="hover:shadow-underline-black" href="/2024/2/16/24075126/figma-ceo-dylan-field-interview-after-adobe">Interview: Figma’s CEO on life after the company’s failed sale to Adobe</a></h3></li><li class="flex items-start border-black/30 py-16 lg:items-center"><div class="relative ml-10 mr-20 aspect-square h-[60px] w-[60px] [&amp;&gt;span]:rounded-[2px]"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0"><img alt="An image announcing Vudu’s rebranding to Fandango at Home." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover"/><noscript><img alt="An image announcing Vudu’s rebranding to Fandango at Home." loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" sizes="100vw" srcSet="https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/376x376/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/415x415/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/480x480/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/540x540/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/640x640/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/750x750/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/828x828/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/1080x1080/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/1200x1200/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/1440x1440/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/1920x1920/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/2048x2048/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/2400x2400/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x716/2400x2400/filters:focal(540x358:541x359):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg"/></noscript></span></div><h3 class="font-polysans text-22 font-medium leading-100 -tracking-1 lg:text-34"><a class="hover:shadow-underline-black" href="/2024/2/16/24075041/vudu-fandango-at-home-rebranding-new-name">Vudu’s name is changing to ‘Fandango at Home’</a></h3></li><li class="duet--ad--native-ad-linkset hidden py-16" data-native-ad-id="container"><div class="hidden"><div class="dynamic-native-ad-native_ad_linkset_link"></div></div><a href="http://theverge.com"><div class="mb-4 flex items-center"><span class="font-polysans text-11 uppercase leading-140 tracking-15" data-native-ad-id="byline">Advertiser Content From</span><img data-native-ad-id="logo" class="max-h-[24px] max-w-[120px] pl-8" alt="Sponsor logo" src="/icons/native-ad-placeholder.png"/></div></a><h3 class="font-polysans text-22 font-medium leading-100 -tracking-1 lg:text-34"><a href="http://theverge.com" class="hover:shadow-underline-black" data-native-ad-id="title"></a></h3></li></ul></div></section></div></div><footer class="duet--navigation--footer bg-gray-13 pb-70 pt-20 text-center font-polysans text-10 uppercase leading-[19px] tracking-[0.1em] text-white md:pt-40 lg:text-left lg:text-12 lg:leading-[21px]"><div class="mx-auto max-w-container-lg"><a href="/" class="mx-auto mb-24 inline-block w-full overflow-hidden lg:mx-0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 309 70" role="img" class="relative mx-auto w-[calc(100vw-40px)] fill-white md:static md:w-[204px] lg:ml-0 lg:w-[398px]" width="100%" height="100%" fill="none"><title>The Verge</title><desc>The Verge logo.</desc><path d="m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z"></path></svg></a><div class="flex flex-col lg:flex-row"><div class="mb-4 sm:mb-0 sm:basis-1/3 lg:basis-2/3"><div class="flex flex-col"><ul class="mb-16 flex list-inside flex-wrap justify-center pl-20 lg:justify-start"><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:hidden"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/legal/terms-of-use">Terms of Use</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/legal/privacy-notice">Privacy Notice</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/legal/cookie-policy">Cookie Policy</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/contact">Do Not Sell Or Share My Personal Info</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/pages/licensing">Licensing FAQ</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/legal/accessibility">Accessibility</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://status.voxmedia.com">Platform Status</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/pages/how-we-rate">How We Rate and Review Products</a></li></ul><ul class="mb-16 flex list-inside flex-wrap justify-center pl-20 lg:justify-start"><li class="mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:hidden"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/contact-the-verge">Contact</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/c/tech/22579076/how-to-tip-the-verge-email-signal-and-more">Tip Us</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/community-guidelines">Community Guidelines</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/about-the-verge">About</a></li><li class="mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="/ethics-statement">Ethics Statement</a></li></ul></div></div><div class="lg:basis-1/3"><p class="mb-8 font-bold uppercase">The Verge is a vox media network</p><ul class="mb-8 flex list-inside flex-wrap justify-center lg:justify-start"><li class="mr-8 list-none leading-5 before:mr-8 before:inline-block before:text-hot-brick before:hidden"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://www.voxmedia.com/vox-advertising">Advertise with us</a></li><li class="mr-8 list-none leading-5 before:mr-8 before:inline-block before:text-hot-brick before:content-[&#x27;/&#x27;]"><a rel="nofollow" class="hover:shadow-underline-inherit" href="https://jobs.voxmedia.com">Jobs @ Vox Media</a></li></ul><p class="font-fkroman tracking-12 text-white">© <!-- -->2024<!-- --> <a rel="nofollow" href="https://www.voxmedia.com">Vox Media</a>, LLC. All Rights Reserved</p></div></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"hydration":{"responses":[{"operationName":"StandardArticleLayoutQuery","variables":{"uid":"Entry:1c995675-e913-450a-abef-091ac7bb185a","communityId":372},"data":{"entryRevision":{"__typename":"Entry","communityGroups":[{"slug":"front-page","isInternal":false,"hubPage":{"slug":"","uid":"HubPage:270"},"isDisclaimer":false,"description":null,"name":"Front Page","url":"https://www.theverge.com/","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The Nintendo Switch 2 will now reportedly arrive in 2025 instead of 2024","uid":"Entry:beee2677-e972-4e4e-898c-fa9f20cfc826","url":"https://www.theverge.com/2024/2/16/24075174/switch-2-launch-date-rumor-q1-2025","author":{"fullName":"Ash Parrish"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/lA9CG498doJGjG9JOisq1_T8jow=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/0mSe0c0D5D_NAUpnNO9RfWG7yqs=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg","asset":{"title":"Stock image illustration featuring the Nintendo logo stamped in black on a background of tan, blue, and black color blocking."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Nintendo","slug":"nintendo","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The best Presidents Day deals you can already get","uid":"Entry:ae3462ed-d729-4045-b0ee-fa4a4cc6cd0f","url":"https://www.theverge.com/24072881/best-presidents-day-sales-deals-2024-apple-tvs-gaming-headphones-smartwatches","author":{"fullName":"Quentyn Kennemer"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/44HX0exmF1grR1zLh7d_8sauDaA=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/m1tVM4z2Whd6IFJ-Vo8SNn_oMoY=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg","asset":{"title":"Apple AirPods Pro"},"caption":{"plaintext":"There’s plenty of tech on sale for Presidents Day, from AirPods to OLED TVs and everything in between."}},"promoImage":null,"communityGroups":[{"name":"Deals","slug":"good-deals","hubPage":{"uid":"HubPage:17413"},"isInternal":false,"isStarred":false},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Logitech","slug":"logitech","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Smart Home","slug":"smart-home","hubPage":{"uid":"HubPage:279"},"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"TVs","slug":"televisions","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Wearable","slug":"wearables","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Headphones","slug":"headphone","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Laptops","slug":"laptops","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"PC Gaming","slug":"pc-gaming","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Cameras and Photography","slug":"photography","hubPage":{"uid":"HubPage:280"},"isInternal":false,"isStarred":false},{"name":"Mobile","slug":"mobile","hubPage":{"uid":"HubPage:282"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Interview: Figma’s CEO on life after the company’s failed sale to Adobe","uid":"Entry:fdc979c4-8ca1-4529-9b87-73ff4e9fc771","url":"https://www.theverge.com/2024/2/16/24075126/figma-ceo-dylan-field-interview-after-adobe","author":{"fullName":"Alex Heath"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/_h6TOd1_tIgIDNFyrkYYvh_dn2A=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/GAN_VXedqCF0aB11s1jGNOkBgJQ=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","asset":{"title":"Figma CEO Dylan Field."},"caption":{"plaintext":"Figma CEO Dylan Field."}},"promoImage":null,"communityGroups":[{"name":"Command Line","slug":"command-line-newsletter","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Design","slug":"design","hubPage":{"uid":"HubPage:8137"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Adobe","slug":"adobe","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Vudu’s name is changing to ‘Fandango at Home’","uid":"Entry:fcb3c34d-db2e-4a74-bc4d-cb54ff107c67","url":"https://www.theverge.com/2024/2/16/24075041/vudu-fandango-at-home-rebranding-new-name","author":{"fullName":"Chris Welch"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/OfW7xmYlzZXLOKRrVJZn4j8QUwY=/0x0:1080x716/1080x716/filters:focal(540x358:541x359)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/DfDuP6neKkLLh9MLWj1y3SHqW94=/0x0:1080x716/100x100/filters:focal(540x358:541x359)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg","asset":{"title":"An image announcing Vudu’s rebranding to Fandango at Home."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Apps","slug":"apps","hubPage":{"uid":"HubPage:277"},"isInternal":false,"isStarred":false},{"name":"Streaming","slug":"streaming-wars","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Amazon — like SpaceX — claims the labor board is unconstitutional","uid":"Entry:0fa52d0e-c11f-4c47-a2fe-263bdccbc61e","url":"https://www.theverge.com/2024/2/16/24074954/amazon-labor-board-nlrb-unconstitutional","author":{"fullName":"Emma Roth"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/-DH_98tyCltbrWTMSUoI7BLSJ1g=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23935561/acastro_STK103__04.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/VMv_ykKU3cj2UPdBp71ECWSYPpI=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23935561/acastro_STK103__04.jpg","asset":{"title":"Illustration showing Amazon’s logo on a black, orange, and tan background, formed by outlines of the letter “A.”"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Amazon","slug":"amazon","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"SpaceX","slug":"spacex","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Space","slug":"space","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Science","slug":"science","hubPage":{"uid":"HubPage:6949"},"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP","uid":"EntryGroup:51"},{"slug":"how-to","isInternal":false,"hubPage":null,"isDisclaimer":false,"description":"It isn’t enough to have great new devices, apps, and games — you also have to know how to use them. Here at The Verge, we offer step-by-step how-tos for experienced and new users who are working with online, macOS, Windows, Chrome OS, iOS, and Android apps, services, phones, laptops, and other tools. From simple instructions on how to install and use new devices, to little-known strategies on how to take advantage of hidden features and the best methods for adding power or storage, we’ve got your technological back.","name":"How to","url":"https://www.theverge.com/how-to","isStarred":true,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How to make the most of Google Keep","uid":"Entry:5c5012b3-110d-43a8-a1fa-9c560b4d5c62","url":"https://www.theverge.com/24073806/google-keep-how-to-note-app","author":{"fullName":"David Nield"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/MCSLGI2GbkS8KmTwKhby7PZXxvg=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25287814/HT012_Google_Keep.png","variantUrl":"https://cdn.vox-cdn.com/thumbor/BCA6XyYcswWyRTufiBbQ9NsdM5Y=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25287814/HT012_Google_Keep.png","asset":{"title":"Vector collage showing different aspects of Google Keep."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"How to","slug":"how-to","hubPage":null,"isInternal":false,"isStarred":true},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Google","slug":"google","hubPage":{"uid":"HubPage:274"},"isInternal":false,"isStarred":false},{"name":"Apps","slug":"apps","hubPage":{"uid":"HubPage:277"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The best Fitbits for your fitness and health","uid":"Entry:6aed87d5-cc53-4ca6-8357-0e89eb6523ef","url":"https://www.theverge.com/22982833/best-fitbit-watch-fitness-tracker","author":{"fullName":"Victoria Song"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/M9nfDJY36uxIGHLRpKlQp1AswKI=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23324425/VRG_ILLO_5090_The_best_Fitbit_for_your_fitness_and_health.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/U1hNiwTYpzGcud--2DLnSAYBTcA=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23324425/VRG_ILLO_5090_The_best_Fitbit_for_your_fitness_and_health.jpg","asset":{"title":"The Fitbit Versa, Fitbit Luxe, Fitbit Charge 5, and Fitbit Ace 3 fitness trackers, on an orange and red background."},"caption":{"plaintext":"Fitbit makes an array of fitness trackers, from basic fitness bands to full-fledged smartwatches, though the best Fitbit smartwatch isn’t technically a Fitbit."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Wearable","slug":"wearables","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Fitness","slug":"fitness-trackers","hubPage":null,"isInternal":false,"isStarred":false},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"How to","slug":"how-to","hubPage":null,"isInternal":false,"isStarred":true},{"name":"Featured Stories","slug":"featured-story","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Buying Guide","slug":"this-is-my-next","hubPage":{"uid":"HubPage:11570"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How to uninstall apps in macOS","uid":"Entry:832aaae4-be3b-40bd-9c72-24e42bf55584","url":"https://www.theverge.com/21286492/macos-uninstall-apps-how-to-macbook-apple","author":{"fullName":"Monica Chin"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/AMRtYvGyydEtgjcaF7Re5fNzN_4=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23952309/HT016_macOS_0003.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/zGXLfeqFMcTrXbw9t7GmhCBNpjQ=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23952309/HT016_macOS_0003.jpg","asset":{"title":"Floating MacBook Pro on wallpaper of Mac and Safari icons, with system preferences opened and the Monterey wallpaper."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"How to","slug":"how-to","hubPage":null,"isInternal":false,"isStarred":true},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"macOS","slug":"apple-mac-os","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How to check which apps are using the most data on an iPhone","uid":"Entry:f3ec0a6e-f6f7-44b5-a1bb-d19ed257e707","url":"https://www.theverge.com/24067924/iphone-ios-data-usage-apps-how-to","author":{"fullName":"David Nield"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/XRvhlvyWnOTePNU6sBBg2EEPwwU=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24008212/HT015_S_Haddad_ios_iphone_14_02.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/AhzMbQHIXZHt0u8nasY1Ik9I0_k=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24008212/HT015_S_Haddad_ios_iphone_14_02.jpg","asset":{"title":"iPhone with icons and illustrated background"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"How to","slug":"how-to","hubPage":null,"isInternal":false,"isStarred":true},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"iOS","slug":"apple-ios","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"Apps","slug":"apps","hubPage":{"uid":"HubPage:277"},"isInternal":false,"isStarred":false},{"name":"Mobile","slug":"mobile","hubPage":{"uid":"HubPage:282"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How to keep your art out of AI generators","uid":"Entry:1c995675-e913-450a-abef-091ac7bb185a","url":"https://www.theverge.com/24063327/ai-art-protect-images-copyright-generators","author":{"fullName":"Jess Weatherbed"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/rEFxnBqXkdcX0EQEVzn2uiJt4VQ=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/H6pfe4JGhly4okPLtKFoa7YAzEU=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","asset":{"title":"Vector collage showing aspects of AI art and protecting your artwork from being used to train AI."},"caption":{"plaintext":"Here’s how to opt-out where you can, and fight back where you can’t."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"How to","slug":"how-to","hubPage":null,"isInternal":false,"isStarred":true},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP","uid":"EntryGroup:475"},{"slug":"guidebook","isInternal":true,"hubPage":null,"isDisclaimer":false,"description":"","name":"guidebook","url":"https://www.theverge.com/guidebook","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The best Presidents Day deals you can already get","uid":"Entry:ae3462ed-d729-4045-b0ee-fa4a4cc6cd0f","url":"https://www.theverge.com/24072881/best-presidents-day-sales-deals-2024-apple-tvs-gaming-headphones-smartwatches","author":{"fullName":"Quentyn Kennemer"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/44HX0exmF1grR1zLh7d_8sauDaA=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/m1tVM4z2Whd6IFJ-Vo8SNn_oMoY=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg","asset":{"title":"Apple AirPods Pro"},"caption":{"plaintext":"There’s plenty of tech on sale for Presidents Day, from AirPods to OLED TVs and everything in between."}},"promoImage":null,"communityGroups":[{"name":"Deals","slug":"good-deals","hubPage":{"uid":"HubPage:17413"},"isInternal":false,"isStarred":false},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Logitech","slug":"logitech","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Smart Home","slug":"smart-home","hubPage":{"uid":"HubPage:279"},"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"TVs","slug":"televisions","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Wearable","slug":"wearables","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Headphones","slug":"headphone","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Laptops","slug":"laptops","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"PC Gaming","slug":"pc-gaming","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Cameras and Photography","slug":"photography","hubPage":{"uid":"HubPage:280"},"isInternal":false,"isStarred":false},{"name":"Mobile","slug":"mobile","hubPage":{"uid":"HubPage:282"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Sony’s noise-canceling WF-1000XM5 are nearly $80 off for Presidents Day","uid":"Entry:ae51fd1c-3fb1-471e-847d-c8e2e696cb09","url":"https://www.theverge.com/2024/2/16/24073856/sony-wf-wh-1000xm5-8bitdo-retro-mechanical-keyboard-xbox-series-s-deal-sale","author":{"fullName":"Sheena Vasani"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/lnaOZGJ71FRsfCP9IYIR5O6VwIQ=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24805959/DSCF2249_Enhanced_NR.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/Sycsd7mliX1lQjEvozAsTLGINYY=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24805959/DSCF2249_Enhanced_NR.jpg","asset":{"title":"A photo of Sony’s WF-1000XM5 earbuds."},"caption":{"plaintext":"Sony’s WF-1000XM5 offer better noise cancellation and sound than the prior model."}},"promoImage":null,"communityGroups":[{"name":"Deals","slug":"good-deals","hubPage":{"uid":"HubPage:17413"},"isInternal":false,"isStarred":false},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Sony","slug":"sony","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Headphones","slug":"headphone","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Nintendo","slug":"nintendo","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"Keyboards","slug":"keyboards","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Xbox","slug":"microsoft-xbox","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The OnePlus 12R is a $500 phone with flagship tendencies","uid":"Entry:4b789e61-1494-457d-a2db-8980ea673126","url":"https://www.theverge.com/24072383/oneplus-12r-review-screen-camera-price","author":{"fullName":"Allison Johnson"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/LazH2qZc6v6JpdgNL_l6SX0MLk0=/0x0:2000x1333/2000x1333/filters:focal(1000x667:1001x668)/cdn.vox-cdn.com/uploads/chorus_asset/file/25287583/DSC06615.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/lNmPj7BImrSiUA-aAE5xmjGKkdE=/0x0:2000x1333/100x100/filters:focal(1000x667:1001x668)/cdn.vox-cdn.com/uploads/chorus_asset/file/25287583/DSC06615.jpg","asset":{"title":"OnePlus 12R on a green background with back panel facing up surrounded by blue translucent squares."},"caption":{"plaintext":"The OnePlus 12R offers a sleek build and a fantastic screen for just $500."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Reviews","slug":"reviews","hubPage":{"uid":"HubPage:16727"},"isInternal":false,"isStarred":true},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Phone Reviews","slug":"phone-review","hubPage":{"uid":"HubPage:15817"},"isInternal":false,"isStarred":false},{"name":"OnePlus","slug":"oneplus","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Mobile","slug":"mobile","hubPage":{"uid":"HubPage:282"},"isInternal":false,"isStarred":false},{"name":"Android","slug":"android","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Google","slug":"google","hubPage":{"uid":"HubPage:274"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Here are the best iPad deals right now","uid":"Entry:1017dcbe-1ded-43bb-8f6d-71207675d174","url":"https://www.theverge.com/21280354/best-ipad-deals-apple","author":{"fullName":"Quentyn Kennemer"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/EbWTO7itqHT6SqYrtIVPGMvt5pU=/0x0:2000x1500/2000x1500/filters:focal(1000x750:1001x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24905994/ProCreate_Dreams_brushes.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/L7qsL_uRiaImurCnWRiF3VX2VSU=/0x0:2000x1500/100x100/filters:focal(1000x750:1001x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24905994/ProCreate_Dreams_brushes.jpg","asset":{"title":"An iPad running the new Procreate Dreams animation app."},"caption":{"plaintext":"Select iPad models go on sale quite frequently, but some discounts on aging models are getting harder to find."}},"promoImage":null,"communityGroups":[{"name":"Deals","slug":"good-deals","hubPage":{"uid":"HubPage:17413"},"isInternal":false,"isStarred":false},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"iPad","slug":"ipad","hubPage":{"uid":"HubPage:18888"},"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"Evergreen Deals","slug":"evergreen-deals","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Here are the best Kindle deals right now","uid":"Entry:fcce30be-1c01-48e9-b609-41b168ee4013","url":"https://www.theverge.com/21539047/best-amazon-kindle-deals","author":{"fullName":"Sheena Vasani"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/c_1YFFuqi9tRv4r1TXTPd_Sh5wk=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25261875/226417__Amazon_Kindle_Scribe_AKrales_0197.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/vX6XYIDrzouuHvA2NwlcY5otcHE=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25261875/226417__Amazon_Kindle_Scribe_AKrales_0197.jpg","asset":{"title":"The Kindle Scribe against a background of yellow post-it notes."},"caption":{"plaintext":"The Kindle Scribe is on sale as a part of a bundle."}},"promoImage":null,"communityGroups":[{"name":"Deals","slug":"good-deals","hubPage":{"uid":"HubPage:17413"},"isInternal":false,"isStarred":false},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Evergreen Deals","slug":"evergreen-deals","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Amazon","slug":"amazon","hubPage":null,"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP","uid":"EntryGroup:79429"},{"slug":"tech","isInternal":false,"hubPage":{"slug":"tech","uid":"HubPage:8135"},"isDisclaimer":false,"description":"The latest tech news about the world's best (and sometimes worst) hardware, apps, and much more. From top companies like Google and Apple to tiny startups vying for your attention, Verge Tech has the latest in what matters in technology daily.","name":"Tech","url":"https://www.theverge.com/tech","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The Nintendo Switch 2 will now reportedly arrive in 2025 instead of 2024","uid":"Entry:beee2677-e972-4e4e-898c-fa9f20cfc826","url":"https://www.theverge.com/2024/2/16/24075174/switch-2-launch-date-rumor-q1-2025","author":{"fullName":"Ash Parrish"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/lA9CG498doJGjG9JOisq1_T8jow=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/0mSe0c0D5D_NAUpnNO9RfWG7yqs=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/23925998/acastro_STK054_03.jpg","asset":{"title":"Stock image illustration featuring the Nintendo logo stamped in black on a background of tan, blue, and black color blocking."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Nintendo","slug":"nintendo","hubPage":null,"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The best Presidents Day deals you can already get","uid":"Entry:ae3462ed-d729-4045-b0ee-fa4a4cc6cd0f","url":"https://www.theverge.com/24072881/best-presidents-day-sales-deals-2024-apple-tvs-gaming-headphones-smartwatches","author":{"fullName":"Quentyn Kennemer"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/44HX0exmF1grR1zLh7d_8sauDaA=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/m1tVM4z2Whd6IFJ-Vo8SNn_oMoY=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/19336098/cwelch_191031_3763_0002.jpg","asset":{"title":"Apple AirPods Pro"},"caption":{"plaintext":"There’s plenty of tech on sale for Presidents Day, from AirPods to OLED TVs and everything in between."}},"promoImage":null,"communityGroups":[{"name":"Deals","slug":"good-deals","hubPage":{"uid":"HubPage:17413"},"isInternal":false,"isStarred":false},{"name":"guidebook","slug":"guidebook","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Logitech","slug":"logitech","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Smart Home","slug":"smart-home","hubPage":{"uid":"HubPage:279"},"isInternal":false,"isStarred":false},{"name":"Gaming","slug":"games","hubPage":{"uid":"HubPage:276"},"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"TVs","slug":"televisions","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Wearable","slug":"wearables","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Headphones","slug":"headphone","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Laptops","slug":"laptops","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"PC Gaming","slug":"pc-gaming","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Cameras and Photography","slug":"photography","hubPage":{"uid":"HubPage:280"},"isInternal":false,"isStarred":false},{"name":"Mobile","slug":"mobile","hubPage":{"uid":"HubPage:282"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Interview: Figma’s CEO on life after the company’s failed sale to Adobe","uid":"Entry:fdc979c4-8ca1-4529-9b87-73ff4e9fc771","url":"https://www.theverge.com/2024/2/16/24075126/figma-ceo-dylan-field-interview-after-adobe","author":{"fullName":"Alex Heath"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/_h6TOd1_tIgIDNFyrkYYvh_dn2A=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/GAN_VXedqCF0aB11s1jGNOkBgJQ=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","asset":{"title":"Figma CEO Dylan Field."},"caption":{"plaintext":"Figma CEO Dylan Field."}},"promoImage":null,"communityGroups":[{"name":"Command Line","slug":"command-line-newsletter","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Design","slug":"design","hubPage":{"uid":"HubPage:8137"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Adobe","slug":"adobe","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Vudu’s name is changing to ‘Fandango at Home’","uid":"Entry:fcb3c34d-db2e-4a74-bc4d-cb54ff107c67","url":"https://www.theverge.com/2024/2/16/24075041/vudu-fandango-at-home-rebranding-new-name","author":{"fullName":"Chris Welch"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/OfW7xmYlzZXLOKRrVJZn4j8QUwY=/0x0:1080x716/1080x716/filters:focal(540x358:541x359)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/DfDuP6neKkLLh9MLWj1y3SHqW94=/0x0:1080x716/100x100/filters:focal(540x358:541x359)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289972/vudu.jpg","asset":{"title":"An image announcing Vudu’s rebranding to Fandango at Home."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Apps","slug":"apps","hubPage":{"uid":"HubPage:277"},"isInternal":false,"isStarred":false},{"name":"Streaming","slug":"streaming-wars","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Amazon — like SpaceX — claims the labor board is unconstitutional","uid":"Entry:0fa52d0e-c11f-4c47-a2fe-263bdccbc61e","url":"https://www.theverge.com/2024/2/16/24074954/amazon-labor-board-nlrb-unconstitutional","author":{"fullName":"Emma Roth"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/-DH_98tyCltbrWTMSUoI7BLSJ1g=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23935561/acastro_STK103__04.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/VMv_ykKU3cj2UPdBp71ECWSYPpI=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23935561/acastro_STK103__04.jpg","asset":{"title":"Illustration showing Amazon’s logo on a black, orange, and tan background, formed by outlines of the letter “A.”"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Amazon","slug":"amazon","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"SpaceX","slug":"spacex","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Space","slug":"space","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Science","slug":"science","hubPage":{"uid":"HubPage:6949"},"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP","uid":"EntryGroup:21019"},{"slug":"ai-artificial-intelligence","isInternal":false,"hubPage":{"slug":"ai-artificial-intelligence","uid":"HubPage:17957"},"isDisclaimer":false,"description":"Artificial intelligence is more a part of our lives than ever before. While some might call it hype and compare it to NFTs or 3D TVs, AI is causing a sea change in nearly every facet of life that technology touches. Bing wants to know you intimately, Bard wants to reduce websites to easy-to-read cards, and ChatGPT has infiltrated nearly every part of our lives. At The Verge, we’re exploring all the good AI is enabling and all the bad it’s bringing along.","name":"Artificial Intelligence","url":"https://www.theverge.com/ai-artificial-intelligence","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Interview: Figma’s CEO on life after the company’s failed sale to Adobe","uid":"Entry:fdc979c4-8ca1-4529-9b87-73ff4e9fc771","url":"https://www.theverge.com/2024/2/16/24075126/figma-ceo-dylan-field-interview-after-adobe","author":{"fullName":"Alex Heath"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/_h6TOd1_tIgIDNFyrkYYvh_dn2A=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/GAN_VXedqCF0aB11s1jGNOkBgJQ=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","asset":{"title":"Figma CEO Dylan Field."},"caption":{"plaintext":"Figma CEO Dylan Field."}},"promoImage":null,"communityGroups":[{"name":"Command Line","slug":"command-line-newsletter","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Design","slug":"design","hubPage":{"uid":"HubPage:8137"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Adobe","slug":"adobe","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"The shine comes off the Vision Pro","uid":"Entry:f2db6c56-0102-4d83-952a-db4ff3d5a61b","url":"https://www.theverge.com/24074795/vision-pro-returns-xbox-future-gemini-open-ai-vergecast","author":{"fullName":"David Pierce"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/SOQWyhCJJvFnlEsKZ8gmUVMXHZU=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289245/VST_0216_Site_post.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/DqAb_g1MopjSr7PbSEfYE6yqXig=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289245/VST_0216_Site_post.jpg","asset":{"title":"An illustration of The Vergecast team, with a Vision Pro over top."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Vergecast","slug":"the-vergecast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Podcasts","slug":"podcast","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":"Spike Jonze’s Her holds up a decade later","title":"Her?","uid":"Entry:6692a09c-7b1a-48c3-9aa5-cd3950f24d49","url":"https://www.theverge.com/24066233/her-ai-film-spike-jonze-joaquin-phoenix-scarlett-johansson","author":{"fullName":"Sheon Han"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/yPuezr_u7k4fJnjmWX4yKfBzIjU=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289339/246992_AI_at_Work_FILM_ECarter.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/FXaUCGeB1hxGGQnsNbNsexs_gyY=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289339/246992_AI_at_Work_FILM_ECarter.jpg","asset":{"title":"3D illustration of a robot version of “The Thinker”."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Film","slug":"film","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Internet Culture","slug":"internet-culture","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Culture","slug":"culture","hubPage":{"uid":"HubPage:15811"},"isInternal":false,"isStarred":false},{"name":"AI Business Week Feb 2024 - internal ","slug":"ai-business-week-feb-2024","hubPage":null,"isInternal":true,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"You sound like a bot","uid":"Entry:4915136c-e61c-4051-ba76-dba6753c7037","url":"https://www.theverge.com/24067999/ai-bot-chatgpt-chatbot-dungeon","author":{"fullName":"Adi Robertson"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/FUjMNb0KI3OkAHZEgVBbBjEfMN8=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25288449/246992_AI_at_Work_BORING_ECarter.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/8MQgX5gg6YEAtzJ0Rbcc_lf2jUg=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25288449/246992_AI_at_Work_BORING_ECarter.jpg","asset":{"title":"3D illustration of a robot rubber stamping a text file."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Web","slug":"web","hubPage":{"uid":"HubPage:275"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Internet Culture","slug":"internet-culture","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"OpenAI","slug":"openai","hubPage":null,"isInternal":false,"isStarred":false},{"name":"AI Business Week Feb 2024 - internal ","slug":"ai-business-week-feb-2024","hubPage":null,"isInternal":true,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"How much electricity does AI consume?","uid":"Entry:5ac41b31-8a49-406a-9d84-6b000b151e37","url":"https://www.theverge.com/24066646/ai-electricity-energy-watts-generative-consumption","author":{"fullName":"James Vincent"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/dNYPsHwH0BlQzOXTa4zHHf6ttdE=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25288452/246992_AI_at_Work_REAL_COST_ECarter.png","variantUrl":"https://cdn.vox-cdn.com/thumbor/LnEd9SBhjnZs0PfUKLA1JUBIUCs=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25288452/246992_AI_at_Work_REAL_COST_ECarter.png","asset":{"title":"Pixel illustration of a computer generation an image connected to many electrical outlets at once."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Web","slug":"web","hubPage":{"uid":"HubPage:275"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Energy","slug":"energy","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Science","slug":"science","hubPage":{"uid":"HubPage:6949"},"isInternal":false,"isStarred":false},{"name":"OpenAI","slug":"openai","hubPage":null,"isInternal":false,"isStarred":false},{"name":"AI Business Week Feb 2024 - internal ","slug":"ai-business-week-feb-2024","hubPage":null,"isInternal":true,"isStarred":false}]}]},"type":"SITE_GROUP","uid":"EntryGroup:45647"},{"slug":"creators","isInternal":false,"hubPage":{"slug":"creators","uid":"HubPage:18970"},"isDisclaimer":false,"description":"YouTube, Instagram, SoundCloud, and other online platforms are changing the way people create and consume media. The Verge's Creators section covers the people using these platforms, what they're making, and how those platforms are changing (for better and worse) in response to the vloggers, influencers, podcasters, photographers, musicians, educators, designers, and more who are using them.\r\n\r\nThe Verge’s Creators section also looks at the way creators are able to turn their projects into careers — from Patreons and merch sales, to ads and Kickstarters — and the ways they’re forced to adapt to changing circumstances as platforms crack down on bad actors and respond to pressure from users and advertisers. New platforms are constantly emerging, and existing ones are ever-changing — what creators have to do to succeed is always going to look different from one year to the next.","name":"Creators","url":"https://www.theverge.com/creators","isStarred":false,"recentEntries":{"results":[{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Interview: Figma’s CEO on life after the company’s failed sale to Adobe","uid":"Entry:fdc979c4-8ca1-4529-9b87-73ff4e9fc771","url":"https://www.theverge.com/2024/2/16/24075126/figma-ceo-dylan-field-interview-after-adobe","author":{"fullName":"Alex Heath"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/_h6TOd1_tIgIDNFyrkYYvh_dn2A=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/GAN_VXedqCF0aB11s1jGNOkBgJQ=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25289959/Command_Line_Site_Post_Dylan_Field_Figma.jpg","asset":{"title":"Figma CEO Dylan Field."},"caption":{"plaintext":"Figma CEO Dylan Field."}},"promoImage":null,"communityGroups":[{"name":"Command Line","slug":"command-line-newsletter","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Design","slug":"design","hubPage":{"uid":"HubPage:8137"},"isInternal":false,"isStarred":false},{"name":"Artificial Intelligence","slug":"ai-artificial-intelligence","hubPage":{"uid":"HubPage:17957"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Interview","slug":"interview","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Adobe","slug":"adobe","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Here’s how dominant YouTube really is in podcasting","uid":"Entry:dcc2c232-e55c-4256-9443-343920e5bc58","url":"https://www.theverge.com/2024/2/15/24074369/youtube-podcast-apple-spotify-podtrac-chart","author":{"fullName":"Ariel Shapiro"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/00Jv8yfP5y_tIswQHCeQ4OLc1d0=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23954045/VRG_Illo_STK427_K_Radtke_Getty_Mics_2.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/3ApXXTivt8qAZ9hpzqdev8mRJI0=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23954045/VRG_Illo_STK427_K_Radtke_Getty_Mics_2.jpg","asset":{"title":"Repeating green microphones over a black background"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"Paywall: Hot Pod","slug":"hot-pod-paywall","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Hot Pod","slug":"hot-pod-newsletter","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"YouTube","slug":"youtube","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"YouTube Shorts adds music video remixing as UMG goes silent on TikTok","uid":"Entry:03d72554-fe37-4d95-91c9-80b9ac10e69c","url":"https://www.theverge.com/2024/2/15/24074036/youtube-shorts-music-video-remix-umg-tiktok","author":{"fullName":"Emma Roth"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/PrshLnuRHGevyR5ALfd9ekib7WU=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23986639/acastro_STK092_03.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/zgDi83DVFRiqV4__fEtfGK4sGyk=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23986639/acastro_STK092_03.jpg","asset":{"title":"YouTube logo image in red over a geometric red, black, and cream background"},"caption":null},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"YouTube","slug":"youtube","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"TikTok","slug":"tiktok","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Music","slug":"music","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Entertainment","slug":"entertainment","hubPage":{"uid":"HubPage:8141"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"Meta is passing on the Apple tax for boosted posts to advertisers","uid":"Entry:7cfef348-648e-457f-9f96-ef96ca459638","url":"https://www.theverge.com/2024/2/15/24073228/meta-apple-tax-facebook-instagram-boosted-posts","author":{"fullName":"Emma Roth"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/u_sSC_t1lrUOo6SU2tGdKVjWGgU=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23951343/STK040_VRG_Illo_N_Barclay_5_facebook.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/fkzEE3zSfYA2hde8DEEP1k07HZM=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23951343/STK040_VRG_Illo_N_Barclay_5_facebook.jpg","asset":{"title":"The Facebook logo on a blue background surrounded by blue circles."},"caption":null},"promoImage":null,"communityGroups":[{"name":"Meta","slug":"meta","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"Facebook","slug":"facebook","hubPage":{"uid":"HubPage:18317"},"isInternal":false,"isStarred":false},{"name":"Instagram","slug":"instagram","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Policy","slug":"policy","hubPage":{"uid":"HubPage:278"},"isInternal":false,"isStarred":false},{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false}]},{"primaryCommunityGroup":{"name":"Front Page","isInternal":false},"type":"STORY","promoHeadline":null,"title":"TikTok’s native app arrives for the Vision Pro","uid":"Entry:e4adde6f-c81d-4399-a84b-c9c7d861bcc6","url":"https://www.theverge.com/2024/2/15/24073674/tiktok-apple-vision-pro-app-launched","author":{"fullName":"Jon Porter"},"leadImage":{"url":"https://cdn.vox-cdn.com/thumbor/Klk2K06OlzqSB6CxbDXm5X_RW5w=/0x0:1080x720/1080x720/filters:focal(540x360:541x361)/cdn.vox-cdn.com/uploads/chorus_asset/file/25287395/TikTok_Apple_Vision_Pro_2.jpg","variantUrl":"https://cdn.vox-cdn.com/thumbor/IsD0keN0VBni3cL-K56o6oz9D-w=/0x0:1080x720/100x100/filters:focal(540x360:541x361)/cdn.vox-cdn.com/uploads/chorus_asset/file/25287395/TikTok_Apple_Vision_Pro_2.jpg","asset":{"title":"TikTok video overlaid on living room inside Vision Pro."},"caption":{"plaintext":"The Vision Pro app offers a familiar interface."}},"promoImage":null,"communityGroups":[{"name":"Front Page","slug":"front-page","hubPage":{"uid":"HubPage:270"},"isInternal":false,"isStarred":false},{"name":"TikTok","slug":"tiktok","hubPage":null,"isInternal":false,"isStarred":false},{"name":"Creators","slug":"creators","hubPage":{"uid":"HubPage:18970"},"isInternal":false,"isStarred":false},{"name":"Tech","slug":"tech","hubPage":{"uid":"HubPage:8135"},"isInternal":false,"isStarred":false},{"name":"News","slug":"news","hubPage":null,"isInternal":true,"isStarred":false},{"name":"Apple","slug":"apple","hubPage":{"uid":"HubPage:271"},"isInternal":false,"isStarred":false},{"name":"Virtual Reality","slug":"vr-virtual-reality","hubPage":null,"isInternal":false,"isStarred":false}]}]},"type":"SITE_GROUP","uid":"EntryGroup:79759"}],"uid":"Entry:1c995675-e913-450a-abef-091ac7bb185a","author":{"_id":9618721,"fullName":"Jess Weatherbed","authorProfile":{"url":"https://www.theverge.com/authors/jess-weatherbed","shortBio":"a news writer focused on creative industries, computing, and internet culture. Jess started her career at TechRadar, covering news and hardware reviews.","uid":"AuthorProfile:31106"}},"uuid":"1c995675-e913-450a-abef-091ac7bb185a","type":"STORY","community":{"_id":372,"domain":"theverge.com","network":{"domain":"theverge.com"},"placeholderImageUrl":"https://cdn.vox-cdn.com/uploads/network/placeholder_image/2/The_Verge.644.jpg","slug":"verge","name":"The Verge","googleAmpLogo":{"url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png","width":250,"height":50},"communityID":372},"title":"How to keep your art out of AI generators","seoHeadline":null,"socialHeadline":null,"promoHeadline":null,"legacyId":23827368,"hasAffiliateLinks":false,"publishDate":"2024-02-07T19:00:00.000Z","originalPublishDate":"2024-02-07T19:00:00.000Z","wordCount":3287,"streams":null,"contributors":[],"primaryCampaignGroup":null,"campaignGroups":[],"primaryCommunityGroup":{"slug":"front-page","parentEntryGroup":null,"name":"Front Page","isInternal":false},"primaryPackageGroup":null,"__isEntryRevision":"Entry","body":{"components":[{"__typename":"EntryBodyParagraph","placement":{"id":"4TjvKw","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"AI-generated imagery feels inescapable. It’s in the \u003ca href=\"https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney\"\u003evideo games you play\u003c/a\u003e, in the \u003ca href=\"https://www.theverge.com/2023/6/27/23770133/secret-invasion-ai-credits-marvel\"\u003emovies you watch\u003c/a\u003e, and has flooded social media platforms. It’s even been used to \u003ca href=\"https://www.theverge.com/2024/1/9/24031468/wacom-wizards-of-the-coast-mtg-artists-against-generative-ai\"\u003epromote the physical hardware\u003c/a\u003e that real, human artists use to create digital paintings and illustrations, to the immense frustration of those who already feel displaced by the technology. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"glIYW7","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"The pervasive nature of it seems especially egregious to creators who are fighting to stop their works from being used, without consent or compensation, to improve the very thing that threatens to disrupt their careers and livelihoods. The data pools that go into training generative AI models often contain images that are indiscriminately scraped from the internet, and some AI image generator tools allow users to upload reference images they want to imitate. Many creative professionals need to advertise their work via social media and online portfolios, so simply taking everything offline isn’t a viable solution. \u003ca href=\"https://www.theverge.com/2023/11/4/23946353/generative-ai-copyright-training-data-openai-microsoft-google-meta-stabilityai\"\u003eAnd a lack of legal clarity around AI technology\u003c/a\u003e has created something of a Wild-West environment that’s difficult to resist. Difficult, but not impossible."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"hPu85y","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"While the tools are often \u003ca href=\"https://www.theatlantic.com/technology/archive/2023/10/openai-dall-e-3-artists-work/675519/\"\u003ecomplicated and time consuming\u003c/a\u003e, several AI companies provide creators with ways to opt their work out of training. And for visual artists who want broader protections there are tools like Glaze and Kin.Art, which make the works useless for training. Here’s how to navigate the best solutions we’ve found so far."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"CCNlJY","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":2,"contents":{"html":"\u003cstrong\u003eOpting Out\u003c/strong\u003e"}},{"__typename":"EntryBodyParagraph","placement":{"id":"4D8q0D","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Generative AI models depend on training datasets, and the companies behind them are motivated to avoid restricting those potential data pools. So while they often do allow artists to opt their work out, the process can be crude and labor intensive — especially if you have a sizable catalog of work. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"58cErZ","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Opting out typically requires submitting a request to an AI provider, either via a dedicated form or directly via email, along with the copies and written descriptions of images you want to protect. Additionally, if you’ve agreed to let third parties license your images, the terms may include a license for AI training. It’s worth scanning the user agreements for any platforms hosting your work to check what rights they hold over it. But different AI tools’ policies vary — here’s how to opt out of some popular ones."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"VikOwS","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":3,"contents":{"html":"\u003cstrong\u003eOpenAI DALL-E\u003c/strong\u003e"}},{"__typename":"EntryBodyParagraph","placement":{"id":"UYpTF9","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"OpenAI started allowing creators to remove their work from its training data alongside its DALL-E 3 generative AI model last September, and it’s one of the easier processes to follow. Content creators or owners just need to \u003ca href=\"https://share.hsforms.com/1_OuT5tfFSpic89PqN6r1CQ4sk30\"\u003esubmit a form to OpenAI\u003c/a\u003e to request that the work be excluded from future training datasets, including a copy of the image, a description of it, and a ticked checkbox confirming that you have the rights for said image."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"ekuzpT","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Unfortunately, you’ll have to submit a separate form for \u003cem\u003eevery\u003c/em\u003e image you want excluded from OpenAI’s datasets, which could amount to thousands of works for some people; \u003ca href=\"https://www.theverge.com/2023/11/3/23944971/openai-wont-say-how-many-artists-have-opted-out-of-training-ai\"\u003eOpenAI hasn’t disclosed how many artists have undertaken this ordeal\u003c/a\u003e. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyImage","placement":{"id":"1Y3B06","alignment":null},"__isEntryBodyComponent":"EntryBodyImage","contentWarning":"","image":{"url":"https://cdn.vox-cdn.com/thumbor/ZnMeuBMJ4NUwYQP5p55P5GXE2Ig=/0x0:1150x1693/1150x1693/filters:focal(575x847:576x848)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg","height":1693,"width":1150,"hideCredit":false,"caption":{"html":"\u003cem\u003eYou have to submit a single form for every artwork you want opting out of OpenAIs training, which simply isn’t realistic for creatives with vast portfolios.\u003c/em\u003e","plaintext":"You have to submit a single form for every artwork you want opting out of OpenAIs training, which simply isn’t realistic for creatives with vast portfolios."},"credit":{"html":"Image: OpenAI"},"asset":{"title":"A screenshot taken of the OpenAI form needed to opt works out of being used to train AI models."}}},{"__typename":"EntryBodyParagraph","placement":{"id":"BtEg4I","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"If you only host your works on your own website, there might be a more efficient option. You can \u003ca href=\"https://platform.openai.com/docs/gptbot\"\u003efollow the instructions linked here\u003c/a\u003e to block the “GPTBot” web crawler used to scrape data from publicly available internet sources, which should protect all the content on it. A downside to this method, however, is that images posted anywhere outside of those walled protections, such as on social media, are still at risk of being scraped. Submitting a form at least ensures that your work is protected by a wider net, providing OpenAI hasn’t already obtained the images via a licensed third party."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"pABu3y","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Both these processes only offer protection against being swept into future training datasets. OpenAI claims that its AI models don’t retain any information they’ve already been trained on, so if you believe your work was already consumed by DALL-E 3 or its previous iterations, it’s too late to have it removed."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"u1MXmx","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"DALL-E 3 is also the model used by Image Creator from Designer, the Microsoft tool previously known as \u003ca href=\"https://www.theverge.com/2023/10/3/23901963/bing-chat-dall-e-3-openai-image-generator\"\u003eBing Image Creator\u003c/a\u003e. As such, the process of opting out with OpenAI directly should also prevent Image Creator from being trained on your works."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"ZBeBmt","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":3,"contents":{"html":"\u003cstrong\u003eAdobe Firefly\u003c/strong\u003e"}},{"__typename":"EntryBodyParagraph","placement":{"id":"0pOv7Y","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Of course, for every AI company that \u003cem\u003edoes\u003c/em\u003e allow artists to remove their works from training data, many others don’t openly advertise having such a service. And if they’re training models on a platform they own, users of that platform may not be allowed to opt out at all. That’s the case with creative software giant Adobe, which uses a model called Firefly across its Creative Cloud suite, including in Photoshop’s generative fill tool."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"8BLvMF","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Adobe proclaims that Firefly is commercially and legally safe because it’s entirely trained on the company’s own stock image platform, Adobe Stock. But there’s no means for Adobe Stock contributors to opt out of training Adobe’s AI models, which has resulted in some \u003ca href=\"https://venturebeat.com/ai/adobe-stock-creators-arent-happy-with-firefly-the-companys-commercially-safe-gen-ai-tool/\"\u003eexisting users criticizing the company\u003c/a\u003e for not seeking their permission. If you don’t want your work used to improve Firefly, you can’t put it on Adobe Stock, period."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyImage","placement":{"id":"zpGkNz","alignment":null},"__isEntryBodyComponent":"EntryBodyImage","contentWarning":"","image":{"url":"https://cdn.vox-cdn.com/thumbor/-YUqoxNIUWrtW2JUHz36t5zMLQA=/0x0:706x135/706x135/filters:focal(353x68:354x69)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg","height":135,"width":706,"hideCredit":false,"caption":{"html":"\u003cem\u003eIt doesn’t get much clearer than this line from Adobe’s FAQs. If you don’t want to train Firefly, avoid Adobe Stock.\u003c/em\u003e","plaintext":"It doesn’t get much clearer than this line from Adobe’s FAQs. If you don’t want to train Firefly, avoid Adobe Stock."},"credit":{"html":"Image: Adobe"},"asset":{"title":"A screenshot taken from Adobe Stock’s FAQ for contributors"}}},{"__typename":"EntryBodyParagraph","placement":{"id":"Z9w23j","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"In principle, Adobe’s approach \u003cem\u003eshould \u003c/em\u003emean that non-Stock users don’t have to worry about Firefly. But the reality is that there’s plenty of pirated work uploaded to the platform. If you find that someone has fraudulently uploaded your work to Adobe Stock, you can send Adobe \u003ca href=\"https://helpx.adobe.com/stock/contributor/help/how-to-report-suspected-misuse-of-your-intellectual-property.html#:~:text=If%20you%20believe%20that%20any,%2Dstock%40adobe.com%20.\"\u003ean IP infringement notice\u003c/a\u003e to get it removed from the platform. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"O0dxPd","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":3,"contents":{"html":"\u003cstrong\u003eMeta \u003c/strong\u003e"}},{"__typename":"EntryBodyParagraph","placement":{"id":"jwerAy","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Creatives who want to avoid training Meta’s AI models will have to jump through similar hoops. Meta is using “\u003ca href=\"https://www.facebook.com/privacy/genai\"\u003einformation from its products and services\u003c/a\u003e” to train its generative AI models, so anything personal you upload, or have historically uploaded, to platforms like Facebook, Instagram, and Threads is fair game for AI training. If you don’t have an account on any of those services then you’ve potentially avoided feeding its AI machine, but deleting existing accounts and/or not uploading future works to them is the next best thing."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"B0W45J","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"You can \u003ca href=\"https://www.facebook.com/help/contact/510058597920541\"\u003esubmit a form to Meta\u003c/a\u003e to request the company correct or delete personal information that’s being used to train its generative AI models, but only if that information has been supplied by a third party. It won’t let you exclude, for instance, art you’ve been voluntarily showcasing on Instagram. Many artists have also found it to be a frustrating process, criticizing how often the tool is unable to process requests. Conceptual artist \u003ca href=\"https://www.wired.com/story/meta-artificial-intelligence-data-deletion/#:~:text=Mihaela%20Voicu%2C%20a%20Romanian%20digital%20artist%20and%20photographer%20who%20has%20tried%20to%20request%20data%20deletion%20twice%20using%20Meta%E2%80%99s%20form%2C%20says%20the%20process%20feels%20like%20%E2%80%9Ca%20bad%20joke.%E2%80%9D%20She%E2%80%99s%20received%20the%20%E2%80%9Cunable%20to%20process%20request%E2%80%9D%20boilerplate%20language%2C%20too.%20%E2%80%9CIt%E2%80%99s%20not%20actually%20intended%20to%20help%20people%2C%E2%80%9D%20she%20believes.\"\u003eBethany Berg told \u003cem\u003eWired\u003c/em\u003e\u003c/a\u003e that the removal form felt like “it was just a fake PR stunt to make it look like they were actually trying to do something.”"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyImage","placement":{"id":"AGMpA9","alignment":null},"__isEntryBodyComponent":"EntryBodyImage","contentWarning":"","image":{"url":"https://cdn.vox-cdn.com/thumbor/ivfJdF-MwlXfMg9DznEVCObGSrM=/0x0:979x969/979x969/filters:focal(490x485:491x486)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg","height":969,"width":979,"hideCredit":false,"caption":{"html":"\u003cem\u003eJust remember that Meta will hold some rights over any content you upload to its platforms, so the most effective solution is to avoid them entirely.\u003c/em\u003e","plaintext":"Just remember that Meta will hold some rights over any content you upload to its platforms, so the most effective solution is to avoid them entirely."},"credit":{"html":"Image: Meta"},"asset":{"title":"A screenshot taken of Meta’s form for opting data out of training AI models."}}},{"__typename":"EntryBodyParagraph","placement":{"id":"lNaW6M","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Beyond that, you can limit what personal information third parties are sharing with Meta by managing your \u003ca href=\"https://accountscenter.facebook.com/info_and_permissions/off_facebook_activity/\"\u003eOff-Facebook Activity\u003c/a\u003e. This tool will display which sites and services are giving your data to Meta and allow you to sever the connection that ties your identity with such data. This won’t clear the data that’s already been uploaded, but it should enable users to monitor if platforms they know are hosting their works are potentially feeding that information back to Meta directly."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"emAiGD","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"That said, Meta also uses “information that is publicly available online” to train its generative AI models, and it doesn’t disclose its datasets. So there’s no way of knowing precisely what’s already in that massive content pool — and no surefire way of staying out."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"1p3e92","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":2,"contents":{"html":"\u003cstrong\u003eWhat about Stability AI, Midjourney, and so on?\u003c/strong\u003e"}},{"__typename":"EntryBodyParagraph","placement":{"id":"9cajcY","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Two of the most popular generative AI tools — Midjourney and Stability AI’s Stable Diffusion — will remove copyright-infringing materials under the Digital Millennium Copyright Act (DMCA). But this information is buried in their respective Terms of Use policies, and the processes are crude. This also isn’t strictly an opt-out tool, and neither company provides a means to opt work out of being sucked into future training data pools."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"fldm9s","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"For both services, you’ll need to email the companies directly. Midjourney can be reached at \u003ca href=\"mailto:takedown@midjourney.com\"\u003etakedown@midjourney.com\u003c/a\u003e. For Stability AI, email your requests to both \u003ca href=\"mailto:mariya@stability.ai\"\u003emariya@stability.ai\u003c/a\u003e and \u003ca href=\"mailto:legal@stability.ai\"\u003elegal@stability.ai\u003c/a\u003e. \u003ca href=\"https://stability.ai/terms-of-use#:~:text=DMCA%20Copyright%20Infringement,stability.ai)\"\u003eStability\u003c/a\u003e’s user terms don’t specify what you’d need to provide, but the information required by \u003ca href=\"https://www.amd.com/en/legal/notices/dmca.html#:~:text=The%20Digital%20Millennium%20Copyright%20Act,by%20the%20Copyright%20owner%20or\"\u003eMidjourney\u003c/a\u003e, and most DMCA copyright infringement notices generally, includes a description of the original works, where the image infringing on them is located, your contact information, and a copy of your signature. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"7HR2nF","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Other, smaller AI providers may also provide a similar approach to removing data that infringes on intellectual property rights thanks to regulations like DCMA, to varying success — if you’re unsure, try contacting the AI provider directly."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"RM7nPh","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":2,"contents":{"html":"\u003cstrong\u003eHow else can I protect my work against generative AI?\u003c/strong\u003e"}},{"__typename":"EntryBodyParagraph","placement":{"id":"4FyiuG","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"With all that laid out, it’s clear that artists’ options when dealing directly with AI companies are pretty limited. Externally, however, several tools and services can grant creators better defenses — or even \u003cem\u003eoffenses\u003c/em\u003e — when fighting back. The various tools work differently, but in general, they run your visual art through processes that confuse or block effective training. That way, even if your work is scraped for an AI model, that model (ideally) won’t learn to reproduce it."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"4yMnWV","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":3,"contents":{"html":"\u003cstrong\u003eGlaze\u003c/strong\u003e"}},{"__typename":"EntryBodyImage","placement":{"id":"oNqWbO","alignment":null},"__isEntryBodyComponent":"EntryBodyImage","contentWarning":"","image":{"url":"https://cdn.vox-cdn.com/thumbor/XYVMl3IPUQ5a7QupLrJj1_F8rUg=/0x0:1282x1132/1282x1132/filters:focal(641x566:642x567)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg","height":1132,"width":1282,"hideCredit":false,"caption":{"html":"\u003cem\u003eWhen you launch Glaze, you’ll need to give it some time to download the resources it needs to protect your work.\u003c/em\u003e","plaintext":"When you launch Glaze, you’ll need to give it some time to download the resources it needs to protect your work."},"credit":{"html":"Image: Sand Lab, University of Chicago"},"asset":{"title":"A screengrab of the Glaze launcher."}}},{"__typename":"EntryBodyParagraph","placement":{"id":"cyDfrC","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"One of the most notable anti-training tools is \u003ca href=\"https://glaze.cs.uchicago.edu/what-is-glaze.html\"\u003eGlaze\u003c/a\u003e, a project launched by a team out of the University of Chicago. The free-to-use tool works as a kind of cloak, making pixel-level changes to images that confuse AI software trying to read them. Real people can’t typically see these alterations on highly-detailed images so there’s little impact on the human viewing experience, but AI image generators that are fed the same materials will recognize it as something else entirely — meaning anyone who tries to replicate its specific art style will be unable to do so."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"iAwbSj","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Glaze is available for \u003ca href=\"https://glaze.cs.uchicago.edu/download.html\"\u003eWindows or macOS\u003c/a\u003e. There are GPU and non-GPU versions available for Windows, but running the GPU variant specifically requires \u003ca href=\"https://developer.nvidia.com/cuda-gpus\"\u003ean Nvidia GPU from this list\u003c/a\u003e with at least 3.6GB of memory. (The developers say Glaze generally uses around 5GB of system memory to run.) Using it is straightforward: at first launch, the application will automatically download a number of machine learning libraries and other resources it needs to cloud your images. When that’s complete, head to the “Select” box at the top left and choose which images on your computer you’d like to Glaze. These can be uploaded in batches, so it’s much quicker than making individual opt-out requests."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyImageComparison","placement":{"id":"yZ9whF","alignment":null},"__isEntryBodyComponent":"EntryBodyImageComparison","imageComparison":{"firstImage":{"asset":{"url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg","width":1600,"height":1400,"title":"A green and purple illustration of an ominous floating figure"},"credit":{"html":"Image: Jess Weatherbed / The Verge"}},"secondImage":{"asset":{"url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg","width":1600,"height":1400,"title":"An image that’s had Glaze AI protection applied at max intensity."},"credit":{"html":"Image: Jess Weatherbed / The Verge"}},"caption":{"html":"\u003cem\u003eYou may want to experiment with the strength of the Glaze application — on simple illustrations like this, Glazing at max intensity can distort the results.\u003c/em\u003e"}}},{"__typename":"EntryBodyParagraph","placement":{"id":"wMNvE0","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"You can then adjust the intensity of the Glaze cloaking from “very low” to “very high,” with the latter offering greater protection against AI but increasing the possibility of changes being visible to humans. Render quality, another option, determines the overall quality of the finished image — higher-quality rendering looks better and offers greater protection but will also take much longer to process. Generally, the finished result should look virtually unchanged from your original. But a close inspection will reveal tiny differences, almost like a textured wash has been applied to it."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"LcC5hr","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":3,"contents":{"html":"\u003cstrong\u003eNightshade\u003c/strong\u003e"}},{"__typename":"EntryBodyImage","placement":{"id":"ezA2Ey","alignment":null},"__isEntryBodyComponent":"EntryBodyImage","contentWarning":"","image":{"url":"https://cdn.vox-cdn.com/thumbor/oQUoPhgyk0ildslgybihtqPE3qE=/0x0:1302x1100/1302x1100/filters:focal(651x550:652x551)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg","height":1100,"width":1302,"hideCredit":false,"caption":{"html":"\u003cem\u003eNightshade shares a very similar UI to Glaze, which is unsurprising considering it’s being developed by the same team.\u003c/em\u003e","plaintext":"Nightshade shares a very similar UI to Glaze, which is unsurprising considering it’s being developed by the same team."},"credit":{"html":"Image: Sand Lab, University of Chicago"},"asset":{"title":"A screenshot of the Nightshade launcher."}}},{"__typename":"EntryBodyParagraph","placement":{"id":"AsHh1k","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003ca href=\"https://nightshade.cs.uchicago.edu/downloads.html\"\u003eNightshade\u003c/a\u003e, from the team behind Glaze, takes a similar but more extreme approach. Images passed through this cloaking tool are actually intended to “poison” generative AI models that train on them, sabotaging the outputs for text prompts. If you upload a batch of dog pictures, for instance, Nightshade is supposed to fool models into seeing some other object like cars — rather than just confusing the model like Glaze does. The idea is that if a model takes in enough confusing images, it will start building rules based on them, so any dog-related prompt might become distorted with wheels and windshields. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"9FgZNQ","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"You can’t specify what you’d like your poisoned images to masquerade as because Nightshade is built around algorithms that can’t accommodate that kind of personalization. If you want a better insight into how it works, check out this \u003ca href=\"https://towardsdatascience.com/how-nightshade-works-b1ae14ae76c3\"\u003ebreakdown provided by data scientist Dorian Drost\u003c/a\u003e."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"o76nW2","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Like Glaze, Nightshade applies a filter-like film over the image that shouldn’t massively impact the human viewing experience, depending on the intensity of the protection layer and how detailed the original art is. (You can apply both Glaze and Nightshade to images without them interfering with each other.) Nightshade is also available for Windows and macOS systems, though only machines running Apple’s own silicon are supported for the latter."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyImageComparison","placement":{"id":"mLr9tZ","alignment":null},"__isEntryBodyComponent":"EntryBodyImageComparison","imageComparison":{"firstImage":{"asset":{"url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg","width":1600,"height":1400,"title":"A green and purple illustration of an ominous floating figure"},"credit":{"html":"Image: Jess Weatherbed / The Verge"}},"secondImage":{"asset":{"url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg","width":1600,"height":1400,"title":"An ominous floating figure in a destroyed city."},"credit":{"html":"Image: Jess Weatherbed / The Verge"}},"caption":{"html":"\u003cem\u003eAt default intensity, Nightshade should produce similar-looking results to Glazed images. The poisoned results on the right are nearly identical to our Glaze tests.\u003c/em\u003e"}}},{"__typename":"EntryBodyParagraph","placement":{"id":"b8aRea","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Most of the overall process is the same as Glaze: you wait for the tool to download machine learning libraries, upload your work, and set the intensity and rendering options. But there’s one extra step. Nightshade will analyze the images and fill the “current tag” field with a single-word description identifying the content, like “dog” or “girl.” For the poisoning effect to work, this needs to be accurate — so you can change it if it’s wrong. Then, when you upload the images online, make sure that single-word tag is included in the metadata or alt text. "},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"gMhrOi","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Some generative AI advocates argue Nightshade won’t be much of a hindrance. AI systems are trained on \u003cem\u003etruly \u003c/em\u003evast amounts of data, so you’d need a lot of poisoning to affect any given prompt. And companies can develop workarounds that detect Nightshade. But most of these workarounds only filter out images that use it, rather than removing the protections — so the end result is just having art excluded from the training data, which is still a win. The Glaze project team is also continually working to update the applications to close any loopholes that are being exploited by workarounds."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"ki1LYR","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":3,"contents":{"html":"\u003cstrong\u003eMist\u003c/strong\u003e"}},{"__typename":"EntryBodyImage","placement":{"id":"k2jEze","alignment":null},"__isEntryBodyComponent":"EntryBodyImage","contentWarning":"","image":{"url":"https://cdn.vox-cdn.com/thumbor/428XwtgEkMHMNdrbsfn-yaw5xiE=/0x0:1767x831/1767x831/filters:focal(884x416:885x417)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg","height":831,"width":1767,"hideCredit":false,"caption":{"html":"\u003cem\u003eMist can be tricky to set up, but its another option to try if you’re unhappy with results from Glaze and Nightshade.\u003c/em\u003e","plaintext":"Mist can be tricky to set up, but its another option to try if you’re unhappy with results from Glaze and Nightshade."},"credit":{"html":"Image: Mist"},"asset":{"title":"A screenshot of the Mist launcher."}}},{"__typename":"EntryBodyParagraph","placement":{"id":"aUjdlq","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003ca href=\"https://github.com/mist-project\"\u003eMist\u003c/a\u003e is a “preprocessing tool” developed by Psyker Group that, like Glaze and Nightshade, also prevents generative AI applications from effectively imitating a creator’s unique style and works. Mist’s approach is more akin to watermarking images. If an AI model is trained on “misted images,” any attempt to mimic them will see the output completely covered in visual distortions that render it unfit for most purposes and generally unpleasant to look at."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyImage","placement":{"id":"ap49lZ","alignment":null},"__isEntryBodyComponent":"EntryBodyImage","contentWarning":"","image":{"url":"https://cdn.vox-cdn.com/thumbor/epkM8JALgo4JWPCrDQpt3RKsEOA=/0x0:512x512/512x512/filters:focal(256x256:257x257)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg","height":512,"width":512,"hideCredit":false,"caption":{"html":"\u003cem\u003eHere’s an example of what’s produced by AI generation tools that reference Misted images.\u003c/em\u003e","plaintext":"Here’s an example of what’s produced by AI generation tools that reference Misted images."},"credit":{"html":"Image: Mist / \u003ca href=\"https://www.artstation.com/ase?continueFlag=726f268c053ad33ebabc8eafed6efef4\"\u003eSang Delan\u003c/a\u003e"},"asset":{"title":"An AI-generated image covered in visual distortions."}}},{"__typename":"EntryBodyParagraph","placement":{"id":"BFdpJO","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Elements of the original image can still be seen in some of these outputs, like similarities in photography or art styles, but the chaotic, noisy filter over the generated image isn’t something that can be easily corrected. Mist requires a graphics card with at least 6GB of VRAM, which isn’t a lot of computational resources, but it’s still greater than the 3.6GB Glaze requires. Mist has been open-sourced on GitHub to allow developers to build their own tools around it, and its creators have committed to offering long-term support and continuously improving its function."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"j8aA19","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"There are currently two ways for non-developers to use Mist. Windows PC users running an Nvidia GPU can download Mist for free via \u003ca href=\"https://drive.google.com/drive/folders/1vg8oK2BUOla5adaJcFYx5QMq0-MoP8kk?usp=drive_link\"\u003ethis Google Drive package\u003c/a\u003e. The software doesn’t require installation and can be used almost immediately after downloading — though it’s a little finicky to set up if you lack any coding or development experience."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyImageComparison","placement":{"id":"SZGw6I","alignment":null},"__isEntryBodyComponent":"EntryBodyImageComparison","imageComparison":{"firstImage":{"asset":{"url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png","width":600,"height":600,"title":null},"credit":{"html":"Image: Mist / \u003ca href=\"https://www.artstation.com/ase?continueFlag=726f268c053ad33ebabc8eafed6efef4\"\u003eSang Delan\u003c/a\u003e"}},"secondImage":{"asset":{"url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png","width":600,"height":600,"title":null},"credit":{"html":"Image: Mist / \u003ca href=\"https://www.artstation.com/ase?continueFlag=726f268c053ad33ebabc8eafed6efef4\"\u003eSang Delan\u003c/a\u003e"}},"caption":{"html":"\u003cem\u003eMisting images can also produce a faint, swirling filter over the results, but like Glaze, it\u0026#39;s harder to spot on detailed art or photography.\u003c/em\u003e"}}},{"__typename":"EntryBodyParagraph","placement":{"id":"my8PWU","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003ca href=\"https://github.com/mist-project/mist-v2/blob/main/docs/Handbook-Free-version.md\"\u003eA detailed handbook\u003c/a\u003e is available that will walk you through the entire process, along with a community Discord channel for troubleshooting. First, make sure you’ve installed the \u003ca href=\"https://dotnet.microsoft.com/en-us/download/dotnet/thank-you/runtime-desktop-7.0.13-windows-x64-installer\"\u003e.NET desktop runtime\u003c/a\u003e. When that’s done, you just select the “ENG” file inside Google Drive and download the zipped Mist_V2 folder within it. Create a new folder called “IMG” in mist-v2 \u0026gt; src \u0026gt; data \u0026gt;. Drop any images that you plan on Misting into the new folder when completed. Then, go back to the main folder (which should be titled “mist-v2_gui_free_version”) and run the Mist GUI booter. Mist allows you to adjust the strength of protection applied to images and select between using your device’s GPU or CPU, which may prove useful if you’re running old or inefficient hardware."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"YKOErl","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"For anyone who’s using macOS or doesn’t possess an Nvidia GPU, you can also run Mist via \u003ca href=\"https://colab.google/\"\u003eColab Notebook\u003c/a\u003e, a cloud-based Jupyter Notebook environment that runs in your web browser. Detailed instructions for how to do this \u003ca href=\"https://colab.research.google.com/drive/1k5tLNsWTTAkOlkl5d9llf93bJ6csvMuZ?usp=sharing\"\u003eare available here\u003c/a\u003e, but it’s a much more complicated process to set up than its Windows equivalent. Glaze and Nightshade, generally, will be much easier to navigate for folks who aren\u0026#39;t familiar with coding processes."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"I4zU7Y","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":3,"contents":{"html":"\u003cstrong\u003eKin.Art\u003c/strong\u003e"}},{"__typename":"EntryBodyParagraph","placement":{"id":"V4LYYF","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003ca href=\"https://kin.art/\"\u003eKin.Art\u003c/a\u003e isn’t so much an AI protection tool as it is an \u003cem\u003eentire\u003c/em\u003e portfolio platform that artists can use to host and sell their work. It goes beyond just banning AI-generated works — though that’s appreciated, given the backlash against sites like \u003ca href=\"https://www.theverge.com/2022/11/15/23449036/deviantart-ai-art-dreamup-training-data-controversy\"\u003eDeviantArt\u003c/a\u003e and \u003ca href=\"https://www.theverge.com/2022/12/23/23523864/artstation-removing-anti-ai-protest-artwork-censorship\"\u003eArtStation\u003c/a\u003e — and actively makes AI scraping and training harder."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"pOJvFP","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"\u003ca href=\"https://kin.art/press/ai-protection\"\u003eKin.Art uses two different techniques\u003c/a\u003e to thwart AI companies. The first is image segmentation, which is used to break apart images and muddle them into something unrecognizable. It’s undetectable to human eyes but disrupts generative AI models from being able to read the image. This visual scrambling will also be present if anyone attempts to save or download the image, though it doesn’t block manual screenshots. The second technique involves scrambling the metadata, like title and description, so any labels the AI model reads won’t accurately reflect the content."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyImage","placement":{"id":"RXK1lK","alignment":null},"__isEntryBodyComponent":"EntryBodyImage","contentWarning":"","image":{"url":"https://cdn.vox-cdn.com/thumbor/SO1ehnIJaxSF_oGgKdTgDKfq7k0=/0x0:915x410/915x410/filters:focal(458x205:459x206)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg","height":410,"width":915,"hideCredit":false,"caption":{"html":"\u003cem\u003eKin.Art’s AI protections just require users to tick a box when uploading their works to the platform.\u003c/em\u003e","plaintext":"Kin.Art’s AI protections just require users to tick a box when uploading their works to the platform."},"credit":{"html":"Image: Kin.Art"},"asset":{"title":"A screenshot of the image uploader on Kin.Art."}}},{"__typename":"EntryBodyParagraph","placement":{"id":"ycai74","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"These protections are automatically applied on the Kin.Art platform, so you just need to create an account and upload your works to benefit from them, and that works like practically any social media platform. There are some neat creator-focused features included, like the ability to add a commission status to advertise your availability to accept requests, and you can link out to external platforms like social media pages directly on your user profile. You can toggle the protections on or off when uploading images, and the service is currently free to use. Instead, Kin.Art will start placing a 5 percent service fee on top of commissions made through the service in March."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyHeading","placement":{"id":"74glQu","alignment":null},"__isEntryBodyComponent":"EntryBodyHeading","level":2,"contents":{"html":"\u003cstrong\u003eWhat about music, writing, and other media?\u003c/strong\u003e"}},{"__typename":"EntryBodyParagraph","placement":{"id":"xtSvB3","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Our guide covers what protections are available for image-based art largely because that format has more tools available than other mediums, and the opting-out processes tend to be clearer (when they are available). That said, creatives in other fields, like writing, voice acting, and music, are also fighting to protect their work. It’s much harder to disrupt how AI models are trained on this kind of data without noticeably affecting the original content, but there are still precautions you can take to reduce the risk of it being swept into AI training datasets."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"65vkRw","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"As with art, always check the user terms of the hosting platform to which you’re uploading your works. Services will generally disclose if they’re handing platform data over to third parties for AI training or using it to develop their own models — if there’s no explicit opt-out process, you may unknowingly be giving consent simply by signing up. Instead, look for platforms like \u003ca href=\"https://blog.medium.com/default-no-to-ai-training-on-your-stories-abb5b4589c8\"\u003eMedium\u003c/a\u003e, which have committed to blocking attempts to use content hosted on the site to train AI models. If you’re hosting work on your own site, you can also do things like block GPTBot to avoid pages being scraped."},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyParagraph","placement":{"id":"acozoe","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"Some rights distributors have made similar commitments, like the \u003ca href=\"https://societe.sacem.fr/en/news/our-society/sacem-favour-virtuous-transparent-and-fair-ai-exercises-its-right-opt-out\"\u003eSociety of Authors, Composers and Publishers of Music\u003c/a\u003e (SACEM) — a French association that announced it was exercising its right to opt out on behalf of its members last year. Another tip for writers, courtesy of the Authors Guild, is to place a short warning notice on your published works that clearly states you don’t consent to it being used to train AI. This is the example provided by the guild:"},"dropcap":false,"endmark":false,"lead":false},{"__typename":"EntryBodyBlockquote","placement":{"id":null,"alignment":null},"__isEntryBodyComponent":"EntryBodyBlockquote","paragraphs":[{"placement":{"id":"HtkBVP"},"contents":{"html":"“NO AI TRAINING: Without in any way limiting the author’s [and publisher’s] exclusive rights under copyright, any use of this publication to “train” generative artificial intelligence (AI) technologies to generate text is expressly prohibited. The author reserves all rights to license uses of this work for generative AI training and development of machine learning language models.”"}}]},{"__typename":"EntryBodyParagraph","placement":{"id":"HaE7AU","alignment":null},"__isEntryBodyComponent":"EntryBodyParagraph","contents":{"html":"These warnings serve to clearly flag that the work isn’t freely available to use, which may be useful in any future lawsuits raised against companies that violate your ownership rights. If bots scraping web data are also intuitive enough to filter out results with such warnings then this could also \u003cem\u003epotentially\u003c/em\u003e provide another layer of proactive protection, but there’s little evidence to show how many actually observe such information. Otherwise, performers and writers will need to submit copyright takedown notices to AI companies if they believe their works have been infringed."},"dropcap":false,"endmark":false,"lead":false}]},"liveCoverageStart":null,"slug":"24063327/ai-art-protect-images-copyright-generators","layoutTemplate":"STANDARD","seoSchema":[{"@context":"http://schema.org/","@type":"NewsArticle","headline":"How to keep your art out of AI generators","description":"Here’s how you can opt out of training some of the more popular generative AI models, or use tools like Glaze and Nightshade to protect art that’s used without permission.","datePublished":"2024-02-07T19:00:00.000Z","dateModified":"2024-02-07T19:00:00.000Z","thumbnailUrl":"https://cdn.vox-cdn.com/thumbor/ewBKLfJJmd6VuWC4ADqvRPjwRqk=/0x0:3000x2000/1400x788/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","author":[{"@type":"Person","name":"Jess Weatherbed","url":"https://www.theverge.com/authors/jess-weatherbed"}],"publisher":{"@type":"Organization","name":"The Verge","logo":{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png","width":250,"height":50}},"image":[{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/ewBKLfJJmd6VuWC4ADqvRPjwRqk=/0x0:3000x2000/1400x788/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","width":1400,"height":788},{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/Xk9VbLJF0HrXY78H9fyaQslEMCo=/0x0:3000x2000/1400x1050/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","width":1400,"height":1050},{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/FLLHuXnc--Ih-H5nU-KalBuZM68=/0x0:3000x2000/1400x1400/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","width":1400,"height":1400}],"url":"https://www.theverge.com/24063327/ai-art-protect-images-copyright-generators","articleBody":"AI-generated imagery feels inescapable. It’s in the video games you play, in the movies you watch, and has flooded social media platforms. It’s even been used to promote the physical hardware that real, human artists use to create digital paintings and illustrations, to the immense frustration of those who already feel displaced by the technology. \n\nThe pervasive nature of it seems especially egregious to creators who are fighting to stop their works from being used, without consent or compensation, to improve the very thing that threatens to disrupt their careers and livelihoods. The data pools that go into training generative AI models often contain images that are indiscriminately scraped from the internet, and some AI image generator tools allow users to upload reference images they want to imitate. Many creative professionals need to advertise their work via social media and online portfolios, so simply taking everything offline isn’t a viable solution. And a lack of legal clarity around AI technology has created something of a Wild-West environment that’s difficult to resist. Difficult, but not impossible.\n\nWhile the tools are often complicated and time consuming, several AI companies provide creators with ways to opt their work out of training. And for visual artists who want broader protections there are tools like Glaze and Kin.Art, which make the works useless for training. Here’s how to navigate the best solutions we’ve found so far.\n\nOpting Out\n\nGenerative AI models depend on training datasets, and the companies behind them are motivated to avoid restricting those potential data pools. So while they often do allow artists to opt their work out, the process can be crude and labor intensive — especially if you have a sizable catalog of work. \n\nOpting out typically requires submitting a request to an AI provider, either via a dedicated form or directly via email, along with the copies and written descriptions of images you want to protect. Additionally, if you’ve agreed to let third parties license your images, the terms may include a license for AI training. It’s worth scanning the user agreements for any platforms hosting your work to check what rights they hold over it. But different AI tools’ policies vary — here’s how to opt out of some popular ones.\n\nOpenAI DALL-E\n\nOpenAI started allowing creators to remove their work from its training data alongside its DALL-E 3 generative AI model last September, and it’s one of the easier processes to follow. Content creators or owners just need to submit a form to OpenAI to request that the work be excluded from future training datasets, including a copy of the image, a description of it, and a ticked checkbox confirming that you have the rights for said image.\n\nUnfortunately, you’ll have to submit a separate form for every image you want excluded from OpenAI’s datasets, which could amount to thousands of works for some people; OpenAI hasn’t disclosed how many artists have undertaken this ordeal. \n\n[Image: You have to submit a single form for every artwork you want opting out of OpenAIs training, which simply isn’t realistic for creatives with vast portfolios. https://cdn.vox-cdn.com/thumbor/ZnMeuBMJ4NUwYQP5p55P5GXE2Ig=/0x0:1150x1693/1150x1693/filters:focal(575x847:576x848)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg]\n\nIf you only host your works on your own website, there might be a more efficient option. You can follow the instructions linked here to block the “GPTBot” web crawler used to scrape data from publicly available internet sources, which should protect all the content on it. A downside to this method, however, is that images posted anywhere outside of those walled protections, such as on social media, are still at risk of being scraped. Submitting a form at least ensures that your work is protected by a wider net, providing OpenAI hasn’t already obtained the images via a licensed third party.\n\nBoth these processes only offer protection against being swept into future training datasets. OpenAI claims that its AI models don’t retain any information they’ve already been trained on, so if you believe your work was already consumed by DALL-E 3 or its previous iterations, it’s too late to have it removed.\n\nDALL-E 3 is also the model used by Image Creator from Designer, the Microsoft tool previously known as Bing Image Creator. As such, the process of opting out with OpenAI directly should also prevent Image Creator from being trained on your works.\n\nAdobe Firefly\n\nOf course, for every AI company that does allow artists to remove their works from training data, many others don’t openly advertise having such a service. And if they’re training models on a platform they own, users of that platform may not be allowed to opt out at all. That’s the case with creative software giant Adobe, which uses a model called Firefly across its Creative Cloud suite, including in Photoshop’s generative fill tool.\n\nAdobe proclaims that Firefly is commercially and legally safe because it’s entirely trained on the company’s own stock image platform, Adobe Stock. But there’s no means for Adobe Stock contributors to opt out of training Adobe’s AI models, which has resulted in some existing users criticizing the company for not seeking their permission. If you don’t want your work used to improve Firefly, you can’t put it on Adobe Stock, period.\n\n[Image: It doesn’t get much clearer than this line from Adobe’s FAQs. If you don’t want to train Firefly, avoid Adobe Stock. https://cdn.vox-cdn.com/thumbor/-YUqoxNIUWrtW2JUHz36t5zMLQA=/0x0:706x135/706x135/filters:focal(353x68:354x69)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg]\n\nIn principle, Adobe’s approach should mean that non-Stock users don’t have to worry about Firefly. But the reality is that there’s plenty of pirated work uploaded to the platform. If you find that someone has fraudulently uploaded your work to Adobe Stock, you can send Adobe an IP infringement notice to get it removed from the platform. \n\nMeta \n\nCreatives who want to avoid training Meta’s AI models will have to jump through similar hoops. Meta is using “information from its products and services” to train its generative AI models, so anything personal you upload, or have historically uploaded, to platforms like Facebook, Instagram, and Threads is fair game for AI training. If you don’t have an account on any of those services then you’ve potentially avoided feeding its AI machine, but deleting existing accounts and/or not uploading future works to them is the next best thing.\n\nYou can submit a form to Meta to request the company correct or delete personal information that’s being used to train its generative AI models, but only if that information has been supplied by a third party. It won’t let you exclude, for instance, art you’ve been voluntarily showcasing on Instagram. Many artists have also found it to be a frustrating process, criticizing how often the tool is unable to process requests. Conceptual artist Bethany Berg told Wired that the removal form felt like “it was just a fake PR stunt to make it look like they were actually trying to do something.”\n\n[Image: Just remember that Meta will hold some rights over any content you upload to its platforms, so the most effective solution is to avoid them entirely. https://cdn.vox-cdn.com/thumbor/ivfJdF-MwlXfMg9DznEVCObGSrM=/0x0:979x969/979x969/filters:focal(490x485:491x486)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg]\n\nBeyond that, you can limit what personal information third parties are sharing with Meta by managing your Off-Facebook Activity. This tool will display which sites and services are giving your data to Meta and allow you to sever the connection that ties your identity with such data. This won’t clear the data that’s already been uploaded, but it should enable users to monitor if platforms they know are hosting their works are potentially feeding that information back to Meta directly.\n\nThat said, Meta also uses “information that is publicly available online” to train its generative AI models, and it doesn’t disclose its datasets. So there’s no way of knowing precisely what’s already in that massive content pool — and no surefire way of staying out.\n\nWhat about Stability AI, Midjourney, and so on?\n\nTwo of the most popular generative AI tools — Midjourney and Stability AI’s Stable Diffusion — will remove copyright-infringing materials under the Digital Millennium Copyright Act (DMCA). But this information is buried in their respective Terms of Use policies, and the processes are crude. This also isn’t strictly an opt-out tool, and neither company provides a means to opt work out of being sucked into future training data pools.\n\nFor both services, you’ll need to email the companies directly. Midjourney can be reached at takedown@midjourney.com. For Stability AI, email your requests to both mariya@stability.ai and legal@stability.ai. Stability’s user terms don’t specify what you’d need to provide, but the information required by Midjourney, and most DMCA copyright infringement notices generally, includes a description of the original works, where the image infringing on them is located, your contact information, and a copy of your signature. \n\nOther, smaller AI providers may also provide a similar approach to removing data that infringes on intellectual property rights thanks to regulations like DCMA, to varying success — if you’re unsure, try contacting the AI provider directly.\n\nHow else can I protect my work against generative AI?\n\nWith all that laid out, it’s clear that artists’ options when dealing directly with AI companies are pretty limited. Externally, however, several tools and services can grant creators better defenses — or even offenses — when fighting back. The various tools work differently, but in general, they run your visual art through processes that confuse or block effective training. That way, even if your work is scraped for an AI model, that model (ideally) won’t learn to reproduce it.\n\nGlaze\n\n[Image: When you launch Glaze, you’ll need to give it some time to download the resources it needs to protect your work. https://cdn.vox-cdn.com/thumbor/XYVMl3IPUQ5a7QupLrJj1_F8rUg=/0x0:1282x1132/1282x1132/filters:focal(641x566:642x567)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg]\n\nOne of the most notable anti-training tools is Glaze, a project launched by a team out of the University of Chicago. The free-to-use tool works as a kind of cloak, making pixel-level changes to images that confuse AI software trying to read them. Real people can’t typically see these alterations on highly-detailed images so there’s little impact on the human viewing experience, but AI image generators that are fed the same materials will recognize it as something else entirely — meaning anyone who tries to replicate its specific art style will be unable to do so.\n\nGlaze is available for Windows or macOS. There are GPU and non-GPU versions available for Windows, but running the GPU variant specifically requires an Nvidia GPU from this list with at least 3.6GB of memory. (The developers say Glaze generally uses around 5GB of system memory to run.) Using it is straightforward: at first launch, the application will automatically download a number of machine learning libraries and other resources it needs to cloud your images. When that’s complete, head to the “Select” box at the top left and choose which images on your computer you’d like to Glaze. These can be uploaded in batches, so it’s much quicker than making individual opt-out requests.\n\n[Image: https://cdn.vox-cdn.com/thumbor/HQJPufnIxBA2F7zxDPxW2-8qhac=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg]\n[Image: https://cdn.vox-cdn.com/thumbor/ZUH7k6ah3Kh_VorufnSRqVAKxb8=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg]\nYou may want to experiment with the strength of the Glaze application — on simple illustrations like this, Glazing at max intensity can distort the results.\n\nYou can then adjust the intensity of the Glaze cloaking from “very low” to “very high,” with the latter offering greater protection against AI but increasing the possibility of changes being visible to humans. Render quality, another option, determines the overall quality of the finished image — higher-quality rendering looks better and offers greater protection but will also take much longer to process. Generally, the finished result should look virtually unchanged from your original. But a close inspection will reveal tiny differences, almost like a textured wash has been applied to it.\n\nNightshade\n\n[Image: Nightshade shares a very similar UI to Glaze, which is unsurprising considering it’s being developed by the same team. https://cdn.vox-cdn.com/thumbor/oQUoPhgyk0ildslgybihtqPE3qE=/0x0:1302x1100/1302x1100/filters:focal(651x550:652x551)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg]\n\nNightshade, from the team behind Glaze, takes a similar but more extreme approach. Images passed through this cloaking tool are actually intended to “poison” generative AI models that train on them, sabotaging the outputs for text prompts. If you upload a batch of dog pictures, for instance, Nightshade is supposed to fool models into seeing some other object like cars — rather than just confusing the model like Glaze does. The idea is that if a model takes in enough confusing images, it will start building rules based on them, so any dog-related prompt might become distorted with wheels and windshields. \n\nYou can’t specify what you’d like your poisoned images to masquerade as because Nightshade is built around algorithms that can’t accommodate that kind of personalization. If you want a better insight into how it works, check out this breakdown provided by data scientist Dorian Drost.\n\nLike Glaze, Nightshade applies a filter-like film over the image that shouldn’t massively impact the human viewing experience, depending on the intensity of the protection layer and how detailed the original art is. (You can apply both Glaze and Nightshade to images without them interfering with each other.) Nightshade is also available for Windows and macOS systems, though only machines running Apple’s own silicon are supported for the latter.\n\n[Image: https://cdn.vox-cdn.com/thumbor/HQJPufnIxBA2F7zxDPxW2-8qhac=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg]\n[Image: https://cdn.vox-cdn.com/thumbor/gzaQ2O2SO_tDyzxCo5YXIUE_Qcw=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg]\nAt default intensity, Nightshade should produce similar-looking results to Glazed images. The poisoned results on the right are nearly identical to our Glaze tests.\n\nMost of the overall process is the same as Glaze: you wait for the tool to download machine learning libraries, upload your work, and set the intensity and rendering options. But there’s one extra step. Nightshade will analyze the images and fill the “current tag” field with a single-word description identifying the content, like “dog” or “girl.” For the poisoning effect to work, this needs to be accurate — so you can change it if it’s wrong. Then, when you upload the images online, make sure that single-word tag is included in the metadata or alt text. \n\nSome generative AI advocates argue Nightshade won’t be much of a hindrance. AI systems are trained on truly vast amounts of data, so you’d need a lot of poisoning to affect any given prompt. And companies can develop workarounds that detect Nightshade. But most of these workarounds only filter out images that use it, rather than removing the protections — so the end result is just having art excluded from the training data, which is still a win. The Glaze project team is also continually working to update the applications to close any loopholes that are being exploited by workarounds.\n\nMist\n\n[Image: Mist can be tricky to set up, but its another option to try if you’re unhappy with results from Glaze and Nightshade. https://cdn.vox-cdn.com/thumbor/428XwtgEkMHMNdrbsfn-yaw5xiE=/0x0:1767x831/1767x831/filters:focal(884x416:885x417)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg]\n\nMist is a “preprocessing tool” developed by Psyker Group that, like Glaze and Nightshade, also prevents generative AI applications from effectively imitating a creator’s unique style and works. Mist’s approach is more akin to watermarking images. If an AI model is trained on “misted images,” any attempt to mimic them will see the output completely covered in visual distortions that render it unfit for most purposes and generally unpleasant to look at.\n\n[Image: Here’s an example of what’s produced by AI generation tools that reference Misted images. https://cdn.vox-cdn.com/thumbor/epkM8JALgo4JWPCrDQpt3RKsEOA=/0x0:512x512/512x512/filters:focal(256x256:257x257)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg]\n\nElements of the original image can still be seen in some of these outputs, like similarities in photography or art styles, but the chaotic, noisy filter over the generated image isn’t something that can be easily corrected. Mist requires a graphics card with at least 6GB of VRAM, which isn’t a lot of computational resources, but it’s still greater than the 3.6GB Glaze requires. Mist has been open-sourced on GitHub to allow developers to build their own tools around it, and its creators have committed to offering long-term support and continuously improving its function.\n\nThere are currently two ways for non-developers to use Mist. Windows PC users running an Nvidia GPU can download Mist for free via this Google Drive package. The software doesn’t require installation and can be used almost immediately after downloading — though it’s a little finicky to set up if you lack any coding or development experience.\n\n[Image: https://cdn.vox-cdn.com/thumbor/5eU328CU5OnDFEK7ITjLgu7SWOM=/0x0:600x600/600x600/filters:focal(300x300:301x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png]\n[Image: https://cdn.vox-cdn.com/thumbor/eOisXUU_lbyl4nxNMhLi1K17QWM=/0x0:600x600/600x600/filters:focal(300x300:301x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png]\nMisting images can also produce a faint, swirling filter over the results, but like Glaze, it's harder to spot on detailed art or photography.\n\nA detailed handbook is available that will walk you through the entire process, along with a community Discord channel for troubleshooting. First, make sure you’ve installed the .NET desktop runtime. When that’s done, you just select the “ENG” file inside Google Drive and download the zipped Mist_V2 folder within it. Create a new folder called “IMG” in mist-v2 \u003e src \u003e data \u003e. Drop any images that you plan on Misting into the new folder when completed. Then, go back to the main folder (which should be titled “mist-v2_gui_free_version”) and run the Mist GUI booter. Mist allows you to adjust the strength of protection applied to images and select between using your device’s GPU or CPU, which may prove useful if you’re running old or inefficient hardware.\n\nFor anyone who’s using macOS or doesn’t possess an Nvidia GPU, you can also run Mist via Colab Notebook, a cloud-based Jupyter Notebook environment that runs in your web browser. Detailed instructions for how to do this are available here, but it’s a much more complicated process to set up than its Windows equivalent. Glaze and Nightshade, generally, will be much easier to navigate for folks who aren't familiar with coding processes.\n\nKin.Art\n\nKin.Art isn’t so much an AI protection tool as it is an entire portfolio platform that artists can use to host and sell their work. It goes beyond just banning AI-generated works — though that’s appreciated, given the backlash against sites like DeviantArt and ArtStation — and actively makes AI scraping and training harder.\n\nKin.Art uses two different techniques to thwart AI companies. The first is image segmentation, which is used to break apart images and muddle them into something unrecognizable. It’s undetectable to human eyes but disrupts generative AI models from being able to read the image. This visual scrambling will also be present if anyone attempts to save or download the image, though it doesn’t block manual screenshots. The second technique involves scrambling the metadata, like title and description, so any labels the AI model reads won’t accurately reflect the content.\n\n[Image: Kin.Art’s AI protections just require users to tick a box when uploading their works to the platform. https://cdn.vox-cdn.com/thumbor/SO1ehnIJaxSF_oGgKdTgDKfq7k0=/0x0:915x410/915x410/filters:focal(458x205:459x206)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg]\n\nThese protections are automatically applied on the Kin.Art platform, so you just need to create an account and upload your works to benefit from them, and that works like practically any social media platform. There are some neat creator-focused features included, like the ability to add a commission status to advertise your availability to accept requests, and you can link out to external platforms like social media pages directly on your user profile. You can toggle the protections on or off when uploading images, and the service is currently free to use. Instead, Kin.Art will start placing a 5 percent service fee on top of commissions made through the service in March.\n\nWhat about music, writing, and other media?\n\nOur guide covers what protections are available for image-based art largely because that format has more tools available than other mediums, and the opting-out processes tend to be clearer (when they are available). That said, creatives in other fields, like writing, voice acting, and music, are also fighting to protect their work. It’s much harder to disrupt how AI models are trained on this kind of data without noticeably affecting the original content, but there are still precautions you can take to reduce the risk of it being swept into AI training datasets.\n\nAs with art, always check the user terms of the hosting platform to which you’re uploading your works. Services will generally disclose if they’re handing platform data over to third parties for AI training or using it to develop their own models — if there’s no explicit opt-out process, you may unknowingly be giving consent simply by signing up. Instead, look for platforms like Medium, which have committed to blocking attempts to use content hosted on the site to train AI models. If you’re hosting work on your own site, you can also do things like block GPTBot to avoid pages being scraped.\n\nSome rights distributors have made similar commitments, like the Society of Authors, Composers and Publishers of Music (SACEM) — a French association that announced it was exercising its right to opt out on behalf of its members last year. Another tip for writers, courtesy of the Authors Guild, is to place a short warning notice on your published works that clearly states you don’t consent to it being used to train AI. This is the example provided by the guild:\n\n\u003e “NO AI TRAINING: Without in any way limiting the author’s [and publisher’s] exclusive rights under copyright, any use of this publication to “train” generative artificial intelligence (AI) technologies to generate text is expressly prohibited. The author reserves all rights to license uses of this work for generative AI training and development of machine learning language models.”\n\nThese warnings serve to clearly flag that the work isn’t freely available to use, which may be useful in any future lawsuits raised against companies that violate your ownership rights. If bots scraping web data are also intuitive enough to filter out results with such warnings then this could also potentially provide another layer of proactive protection, but there’s little evidence to show how many actually observe such information. Otherwise, performers and writers will need to submit copyright takedown notices to AI companies if they believe their works have been infringed.\n"}],"package":null,"url":"https://www.theverge.com/24063327/ai-art-protect-images-copyright-generators","commentsClosed":false,"railComponents":[{"__typename":"EntryRailNewsletter","entryRailNewsletter":{"name":"Verge Deals","slug":"deals"}}],"dek":{"plaintext":"Some AI companies provide ways to opt images out of being used in training data, while tools like Glaze and Nightshade can interfere with AI models directly."},"leadImage":{"defaultImageUrl":"https://cdn.vox-cdn.com/thumbor/offjB8fuUVZ0qRXVsrZ1YIRhbbE=/0x0:3000x2000/1200x628/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg","asset":{"title":"Vector collage showing aspects of AI art and protecting your artwork from being used to train AI.","contentType":"image/jpeg"}},"seoDescription":{"plaintext":"Here’s how you can opt out of training some of the more popular generative AI models, or use tools like Glaze and Nightshade to protect art that’s used without permission."},"socialDescription":{"plaintext":"Here’s what you need to know about opting out and protecting your work."},"socialImage":null,"shouldUseHTMLNoindex":false,"shouldUseHTMLNofollow":false,"password":null,"additionalContributors":null,"_id":23827368,"leadComponent":{"__typename":"EntryLeadImage","standard":{"hideCredit":false,"asset":{"title":"Vector collage showing aspects of AI art and protecting your artwork from being used to train AI."},"caption":{"html":"\u003cem\u003eHere’s how to opt-out where you can, and fight back where you can’t.\u003c/em\u003e","plaintext":"Here’s how to opt-out where you can, and fight back where you can’t."},"credit":{"html":"Samar Haddad / The Verge"},"variantUrl":"https://cdn.vox-cdn.com/thumbor/O80mSf7mmJBzyLQuBfqwsBnfykk=/0x0:3000x2000/2000x1333/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/25250858/HT054_AI.jpg"}},"liveCoverageEnd":null,"seoArticleBody":"AI-generated imagery feels inescapable. It’s in the video games you play, in the movies you watch, and has flooded social media platforms. It’s even been used to promote the physical hardware that real, human artists use to create digital paintings and illustrations, to the immense frustration of those who already feel displaced by the technology. \n\nThe pervasive nature of it seems especially egregious to creators who are fighting to stop their works from being used, without consent or compensation, to improve the very thing that threatens to disrupt their careers and livelihoods. The data pools that go into training generative AI models often contain images that are indiscriminately scraped from the internet, and some AI image generator tools allow users to upload reference images they want to imitate. Many creative professionals need to advertise their work via social media and online portfolios, so simply taking everything offline isn’t a viable solution. And a lack of legal clarity around AI technology has created something of a Wild-West environment that’s difficult to resist. Difficult, but not impossible.\n\nWhile the tools are often complicated and time consuming, several AI companies provide creators with ways to opt their work out of training. And for visual artists who want broader protections there are tools like Glaze and Kin.Art, which make the works useless for training. Here’s how to navigate the best solutions we’ve found so far.\n\nOpting Out\n\nGenerative AI models depend on training datasets, and the companies behind them are motivated to avoid restricting those potential data pools. So while they often do allow artists to opt their work out, the process can be crude and labor intensive — especially if you have a sizable catalog of work. \n\nOpting out typically requires submitting a request to an AI provider, either via a dedicated form or directly via email, along with the copies and written descriptions of images you want to protect. Additionally, if you’ve agreed to let third parties license your images, the terms may include a license for AI training. It’s worth scanning the user agreements for any platforms hosting your work to check what rights they hold over it. But different AI tools’ policies vary — here’s how to opt out of some popular ones.\n\nOpenAI DALL-E\n\nOpenAI started allowing creators to remove their work from its training data alongside its DALL-E 3 generative AI model last September, and it’s one of the easier processes to follow. Content creators or owners just need to submit a form to OpenAI to request that the work be excluded from future training datasets, including a copy of the image, a description of it, and a ticked checkbox confirming that you have the rights for said image.\n\nUnfortunately, you’ll have to submit a separate form for every image you want excluded from OpenAI’s datasets, which could amount to thousands of works for some people; OpenAI hasn’t disclosed how many artists have undertaken this ordeal. \n\n[Image: You have to submit a single form for every artwork you want opting out of OpenAIs training, which simply isn’t realistic for creatives with vast portfolios. https://cdn.vox-cdn.com/thumbor/ZnMeuBMJ4NUwYQP5p55P5GXE2Ig=/0x0:1150x1693/1150x1693/filters:focal(575x847:576x848)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270057/OpenAI_opt_out_form.jpg]\n\nIf you only host your works on your own website, there might be a more efficient option. You can follow the instructions linked here to block the “GPTBot” web crawler used to scrape data from publicly available internet sources, which should protect all the content on it. A downside to this method, however, is that images posted anywhere outside of those walled protections, such as on social media, are still at risk of being scraped. Submitting a form at least ensures that your work is protected by a wider net, providing OpenAI hasn’t already obtained the images via a licensed third party.\n\nBoth these processes only offer protection against being swept into future training datasets. OpenAI claims that its AI models don’t retain any information they’ve already been trained on, so if you believe your work was already consumed by DALL-E 3 or its previous iterations, it’s too late to have it removed.\n\nDALL-E 3 is also the model used by Image Creator from Designer, the Microsoft tool previously known as Bing Image Creator. As such, the process of opting out with OpenAI directly should also prevent Image Creator from being trained on your works.\n\nAdobe Firefly\n\nOf course, for every AI company that does allow artists to remove their works from training data, many others don’t openly advertise having such a service. And if they’re training models on a platform they own, users of that platform may not be allowed to opt out at all. That’s the case with creative software giant Adobe, which uses a model called Firefly across its Creative Cloud suite, including in Photoshop’s generative fill tool.\n\nAdobe proclaims that Firefly is commercially and legally safe because it’s entirely trained on the company’s own stock image platform, Adobe Stock. But there’s no means for Adobe Stock contributors to opt out of training Adobe’s AI models, which has resulted in some existing users criticizing the company for not seeking their permission. If you don’t want your work used to improve Firefly, you can’t put it on Adobe Stock, period.\n\n[Image: It doesn’t get much clearer than this line from Adobe’s FAQs. If you don’t want to train Firefly, avoid Adobe Stock. https://cdn.vox-cdn.com/thumbor/-YUqoxNIUWrtW2JUHz36t5zMLQA=/0x0:706x135/706x135/filters:focal(353x68:354x69)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270039/Adobe_ai_opt_out.jpg]\n\nIn principle, Adobe’s approach should mean that non-Stock users don’t have to worry about Firefly. But the reality is that there’s plenty of pirated work uploaded to the platform. If you find that someone has fraudulently uploaded your work to Adobe Stock, you can send Adobe an IP infringement notice to get it removed from the platform. \n\nMeta \n\nCreatives who want to avoid training Meta’s AI models will have to jump through similar hoops. Meta is using “information from its products and services” to train its generative AI models, so anything personal you upload, or have historically uploaded, to platforms like Facebook, Instagram, and Threads is fair game for AI training. If you don’t have an account on any of those services then you’ve potentially avoided feeding its AI machine, but deleting existing accounts and/or not uploading future works to them is the next best thing.\n\nYou can submit a form to Meta to request the company correct or delete personal information that’s being used to train its generative AI models, but only if that information has been supplied by a third party. It won’t let you exclude, for instance, art you’ve been voluntarily showcasing on Instagram. Many artists have also found it to be a frustrating process, criticizing how often the tool is unable to process requests. Conceptual artist Bethany Berg told Wired that the removal form felt like “it was just a fake PR stunt to make it look like they were actually trying to do something.”\n\n[Image: Just remember that Meta will hold some rights over any content you upload to its platforms, so the most effective solution is to avoid them entirely. https://cdn.vox-cdn.com/thumbor/ivfJdF-MwlXfMg9DznEVCObGSrM=/0x0:979x969/979x969/filters:focal(490x485:491x486)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270042/meta_ai_opt_out.jpg]\n\nBeyond that, you can limit what personal information third parties are sharing with Meta by managing your Off-Facebook Activity. This tool will display which sites and services are giving your data to Meta and allow you to sever the connection that ties your identity with such data. This won’t clear the data that’s already been uploaded, but it should enable users to monitor if platforms they know are hosting their works are potentially feeding that information back to Meta directly.\n\nThat said, Meta also uses “information that is publicly available online” to train its generative AI models, and it doesn’t disclose its datasets. So there’s no way of knowing precisely what’s already in that massive content pool — and no surefire way of staying out.\n\nWhat about Stability AI, Midjourney, and so on?\n\nTwo of the most popular generative AI tools — Midjourney and Stability AI’s Stable Diffusion — will remove copyright-infringing materials under the Digital Millennium Copyright Act (DMCA). But this information is buried in their respective Terms of Use policies, and the processes are crude. This also isn’t strictly an opt-out tool, and neither company provides a means to opt work out of being sucked into future training data pools.\n\nFor both services, you’ll need to email the companies directly. Midjourney can be reached at takedown@midjourney.com. For Stability AI, email your requests to both mariya@stability.ai and legal@stability.ai. Stability’s user terms don’t specify what you’d need to provide, but the information required by Midjourney, and most DMCA copyright infringement notices generally, includes a description of the original works, where the image infringing on them is located, your contact information, and a copy of your signature. \n\nOther, smaller AI providers may also provide a similar approach to removing data that infringes on intellectual property rights thanks to regulations like DCMA, to varying success — if you’re unsure, try contacting the AI provider directly.\n\nHow else can I protect my work against generative AI?\n\nWith all that laid out, it’s clear that artists’ options when dealing directly with AI companies are pretty limited. Externally, however, several tools and services can grant creators better defenses — or even offenses — when fighting back. The various tools work differently, but in general, they run your visual art through processes that confuse or block effective training. That way, even if your work is scraped for an AI model, that model (ideally) won’t learn to reproduce it.\n\nGlaze\n\n[Image: When you launch Glaze, you’ll need to give it some time to download the resources it needs to protect your work. https://cdn.vox-cdn.com/thumbor/XYVMl3IPUQ5a7QupLrJj1_F8rUg=/0x0:1282x1132/1282x1132/filters:focal(641x566:642x567)/cdn.vox-cdn.com/uploads/chorus_asset/file/25271972/Glaze_launcher.jpg]\n\nOne of the most notable anti-training tools is Glaze, a project launched by a team out of the University of Chicago. The free-to-use tool works as a kind of cloak, making pixel-level changes to images that confuse AI software trying to read them. Real people can’t typically see these alterations on highly-detailed images so there’s little impact on the human viewing experience, but AI image generators that are fed the same materials will recognize it as something else entirely — meaning anyone who tries to replicate its specific art style will be unable to do so.\n\nGlaze is available for Windows or macOS. There are GPU and non-GPU versions available for Windows, but running the GPU variant specifically requires an Nvidia GPU from this list with at least 3.6GB of memory. (The developers say Glaze generally uses around 5GB of system memory to run.) Using it is straightforward: at first launch, the application will automatically download a number of machine learning libraries and other resources it needs to cloud your images. When that’s complete, head to the “Select” box at the top left and choose which images on your computer you’d like to Glaze. These can be uploaded in batches, so it’s much quicker than making individual opt-out requests.\n\n[Image: https://cdn.vox-cdn.com/thumbor/HQJPufnIxBA2F7zxDPxW2-8qhac=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg]\n[Image: https://cdn.vox-cdn.com/thumbor/ZUH7k6ah3Kh_VorufnSRqVAKxb8=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272552/AI_how_to_example_image_for_demo_glazed_intensity_40_V1.jpg]\nYou may want to experiment with the strength of the Glaze application — on simple illustrations like this, Glazing at max intensity can distort the results.\n\nYou can then adjust the intensity of the Glaze cloaking from “very low” to “very high,” with the latter offering greater protection against AI but increasing the possibility of changes being visible to humans. Render quality, another option, determines the overall quality of the finished image — higher-quality rendering looks better and offers greater protection but will also take much longer to process. Generally, the finished result should look virtually unchanged from your original. But a close inspection will reveal tiny differences, almost like a textured wash has been applied to it.\n\nNightshade\n\n[Image: Nightshade shares a very similar UI to Glaze, which is unsurprising considering it’s being developed by the same team. https://cdn.vox-cdn.com/thumbor/oQUoPhgyk0ildslgybihtqPE3qE=/0x0:1302x1100/1302x1100/filters:focal(651x550:652x551)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270255/Nightshade_launcher.jpg]\n\nNightshade, from the team behind Glaze, takes a similar but more extreme approach. Images passed through this cloaking tool are actually intended to “poison” generative AI models that train on them, sabotaging the outputs for text prompts. If you upload a batch of dog pictures, for instance, Nightshade is supposed to fool models into seeing some other object like cars — rather than just confusing the model like Glaze does. The idea is that if a model takes in enough confusing images, it will start building rules based on them, so any dog-related prompt might become distorted with wheels and windshields. \n\nYou can’t specify what you’d like your poisoned images to masquerade as because Nightshade is built around algorithms that can’t accommodate that kind of personalization. If you want a better insight into how it works, check out this breakdown provided by data scientist Dorian Drost.\n\nLike Glaze, Nightshade applies a filter-like film over the image that shouldn’t massively impact the human viewing experience, depending on the intensity of the protection layer and how detailed the original art is. (You can apply both Glaze and Nightshade to images without them interfering with each other.) Nightshade is also available for Windows and macOS systems, though only machines running Apple’s own silicon are supported for the latter.\n\n[Image: https://cdn.vox-cdn.com/thumbor/HQJPufnIxBA2F7zxDPxW2-8qhac=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272553/AI_how_to_example_image_for_demo.jpg]\n[Image: https://cdn.vox-cdn.com/thumbor/gzaQ2O2SO_tDyzxCo5YXIUE_Qcw=/0x0:1600x1400/1600x1400/filters:focal(800x700:801x701)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272592/AI_how_to_example_image_for_demo_nightshade_intensity_LOW_V1.jpg]\nAt default intensity, Nightshade should produce similar-looking results to Glazed images. The poisoned results on the right are nearly identical to our Glaze tests.\n\nMost of the overall process is the same as Glaze: you wait for the tool to download machine learning libraries, upload your work, and set the intensity and rendering options. But there’s one extra step. Nightshade will analyze the images and fill the “current tag” field with a single-word description identifying the content, like “dog” or “girl.” For the poisoning effect to work, this needs to be accurate — so you can change it if it’s wrong. Then, when you upload the images online, make sure that single-word tag is included in the metadata or alt text. \n\nSome generative AI advocates argue Nightshade won’t be much of a hindrance. AI systems are trained on truly vast amounts of data, so you’d need a lot of poisoning to affect any given prompt. And companies can develop workarounds that detect Nightshade. But most of these workarounds only filter out images that use it, rather than removing the protections — so the end result is just having art excluded from the training data, which is still a win. The Glaze project team is also continually working to update the applications to close any loopholes that are being exploited by workarounds.\n\nMist\n\n[Image: Mist can be tricky to set up, but its another option to try if you’re unhappy with results from Glaze and Nightshade. https://cdn.vox-cdn.com/thumbor/428XwtgEkMHMNdrbsfn-yaw5xiE=/0x0:1767x831/1767x831/filters:focal(884x416:885x417)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270243/Mist_launcher.jpg]\n\nMist is a “preprocessing tool” developed by Psyker Group that, like Glaze and Nightshade, also prevents generative AI applications from effectively imitating a creator’s unique style and works. Mist’s approach is more akin to watermarking images. If an AI model is trained on “misted images,” any attempt to mimic them will see the output completely covered in visual distortions that render it unfit for most purposes and generally unpleasant to look at.\n\n[Image: Here’s an example of what’s produced by AI generation tools that reference Misted images. https://cdn.vox-cdn.com/thumbor/epkM8JALgo4JWPCrDQpt3RKsEOA=/0x0:512x512/512x512/filters:focal(256x256:257x257)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272426/misted_t2i.jpg]\n\nElements of the original image can still be seen in some of these outputs, like similarities in photography or art styles, but the chaotic, noisy filter over the generated image isn’t something that can be easily corrected. Mist requires a graphics card with at least 6GB of VRAM, which isn’t a lot of computational resources, but it’s still greater than the 3.6GB Glaze requires. Mist has been open-sourced on GitHub to allow developers to build their own tools around it, and its creators have committed to offering long-term support and continuously improving its function.\n\nThere are currently two ways for non-developers to use Mist. Windows PC users running an Nvidia GPU can download Mist for free via this Google Drive package. The software doesn’t require installation and can be used almost immediately after downloading — though it’s a little finicky to set up if you lack any coding or development experience.\n\n[Image: https://cdn.vox-cdn.com/thumbor/5eU328CU5OnDFEK7ITjLgu7SWOM=/0x0:600x600/600x600/filters:focal(300x300:301x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272436/ori_sample.png]\n[Image: https://cdn.vox-cdn.com/thumbor/eOisXUU_lbyl4nxNMhLi1K17QWM=/0x0:600x600/600x600/filters:focal(300x300:301x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/25272437/mist_4.png]\nMisting images can also produce a faint, swirling filter over the results, but like Glaze, it's harder to spot on detailed art or photography.\n\nA detailed handbook is available that will walk you through the entire process, along with a community Discord channel for troubleshooting. First, make sure you’ve installed the .NET desktop runtime. When that’s done, you just select the “ENG” file inside Google Drive and download the zipped Mist_V2 folder within it. Create a new folder called “IMG” in mist-v2 \u003e src \u003e data \u003e. Drop any images that you plan on Misting into the new folder when completed. Then, go back to the main folder (which should be titled “mist-v2_gui_free_version”) and run the Mist GUI booter. Mist allows you to adjust the strength of protection applied to images and select between using your device’s GPU or CPU, which may prove useful if you’re running old or inefficient hardware.\n\nFor anyone who’s using macOS or doesn’t possess an Nvidia GPU, you can also run Mist via Colab Notebook, a cloud-based Jupyter Notebook environment that runs in your web browser. Detailed instructions for how to do this are available here, but it’s a much more complicated process to set up than its Windows equivalent. Glaze and Nightshade, generally, will be much easier to navigate for folks who aren't familiar with coding processes.\n\nKin.Art\n\nKin.Art isn’t so much an AI protection tool as it is an entire portfolio platform that artists can use to host and sell their work. It goes beyond just banning AI-generated works — though that’s appreciated, given the backlash against sites like DeviantArt and ArtStation — and actively makes AI scraping and training harder.\n\nKin.Art uses two different techniques to thwart AI companies. The first is image segmentation, which is used to break apart images and muddle them into something unrecognizable. It’s undetectable to human eyes but disrupts generative AI models from being able to read the image. This visual scrambling will also be present if anyone attempts to save or download the image, though it doesn’t block manual screenshots. The second technique involves scrambling the metadata, like title and description, so any labels the AI model reads won’t accurately reflect the content.\n\n[Image: Kin.Art’s AI protections just require users to tick a box when uploading their works to the platform. https://cdn.vox-cdn.com/thumbor/SO1ehnIJaxSF_oGgKdTgDKfq7k0=/0x0:915x410/915x410/filters:focal(458x205:459x206)/cdn.vox-cdn.com/uploads/chorus_asset/file/25270112/Kin_art_anti_ai_upload.jpg]\n\nThese protections are automatically applied on the Kin.Art platform, so you just need to create an account and upload your works to benefit from them, and that works like practically any social media platform. There are some neat creator-focused features included, like the ability to add a commission status to advertise your availability to accept requests, and you can link out to external platforms like social media pages directly on your user profile. You can toggle the protections on or off when uploading images, and the service is currently free to use. Instead, Kin.Art will start placing a 5 percent service fee on top of commissions made through the service in March.\n\nWhat about music, writing, and other media?\n\nOur guide covers what protections are available for image-based art largely because that format has more tools available than other mediums, and the opting-out processes tend to be clearer (when they are available). That said, creatives in other fields, like writing, voice acting, and music, are also fighting to protect their work. It’s much harder to disrupt how AI models are trained on this kind of data without noticeably affecting the original content, but there are still precautions you can take to reduce the risk of it being swept into AI training datasets.\n\nAs with art, always check the user terms of the hosting platform to which you’re uploading your works. Services will generally disclose if they’re handing platform data over to third parties for AI training or using it to develop their own models — if there’s no explicit opt-out process, you may unknowingly be giving consent simply by signing up. Instead, look for platforms like Medium, which have committed to blocking attempts to use content hosted on the site to train AI models. If you’re hosting work on your own site, you can also do things like block GPTBot to avoid pages being scraped.\n\nSome rights distributors have made similar commitments, like the Society of Authors, Composers and Publishers of Music (SACEM) — a French association that announced it was exercising its right to opt out on behalf of its members last year. Another tip for writers, courtesy of the Authors Guild, is to place a short warning notice on your published works that clearly states you don’t consent to it being used to train AI. This is the example provided by the guild:\n\n\u003e “NO AI TRAINING: Without in any way limiting the author’s [and publisher’s] exclusive rights under copyright, any use of this publication to “train” generative artificial intelligence (AI) technologies to generate text is expressly prohibited. The author reserves all rights to license uses of this work for generative AI training and development of machine learning language models.”\n\nThese warnings serve to clearly flag that the work isn’t freely available to use, which may be useful in any future lawsuits raised against companies that violate your ownership rights. If bots scraping web data are also intuitive enough to filter out results with such warnings then this could also potentially provide another layer of proactive protection, but there’s little evidence to show how many actually observe such information. Otherwise, performers and writers will need to submit copyright takedown notices to AI companies if they believe their works have been infringed.\n","stream":null,"visibleNetworkIds":[],"scheduledForExpirationAt":null}}}]},"uid":"Entry:1c995675-e913-450a-abef-091ac7bb185a","mostPopular":[{"author":{"fullName":"Andrew J. Hawkins"},"publishDate":"2024-05-06T16:40:06","title":"More Tesla employees laid off as bloodbath enters its fourth week","url":"https://www.theverge.com/2024/5/6/24150274/tesla-layoffs-employee-fourth-week-elon-musk-ev-demand","uid":"0"},{"author":{"fullName":"Chris Welch"},"publishDate":"2024-05-06T20:57:39","title":"These are the upcoming Sonos Ace wireless headphones","url":"https://www.theverge.com/2024/5/6/24150573/sonos-ace-headphones-reveal-leak-wireless","uid":"1"},{"author":{"fullName":"David Pierce"},"publishDate":"2024-05-05T12:00:00","title":"The best new browser for Windows","url":"https://www.theverge.com/2024/5/5/24148223/arc-browser-windows-claude-sofa-bose-beats-hacks-coffee-installer","uid":"2"},{"author":{"fullName":"David Pierce"},"publishDate":"2024-05-05T13:00:00","title":"Better Siri is coming: what Apple’s research says about its AI plans","url":"https://www.theverge.com/2024/5/5/24147995/apple-siri-ai-research-chatbot-creativity","uid":"3"},{"author":{"fullName":"Emma Roth"},"publishDate":"2024-05-06T15:55:52","title":"‘Apple Pencil Pro’ spotted in code on Apple’s Japanese site","url":"https://www.theverge.com/2024/5/6/24150198/apple-pencil-pro-japan-website-code-leak","uid":"4"}],"navProps":{"campaignGroup":null,"stickyNav":true,"logoColor":"franklin","lightText":false},"_sentryTraceData":"54438197329444e5ad6a0a7f61ec2de2-bc00f6e0a152de99-0","_sentryBaggage":"sentry-environment=production,sentry-release=TIjH7e7ABna7etOOsIsVO,sentry-public_key=6547365f9d98454ba8daa58e42013d33,sentry-trace_id=54438197329444e5ad6a0a7f61ec2de2"},"__N_SSP":true},"page":"/entry/standard/[uid]","query":{"uid":"Entry:1c995675-e913-450a-abef-091ac7bb185a"},"buildId":"TIjH7e7ABna7etOOsIsVO","isFallback":false,"gssp":true,"scriptLoader":[{"src":"https://theverge.coral.coralproject.net/assets/js/count.js?v=0","strategy":"lazyOnload","className":"coral-script","defer":true}]}</script></body></html> contentType 9 text/html url 80 https://www.theverge.com:443/24063327/ai-art-protect-images-copyright-generators responseCode 3 200 