riaghsheaqvqfclckcisdsdmbokansmomiborgma length 5 57896 page 57896 <!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Chatbots Have Thoroughly Infiltrated Scientific Publishing | Scientific American</title>
    <link rel="canonical" href="https://www.scientificamerican.com/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/">
    <meta name="theme-color" content="#fff"/>
    <meta name="robots" content="max-image-preview:large"/>
    <link rel="image_src" src="https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1200">
    <meta property=og:url content="https://www.scientificamerican.com/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/"/>
    <meta property=og:image content="https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1200"/>
    <meta name=twitter:image content="https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1200"/>
    <meta name=author content="Chris Stokel-Walker"/>
    <meta name=description content="One percent of scientific articles published in 2023 showed signs of generative AI’s potential involvement, according to a recent analysis"/>
    <meta property=og:title content="AI Chatbots Have Thoroughly Infiltrated Scientific Publishing"/>
    <meta property=og:description content="One percent of scientific articles published in 2023 showed signs of generative AI’s potential involvement, according to a recent analysis"/>
    <meta property=og:site_name content="Scientific American"/>
    <meta property=og:image:alt content="Cropped image of a line chart shows various words, including “noteworthy” and “intricate,” increasing in usage over time."/>
    <meta property=og:type content="article"/>
    <meta name=twitter:title content="Chatbots Have Thoroughly Infiltrated Scientific Publishing"/>
    <meta name=twitter:description content="One percent of scientific articles published in 2023 showed signs of generative AI’s potential involvement, according to a recent analysis"/>
    <meta name=twitter:image:alt content="Cropped image of a line chart shows various words, including “noteworthy” and “intricate,” increasing in usage over time."/>
    <meta property=og:locale content="en_US"/>
    <meta name=twitter:site content="@sciam"/>
    <meta name=twitter:domain content="scientificamerican.com"/>
    <meta name=twitter:card content="summary_large_image"/>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Chatbots Have Thoroughly Infiltrated Scientific Publishing","image":["https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1200"],"datePublished":"2024-05-01T10:45:00+00:00","dateModified":"2024-05-01T14:26:56.128000+00:00","author":[{"@type":"Person","name":"Chris Stokel-Walker","url":"https://www.scientificamerican.com/author/chris-stokel-walker/"}]}</script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="icon shortcut" href="https://www.scientificamerican.com/account/sciam-favicon.ico" />
    <link
      rel="alternate"
      type="application/rss+xml"
      title="RSS"
      href="https://www.scientificamerican.com/platform/syndication/rss/"
    />
    <script data-layer="critical">;performance.mark('app-load-start');((d,ael,dcl,unl,cxl,log,onunl)=>{log('[readyState]',d.readyState);d[ael]('readystatechange',()=>log('[readyState]',d.readyState));d[ael](dcl,()=>log(dcl));d[ael](unl,onunl);window.onload=()=>{d.removeEventListener(unl,onunl);log('windowloaded')};})(document,'addEventListener','DOMContentLoaded','beforeunload','cancelled',(...msg)=>console.log('[dev]',...msg),()=>{window[cxl]=true;log(cxl)})</script>
    <script type="module" crossorigin src="/static/bundle.356c56a5.js"></script>
    <link rel="modulepreload" crossorigin href="/static/chunks/preload-helper-4b76a383.js">
    <link rel="modulepreload" crossorigin href="/static/chunks/vendor-react-fc923b03.js">
    <link rel="modulepreload" crossorigin href="/static/chunks/sciam-290177bf.js">
    <link rel="modulepreload" crossorigin href="/static/chunks/datalayer-344da07f.js">
    <link rel="modulepreload" crossorigin href="/static/chunks/use-page-267d7b20.js">
    <link rel="modulepreload" crossorigin href="/static/chunks/useOverlay-92a7d566.js">
    <link rel="stylesheet" href="/static/assets/bundle-287404a4.css">
    
    <link rel="stylesheet" href="/static/assets/Input-b967ce2c.css">
    <link rel="stylesheet" href="/static/assets/Header-ace76fb1.css">
    <link rel="stylesheet" href="/static/assets/ArticleDisplay-ab788ec8.css">
    <link rel="stylesheet" href="/static/assets/ArticleList-6d1b2284.css">
    <link rel="stylesheet" href="/static/assets/index-99a28afa.css">
    <link rel="stylesheet" href="/static/assets/DefaultLayout-4266d6e7.css">
    <link rel="stylesheet" href="/static/assets/article-0798e3cc.css">
    <link rel="modulepreload" href="/static/article.9a0aa9b4.js" crossorigin fetchpriority="auto">
    <link rel="preload" href="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" as="script" fetchpriority="auto">
    <link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-5FLM662" as="script" fetchpriority="auto">
    <link rel="preload" href="https://www.scientificamerican.com/sciads/sciads.js" as="script" fetchpriority="auto">
    <link rel="preload" href="https://cdn.tp.scientificamerican.com/api/tinypass.min.js" as="script" fetchpriority="low">
    <link rel="preconnect" href="https://cdn.cxense.com/cx.cce.js" as="script">
  </head>
  <body>
    <div id="app"><header class="headerContainer-8KxQ5"><a href="#main" id="skipToMain" class="skiptocontent sr-only-focusable sr-only">Skip to main content</a><div class="header-1t1JE flex-aYeiI"><div class="left-ajw3c flex-aYeiI"><a href="/" aria-label="Link to homepage" class="logoLink-Wt3sq"><span class="sr-only">Scientific American</span><svg width="1em" height="1em" viewBox="0 0 120.79 128.39" fill="currentColor" role="img" aria-label="Scientific American"><path d="M7.98 58.19c2.3 0 5.24 3.18 14.53 3.18 13.66 0 21.75-8.57 21.75-17.86 0-7.86-3.73-12.94-11.43-17.23l-9.37-5.24c-4.05-2.3-7.46-5.32-7.46-9.92 0-4.92 3.73-7.7 9.69-7.7s11.35 4.21 13.02 13.26h1.98V.95h-1.83c-.16 1.43-.87 2.06-1.75 2.06-2.06 0-4.53-2.94-12.62-2.94C13.85.08 5.12 6.51 5.12 16.35c0 7.3 3.26 11.83 9.77 15.56l9.61 5.48c5.48 3.18 7.7 6.19 7.7 10.72 0 5.64-3.18 9.77-10.64 9.77-9.29 0-13.58-5.08-15.32-16.2H4.1V60.5h1.98c.16-1.67.95-2.3 1.91-2.3Zm65.97 3.26c11.11-.03 19.13-8.81 20.4-20.72l-2.22-.64c-2.54 8.26-7.22 12.46-13.97 12.46-12.23 0-16.04-14.93-16.04-27.87 0-15.56 6.11-21.28 14.13-21.28 5.72 0 11.83 5.72 14.45 16.59h2.06V.95h-1.91c-.16 1.27-.87 2.06-2.14 2.06-1.91 0-5.72-3.02-11.83-3.02-14.85 0-28.66 12.07-28.66 32.39 0 17.39 10.96 29.1 25.72 29.06Zm14.53 42.72L76.49 68.84H56.24v1.75c3.33.16 4.76.95 4.76 5.95v42c0 6.03-1.67 8.1-5.32 8.1-2.54 0-4.53-1.91-6.51-6.91L29.11 68.12h-2.7L6.35 119.89c-2.17 5.72-4.3 6.75-6.35 6.75v1.75h18.02v-1.75c-5.8-.24-8.65-2.7-5.8-10.48l2.05-5.4h17.88l3.45 8.97c2.3 5.72.64 6.91-3.73 6.91v1.75h39.62v-1.75c-4.13 0-6.27-1.19-6.27-8.02l.48-42.08 17.07 51.29h2.14l17.63-51.05v43.9c0 5.48-1.75 5.95-5.08 5.95v1.75h23.34v-1.75c-3.33 0-4.76-.48-4.76-5.95V76.54c0-5.56 1.43-5.95 4.76-5.95v-1.75h-19.85l-12.46 35.33Zm-72.88 3.1 7.56-19.85 7.63 19.85H15.6ZM120.79 2.7V.95h-23.1V2.7c3.33 0 4.84.32 4.84 5.95v44.14c0 5.48-1.51 5.95-4.84 5.95v1.75h23.1v-1.75c-3.33 0-4.76-.48-4.76-5.95V8.65c0-5.64 1.43-5.95 4.76-5.95Z"></path></svg></a></div><div class="center-oMgM8 flex-aYeiI"></div><div class="right-4LP3J flex-aYeiI"><div class="profileIconDropdownContainer-DM-LM"><button type="button" class="profileIconLoggedOutBtn-F9aJJ"><span class="sr-only">Sign in</span><svg width="1em" height="1em" viewBox="0 0 472 472" fill="currentColor" role="img" aria-label="User" class="profileIconLoggedOutImg-UUxUk"><path d="M403 69a235 235 0 0 0-334 0 235 235 0 0 0 0 334 235 235 0 0 0 334 0 235 235 0 0 0 0-334ZM118 412a122 122 0 0 1 237 0 211 211 0 0 1-237 0Zm41-197a77 77 0 1 1 155 0 77 77 0 0 1-155 0Zm216 181c-14-43-48-77-91-92a101 101 0 1 0-96 0c-43 15-77 49-91 92a212 212 0 1 1 278 0Z"></path></svg></button></div></div></div></header><article class="article-GDG-h"><div class="article__header-a5-f7"><div class="article_date_and_read_time-NVTxn"><p class="article_pub_date-mp61W">May 1, 2024</p><p class="article_read_time-k3gXv">5<!-- --> min read</p></div><h1 class="article_hed-LDnzF"><p>AI Chatbots Have Thoroughly Infiltrated Scientific Publishing</p></h1><div class="article_dek-VydJj"><p>One percent of scientific articles published in 2023 showed signs of generative AI&rsquo;s potential involvement, according to a recent analysis</p></div><p class="article_authors-OZP24">By <a class="article_authors__link-M7PNB" href="/author/chris-stokel-walker/">Chris Stokel-Walker</a></p><figure class="lead_image-3nDcx"><img src="https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=600" alt="Cropped image of a line chart shows various words, including “noteworthy” and “intricate,” increasing in usage over time." srcSet="https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=600 600w, https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=900 900w, https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1000 1000w, https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1200 1200w, https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1350 1350w" sizes="(min-width: 900px) 900px, (min-resolution: 2dppx) 75vw, (min-resolution: 2.1dppx) 50vw, 100vw" class="lead_image__img-e3fpf" style="--w:3750;--h:2500" fetchpriority="high"/><figcaption class="lead_image__figcaption-Y9Y9T"> <div class="lead_image__credit-jEB44"><p>Amanda Monta&ntilde;ez; Source: Andrew Gray</p></div></figcaption></figure><div class="article_eyebrows-1uGmS"><div class="eyebrows_container-QeE5W"></div></div></div><div class="article__content-24wun"><p class="article__block-KZIY9" data-block="sciam/paragraph">Researchers are misusing ChatGPT and other artificial intelligence chatbots to produce scientific literature. At least, that&rsquo;s a new fear that some scientists have raised, citing a stark rise in suspicious AI shibboleths showing up in published papers.</p><p class="article__block-KZIY9" data-block="sciam/paragraph">Some of these tells&mdash;such as the <a href="https://twitter.com/gcabanac/status/1767574447337124290?">inadvertent inclusion</a> of &ldquo;certainly, here is a possible introduction for your topic&rdquo; in a recent paper in <i>Surfaces and Interfaces</i>, a journal published by Elsevier&mdash;are reasonably obvious evidence that a scientist used an AI chatbot known as a large language model (LLM). But &ldquo;that&rsquo;s probably only the tip of the iceberg,&rdquo; says scientific integrity consultant Elisabeth Bik. (A representative of Elsevier told <i>Scientific American</i> that the publisher regrets the situation and is investigating how it could have &ldquo;slipped through&rdquo; the manuscript evaluation process.) In most other cases AI involvement isn&rsquo;t as clear-cut, and automated AI text detectors are <a href="https://www.scientificamerican.com/article/tech-companies-new-favorite-solution-for-the-ai-content-crisis-isnt-enough/">unreliable tools</a> for analyzing a paper.</p><p class="article__block-KZIY9" data-block="sciam/paragraph">Researchers from several fields have, however, identified a few key words and phrases (such as &ldquo;<a href="https://blog.j11y.io/2023-11-22_multifaceted/">complex and multifaceted</a>&rdquo;) that tend to appear more often in AI-generated sentences than in typical human writing. &ldquo;When you&rsquo;ve looked at this stuff long enough, you get a feel for the style,&rdquo; says Andrew Gray, a librarian and researcher at University College London.</p><hr/><h2 class="article__block-KZIY9">On supporting science journalism</h2><p class="article__block-KZIY9">If you&#x27;re enjoying this article, consider supporting our award-winning journalism by<!-- --> <a href="/getsciam/">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><hr/><p class="article__block-KZIY9" data-block="sciam/paragraph">LLMs are designed to generate text&mdash;but what they produce may or may not be factually accurate. &ldquo;The problem is that these tools are not good enough yet to trust,&rdquo; Bik says. They succumb to what computer scientists call <a href="https://www.scientificamerican.com/article/chatbot-hallucinations-inevitable/">hallucination</a>: simply put, they make stuff up. &ldquo;Specifically, for scientific papers,&rdquo; Bik notes, an AI &ldquo;will generate citation references that don&rsquo;t exist.&rdquo; So if scientists place too much confidence in LLMs, study authors risk inserting AI-fabricated flaws into their work, mixing more potential for error into the already messy reality of scientific publishing.</p><p class="article__block-KZIY9" data-block="sciam/paragraph">Gray recently hunted for AI buzzwords in scientific papers using Dimensions, a data analytics platform that its developers say tracks <a href="https://www.dimensions.ai/">more than 140 million</a> papers worldwide. He searched for words disproportionately used by chatbots, such as &ldquo;intricate,&rdquo; &ldquo;meticulous&rdquo; and &ldquo;commendable.&rdquo; These indicator words, he says, give a better sense of the problem&rsquo;s scale than any &ldquo;giveaway&rdquo; AI phrase a clumsy author might copy into a paper. At least 60,000 papers&mdash;slightly more than 1 percent of all scientific articles published globally last year&mdash;may have used an LLM, according to Gray&rsquo;s <a href="https://arxiv.org/abs/2403.16887">analysis</a>, which was released on the preprint server arXiv.org and has yet to be peer-reviewed. Other studies that focused specifically on subsections of science suggest even more reliance on LLMs. <a href="https://arxiv.org/abs/2404.01268">One such investigation found that </a>up to 17.5 percent of recent computer science papers exhibit signs of AI writing.</p><figure class="article__image-EQ52t default-ztNlj" data-block="contentful/image" style="--w:1324;--h:11981;--w-desktop:3750;--h-desktop:9271"><picture><source media="(min-width: 750px)" srcSet="https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=1350 1350w, https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=2000 2000w, https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"/><source media="(min-width: 0px)" srcSet="https://static.scientificamerican.com/dam/m/5c79875b1cc75f72/original/AIsciencePub_graphic_m.png?w=1000 1000w, https://static.scientificamerican.com/dam/m/5c79875b1cc75f72/original/AIsciencePub_graphic_m.png?w=1200 1200w, https://static.scientificamerican.com/dam/m/5c79875b1cc75f72/original/AIsciencePub_graphic_m.png?w=600 600w, https://static.scientificamerican.com/dam/m/5c79875b1cc75f72/original/AIsciencePub_graphic_m.png?w=750 750w" sizes="(min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"/><img alt="Line charts show how scientific publishing volume and usage of various AI-associated and “control” words changed from 2015 to 2023, per the Dimensions database. Bar charts compare year-over-year percentage change in usage of these words from 2022 to 2023." decoding="async" loading="lazy" src="https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=900" width="3750" height="9271" srcSet="https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=1000 1000w, https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=1200 1200w, https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=1350 1350w, https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=2000 2000w, https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=600 600w, https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=750 750w, https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png?w=900 900w" sizes="(min-width: 2000px) 2000px, (min-resolution: 3dppx) 50vw, (min-resolution: 2dppx) 75vw, 100vw"/></picture><figcaption><div><p>Amanda Monta&ntilde;ez; Source: Andrew Gray</p></div></figcaption></figure><p class="article__block-KZIY9" data-block="sciam/paragraph">Those findings are supported by <i>Scientific American</i>&rsquo;s own search using Dimensions and several other scientific publication databases, including Google Scholar, Scopus, PubMed, OpenAlex and Internet Archive Scholar. This search looked for signs that can suggest an LLM was involved in the production of text for academic papers&mdash;measured by the prevalence of phrases that ChatGPT and other AI models typically append, such as &ldquo;as of my last knowledge update.&rdquo; In 2020 that phrase appeared only once in results tracked by four of the major paper analytics platforms used in the investigation. But it appeared 136 times in 2022. There were some limitations to this approach, though: It could not filter out papers that might have represented studies of AI models themselves rather than AI-generated content. And these databases include material beyond peer-reviewed articles in scientific journals.</p><p class="article__block-KZIY9" data-block="sciam/paragraph">Like Gray&rsquo;s approach, this search also turned up subtler traces that may have pointed toward an LLM: it looked at the number of times stock phrases or words preferred by ChatGPT were found in the scientific literature and tracked whether their prevalence was notably different in the years just before the November 2022 release of OpenAI&rsquo;s chatbot (going back to 2020). The findings suggest something has changed in the lexicon of scientific writing&mdash;a development that might be caused by the writing tics of increasingly present chatbots. &ldquo;There&rsquo;s some evidence of some words changing steadily over time&rdquo; as language normally evolves, Gray says. &ldquo;But there&rsquo;s this question of how much of this is long-term natural change of language and how much is something different.&rdquo;</p><h2 class="article__block-KZIY9" data-block="sciam/heading">Symptoms of ChatGPT</h2><p class="article__block-KZIY9" data-block="sciam/paragraph">For signs that AI may be involved in paper production or editing, <i>Scientific American</i>&rsquo;s search delved into the word &ldquo;delve&rdquo;&mdash;which, as <a href="https://pshapira.net/2024/03/31/delving-into-delve/">some informal monitors</a> of AI-made text have pointed out, has seen an unusual spike in use across academia. An analysis of its use across the 37 million or so citations and paper abstracts in life sciences and biomedicine contained within the PubMed catalog highlighted how much the word is in vogue. Up from 349 uses in 2020, &ldquo;delve&rdquo; appeared 2,847 times in 2023 and has already cropped up 2,630 times so far in 2024&mdash;a 654 percent increase. Similar but less pronounced increases were seen in the Scopus database, which covers a wider range of sciences, and in Dimensions data.</p><p class="article__block-KZIY9" data-block="sciam/paragraph">Other terms flagged by these monitors as AI-generated catchwords have seen similar rises, according to the <i>Scientific American</i> analysis: &ldquo;commendable&rdquo; appeared 240 times in papers tracked by Scopus and 10,977 times in papers tracked by Dimensions in 2020. Those numbers spiked to 829 (a 245 percent increase) and 20,536 (an 87 percent increase), respectively, in 2023. And in a perhaps ironic twist for would-be &ldquo;meticulous&rdquo; research, that word doubled on Scopus between 2020 and 2023.</p><h2 class="article__block-KZIY9" data-block="sciam/heading">More Than Mere Words</h2><p class="article__block-KZIY9" data-block="sciam/paragraph">In a world where academics live by the mantra &ldquo;<a href="https://www.businessinsider.com/fake-science-crisis-ai-generated-rat-giant-penis-image-2024-3">publish or perish</a>,&rdquo; it&rsquo;s unsurprising that some are using chatbots to save time or to bolster their command of English in a sector where it is often required for publication&mdash;and may be a writer&rsquo;s second or third language. But employing AI technology as a grammar or syntax helper could be a slippery slope to misapplying it in other parts of the scientific process. Writing a paper with an LLM co-author, the worry goes, may lead to key figures generated whole cloth by AI or to peer reviews that are outsourced to automated evaluators.</p><p class="article__block-KZIY9" data-block="sciam/paragraph">These are not purely hypothetical scenarios. AI certainly has been used to produce scientific diagrams and illustrations that have often been included in academic papers&mdash;including, notably, one <a href="https://scienceintegritydigest.com/2024/02/15/the-rat-with-the-big-balls-and-enormous-penis-how-frontiers-published-a-paper-with-botched-ai-generated-images/">bizarrely endowed rodent</a>&mdash;and even to <a href="https://www.scientificamerican.com/article/can-ai-replace-human-research-participants-these-scientists-see-risks/">replace human participants in experiments</a>. And the use of AI chatbots may have <a href="https://arxiv.org/abs/2403.07183">permeated the peer-review process itself</a>, based on a preprint study of the language in feedback given to scientists who presented research at conferences on AI in 2023 and 2024. If AI-generated judgments creep into academic papers alongside AI text, that concerns experts, including Matt Hodgkinson, a council member of the Committee on Publication Ethics, a U.K.-based nonprofit organization that promotes ethical academic research practices. Chatbots are &ldquo;not good at doing analysis,&rdquo; he says, &ldquo;and that&rsquo;s where the real danger lies.&rdquo;</p></div><footer class="article__block-KZIY9 footer-u1I4n"><div class="divide-L7a-x"><div class="rights-Y0o9k"><a target="_blank" href="https://s100.copyright.com/AppDispatchServlet?publisherName=sciam&amp;publication=sciam&amp;title=Chatbots+Have+Thoroughly+Infiltrated+Scientific+Publishing&amp;publicationDate=2024-05-01&amp;contentID=7bVpuVjnKZbJ8IQrkgMTlR&amp;orderBeanReset=true&amp;author=Chris+Stokel-Walker&amp;copyright=Copyright+2024+Scientific+American%2C+Inc.">Rights &amp; Permissions</a></div></div><div class="divide-L7a-x"></div><div class="divide-L7a-x"><div class="subdivide-5Zp4J"><div class="bio-LnT3Q"><p><b><a class="bioLink-kqdDv" href="/author/chris-stokel-walker/">Chris Stokel-Walker</a></b> is a freelance journalist in Newcastle, UK.</p></div><a href="/author/chris-stokel-walker/">More by <span>Chris Stokel-Walker</span></a></div></div><div class="divide-L7a-x"></div></footer><div class="breakoutContainer-8fsaw"><gpt-ad class="ad-G8iDN" unitpath="injector" style="--margin:20px 0" sizes-from-0="300x250,300x50,320x50,fluid" sizes-from-745="728x90,300x250,fluid" sizes-from-1000="970x250,970x90,728x90,300x250,fluid" targeting-pos="article-footer"></gpt-ad></div></article><div class="articleList-R10iq root-fREBs"><div class="articleListGrid-N4wvY grid-PoVrj containerHideLastItemIfNativeLoads-PffoX"></div></div><footer class="footer-VfsmT"><div class="footerContainer-pfbjC"><h2 class="footerMainText-wQ3og">Expand Your World with Science</h2></div><div class="footerFlexContainer-XKe5g footerContainer-pfbjC"><div class="footerLinks-m1THn"><p class="footerText-PzHcy">Learn and share the most exciting discoveries, innovations and ideas shaping our world today.</p><a class="footerLink-uRzI4" href="https://www.scientificamerican.com/getsciam/">Subscribe</a><a class="footerLink-uRzI4" href="https://www.scientificamerican.com/newsletter-signup/">Sign up for our newsletters</a><a class="footerLink-uRzI4" href="https://www.scientificamerican.com/">See the latest stories</a><a class="footerLink-uRzI4" href="https://www.scientificamerican.com/latest-issue/">Read the latest issue</a><a class="footerLink-uRzI4" href="https://www.scientificamerican.com/getsciam/gift/">Give a Gift Subscription</a><p class="footerSocialMedia-7KIIV">Follow Us:<a href="https://www.instagram.com/scientific_american/?hl=en" alt="Instagram link" title="Instagram"><svg class="footerSocialIcon-UQyIx" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z"></path></svg></a><a href="https://www.youtube.com/user/SciAmerican" alt="YouTube link" title="YouTube"><svg class="footerSocialIcon-UQyIx" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a><a href="https://twitter.com/sciam" alt="Twitter link" title="Twitter"><svg class="footerSocialIcon-UQyIx" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a href="https://www.facebook.com/ScientificAmerican" alt="Facebook link" title="Facebook"><svg class="footerSocialIcon-UQyIx" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z"></path></svg></a><a href="/platform/syndication/rss/" alt="RSS feed" title="RSS feed"><svg class="footerSocialIcon-UQyIx" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M0 64C0 46.3 14.3 32 32 32c229.8 0 416 186.2 416 416c0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96C14.3 96 0 81.7 0 64zM0 416a64 64 0 1 1 128 0A64 64 0 1 1 0 416zM32 160c159.1 0 288 128.9 288 288c0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224c-17.7 0-32-14.3-32-32s14.3-32 32-32z"></path></svg></a></p></div><div class="footerImageContainer-omuef"><img class="footerImage-fMFhw" src="/static/assets/footerProductImg-82df991e.png" alt="Scientific American publications in print &amp; digital formats" as="image" loading="lazy"/></div></div><div class="grid-c0--6 footerContainer-pfbjC"><div><ul><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/page/return-refund-policy/">Return &amp; Refund Policy</a></li><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/page/about-scientific-american/">About</a></li><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/pressroom/">Press Room</a></li></ul></div><div><ul class="footer-links"><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/page/frequently-asked-questions/subscriptions/">FAQs</a></li><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/page/contact-us/customer-service/">Contact Us</a></li><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/page/international/">International Editions</a></li></ul></div><div><ul class="footer-links"><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/mediakit/">Advertise</a></li><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/accessibility-statement/">Accessibility Statement</a></li><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/page/terms-of-use/">Terms of Use</a></li></ul></div><div><ul class="footer-links"><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/page/privacy-policy/">Privacy Policy</a></li><li><a class="footerSmallLink-tZvCu" href="https://www.scientificamerican.com/page/california-consumer-privacy-statement/">California Consumer Privacy Statement</a></li><li><a class="footerSmallLink-tZvCu" href="#">Use of cookies/Do not sell my data</a></li></ul></div></div><div class="footerContainer-pfbjC"><p>Scientific American is part of Springer Nature, which owns or has commercial relations with thousands of scientific publications (many of them can be found at www.springernature.com/us). Scientific American maintains a strict policy of editorial independence in reporting developments in science to our readers.</p><p>© 2024 SCIENTIFIC AMERICAN, A DIVISION OF SPRINGER NATURE AMERICA, INC.<br/>ALL RIGHTS RESERVED.</p></div></footer></div>
    <script id="__DATA__">window.__DATA__=JSON.parse(`{"initialData":{"article":{"id":1307114,"contentful_id":"7bVpuVjnKZbJ8IQrkgMTlR","mura_id":null,"mura_contentid":null,"title":"Chatbots Have Thoroughly Infiltrated Scientific Publishing","display_title":"<p>AI Chatbots Have Thoroughly Infiltrated Scientific Publishing</p>","share_title":"AI Chatbots Have Thoroughly Infiltrated Scientific Publishing","display_category":"Artificial Intelligence","display_category_slug":"artificial-intelligence","display_date":null,"slug":"chatbots-have-thoroughly-infiltrated-scientific-publishing","summary":"<p>One percent of scientific articles published in 2023 showed signs of generative AI&rsquo;s potential involvement, according to a recent analysis</p>","why_box":"","content":[{"tag":"p","type":"paragraph","attributes":{},"content":"Researchers are misusing ChatGPT and other artificial intelligence chatbots to produce scientific literature. At least, that&rsquo;s a new fear that some scientists have raised, citing a stark rise in suspicious AI shibboleths showing up in published papers."},{"tag":"p","type":"paragraph","attributes":{},"content":"Some of these tells&mdash;such as the <a href=\\"https://twitter.com/gcabanac/status/1767574447337124290?\\">inadvertent inclusion</a> of &ldquo;certainly, here is a possible introduction for your topic&rdquo; in a recent paper in <i>Surfaces and Interfaces</i>, a journal published by Elsevier&mdash;are reasonably obvious evidence that a scientist used an AI chatbot known as a large language model (LLM). But &ldquo;that&rsquo;s probably only the tip of the iceberg,&rdquo; says scientific integrity consultant Elisabeth Bik. (A representative of Elsevier told <i>Scientific American</i> that the publisher regrets the situation and is investigating how it could have &ldquo;slipped through&rdquo; the manuscript evaluation process.) In most other cases AI involvement isn&rsquo;t as clear-cut, and automated AI text detectors are <a href=\\"https://www.scientificamerican.com/article/tech-companies-new-favorite-solution-for-the-ai-content-crisis-isnt-enough/\\">unreliable tools</a> for analyzing a paper."},{"tag":"p","type":"paragraph","attributes":{},"content":"Researchers from several fields have, however, identified a few key words and phrases (such as &ldquo;<a href=\\"https://blog.j11y.io/2023-11-22_multifaceted/\\">complex and multifaceted</a>&rdquo;) that tend to appear more often in AI-generated sentences than in typical human writing. &ldquo;When you&rsquo;ve looked at this stuff long enough, you get a feel for the style,&rdquo; says Andrew Gray, a librarian and researcher at University College London."},{"tag":"p","type":"paragraph","attributes":{},"content":"LLMs are designed to generate text&mdash;but what they produce may or may not be factually accurate. &ldquo;The problem is that these tools are not good enough yet to trust,&rdquo; Bik says. They succumb to what computer scientists call <a href=\\"https://www.scientificamerican.com/article/chatbot-hallucinations-inevitable/\\">hallucination</a>: simply put, they make stuff up. &ldquo;Specifically, for scientific papers,&rdquo; Bik notes, an AI &ldquo;will generate citation references that don&rsquo;t exist.&rdquo; So if scientists place too much confidence in LLMs, study authors risk inserting AI-fabricated flaws into their work, mixing more potential for error into the already messy reality of scientific publishing."},{"tag":"p","type":"paragraph","attributes":{},"content":"Gray recently hunted for AI buzzwords in scientific papers using Dimensions, a data analytics platform that its developers say tracks <a href=\\"https://www.dimensions.ai/\\">more than 140 million</a> papers worldwide. He searched for words disproportionately used by chatbots, such as &ldquo;intricate,&rdquo; &ldquo;meticulous&rdquo; and &ldquo;commendable.&rdquo; These indicator words, he says, give a better sense of the problem&rsquo;s scale than any &ldquo;giveaway&rdquo; AI phrase a clumsy author might copy into a paper. At least 60,000 papers&mdash;slightly more than 1 percent of all scientific articles published globally last year&mdash;may have used an LLM, according to Gray&rsquo;s <a href=\\"https://arxiv.org/abs/2403.16887\\">analysis</a>, which was released on the preprint server arXiv.org and has yet to be peer-reviewed. Other studies that focused specifically on subsections of science suggest even more reliance on LLMs. <a href=\\"https://arxiv.org/abs/2404.01268\\">One such investigation found that </a>up to 17.5 percent of recent computer science papers exhibit signs of AI writing."},{"type":"embed:image","tag":null,"attributes":{},"content":"","data":{"id":265852,"default_asset_url":"https://static.scientificamerican.com/dam/m/5c79875b1cc75f72/original/AIsciencePub_graphic_m.png","desktop_asset_url":"https://static.scientificamerican.com/dam/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png","caption":"<p>Amanda Monta&ntilde;ez; Source: Andrew Gray</p>","credits":"","contentful_id":"3jDzomrDCDhnLy3WzhH8qj","is_published":true,"revision":2,"created_at":"2024-04-29T13:27:18.615000-04:00","updated_at":"2024-04-29T14:08:51.768000-04:00","title":"Line chart of AI-related adjectives in scientific publishing","asset":[{"id":"81D93B3C-669C-44EE-958A579855B8D3E7","alt":"Line charts show how scientific publishing volume and usage of various AI-associated and “control” words changed from 2015 to 2023, per the Dimensions database. Bar charts compare year-over-year percentage change in usage of these words from 2022 to 2023.","url":"https://sciam.bynder.com/m/5c79875b1cc75f72/original/AIsciencePub_graphic_m.png","data":{"id":"81D93B3C-669C-44EE-958A579855B8D3E7","url":"https://sciam.bynder.com/media/?mediaId=81D93B3C-669C-44EE-958A579855B8D3E7","name":"AIsciencePub_graphic_m","tags":[],"type":"image","files":{"mini":{"url":"https://sciam.bynder.com/m/5c79875b1cc75f72/mini-AIsciencePub_graphic_m.png","width":80,"height":80,"fileSize":null},"original":{"url":"https://sciam.bynder.com/m/5c79875b1cc75f72/original/AIsciencePub_graphic_m.png","width":1324,"height":11981,"fileSize":1011079},"webImage":{"url":"https://sciam.bynder.com/m/5c79875b1cc75f72/webimage-AIsciencePub_graphic_m.png","width":66,"height":600,"fileSize":null},"thumbnail":{"url":"https://sciam.bynder.com/m/5c79875b1cc75f72/thul-AIsciencePub_graphic_m.png","width":28,"height":250,"fileSize":null}},"width":1324,"height":11981,"idHash":"5c79875b1cc75f72","archive":0,"brandId":"8652EEC0-D205-4C9D-8764853ED3CF88E6","limited":0,"version":2,"fileSize":1011079,"isPublic":1,"original":"https://sciam.bynder.com/m/5c79875b1cc75f72/original/AIsciencePub_graphic_m.png","copyright":"","extension":["png"],"__typename":"Image","mediaItems":[{"id":"F05CA284-B53B-4AF7-A2E207C4CD5A4EDE","size":1011079,"type":"original","width":1324,"active":1,"height":11981,"version":1,"fileName":"AIsciencePub_graphic_m.png","focusPoint":{"x":722,"y":9625},"thumbnails":{"mini":"https://d3cy9zhslanhfa.cloudfront.net/media/CCB2273B-8BBF-40B1-8DF906B5CEFE082D/81D93B3C-669C-44EE-958A579855B8D3E7/mini-07AEA41E-B6B2-48A1-9BEA1AFFF3E62935.png","thul":"https://d3cy9zhslanhfa.cloudfront.net/media/CCB2273B-8BBF-40B1-8DF906B5CEFE082D/81D93B3C-669C-44EE-958A579855B8D3E7/thul-88CD42DE-5784-49BF-9D7F57A7DCBE9548.png","webimage":"https://d3cy9zhslanhfa.cloudfront.net/media/CCB2273B-8BBF-40B1-8DF906B5CEFE082D/81D93B3C-669C-44EE-958A579855B8D3E7/webimage-10349A02-30A0-4DD1-A0709F7E6CAD2DAF.png"},"dateCreated":"2024-04-18T19:18:41Z"}],"thumbnails":{"mini":"https://sciam.bynder.com/m/5c79875b1cc75f72/mini-AIsciencePub_graphic_m.png","thul":"https://sciam.bynder.com/m/5c79875b1cc75f72/thul-AIsciencePub_graphic_m.png","webimage":"https://sciam.bynder.com/m/5c79875b1cc75f72/webimage-AIsciencePub_graphic_m.png"},"dateCreated":"2024-04-18T19:18:41Z","derivatives":{"mini":"https://sciam.bynder.com/m/5c79875b1cc75f72/mini-AIsciencePub_graphic_m.png","custom":[],"webImage":"https://sciam.bynder.com/m/5c79875b1cc75f72/webimage-AIsciencePub_graphic_m.png","thumbnail":"https://sciam.bynder.com/m/5c79875b1cc75f72/thul-AIsciencePub_graphic_m.png"},"description":"Graphic for news story on use of AI in scientific publishing","orientation":"portrait","userCreated":"Amanda Montanez","watermarked":0,"dateModified":"2024-04-18T19:20:25Z","selectedFile":{"url":"https://sciam.bynder.com/m/5c79875b1cc75f72/original/AIsciencePub_graphic_m.png","width":1324,"height":11981,"fileSize":1011079},"datePublished":"2024-04-18T19:16:42Z","relatedAssets":[{"assets":["418E5AC3-6EFD-4648-B2F7E6E6123FCF02","C9C682BC-BAA3-4B0A-922C9A19643B1707","CA4157DE-04B9-497B-9278E3C30175FBC9","CDC750C2-517F-4F90-AF006C4CCC8B6FCC","418E5AC3-6EFD-4648-B2F7E6E6123FCF02","C9C682BC-BAA3-4B0A-922C9A19643B1707","CA4157DE-04B9-497B-9278E3C30175FBC9","CDC750C2-517F-4F90-AF006C4CCC8B6FCC"],"metaPropertyId":"545D90A0-0ED5-45E0-A1FFC89C34331B54","metaPropertyName":"relatedassets"}],"metaproperties":{"Asset_Type":["Graphic"],"Usage_Rights":["1-Copyright"],"Asset_Sub-Type":["Mobile"]},"ecsArchiveFiles":[],"propertyOptions":["98DBA6B0-062C-47A7-A47B415A4DA2D8AB","A884AE85-331A-4A5A-A0BB3D64DFD4DD96","FB39965F-4DED-493C-836EE352830835D0"],"transformBaseUrl":null,"videoPreviewURLs":[],"textMetaproperties":{"Alt_txt":"Line charts show how scientific publishing volume and usage of various AI-associated and “control” words changed from 2015 to 2023, per the Dimensions database. Bar charts compare year-over-year percentage change in usage of these words from 2022 to 2023.","Credits":"Amanda Montañez; Source: Andrew Gray"},"activeOriginalFocusPoint":{"x":722,"y":9625}},"name":"AIsciencePub_graphic_m","tags":[],"width":1324,"height":11981,"rights":{"usage":"Unlimited","bucket":"1-Copyright","public":"Public","copyright":""},"source":"bynder","credits":"Amanda Montañez; Source: Andrew Gray","version":2,"variants":{"thumbnail":{"url":"https://sciam.bynder.com/m/5c79875b1cc75f72/webimage-AIsciencePub_graphic_m.png"}},"mime_type":"image/png","asset_type":"image","focus_point":{"x":54,"y":80}}],"alt":"Line charts show how scientific publishing volume and usage of various AI-associated and “control” words changed from 2015 to 2023, per the Dimensions database. Bar charts compare year-over-year percentage change in usage of these words from 2022 to 2023.","asset_desktop":[{"id":"C9C682BC-BAA3-4B0A-922C9A19643B1707","alt":"Line charts show how scientific publishing volume and usage of various AI-associated and “control” words changed from 2015 to 2023, per the Dimensions database. Bar charts compare year-over-year percentage change in usage of these words from 2022 to 2023.","url":"https://sciam.bynder.com/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png","data":{"id":"C9C682BC-BAA3-4B0A-922C9A19643B1707","url":"https://sciam.bynder.com/media/?mediaId=C9C682BC-BAA3-4B0A-922C9A19643B1707","name":"AIsciencePub_graphic_d","tags":[],"type":"image","files":{"mini":{"url":"https://sciam.bynder.com/m/70b3cc20536569c3/mini-AIsciencePub_graphic_d.png","width":80,"height":80,"fileSize":null},"original":{"url":"https://sciam.bynder.com/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png","width":3750,"height":9271,"fileSize":1436901},"webImage":{"url":"https://sciam.bynder.com/m/70b3cc20536569c3/webimage-AIsciencePub_graphic_d.png","width":243,"height":600,"fileSize":null},"thumbnail":{"url":"https://sciam.bynder.com/m/70b3cc20536569c3/thul-AIsciencePub_graphic_d.png","width":101,"height":250,"fileSize":null}},"width":3750,"height":9271,"idHash":"70b3cc20536569c3","archive":0,"brandId":"8652EEC0-D205-4C9D-8764853ED3CF88E6","limited":0,"version":2,"fileSize":1436901,"isPublic":1,"original":"https://sciam.bynder.com/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png","copyright":"","extension":["png"],"__typename":"Image","mediaItems":[{"id":"1DDFDD43-6065-4853-BA77CCC76A2E870B","size":1436901,"type":"original","width":3750,"active":1,"height":9271,"version":1,"fileName":"AIsciencePub_graphic_d.png","focusPoint":{"x":1466,"y":2719},"thumbnails":{"mini":"https://d3cy9zhslanhfa.cloudfront.net/media/CCB2273B-8BBF-40B1-8DF906B5CEFE082D/C9C682BC-BAA3-4B0A-922C9A19643B1707/mini-DACC57C9-EA98-4A1A-BF7CE49FAD3015EC.png","thul":"https://d3cy9zhslanhfa.cloudfront.net/media/CCB2273B-8BBF-40B1-8DF906B5CEFE082D/C9C682BC-BAA3-4B0A-922C9A19643B1707/thul-4FDE8BDA-A472-4FA5-86C33603B56EEF76.png","webimage":"https://d3cy9zhslanhfa.cloudfront.net/media/CCB2273B-8BBF-40B1-8DF906B5CEFE082D/C9C682BC-BAA3-4B0A-922C9A19643B1707/webimage-5604B5EE-C834-48BD-A1A7C86745FD2C1E.png"},"dateCreated":"2024-04-18T19:18:41Z"}],"thumbnails":{"mini":"https://sciam.bynder.com/m/70b3cc20536569c3/mini-AIsciencePub_graphic_d.png","thul":"https://sciam.bynder.com/m/70b3cc20536569c3/thul-AIsciencePub_graphic_d.png","webimage":"https://sciam.bynder.com/m/70b3cc20536569c3/webimage-AIsciencePub_graphic_d.png"},"dateCreated":"2024-04-18T19:18:42Z","derivatives":{"mini":"https://sciam.bynder.com/m/70b3cc20536569c3/mini-AIsciencePub_graphic_d.png","custom":[],"webImage":"https://sciam.bynder.com/m/70b3cc20536569c3/webimage-AIsciencePub_graphic_d.png","thumbnail":"https://sciam.bynder.com/m/70b3cc20536569c3/thul-AIsciencePub_graphic_d.png"},"description":"Graphic for news story on use of AI in scientific publishing","orientation":"portrait","userCreated":"Amanda Montanez","watermarked":0,"dateModified":"2024-04-18T19:20:25Z","selectedFile":{"url":"https://sciam.bynder.com/m/70b3cc20536569c3/original/AIsciencePub_graphic_d.png","width":3750,"height":9271,"fileSize":1436901},"datePublished":"2024-04-18T19:16:42Z","relatedAssets":[{"assets":["418E5AC3-6EFD-4648-B2F7E6E6123FCF02","81D93B3C-669C-44EE-958A579855B8D3E7","CA4157DE-04B9-497B-9278E3C30175FBC9","CDC750C2-517F-4F90-AF006C4CCC8B6FCC","418E5AC3-6EFD-4648-B2F7E6E6123FCF02","81D93B3C-669C-44EE-958A579855B8D3E7","CA4157DE-04B9-497B-9278E3C30175FBC9","CDC750C2-517F-4F90-AF006C4CCC8B6FCC"],"metaPropertyId":"545D90A0-0ED5-45E0-A1FFC89C34331B54","metaPropertyName":"relatedassets"}],"metaproperties":{"Asset_Type":["Graphic"],"Usage_Rights":["1-Copyright"],"Asset_Sub-Type":["Desktop"]},"ecsArchiveFiles":[],"propertyOptions":["5AE0FC03-5EBF-4FD5-8D0E1C03CBE85731","98DBA6B0-062C-47A7-A47B415A4DA2D8AB","A884AE85-331A-4A5A-A0BB3D64DFD4DD96"],"transformBaseUrl":null,"videoPreviewURLs":[],"textMetaproperties":{"Alt_txt":"Line charts show how scientific publishing volume and usage of various AI-associated and “control” words changed from 2015 to 2023, per the Dimensions database. Bar charts compare year-over-year percentage change in usage of these words from 2022 to 2023.","Credits":"Amanda Montañez; Source: Andrew Gray"},"activeOriginalFocusPoint":{"x":1466,"y":2719}},"name":"AIsciencePub_graphic_d","tags":[],"width":3750,"height":9271,"rights":{"usage":"Unlimited","bucket":"1-Copyright","public":"Public","copyright":""},"source":"bynder","credits":"Amanda Montañez; Source: Andrew Gray","version":2,"variants":{"thumbnail":{"url":"https://sciam.bynder.com/m/70b3cc20536569c3/webimage-AIsciencePub_graphic_d.png"}},"mime_type":"image/png","asset_type":"image","focus_point":{"x":39,"y":29}}],"display_width":null,"display_height":null,"display_width_desktop":null,"display_height_desktop":null,"display_type":"default","source":null,"url":null,"display_url_desktop":null,"hyperlink_url":null}},{"tag":"p","type":"paragraph","attributes":{},"content":"Those findings are supported by <i>Scientific American</i>&rsquo;s own search using Dimensions and several other scientific publication databases, including Google Scholar, Scopus, PubMed, OpenAlex and Internet Archive Scholar. This search looked for signs that can suggest an LLM was involved in the production of text for academic papers&mdash;measured by the prevalence of phrases that ChatGPT and other AI models typically append, such as &ldquo;as of my last knowledge update.&rdquo; In 2020 that phrase appeared only once in results tracked by four of the major paper analytics platforms used in the investigation. But it appeared 136 times in 2022. There were some limitations to this approach, though: It could not filter out papers that might have represented studies of AI models themselves rather than AI-generated content. And these databases include material beyond peer-reviewed articles in scientific journals."},{"tag":"p","type":"paragraph","attributes":{},"content":"Like Gray&rsquo;s approach, this search also turned up subtler traces that may have pointed toward an LLM: it looked at the number of times stock phrases or words preferred by ChatGPT were found in the scientific literature and tracked whether their prevalence was notably different in the years just before the November 2022 release of OpenAI&rsquo;s chatbot (going back to 2020). The findings suggest something has changed in the lexicon of scientific writing&mdash;a development that might be caused by the writing tics of increasingly present chatbots. &ldquo;There&rsquo;s some evidence of some words changing steadily over time&rdquo; as language normally evolves, Gray says. &ldquo;But there&rsquo;s this question of how much of this is long-term natural change of language and how much is something different.&rdquo;"},{"tag":"h2","type":"heading","attributes":{},"content":"Symptoms of ChatGPT"},{"tag":"p","type":"paragraph","attributes":{},"content":"For signs that AI may be involved in paper production or editing, <i>Scientific American</i>&rsquo;s search delved into the word &ldquo;delve&rdquo;&mdash;which, as <a href=\\"https://pshapira.net/2024/03/31/delving-into-delve/\\">some informal monitors</a> of AI-made text have pointed out, has seen an unusual spike in use across academia. An analysis of its use across the 37 million or so citations and paper abstracts in life sciences and biomedicine contained within the PubMed catalog highlighted how much the word is in vogue. Up from 349 uses in 2020, &ldquo;delve&rdquo; appeared 2,847 times in 2023 and has already cropped up 2,630 times so far in 2024&mdash;a 654 percent increase. Similar but less pronounced increases were seen in the Scopus database, which covers a wider range of sciences, and in Dimensions data."},{"tag":"p","type":"paragraph","attributes":{},"content":"Other terms flagged by these monitors as AI-generated catchwords have seen similar rises, according to the <i>Scientific American</i> analysis: &ldquo;commendable&rdquo; appeared 240 times in papers tracked by Scopus and 10,977 times in papers tracked by Dimensions in 2020. Those numbers spiked to 829 (a 245 percent increase) and 20,536 (an 87 percent increase), respectively, in 2023. And in a perhaps ironic twist for would-be &ldquo;meticulous&rdquo; research, that word doubled on Scopus between 2020 and 2023."},{"tag":"h2","type":"heading","attributes":{},"content":"More Than Mere Words"},{"tag":"p","type":"paragraph","attributes":{},"content":"In a world where academics live by the mantra &ldquo;<a href=\\"https://www.businessinsider.com/fake-science-crisis-ai-generated-rat-giant-penis-image-2024-3\\">publish or perish</a>,&rdquo; it&rsquo;s unsurprising that some are using chatbots to save time or to bolster their command of English in a sector where it is often required for publication&mdash;and may be a writer&rsquo;s second or third language. But employing AI technology as a grammar or syntax helper could be a slippery slope to misapplying it in other parts of the scientific process. Writing a paper with an LLM co-author, the worry goes, may lead to key figures generated whole cloth by AI or to peer reviews that are outsourced to automated evaluators."},{"tag":"p","type":"paragraph","attributes":{},"content":"These are not purely hypothetical scenarios. AI certainly has been used to produce scientific diagrams and illustrations that have often been included in academic papers&mdash;including, notably, one <a href=\\"https://scienceintegritydigest.com/2024/02/15/the-rat-with-the-big-balls-and-enormous-penis-how-frontiers-published-a-paper-with-botched-ai-generated-images/\\">bizarrely endowed rodent</a>&mdash;and even to <a href=\\"https://www.scientificamerican.com/article/can-ai-replace-human-research-participants-these-scientists-see-risks/\\">replace human participants in experiments</a>. And the use of AI chatbots may have <a href=\\"https://arxiv.org/abs/2403.07183\\">permeated the peer-review process itself</a>, based on a preprint study of the language in feedback given to scientists who presented research at conferences on AI in 2023 and 2024. If AI-generated judgments creep into academic papers alongside AI text, that concerns experts, including Matt Hodgkinson, a council member of the Committee on Publication Ethics, a U.K.-based nonprofit organization that promotes ethical academic research practices. Chatbots are &ldquo;not good at doing analysis,&rdquo; he says, &ldquo;and that&rsquo;s where the real danger lies.&rdquo;"}],"authors":[{"mura_id":"0EDEF68B-280E-438F-A315657E6418A059","url":"/author/chris-stokel-walker/","contentful_id":"2k3FKpWfqZP6XCcfRUK89Y","name":"Chris Stokel-Walker","slug":"chris-stokel-walker","biography":"<p><b>Chris Stokel-Walker</b> is a freelance journalist in Newcastle, UK.</p>","picture_file":null,"contacts":[]}],"editors":[],"image_url":"https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png","image_width":3750,"image_height":2500,"image_alt_text":"Cropped image of a line chart shows various words, including “noteworthy” and “intricate,” increasing in usage over time.","image_caption":null,"image_credits":"<p>Amanda Monta&ntilde;ez; Source: Andrew Gray</p>","image_desktop_url":null,"image_desktop_width":0,"image_desktop_height":0,"release_date":"2024-05-01T10:45:00+00:00","primary_category":"Technology","primary_category_slug":"technology","subcategory":"Artificial Intelligence","subcategory_slug":"artificial-intelligence","subtype":"news","column":null,"partner_title":null,"partner_url":null,"partner_end_note":null,"article_doi":null,"categories":[],"contains_media":null,"is_partner":false,"is_resalable":true,"is_syndicated":false,"is_opinion":false,"journal_issue_name":null,"keywords":[],"media_url":null,"media_type":null,"podcast_series_name":null,"podcast_series_slug":null,"published_at_date":"2024-05-01","published_at_date_time":"2024-05-01T10:45:00+00:00","published_at_time":"10:45:00","tags":[],"type":"Article","updated_at_date_time":"2024-05-01T14:26:56.128000+00:00","paywall_exempt":false,"page_number":null,"print_title":null,"print_dek":"","canonical_url":null,"url":"/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/","footnote":"","content_modeling":["tone surprising"],"content_difficulty":null,"sentiment":"negative","durability":null,"layout":"default"},"issue":null,"persistentHeaderTitle":"Chatbots Have Thoroughly Infiltrated Scientific Publishing","dataLayerContent":{"content":{"articleDoi":"","authors":["Chris Stokel-Walker"],"brand":"","categories":"","collectionId":"","collectionName":"","column":"","containsMedia":"","contentfulId":"7bVpuVjnKZbJ8IQrkgMTlR","contentId":"","contentDifficulty":"","contentModeling":["tone surprising"],"durability":"","editors":[],"isOpinion":false,"isPartner":false,"isResalable":true,"isSyndicated":false,"journalIssueName":"","language":"en","partnerName":"","platform":"hopper","paywallExempt":null,"podcastSeries":"","primaryCategory":"Technology","printDek":"","printTitle":"","publishedAtDate":"2024-05-01","publishedAtDateTime":"2024-05-01T10:45:00+00:00","publishedAtTime":"10:45:00","sentiment":"negative","subCategory":"Artificial Intelligence","subtype":"","tags":[],"title":"Chatbots Have Thoroughly Infiltrated Scientific Publishing","type":"news","updatedAtDateTime":"2024-05-01T14:26:56.128000+00:00","wordCount":1134,"isSponsored":false,"campaign":"","advertiser":""}},"meta":{"title":"Chatbots Have Thoroughly Infiltrated Scientific Publishing","canonicalUrl":"https://www.scientificamerican.com/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/","image":"https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1200","imageWidth":3750,"tags":{"author":"Chris Stokel-Walker","description":"One percent of scientific articles published in 2023 showed signs of generative AI’s potential involvement, according to a recent analysis","og:title":"AI Chatbots Have Thoroughly Infiltrated Scientific Publishing","og:description":"One percent of scientific articles published in 2023 showed signs of generative AI’s potential involvement, according to a recent analysis","og:site_name":"Scientific American","og:image":"https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1200","og:image:alt":"Cropped image of a line chart shows various words, including “noteworthy” and “intricate,” increasing in usage over time.","og:type":"article","og:url":"https://www.scientificamerican.com/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/","twitter:title":"Chatbots Have Thoroughly Infiltrated Scientific Publishing","twitter:description":"One percent of scientific articles published in 2023 showed signs of generative AI’s potential involvement, according to a recent analysis","twitter:image":"https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1200","twitter:image:alt":"Cropped image of a line chart shows various words, including “noteworthy” and “intricate,” increasing in usage over time."},"jsonLD":{"@context":"https://schema.org","@type":"Article","headline":"Chatbots Have Thoroughly Infiltrated Scientific Publishing","image":["https://static.scientificamerican.com/dam/m/2161eea18fe7dd06/original/AIsciencePubs_graphic_leadImage.png?w=1200"],"datePublished":"2024-05-01T10:45:00+00:00","dateModified":"2024-05-01T14:26:56.128000+00:00","author":[{"@type":"Person","name":"Chris Stokel-Walker","url":"https://www.scientificamerican.com/author/chris-stokel-walker/"}]}},"adsConfig":{"unitpath":"/270604982/sciam/article","targeting":{"title":"Chatbots Have Thoroughly Infiltrated Scientific Publishing","cat":[],"subject":"Technology","authors":["Chris Stokel-Walker"],"podcast":null,"version":"hopper"}},"readTime":5,"newCMS":true,"isPreview":false},"bundle":"article"}`)</script>
    <script data-layer="footer">;OptanonWrapper=()=>{};consentQueue=[];tp=[];pdl={requireConsent:'v2'};window.dataLayer=[];;window.__ads=[];_sf_async_config={}</script>
  </body>
</html>
 contentType 9 text/html url 106 https://www.scientificamerican.com:443/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/ responseCode 3 200 